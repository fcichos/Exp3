[
  {
    "objectID": "electromagnetic-waves/Energy Transport.html",
    "href": "electromagnetic-waves/Energy Transport.html",
    "title": "Energy Transport and Momentum Transport of EM Waves",
    "section": "",
    "text": "A characteristic property of waves is that they transport energy rather than mass. It is this energy which we typically detect with the help of a photodetector and not the electric field. We therefore need a quantity that describes this energy transport. From electrostatics, we know that that the energy density of the electric field is given by \\(w_e=\\frac{1}{2}\\epsilon_0 \\vec{E}\\cdot\\vec{E}\\). This was the energy needed to assemble a collection of charges at a place. The energy density of the magnetic field is given by \\(w_m=\\frac{1}{\\mu_0}\\vec{B}\\cdot\\vec{B}\\).\nTo obtain such a quantity we recall the energy density of the electric and magnetic field which in sum give\n\\[\\begin{eqnarray}\nw=w_e+w_m=\\frac{1}{2}\\epsilon_0 \\vec{E}\\cdot\\vec{E}+\\frac{1}{\\mu_0}\\vec{B}\\cdot\\vec{B}\n\\end{eqnarray}\\]\nUsing the relation between the electric and the magnetic field amplitude we can further simplify the above expression for electromagnetic waves to \\(w=\\epsilon_0 E^2\\), but we will keep the full expression in the following.\nLet’s assume that we look at a volume \\(V\\) in which we have an electromagnetic wave, then the change in the energy inside that volume with time is given by\n\\[\n\\frac{dW}{dt}=\\int \\frac{dw}{dt}dV\n\\]\nthe integral over the time derivate of the energy density \\(w\\). Applying energy conservation, the loss of energy in our volume must be due to some energy flow out of the volume that is described by a quantity \\(\\vec{S}\\) that is describing that energy current density. If we consider a spherical surface without loss of generality, then the integrated energy flux through the surface should amount for the loss of energy in the volume, i.e.\n\\[\n\\int \\frac{dw}{dt}dV=-\\oint_A \\vec{S}\\cdot \\vec{n}da\n\\]\nwhere \\(\\vec{n}\\) is a unit vector normal to the outside of the surface. The integral on the right side is running over the whole surface of our volume. Note that the minus sign on the right side occurs due to the fact that the volume is loosing energy. We may now apply Gauss’ theorem and convert the surface integral on the right side by a volume integral over the divergence of the energy current density \\(\\vec{S}\\), i.e.\n\\[\n\\oint_A \\vec{S}\\cdot \\vec{n}da=\\int \\nabla \\cdot\\vec{S}dV=-\\int \\frac{dw}{dt}dV\n\\]\nWe thus obtain the continuity equation\n\\[\n\\frac{dw}{dt}=-\\nabla \\cdot\\vec{S}\n\\]\nunder vacuum conditions, meaning that we have no free charges and no charge current density.\nWe may use this equation to calculate the energy current density \\(\\vec{S}\\) by the time derivative of our energy density of the electromagnetic wave.\n\\[\n\\frac{\\partial w}{\\partial t}=\\epsilon_0 \\vec{E}\\frac{\\partial \\vec{E}}{\\partial t} + \\frac{1}{\\mu_0}\\vec{B}\\frac{\\partial \\vec{B}}{\\partial t}\n\\label{eq:ed}\\tag{ED}\n\\]\nWe may simplify that expression with the help of Maxwell’s euqations\n\\[\\begin{eqnarray}\n\\frac{\\partial \\vec{B}}{\\partial t}=-\\nabla \\times \\vec{E}\\\\\n\\frac{\\partial \\vec{E}}{\\partial t}=\\frac{1}{\\mu_0\\epsilon_0}\\nabla \\times \\vec{B}\n\\end{eqnarray}\\]\nand the \\(\\vec{H}=\\vec{B}/\\mu_0\\) relating the magnetic field \\(\\vec{H}\\) to the magnetic flux density \\(\\vec{B}\\). Inserting this in eq. \\(\\ref{eq:ed}\\), we find\n\\[\n\\frac{dw}{dt}=\\vec{E}(\\nabla\\times \\vec{H})-\\vec{H}(\\nabla \\times \\vec{E})\n\\]\nUsing the vector identity\n\\[\n\\nabla\\cdot (\\vec{H}\\times \\vec{E})=\\vec{E}(\\nabla\\times \\vec{H})-\\vec{H}(\\nabla \\times \\vec{E})\n\\]\nwe find\n\\[\n\\frac{dw}{dt}=\\nabla(\\vec{H}\\times \\vec{E}) =- \\nabla(\\vec{E}\\times \\vec{H})=-\\nabla \\cdot \\vec{S}\n\\]\nwhich is valid for vacuum and our energy current density can be identified as\n\\[\n\\vec{S}=\\vec{E}\\times \\vec{H}\n\\tag{Poynting Vector}\n\\]\nThe vector \\(\\vec{S}\\) is called the Poyning vector and describes the energy transport of an electromagnetic wave. The equation \\(\\frac{dw}{dt}+\\nabla \\cdot \\vec{S}=0\\) can be also generalized to a situation where charge current densities \\(\\vec{j}\\) are present. In this case we have to include in our consideration the work done by the electric field on the charge current density, which is \\(\\vec{E}\\cdot\\vec{j}\\)\n\\[\n\\frac{dw}{dt}+\\nabla \\cdot \\vec{S}=\\vec{E}\\cdot\\vec{j}\n\\tag{Poynting theorem}\n\\]\nThis equation is known as Poynting theorem and just a way of writing energy conservation.\nLet’s have a closer look at the Poynting vector, which we can write with the help of the magnetic flux density \\(\\vec{B}\\) as\n\\[\n\\vec{S}=\\epsilon_0c^2(\\vec{E}\\times \\vec{B})\n\\]\nThe magnitude of the Poynting vector is then given by\n\\[\\begin{eqnarray}\nS=|\\vec{S}|&=&\\epsilon_0c^2|\\vec{E}||\\vec{B}|\\\\\n&=&\\epsilon_0 c E^2=I\n\\end{eqnarray}\\]\nwhich is the same as the intensity. The magnitude of the Poynting vector describes the intensity of an electromagnetic wave or the energy flow through an area. It therefore has the unit of an intensity, which is \\(W/m^2\\).\nIf we now have a plane wave\n\\[\n\\vec{E}=\\vec{E}_0\\cos(\\omega t -\\vec{k}\\cdot\\vec{r})\n\\]\nin the real value description, then its intensity is\n\\[\nI=I_0\\cos^2(\\omega t)\n\\]\nat a position \\(\\vec{r}=0\\) with \\(I_0=c\\epsilon_0 E_0^2\\). As we commonly calculate the intensity as the time average over one cycle of oscillation, we find for this wave the intensity\n\\[\n\\langle I \\rangle =I_0\\langle\\cos^2(\\omega t) \\rangle =\\frac{1}{2}I_0\n\\]\nThis is the intensity we would record with the help of a detector and the flow of energy is set by the direction of the Poynting vector. This is not to be confused with the flow of the wavefronts, which go in the direction of the wavevector.\nAn example where this happens are birefringent materials, where the wavefronts and the Poynting vector are not parallel to each other. In this case the energy flow is not in the direction of the wavefronts. This is a very important concept in optics, as it is the energy flow that is important for the heating of materials and not the direction of the wavefronts.\n\n\n\nBirefringence teaser. The wavefronts of the two waves are not parallel to the Poynting vector, which is the direction of the energy flow.",
    "crumbs": [
      "Electromagnetic Optics",
      "Lecture 13",
      "Energy Transport"
    ]
  },
  {
    "objectID": "electromagnetic-waves/Energy Transport.html#energy-transport",
    "href": "electromagnetic-waves/Energy Transport.html#energy-transport",
    "title": "Energy Transport and Momentum Transport of EM Waves",
    "section": "",
    "text": "A characteristic property of waves is that they transport energy rather than mass. It is this energy which we typically detect with the help of a photodetector and not the electric field. We therefore need a quantity that describes this energy transport. From electrostatics, we know that that the energy density of the electric field is given by \\(w_e=\\frac{1}{2}\\epsilon_0 \\vec{E}\\cdot\\vec{E}\\). This was the energy needed to assemble a collection of charges at a place. The energy density of the magnetic field is given by \\(w_m=\\frac{1}{\\mu_0}\\vec{B}\\cdot\\vec{B}\\).\nTo obtain such a quantity we recall the energy density of the electric and magnetic field which in sum give\n\\[\\begin{eqnarray}\nw=w_e+w_m=\\frac{1}{2}\\epsilon_0 \\vec{E}\\cdot\\vec{E}+\\frac{1}{\\mu_0}\\vec{B}\\cdot\\vec{B}\n\\end{eqnarray}\\]\nUsing the relation between the electric and the magnetic field amplitude we can further simplify the above expression for electromagnetic waves to \\(w=\\epsilon_0 E^2\\), but we will keep the full expression in the following.\nLet’s assume that we look at a volume \\(V\\) in which we have an electromagnetic wave, then the change in the energy inside that volume with time is given by\n\\[\n\\frac{dW}{dt}=\\int \\frac{dw}{dt}dV\n\\]\nthe integral over the time derivate of the energy density \\(w\\). Applying energy conservation, the loss of energy in our volume must be due to some energy flow out of the volume that is described by a quantity \\(\\vec{S}\\) that is describing that energy current density. If we consider a spherical surface without loss of generality, then the integrated energy flux through the surface should amount for the loss of energy in the volume, i.e.\n\\[\n\\int \\frac{dw}{dt}dV=-\\oint_A \\vec{S}\\cdot \\vec{n}da\n\\]\nwhere \\(\\vec{n}\\) is a unit vector normal to the outside of the surface. The integral on the right side is running over the whole surface of our volume. Note that the minus sign on the right side occurs due to the fact that the volume is loosing energy. We may now apply Gauss’ theorem and convert the surface integral on the right side by a volume integral over the divergence of the energy current density \\(\\vec{S}\\), i.e.\n\\[\n\\oint_A \\vec{S}\\cdot \\vec{n}da=\\int \\nabla \\cdot\\vec{S}dV=-\\int \\frac{dw}{dt}dV\n\\]\nWe thus obtain the continuity equation\n\\[\n\\frac{dw}{dt}=-\\nabla \\cdot\\vec{S}\n\\]\nunder vacuum conditions, meaning that we have no free charges and no charge current density.\nWe may use this equation to calculate the energy current density \\(\\vec{S}\\) by the time derivative of our energy density of the electromagnetic wave.\n\\[\n\\frac{\\partial w}{\\partial t}=\\epsilon_0 \\vec{E}\\frac{\\partial \\vec{E}}{\\partial t} + \\frac{1}{\\mu_0}\\vec{B}\\frac{\\partial \\vec{B}}{\\partial t}\n\\label{eq:ed}\\tag{ED}\n\\]\nWe may simplify that expression with the help of Maxwell’s euqations\n\\[\\begin{eqnarray}\n\\frac{\\partial \\vec{B}}{\\partial t}=-\\nabla \\times \\vec{E}\\\\\n\\frac{\\partial \\vec{E}}{\\partial t}=\\frac{1}{\\mu_0\\epsilon_0}\\nabla \\times \\vec{B}\n\\end{eqnarray}\\]\nand the \\(\\vec{H}=\\vec{B}/\\mu_0\\) relating the magnetic field \\(\\vec{H}\\) to the magnetic flux density \\(\\vec{B}\\). Inserting this in eq. \\(\\ref{eq:ed}\\), we find\n\\[\n\\frac{dw}{dt}=\\vec{E}(\\nabla\\times \\vec{H})-\\vec{H}(\\nabla \\times \\vec{E})\n\\]\nUsing the vector identity\n\\[\n\\nabla\\cdot (\\vec{H}\\times \\vec{E})=\\vec{E}(\\nabla\\times \\vec{H})-\\vec{H}(\\nabla \\times \\vec{E})\n\\]\nwe find\n\\[\n\\frac{dw}{dt}=\\nabla(\\vec{H}\\times \\vec{E}) =- \\nabla(\\vec{E}\\times \\vec{H})=-\\nabla \\cdot \\vec{S}\n\\]\nwhich is valid for vacuum and our energy current density can be identified as\n\\[\n\\vec{S}=\\vec{E}\\times \\vec{H}\n\\tag{Poynting Vector}\n\\]\nThe vector \\(\\vec{S}\\) is called the Poyning vector and describes the energy transport of an electromagnetic wave. The equation \\(\\frac{dw}{dt}+\\nabla \\cdot \\vec{S}=0\\) can be also generalized to a situation where charge current densities \\(\\vec{j}\\) are present. In this case we have to include in our consideration the work done by the electric field on the charge current density, which is \\(\\vec{E}\\cdot\\vec{j}\\)\n\\[\n\\frac{dw}{dt}+\\nabla \\cdot \\vec{S}=\\vec{E}\\cdot\\vec{j}\n\\tag{Poynting theorem}\n\\]\nThis equation is known as Poynting theorem and just a way of writing energy conservation.\nLet’s have a closer look at the Poynting vector, which we can write with the help of the magnetic flux density \\(\\vec{B}\\) as\n\\[\n\\vec{S}=\\epsilon_0c^2(\\vec{E}\\times \\vec{B})\n\\]\nThe magnitude of the Poynting vector is then given by\n\\[\\begin{eqnarray}\nS=|\\vec{S}|&=&\\epsilon_0c^2|\\vec{E}||\\vec{B}|\\\\\n&=&\\epsilon_0 c E^2=I\n\\end{eqnarray}\\]\nwhich is the same as the intensity. The magnitude of the Poynting vector describes the intensity of an electromagnetic wave or the energy flow through an area. It therefore has the unit of an intensity, which is \\(W/m^2\\).\nIf we now have a plane wave\n\\[\n\\vec{E}=\\vec{E}_0\\cos(\\omega t -\\vec{k}\\cdot\\vec{r})\n\\]\nin the real value description, then its intensity is\n\\[\nI=I_0\\cos^2(\\omega t)\n\\]\nat a position \\(\\vec{r}=0\\) with \\(I_0=c\\epsilon_0 E_0^2\\). As we commonly calculate the intensity as the time average over one cycle of oscillation, we find for this wave the intensity\n\\[\n\\langle I \\rangle =I_0\\langle\\cos^2(\\omega t) \\rangle =\\frac{1}{2}I_0\n\\]\nThis is the intensity we would record with the help of a detector and the flow of energy is set by the direction of the Poynting vector. This is not to be confused with the flow of the wavefronts, which go in the direction of the wavevector.\nAn example where this happens are birefringent materials, where the wavefronts and the Poynting vector are not parallel to each other. In this case the energy flow is not in the direction of the wavefronts. This is a very important concept in optics, as it is the energy flow that is important for the heating of materials and not the direction of the wavefronts.\n\n\n\nBirefringence teaser. The wavefronts of the two waves are not parallel to the Poynting vector, which is the direction of the energy flow.",
    "crumbs": [
      "Electromagnetic Optics",
      "Lecture 13",
      "Energy Transport"
    ]
  },
  {
    "objectID": "electromagnetic-waves/Energy Transport.html#momentum-transport-and-radiation-pressure",
    "href": "electromagnetic-waves/Energy Transport.html#momentum-transport-and-radiation-pressure",
    "title": "Energy Transport and Momentum Transport of EM Waves",
    "section": "Momentum Transport and Radiation Pressure",
    "text": "Momentum Transport and Radiation Pressure\nLike the energy of a wave that can be transfered to objects like photodetectors, elecromagnetic waves also transport momentum, which can be turned into a motion of objects, when waves collide with massive objects. The momentum is a property of the electromagnetic wave. We would like to describe that so-called radiation pressure (the flow of momentum through an area) in a very simple way.\nFor this purpose we need he relativistic energy\n\\[\nW^2=p^2c^2+m^2c^4\n\\]\nwhich can be calculated from the momentum \\(p\\), the speed of light \\(c\\) and the mass \\(m\\). As lighwaves propagate with the speed of light, they cannot have a mass and the second term ist zero. The momentum of an electromagnetic wave is thus given by its energy devided by the speed of light\n\\[\np=\\frac{W}{c}\n\\]\nTherefore the momentum density in a volume must be also equal to the energy density devided by the speed of light.\n\\[\n\\frac{dp}{dV}=\\frac{1}{c}w=\\frac{\\epsilon_0 E^2}{c}=\\frac{S}{c^2}\n\\]\nTherefore the momentum density \\(dp/dV\\) is directly related to the magnitude of the Poyting vector and the intensity.\nThe momentum that is therfore transported through an area \\(A\\) in a time \\(dt\\) by electromagnetic radiation is given by\n\\[\n\\frac{dp}{A c dt}=\\frac{S}{c^2}\n\\]\nsince the volume from which the momentum comes is \\(dv=A c dt\\). Consequently, the momentum current density (momentum per time and area) is after a slight transformation given by\n\\[\n\\frac{1}{A}\\frac{dp}{dt}=\\frac{S}{c}\n\\]\nAs \\(dp/dt\\) can be identified as a force the left side corresponds to a force divided by an area and thus the radiation pressure we are looking for.\n\\[\np_{\\rm rad}=\\frac{S}{c}\n\\tag{radiation pressure}\n\\]\nSo far, this is a hypothetical radiaton pressure, which we relate to the flow of momentum. It becomes a real pressure, if the radiation interacts with some surface.\nIf we consider a perfectly absorbing surface of area \\(A\\), then the momentum of the electromagnetic wave is completely transfered to the surface and\n\\[\np_{\\rm rad}=\\frac{S}{c}\n\\tag{perfect absorption}\n\\]\nis the radiation pressure for perfect absorption.\nIf we have, however, a perfectly reflecing surface, we transfer due to the reflection, twice the momentum to the wall and therefore teh radiaton pressure for perfect reflection is\n\\[\np_{\\rm rad}=2\\frac{S}{c}\n\\tag{perfect reflection}\n\\]\nThus if you want to measure radiation pressure, its best to use reflecting surfaces. This has been done for the first time in an experiment by Nichols and Hull in the years from 1900-1903.\n\nRadiation Pressure measurements\n\n\n\n\n\n\n\n\nOriginal apparatus\n\n\n\n\n\n\n\nSchematic setup\n\n\n\n\n\n\nFigure 1— Experiment by Nichols and Hull at Dartmouth college to measure radiation pressure of light being reflected by two mirrors.\n\n\n\nNichols and Hull mounted therefore the two mirrors on a torsion spring in a geometry much like the Cavendish experiment. The light falling on both mirrors creates tiny forces which elongate the torsionspring which is mounted in a vessel where air is removed. From the elongation one may determine the forces and thus the pressure. From a separate measurement of the absorption and conversion of light into heat (with a Boulometer), one can deermine the intensity or energy contained in the radiation.\n\n\nComet Tails\n\n\n\n\n\n\nFigure 2— Ion and dust tail of the comet Neowise photographed in 07/2020 by B.Cichos.\n\n\n\nRadiation pressure is also of importance in astronomy and in particular visible in the tail of comets. Comets show tails composed of light gas ions and dust particles which seperate under the influence of radiation pressure. While orbiting around a star, the radiation pressure pushes the ligh gas ions radially away from the star, while the dust particles follow a curved shape ben towards the orbit due to their larger mass. This is also visible in the photograph we took in July 2020 for the comet Neowise which passed earth in a very spectacular way.\n\n\nOptical Tweezers and Magneto-optical Traps\nRadiation pressure has emerged as a crucial tool for manipulating both microscopic particles and atomic species. Figure 3 (left) illustrates optical tweezers, where a tightly focused laser beam traps colloidal particles. While radiation pressure tends to push particles along the beam direction, additional gradient forces arising from the intense light field’s spatial variation maintain the particle’s position in the focal region. This technique has become invaluable in biophysics for:\n\nMeasuring piconewton forces generated by molecular motors\nStudying protein folding mechanisms\nInvestigating enzymatic processes such as CRISPR/Cas gene editing\n\nbut also for fundamental physics\n\nlike the measurement of the Casimir force\nunderstanding the interaction of light with matter\nand the measurement of the radiation pressure itself\nor even measuring the Maxwell Boltzmann distribution of single particles\n\n\n\n\n\n\n\nFigure 3— Principle sketch for optical tweezers (left, taken from a publication by D. Grier) and a sketch of a magneto-optical trap (MOT, right) as used for cooling and trapping of atomic gases for atomic clocks or Bose Einstein condensation.\n\n\n\n\n\n\n\n\n\nFigure 4\n\n\n\nAt the atomic scale, radiation pressure combined with magnetic fields enables the trapping and cooling of atoms to temperatures of a few millikelvin in Magneto-Optical Traps (MOTs). Through additional cooling mechanisms, these atomic gases can reach even lower temperatures where they transition into a quantum state known as a Bose-Einstein condensate. This process relies on precise control of atomic hyperfine transitions.\nThese atomic trapping techniques form the foundation of modern atomic clocks, essential for GPS navigation and gravitational wave detection. Figure 5 shows a fountain atomic clock design, where laser-cooled atoms are propelled upward through a microwave cavity by radiation pressure. Here, the atoms’ hyperfine energy levels interact with the microwave field.\n\n\n\n\n\n\nFigure 5— Schematic diagram of an atomic fountain clock, showing the path of laser-cooled atoms through a microwave cavity for precise frequency measurements.\n\n\n\nIn their fountain-like trajectory, atoms pass through the microwave cavity twice, enabling precise measurements of atomic transition frequencies. These measurements establish a fundamental time reference with unprecedented accuracy, used to synchronize timekeeping systems worldwide.",
    "crumbs": [
      "Electromagnetic Optics",
      "Lecture 13",
      "Energy Transport"
    ]
  },
  {
    "objectID": "electromagnetic-waves/Anisotropic Materials.html",
    "href": "electromagnetic-waves/Anisotropic Materials.html",
    "title": "Anisotropic Materials",
    "section": "",
    "text": "So war we have only discussed isotropic materials, meaning that the speed of light was independent by the direction of light propagation in the material. Often, the light propagation is, however, not isotropic as the underlying materials have an anisotropic structure.\n\n\n\n\n\n\nFigure 1— Ethene molecules as an example for an anisotropically polarizable object. The red arrows denote the electric field directions.\n\n\n\nJust consider the above molecule \\(C_2H_4\\) (Ethen), where the two carbon atoms are bound by a double bond. In an external electric field aligned along that bond, we certainly expect the electrons to be more easily displaced over a larger distance, when the field is aligned parallel to the double bond. The dipole induced will therefore depend on the orientation of molecule and electric field. We therefore need to express the electronic polarizability \\(\\alpha\\) for the calculation of the dipole moment \\(\\vec{p}=\\alpha \\vec{E}\\) as a tensor \\(\\overleftrightarrow{a}\\).\n\\[\n\\overleftrightarrow{a}=\n\\begin{pmatrix}\n\\alpha_{11} & \\alpha_{12} & \\alpha_{13} \\\\\n\\alpha_{21} & \\alpha_{22} & \\alpha_{23} \\\\\n\\alpha_{31} & \\alpha_{32} & \\alpha_{33}\n\\end{pmatrix}\n\\]\nConsequently also the susceptibility \\(\\chi\\), the dielectric function \\(\\epsilon_r\\) and refractive index \\(n\\) will be tensors in anisotropic materials. The entries of these tensors now depend on the choice of the coordinate system, since the polarisabilities are connected to the structures. Accordingly, there is also coordinate system in which the tensor becomes completely diagonal.\n\\[\n\\overleftrightarrow{\\epsilon_r}=\n\\begin{pmatrix}\n\\epsilon_{11} & 0 & 0 \\\\\n0 & \\epsilon_{22} & 0 \\\\\n0 & 0 & \\epsilon_{33}\n\\end{pmatrix}\\tag{dielectric tensor}\n\\]\nThis coordinate systems is the principle coordinate system of the tensor. The electric displacement field \\(\\vec{D}\\) is related to the electric field \\(\\vec{E}\\) by\n\\[\n\\vec{D}=\\epsilon_0 \\overleftrightarrow{\\epsilon_r} \\vec{E}\n\\]\nand in the principle coordinate system of the tensor we obtain\n\\[\n\\begin{pmatrix}\nD_1 \\\\\nD_2 \\\\\nD_3 \\\\\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n\\epsilon_0\\epsilon_{11} E_1\\\\\n\\epsilon_0\\epsilon_{22} E_2\\\\\n\\epsilon_0\\epsilon_{33} E_3\\\\\n\\end{pmatrix}\n\\]\nFrom this it becomes evident, that the displacement field \\(\\vec{D}\\) is not anymore parallel to the electric field \\(\\vec{E}\\). The dielectric tensor and refractive index tensor are directly related through \\(n_{ij} = \\sqrt{\\epsilon_{ij}}\\). In the principal coordinate system, where both tensors are diagonal, the principal refractive indices are simply the square roots of the principal dielectric constants. This relationship allows us to visualize the optical properties through the index ellipsoid. This also means now, that the wavevector \\(\\vec{k}\\) is now perpendicular to the displacement field and not to the electric field. The magnetic field is still directed along the same direction and thus the Poynting vector is not parallel to the wavevector. Energy and phasefronts flow in different directions.The sketch below indicates the relations of the vectors.\n\n\n\n\n\n\nEnergy Flow in Anisotropic Materials\n\n\n\nIn anisotropic materials, the direction of energy flow (given by the Poynting vector \\(\\vec{S}=\\vec{E}\\times\\vec{H}\\)) generally differs from the direction of phase propagation (given by the wavevector \\(\\vec{k}\\)). This is because \\(\\vec{E}\\) and \\(\\vec{D}\\) are not parallel in anisotropic media. While the wavevector \\(\\vec{k}\\) determines the direction of phase velocity and is perpendicular to the wavefronts, the energy actually flows in the direction of the Poynting vector \\(\\vec{S}\\). This direction is always perpendicular to the k-surface at the point where \\(\\vec{k}\\) intersects it. This explains why a single incident beam can split into two beams (ordinary and extraordinary) traveling in different directions through the material, even though their wavefronts remain parallel.\n\n\n\n\n\n\n\n\nFigure 2— Sketch of the relations between the electric field \\(\\vec{E}\\), the displacement field \\(\\vec{D}\\), the wavevector \\(\\vec{k}\\) and the magnetic field \\(\\vec{H}\\).\n\n\n\nThe tensorial nature of the dielectric function has now consequences for the propagation of light. In general different symmetries are considered. If we have for example two of the diagonal elements be equal to each other\n\\[\n\\epsilon_{11}=\\epsilon_{22}\\neq\\epsilon_{33}\n\\]\nthen we call the material uniaxial. The system has one optical axis. In case\n\\[\n\\epsilon_{11}\\neq\\epsilon_{22}\\neq\\epsilon_{33}\\neq\\epsilon_{11}\n\\]\nwe call the material biaxial and the material has two optical axes. We will have a look at the meaning of an optical axis a bit later.\nA tensor as the dielectric tensor (similar to the tensor of inertia) can be geometrically represented by an ellipsoid with three different half axes as depicted below. This can be done for the refractive index or the dielectric tensor. When doing so with the refractive index, we obtain an index ellipsoid, where the half-axes correspond to the three refractive indices \\(n_1=\\sqrt{\\epsilon_{11}}\\), \\(n_2=\\sqrt{\\epsilon_{22}}\\) and \\(n_3=\\sqrt{\\epsilon_{33}}\\).\n\n\n\n\n\n\nFigure 3— Index ellipsoid for a uniaxial material and a construction of the refractive indices. The k-vector cuts the ellipsoid in one point. The plane perpendicular to the k-vector intersects the ellipsoid in an ellipse. The long and short axis of the ellipse correspond to the normal modes of the material.\n\n\n\nTo find out the relevant refractive indices for a certain propagation direction on now undertakes the following steps:\n\nchose a direction of light propagation with the direction of the wavevector \\(\\vec{k}\\)\nconstruct a plane perpendicular to the wavevector\ntake the intersection of this plane with the ellisoid, which is in general an ellipse\nthe ellipse has a long and a short axis, which correspond to the direction of the so-called normal modes\na \\(\\vec{D}\\) field along those half-axes propages with the corresponding refractive index \\(n_o\\) (ordinary), \\(n_e\\) (extra_ordinary)\n\n\n\n\n\n\n\nNormal Modes in Anisotropic Materials\n\n\n\nNormal modes are specific directions of the displacement field \\(\\vec{D}\\) for which the light wave can propagate through the anisotropic medium without changing its polarization state. These modes correspond to the major and minor axes of the ellipse formed by intersecting the index ellipsoid with a plane perpendicular to the propagation direction. For a given propagation direction, there are always two orthogonal normal modes, each associated with a specific refractive index (ordinary or extraordinary). Any other polarization state can be expressed as a superposition of these two normal modes, but will generally change as the wave propagates through the medium due to the different phase velocities of the two modes.\n\n\nAn optical axis is now a propagation direction, for which the refractive index does not depend on the direction of the electric field. For a biaxial material, there are two distinct directions for a propagation, while there is only one for uniaxial.\nConsidering now in more detail the propagation of light as a function of the direction of light propagation one obtains a dispersion relation (how the wavenumber depends on teh direction for a given frequency of light). This surface is the so-called k-surface, which in general consists of 2 sheets. This k-surface is obtained from Maxwells equations\n\\[\n\\begin{aligned}\n\\vec{k}\\times \\vec{H} & = -\\omega \\vec{D}\\\\\n\\vec{k}\\times\\vec{E} &=\\omega \\mu_0 \\vec{H}\n\\end{aligned}\n\\]\nwhich leads to\n\\[\n\\vec{k}\\times(\\vec{k}\\times\\vec{E})+\\omega^2\\mu_0 \\epsilon_0 \\overleftrightarrow{\\epsilon_r} \\vec{E}=0\n\\]\nThis equation leads to a system of equations for the components of the wavevector (\\(\\vec{k}=\\{k_1,k_2,k_3\\}\\)) that define the k-surface for a given frequency.\nThe k-surface represents all possible wavevectors at a given frequency in the material. For a uniaxial crystal, this surface consists of two sheets: a sphere representing the ordinary waves and an ellipsoid representing the extraordinary waves. Where these surfaces intersect defines the optical axis, along which the ordinary and extraordinary waves travel with the same phase velocity. This geometric representation helps visualize how light propagates in different directions through the crystal.\n\n\n\n\n\n\nFigure 4— K-surface for a uniaxial material. The circular surface corresponds to the ordinary refractive index and the elliptical surface to the extra-ordinary refractive index. The polarization of the electric field is indicated.\n\n\n\nIf we select now a specific direction of propagation for the light with the direction of \\(\\vec{k}\\), the intersections of the k-surface with the k-vector deliver the solutions for the refractive indices. From the figure above, it becomes obvious, that the electric field vector must be perpendicular to the plane in the case of the ordinary refractive index. Only in this case, the wavevector can be rotated in the above sketch such that the direction of the electric field does not change. If the electric field is within the plane of the above sketch, the field direction with respect to the crystal structure changes and therefore the refractive index changes.\nThe ordinary ray corresponds to light where the electric field is perpendicular to the plane containing the optical axis and the direction of propagation, while the extraordinary ray corresponds to light where the electric field has a component parallel to this plane. The association with s- or p-polarization depends on the orientation of the crystal’s optical axis relative to the plane of incidence.\n\n\n\n\n\n\n\n\nBirefringence.\n\n\n\n\n\n\n\nBirefringence experiment.\n\n\n\n\n\n\nFigure 5— Birefringence. The left side shows the general case of birefringence. The right side shows the birefringence in a calcit crystal.\n\n\n\nLet’s discuss the sketches above, which show the general case of birefringence. The image on the left side shows an interface between air on the bottom and the anisotropic material on the top. The wavevector is incident from below and is normal zo the surface. Its direction will intersect both k-surfaces and thereby select the ordinary refractive index and the extra-ordinary refractive index for the two different polarization directions. Both waves propgate in the same direction, so their wavefronts are perpendicular to the k-vectors as shown in the middle sketch. Yet, the Poynting vectors go in different direction. The Poynting vector, which points in the direction of energy propagation, is always perpendicular to the k-surface, since the k-surface is an isoenergy surface (think about that for a moment). This means that the beam is split into two beams with parallel wavefronts as indicated. This phenomenon is called birefringence and separates two orthogonal polarizations into two beams as indicated.\nThis effect is probably best visible, when you put a birefringent material like the common calcit crystal on a newpaper or book. You will immediately see the birefringence in the double images as in the figure above to the right.\nThe different refractive index for both polarizations make those materials very suitable for the creating polarizing optical elements like beam splitters. A selection of different polarizing beam splitters is shown in the image below.\n\n\n\n\n\n\nFigure 6— Polarizing beam splitters. Glan-Foucault prism, Wollaston prism, Rochon prism and de Senarmont prism. All of them are based on birefringence and consist of two prisms with different refractive indices for the two polarizations.\n\n\n\nBirefringence is often observed in mechanically stressed materials like quickly cooled glasses or stretched polymer foils. The latter is demonstrated in the images below, where we used\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 7— Scotch tape art. Scotch tape christmas tree and tulip between crossed polarizers showing their birefringent behavior.",
    "crumbs": [
      "Electromagnetic Optics",
      "Lecture 17",
      "Anisotropic Materials"
    ]
  },
  {
    "objectID": "electromagnetic-waves/Anisotropic Materials.html#light-propagation",
    "href": "electromagnetic-waves/Anisotropic Materials.html#light-propagation",
    "title": "Anisotropic Materials",
    "section": "",
    "text": "So war we have only discussed isotropic materials, meaning that the speed of light was independent by the direction of light propagation in the material. Often, the light propagation is, however, not isotropic as the underlying materials have an anisotropic structure.\n\n\n\n\n\n\nFigure 1— Ethene molecules as an example for an anisotropically polarizable object. The red arrows denote the electric field directions.\n\n\n\nJust consider the above molecule \\(C_2H_4\\) (Ethen), where the two carbon atoms are bound by a double bond. In an external electric field aligned along that bond, we certainly expect the electrons to be more easily displaced over a larger distance, when the field is aligned parallel to the double bond. The dipole induced will therefore depend on the orientation of molecule and electric field. We therefore need to express the electronic polarizability \\(\\alpha\\) for the calculation of the dipole moment \\(\\vec{p}=\\alpha \\vec{E}\\) as a tensor \\(\\overleftrightarrow{a}\\).\n\\[\n\\overleftrightarrow{a}=\n\\begin{pmatrix}\n\\alpha_{11} & \\alpha_{12} & \\alpha_{13} \\\\\n\\alpha_{21} & \\alpha_{22} & \\alpha_{23} \\\\\n\\alpha_{31} & \\alpha_{32} & \\alpha_{33}\n\\end{pmatrix}\n\\]\nConsequently also the susceptibility \\(\\chi\\), the dielectric function \\(\\epsilon_r\\) and refractive index \\(n\\) will be tensors in anisotropic materials. The entries of these tensors now depend on the choice of the coordinate system, since the polarisabilities are connected to the structures. Accordingly, there is also coordinate system in which the tensor becomes completely diagonal.\n\\[\n\\overleftrightarrow{\\epsilon_r}=\n\\begin{pmatrix}\n\\epsilon_{11} & 0 & 0 \\\\\n0 & \\epsilon_{22} & 0 \\\\\n0 & 0 & \\epsilon_{33}\n\\end{pmatrix}\\tag{dielectric tensor}\n\\]\nThis coordinate systems is the principle coordinate system of the tensor. The electric displacement field \\(\\vec{D}\\) is related to the electric field \\(\\vec{E}\\) by\n\\[\n\\vec{D}=\\epsilon_0 \\overleftrightarrow{\\epsilon_r} \\vec{E}\n\\]\nand in the principle coordinate system of the tensor we obtain\n\\[\n\\begin{pmatrix}\nD_1 \\\\\nD_2 \\\\\nD_3 \\\\\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n\\epsilon_0\\epsilon_{11} E_1\\\\\n\\epsilon_0\\epsilon_{22} E_2\\\\\n\\epsilon_0\\epsilon_{33} E_3\\\\\n\\end{pmatrix}\n\\]\nFrom this it becomes evident, that the displacement field \\(\\vec{D}\\) is not anymore parallel to the electric field \\(\\vec{E}\\). The dielectric tensor and refractive index tensor are directly related through \\(n_{ij} = \\sqrt{\\epsilon_{ij}}\\). In the principal coordinate system, where both tensors are diagonal, the principal refractive indices are simply the square roots of the principal dielectric constants. This relationship allows us to visualize the optical properties through the index ellipsoid. This also means now, that the wavevector \\(\\vec{k}\\) is now perpendicular to the displacement field and not to the electric field. The magnetic field is still directed along the same direction and thus the Poynting vector is not parallel to the wavevector. Energy and phasefronts flow in different directions.The sketch below indicates the relations of the vectors.\n\n\n\n\n\n\nEnergy Flow in Anisotropic Materials\n\n\n\nIn anisotropic materials, the direction of energy flow (given by the Poynting vector \\(\\vec{S}=\\vec{E}\\times\\vec{H}\\)) generally differs from the direction of phase propagation (given by the wavevector \\(\\vec{k}\\)). This is because \\(\\vec{E}\\) and \\(\\vec{D}\\) are not parallel in anisotropic media. While the wavevector \\(\\vec{k}\\) determines the direction of phase velocity and is perpendicular to the wavefronts, the energy actually flows in the direction of the Poynting vector \\(\\vec{S}\\). This direction is always perpendicular to the k-surface at the point where \\(\\vec{k}\\) intersects it. This explains why a single incident beam can split into two beams (ordinary and extraordinary) traveling in different directions through the material, even though their wavefronts remain parallel.\n\n\n\n\n\n\n\n\nFigure 2— Sketch of the relations between the electric field \\(\\vec{E}\\), the displacement field \\(\\vec{D}\\), the wavevector \\(\\vec{k}\\) and the magnetic field \\(\\vec{H}\\).\n\n\n\nThe tensorial nature of the dielectric function has now consequences for the propagation of light. In general different symmetries are considered. If we have for example two of the diagonal elements be equal to each other\n\\[\n\\epsilon_{11}=\\epsilon_{22}\\neq\\epsilon_{33}\n\\]\nthen we call the material uniaxial. The system has one optical axis. In case\n\\[\n\\epsilon_{11}\\neq\\epsilon_{22}\\neq\\epsilon_{33}\\neq\\epsilon_{11}\n\\]\nwe call the material biaxial and the material has two optical axes. We will have a look at the meaning of an optical axis a bit later.\nA tensor as the dielectric tensor (similar to the tensor of inertia) can be geometrically represented by an ellipsoid with three different half axes as depicted below. This can be done for the refractive index or the dielectric tensor. When doing so with the refractive index, we obtain an index ellipsoid, where the half-axes correspond to the three refractive indices \\(n_1=\\sqrt{\\epsilon_{11}}\\), \\(n_2=\\sqrt{\\epsilon_{22}}\\) and \\(n_3=\\sqrt{\\epsilon_{33}}\\).\n\n\n\n\n\n\nFigure 3— Index ellipsoid for a uniaxial material and a construction of the refractive indices. The k-vector cuts the ellipsoid in one point. The plane perpendicular to the k-vector intersects the ellipsoid in an ellipse. The long and short axis of the ellipse correspond to the normal modes of the material.\n\n\n\nTo find out the relevant refractive indices for a certain propagation direction on now undertakes the following steps:\n\nchose a direction of light propagation with the direction of the wavevector \\(\\vec{k}\\)\nconstruct a plane perpendicular to the wavevector\ntake the intersection of this plane with the ellisoid, which is in general an ellipse\nthe ellipse has a long and a short axis, which correspond to the direction of the so-called normal modes\na \\(\\vec{D}\\) field along those half-axes propages with the corresponding refractive index \\(n_o\\) (ordinary), \\(n_e\\) (extra_ordinary)\n\n\n\n\n\n\n\nNormal Modes in Anisotropic Materials\n\n\n\nNormal modes are specific directions of the displacement field \\(\\vec{D}\\) for which the light wave can propagate through the anisotropic medium without changing its polarization state. These modes correspond to the major and minor axes of the ellipse formed by intersecting the index ellipsoid with a plane perpendicular to the propagation direction. For a given propagation direction, there are always two orthogonal normal modes, each associated with a specific refractive index (ordinary or extraordinary). Any other polarization state can be expressed as a superposition of these two normal modes, but will generally change as the wave propagates through the medium due to the different phase velocities of the two modes.\n\n\nAn optical axis is now a propagation direction, for which the refractive index does not depend on the direction of the electric field. For a biaxial material, there are two distinct directions for a propagation, while there is only one for uniaxial.\nConsidering now in more detail the propagation of light as a function of the direction of light propagation one obtains a dispersion relation (how the wavenumber depends on teh direction for a given frequency of light). This surface is the so-called k-surface, which in general consists of 2 sheets. This k-surface is obtained from Maxwells equations\n\\[\n\\begin{aligned}\n\\vec{k}\\times \\vec{H} & = -\\omega \\vec{D}\\\\\n\\vec{k}\\times\\vec{E} &=\\omega \\mu_0 \\vec{H}\n\\end{aligned}\n\\]\nwhich leads to\n\\[\n\\vec{k}\\times(\\vec{k}\\times\\vec{E})+\\omega^2\\mu_0 \\epsilon_0 \\overleftrightarrow{\\epsilon_r} \\vec{E}=0\n\\]\nThis equation leads to a system of equations for the components of the wavevector (\\(\\vec{k}=\\{k_1,k_2,k_3\\}\\)) that define the k-surface for a given frequency.\nThe k-surface represents all possible wavevectors at a given frequency in the material. For a uniaxial crystal, this surface consists of two sheets: a sphere representing the ordinary waves and an ellipsoid representing the extraordinary waves. Where these surfaces intersect defines the optical axis, along which the ordinary and extraordinary waves travel with the same phase velocity. This geometric representation helps visualize how light propagates in different directions through the crystal.\n\n\n\n\n\n\nFigure 4— K-surface for a uniaxial material. The circular surface corresponds to the ordinary refractive index and the elliptical surface to the extra-ordinary refractive index. The polarization of the electric field is indicated.\n\n\n\nIf we select now a specific direction of propagation for the light with the direction of \\(\\vec{k}\\), the intersections of the k-surface with the k-vector deliver the solutions for the refractive indices. From the figure above, it becomes obvious, that the electric field vector must be perpendicular to the plane in the case of the ordinary refractive index. Only in this case, the wavevector can be rotated in the above sketch such that the direction of the electric field does not change. If the electric field is within the plane of the above sketch, the field direction with respect to the crystal structure changes and therefore the refractive index changes.\nThe ordinary ray corresponds to light where the electric field is perpendicular to the plane containing the optical axis and the direction of propagation, while the extraordinary ray corresponds to light where the electric field has a component parallel to this plane. The association with s- or p-polarization depends on the orientation of the crystal’s optical axis relative to the plane of incidence.\n\n\n\n\n\n\n\n\nBirefringence.\n\n\n\n\n\n\n\nBirefringence experiment.\n\n\n\n\n\n\nFigure 5— Birefringence. The left side shows the general case of birefringence. The right side shows the birefringence in a calcit crystal.\n\n\n\nLet’s discuss the sketches above, which show the general case of birefringence. The image on the left side shows an interface between air on the bottom and the anisotropic material on the top. The wavevector is incident from below and is normal zo the surface. Its direction will intersect both k-surfaces and thereby select the ordinary refractive index and the extra-ordinary refractive index for the two different polarization directions. Both waves propgate in the same direction, so their wavefronts are perpendicular to the k-vectors as shown in the middle sketch. Yet, the Poynting vectors go in different direction. The Poynting vector, which points in the direction of energy propagation, is always perpendicular to the k-surface, since the k-surface is an isoenergy surface (think about that for a moment). This means that the beam is split into two beams with parallel wavefronts as indicated. This phenomenon is called birefringence and separates two orthogonal polarizations into two beams as indicated.\nThis effect is probably best visible, when you put a birefringent material like the common calcit crystal on a newpaper or book. You will immediately see the birefringence in the double images as in the figure above to the right.\nThe different refractive index for both polarizations make those materials very suitable for the creating polarizing optical elements like beam splitters. A selection of different polarizing beam splitters is shown in the image below.\n\n\n\n\n\n\nFigure 6— Polarizing beam splitters. Glan-Foucault prism, Wollaston prism, Rochon prism and de Senarmont prism. All of them are based on birefringence and consist of two prisms with different refractive indices for the two polarizations.\n\n\n\nBirefringence is often observed in mechanically stressed materials like quickly cooled glasses or stretched polymer foils. The latter is demonstrated in the images below, where we used\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 7— Scotch tape art. Scotch tape christmas tree and tulip between crossed polarizers showing their birefringent behavior.",
    "crumbs": [
      "Electromagnetic Optics",
      "Lecture 17",
      "Anisotropic Materials"
    ]
  },
  {
    "objectID": "electromagnetic-waves/Anisotropic Materials.html#wave-retarders",
    "href": "electromagnetic-waves/Anisotropic Materials.html#wave-retarders",
    "title": "Anisotropic Materials",
    "section": "Wave retarders",
    "text": "Wave retarders\nWave retarders are essential optical components that manipulate the polarization state of light by exploiting the different phase velocities of ordinary and extraordinary waves in anisotropic materials. These components are fundamental in many optical systems, from liquid crystal displays to laser systems and optical communications. Anisotropic materials can now but cut in specific way, for example such that the optical axis is parallel to the interface as in the picture below. Under these circumstances at normal incidence both wavevectors and both Poynting vectors of the polarizations propagate along the same direction. Yet, the p-polarization has a lower phase velocity (long k-vector) than the s-polarization. If now the incident light has now elecric field components parallel and perpedicular to the optical axis which are of same amplitude, then one component of the incident polarization is delayed in its phase with respect to the other comonent.\nLet\n\\[\n\\vec{E}=(E_{0x}\\hat{e}_x +E_{0y}\\hat{e}_y)e^{i(\\omega t -k z)}\n\\]\nbe the incident electric field of the plane wave travelling along the z-direction with \\(E_{0x}=E_{0y}\\) and the optical axis aligned along the y-axis. Then each vector component of the wave travels with a different wavevector\n\\[\n\\begin{aligned}\nE_x & =  E_{0x}e^{i(\\omega t -n_e k_0 z)}\\\\\nE_y & =  E_{0y}e^{i(\\omega t -n_o k_0 z)}\n\\end{aligned}\n\\]\nAfter a material of thickness \\(d\\) both components have accumulated a phase shift of\n\\[\n\\Delta \\phi=(n_e-n_o)k_0 d\n\\]\n\nQuarter Wave Plate\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 8— Sketch of the conditions for a wave retarder. Both ordinary and extra-ordinary wave propagate in the same direction, but with different phase velocities. The phase difference between the two components is \\(\\Delta \\phi\\). The right side shows the resulting circular polarization.\n\n\n\nIf we design now a material of a certain thickness such that the phase shift is \\(\\Delta \\phi=\\pi/2\\), then the light exiting the material will be circularly polarized as in the sketch on the right side. The minimum thickness of the crystal is then\n\\[\nd=\\frac{\\pi}{2}\\frac{1}{k_0(n_e-n_o)}=\\frac{\\lambda}{4(n_e-n_o)}\n\\]\nThe crystal thickness is, however, not restricted to this minimal thickness, but to any thickness which creates a phase difference of \\(\\pi/2\\). Such an optical element which is generating a phase difference of \\(\\pi/2\\) between the different electric field components with respect to the optical axis is called a Quarter Wave Plate, since the phase difference corresponds to a quarter wavelength.\nIf the two elecric field components are not of equal amplitude, then a quarter wave plate will generate elliptically polarized light. Note that if you send circular polarization to a QWP, linearly polarized light will be created.\n\n\nHalf Wave Plate\nA half wave plate creates a phase difference of \\(\\pi\\) (half a wavelength) between the two electric field components. When linearly polarized light passes through a half wave plate, its polarization direction is rotated. The component of the electric field parallel to the optical axis experiences the extraordinary refractive index \\(n_e\\), while the perpendicular component experiences the ordinary refractive index \\(n_o\\). The \\(\\pi\\) phase shift effectively flips the sign of the component perpendicular to the optical axis.\nWhen linearly polarized light is incident at an angle \\(\\theta\\) with respect to the optical axis, the output polarization will be rotated to an angle \\(2\\theta\\) with respect to the optical axis but on the opposite side. This means the total rotation of the polarization direction is \\(2\\theta\\). For example, if the incident polarization makes a \\(30°\\) angle with the optical axis, the output polarization will be rotated by \\(60°\\) with respect to the original direction. The special case of \\(45°\\) input leads to a \\(90°\\) rotation of the polarization.\nThe minimum thickness of a half wave plate is given by:\n\\[\nd=\\frac{\\pi}{k_0(n_e-n_o)}=\\frac{\\lambda}{2(n_e-n_o)}\n\\]\nSimilar to the quarter wave plate, any thickness which creates a phase difference of \\(\\pi\\) can be used as a half wave plate. The actual thickness used in practice is often chosen based on manufacturing constraints and the specific wavelength range for which the plate is designed.",
    "crumbs": [
      "Electromagnetic Optics",
      "Lecture 17",
      "Anisotropic Materials"
    ]
  },
  {
    "objectID": "electromagnetic-waves/Dielectric Spectroscopy.html",
    "href": "electromagnetic-waves/Dielectric Spectroscopy.html",
    "title": "Dielectric Spectroscopy",
    "section": "",
    "text": "Dielectric spectroscopy (DS), also known as impedance spectroscopy, measures how a material interacts with an applied electric field as a function of frequency. This technique provides insights into the molecular dynamics and electrical properties of materials."
  },
  {
    "objectID": "electromagnetic-waves/Dielectric Spectroscopy.html#basic-principles",
    "href": "electromagnetic-waves/Dielectric Spectroscopy.html#basic-principles",
    "title": "Dielectric Spectroscopy",
    "section": "Basic Principles",
    "text": "Basic Principles\nWhen an electric field \\(\\vec{E}(t)\\) is applied to a dielectric material, it induces a polarization \\(\\vec{P}(t)\\). The relationship between these quantities is characterized by the complex dielectric function:\n\\[\n\\epsilon^*(\\omega) = \\epsilon'(\\omega) - i\\epsilon''(\\omega)\n\\]\nwhere: - \\(\\epsilon'(\\omega)\\) is the real part (storage component) - \\(\\epsilon''(\\omega)\\) is the imaginary part (loss component) - \\(\\omega\\) is the angular frequency"
  },
  {
    "objectID": "electromagnetic-waves/Dielectric Spectroscopy.html#measurement-approach",
    "href": "electromagnetic-waves/Dielectric Spectroscopy.html#measurement-approach",
    "title": "Dielectric Spectroscopy",
    "section": "Measurement Approach",
    "text": "Measurement Approach\nThe material is typically placed between two electrodes, forming a capacitor. The complex impedance \\(Z^*(\\omega)\\) is measured:\n\\[\nZ^*(\\omega) = Z'(\\omega) + iZ''(\\omega) = \\frac{1}{i\\omega C_0\\epsilon^*(\\omega)}\n\\]\nwhere \\(C_0\\) is the vacuum capacitance of the setup.\nThe dielectric response can be expressed in terms of various functions:\n\nComplex permittivity: \\[\\epsilon^*(\\omega) = \\frac{1}{i\\omega Z^*(\\omega)C_0}\\]\nComplex conductivity: \\[\\sigma^*(\\omega) = i\\omega\\epsilon_0\\epsilon^*(\\omega)\\]\nComplex modulus: \\[M^*(\\omega) = \\frac{1}{\\epsilon^*(\\omega)}\\]"
  },
  {
    "objectID": "electromagnetic-waves/Dielectric Spectroscopy.html#relaxation-processes",
    "href": "electromagnetic-waves/Dielectric Spectroscopy.html#relaxation-processes",
    "title": "Dielectric Spectroscopy",
    "section": "Relaxation Processes",
    "text": "Relaxation Processes\nThe frequency response often follows the Havriliak-Negami (HN) function:\n\\[\n\\epsilon^*(\\omega) = \\epsilon_\\infty + \\frac{\\Delta\\epsilon}{[1+(i\\omega\\tau)^\\alpha]^\\beta}\n\\]\nwhere: - \\(\\epsilon_\\infty\\) is the high-frequency limit - \\(\\Delta\\epsilon\\) is the relaxation strength - \\(\\tau\\) is the characteristic relaxation time - \\(\\alpha\\) and \\(\\beta\\) are shape parameters\nSpecial cases include: - Debye relaxation (\\(\\alpha=\\beta=1\\)) - Cole-Cole relaxation (\\(\\beta=1\\)) - Cole-Davidson relaxation (\\(\\alpha=1\\))\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Frequency range\nfreq = np.logspace(-2, 6, 1000)\nomega = 2 * np.pi * freq\n\n# Parameters for two relaxation processes\neps_inf = 2.0\ndelta_eps1 = 4.0\ndelta_eps2 = 2.0\ntau1 = 1e-3\ntau2 = 1e-5\n\n# Debye function\ndef debye(omega, delta_eps, tau):\n    return delta_eps / (1 + 1j * omega * tau)\n\n# Calculate complex permittivity\neps = eps_inf + debye(omega, delta_eps1, tau1) + debye(omega, delta_eps2, tau2)\n\nplt.figure(figsize=(8, 6))\nplt.semilogx(freq, eps.imag, 'b-', label=\"Dielectric loss\")\nplt.xlabel('Frequency (Hz)')\nplt.ylabel(\"ε''\")\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\n\n\n\nTypical dielectric loss spectrum showing multiple relaxation processes"
  },
  {
    "objectID": "electromagnetic-waves/Dielectric Spectroscopy.html#applications",
    "href": "electromagnetic-waves/Dielectric Spectroscopy.html#applications",
    "title": "Dielectric Spectroscopy",
    "section": "Applications",
    "text": "Applications\nDielectric spectroscopy finds applications in various fields:\n\nMaterials Science\n\nPolymer dynamics\nPhase transitions\nAging phenomena\n\nBiological Systems\n\nProtein hydration\nMembrane properties\nTissue characterization\n\nPharmaceutical Industry\n\nDrug stability\nQuality control\nFormulation development\n\n\n\n\n\n\n\n\nExperimental Considerations\n\n\n\nKey factors affecting measurements:\n\nTemperature control\nSample preparation\nElectrode polarization\nContact quality\nEnvironmental conditions\n\n\n\n\n\n\n\n\n\nData Analysis\n\n\n\nThe interpretation of dielectric spectra requires:\n\nProper model selection\nUnderstanding of molecular mechanisms\nconsideration of multiple relaxation processes\nAnalysis of temperature dependence"
  },
  {
    "objectID": "electromagnetic-waves/Dielectric Spectroscopy.html#temperature-dependence",
    "href": "electromagnetic-waves/Dielectric Spectroscopy.html#temperature-dependence",
    "title": "Dielectric Spectroscopy",
    "section": "Temperature Dependence",
    "text": "Temperature Dependence\nMany relaxation processes follow the Arrhenius equation:\n\\[\n\\tau = \\tau_0\\exp\\left(\\frac{E_a}{k_BT}\\right)\n\\]\nwhere: - \\(\\tau_0\\) is the attempt time - \\(E_a\\) is the activation energy - \\(k_B\\) is Boltzmann’s constant - \\(T\\) is temperature\nNon-Arrhenius behavior often follows the Vogel-Fulcher-Tammann (VFT) equation:\n\\[\n\\tau = \\tau_0\\exp\\left(\\frac{DT_0}{T-T_0}\\right)\n\\]\nwhere: - \\(D\\) is the strength parameter - \\(T_0\\) is the Vogel temperature"
  },
  {
    "objectID": "electromagnetic-waves/Electromagnetic Optics.html",
    "href": "electromagnetic-waves/Electromagnetic Optics.html",
    "title": "Electromagnetic Optics",
    "section": "",
    "text": "So far we have looked at the propagation of light in form of ray’s and its description in Gemoetrical Optics. We made a number of assumtions that we formulated as postulates. We then extended this description by a scalar Wave Optics description to allow for a description of interference and diffraction, which can not be explained by Geometrical Optics. Yet concepts of refractive index and light matter interaction and the intensities are not covered by Wave Optics and also just postulates.\nElectromagnetic Optics allows us to define these missing things. We discover light as electromagnetic waves consisting of electric and magnetic fields, which allow us to describe the interaction with charges in atoms, which is the foundation for the refractive index for example. The new thing is therefore the fact that we now need vectors for the description of light.",
    "crumbs": [
      "Electromagnetic Optics",
      "Lecture 12",
      "Electromagnetic Optics"
    ]
  },
  {
    "objectID": "electromagnetic-waves/Electromagnetic Optics.html#electromagnetic-spectrum",
    "href": "electromagnetic-waves/Electromagnetic Optics.html#electromagnetic-spectrum",
    "title": "Electromagnetic Optics",
    "section": "Electromagnetic Spectrum",
    "text": "Electromagnetic Spectrum\nWhile most of our considerations are focused on electromagnetic waves in the visible region, all of them can be generalized to other regions of the very broad electromagnetic spectrum. The electromagnetic theory is scale free, meaning that the same effect on specific structures occur also at smaller scales if you scale the wavelength of the wave.\n\n\n\n\n\n\n\n\n\nElectromagnetic Spectrum\n\n\n\n\n\n\nElectromagnetic wave spectrum with its specific regions.\n\n\n\n\nMaxwell Equations\nTo obtain a wave equation in terms of electric \\(\\vec{E}\\) and magnetic fields \\(\\vec{B}\\) we need Maxwell’s equations. We will consider them in vacumm, i.e. for zero charge \\(\\rho=0\\) and current density. The electric and magnetic permeabilities of vacuum are given by \\(\\epsilon_0\\) and \\(\\mu_0\\).\n\\[\n\\nabla \\times \\vec{E}=-\\frac{\\partial \\vec{B}}{\\partial t}\n\\label{eq:ME1}\\tag{ME.1}\n\\]\n\\[\n\\nabla\\cdot\\vec{E}=0\n\\tag{ME.2}\n\\]\n\\[\n\\nabla\\times \\vec{B}=\\epsilon_0\\mu_0\\frac{\\partial \\vec{E}}{\\partial t}\n\\tag{ME.3}\n\\]\n\\[\n\\nabla\\cdot \\vec{B}=0\n\\tag{ME.4}\n\\]\nMaxwell’s third equation (ME.3) is significant because it expands upon Ampère’s law, which states that magnetic field lines form closed loops around electric currents. This principle can be applied to a capacitor circuit, where we can calculate the magnetic field by integrating along a circular path around the current-carrying wire.\nIn this setup, the current density flows through a surface bounded by the circular path. Importantly, we can choose any surface that shares the same boundary circle (mathematically known as path-independent surface integration). However, this creates an apparent paradox: Ampère’s law must work both for: 1. A simple surface through which the conduction current flows 2. A surface that passes through the capacitor gap where no actual charges flow\nTo resolve this inconsistency, Maxwell introduced the concept of displacement current. This additional current exists even in regions without flowing charges and is proportional to the time rate of change of the electric field, multiplied by the vacuum permittivity (\\(\\epsilon_{0}\\)).\n\n\n\n\n\nThe displacement current makes physical sense because current only flows in the capacitor’s wires when the electric field between the plates is changing. This addition to Ampère’s law was crucial, as it completed the set of equations that describe electromagnetic waves.\nThis term is essential for deriving the electromagnetic wave equation and understanding how electromagnetic waves propagate through space.\n\n\nDeriving the Wave Equation\nWe will take the first (ME.1) of the four equations and apply another rotation \\(\\nabla \\times\\) to both sides\n\\[\n\\nabla\\times\\nabla\\times = -\\nabla \\times \\frac{\\partial \\vec{B}}{\\partial t}\n\\]\nWe can exchange the time and spatial derivate on the right side as \\(\\nabla\\) is not depending on time to get\n\\[\\begin{eqnarray}\n\\nabla\\times\\nabla\\times \\vec{E}&=& - \\frac{\\partial \\nabla \\times \\vec{B}}{\\partial t}\\\\\n&=&-\\epsilon_0\\mu_0 \\frac{\\partial^2 \\vec{E}}{\\partial t^2}\n\\end{eqnarray}\\]\nwhere we used the third equation (ME.3) to replace the rotation of the magnetic field. We now have to expand the left side with the identity\n\\[\n\\nabla\\times\\nabla\\times \\vec{E}=\\nabla(\\nabla\\cdot \\vec{E})-\\nabla(\\nabla \\vec{E})\n\\]\nNote the the first term on the right side is the gradient of the divergence of \\(\\vec{E}\\), while the second term is the divergence of the gradient of \\(\\vec{E}\\). We know that in vacuum the divergence of the elecric field is zero (no sources of the electric field) and therefore \\(\\nabla\\times\\nabla\\times \\vec{E}=-\\nabla(\\nabla \\vec{E})\\) and we have our wave equation\n\\[\n\\frac{\\partial^2 \\vec{E}}{\\partial \\vec{r}^2}-\\epsilon_0\\mu_0 \\frac{\\partial^2\\vec{E}}{\\partial t^2}=0\n\\tag{Wave Equation}\n\\]\n\n\n\n\n\n\nWave Equation\n\n\n\nThe wave equation for the propagation of electric fields in vaccum is given by\n\\[\n\\frac{\\partial^2 \\vec{E}}{\\partial \\vec{r}^2}-\\epsilon_0\\mu_0 \\frac{\\partial^2\\vec{E}}{\\partial t^2}=0\n\\]\nThe phase velocity of the wave is\n\\[\nc=\\frac{1}{\\sqrt{\\mu_0\\epsilon_0}}=299792458 \\, {\\rm\\frac{m}{s}}\n\\]\n\n\nOne of the interesting relations to electrostatics is now, that the static permeabilities \\(\\epsilon_0.\\mu_0\\) determine the speed of light. Note that the above wave equation is a vectorial equation., That means there is a wave equation for each component of the elecric field, e.g.\n\\[\n\\frac{\\partial^2 E_x}{\\partial x^2}+\\frac{\\partial^2 E_x}{\\partial y^2}+\\frac{\\partial^2 E_x}{\\partial z^2}-\\frac{1}{c^2} \\frac{\\partial^2 E_x}{\\partial t^2}=0\n\\]\nfor the x-component of the electric field. Equivalent equations exist for the other field components.\nThe same mathematical treatment can be done for the magnetic field \\(\\vec{B}\\) and the same wave equation will follow from that.\n\n\n\n\n\n\nMichelson Morley Experiment\n\n\n\n\n\n\n\n\n\n\nThe Michelson-Morley experiment of 1887 was designed to detect the hypothetical luminiferous ether through which light was thought to propagate. Using an interferometer, they split a light beam into two perpendicular paths and recombined them to create an interference pattern. The theoretical derivation considered the time for light to travel in both directions: along the direction of Earth’s motion through the ether, the outward and return journey times are given by:\n\\[t_1 = \\frac{L}{c-v}\\] \\[t_2 = \\frac{L}{c+v}\\]\nwhere L is the arm length, c is the speed of light, and v is Earth’s velocity through the ether. The total time for this path is therefore:\n\\[T_1 = t_1 + t_2 = \\frac{L}{c-v} + \\frac{L}{c+v} = \\frac{2Lc}{c^2-v^2}\\]\nFor the perpendicular arm, the time calculation involved the Pythagorean theorem, as light would travel diagonally relative to the ether, giving:\n\\[T_2 = \\frac{2L}{\\sqrt{c^2-v^2}}\\]\nThe time difference ΔT = T₁ - T₂, when expanded using the binomial theorem and keeping terms to second order in v/c, yields:\n\\[\\Delta T = \\frac{L}{c} \\times \\frac{v^2}{c^2}\\]\nThis time difference corresponds to a path difference of:\n\\[\\Delta d = 2L\\frac{v^2}{c^2}\\]\nHowever, Michelson and Morley observed no significant fringe shift, contradicting the ether theory and paving the way for special relativity, which established the constancy of the speed of light in all inertial reference frames.",
    "crumbs": [
      "Electromagnetic Optics",
      "Lecture 12",
      "Electromagnetic Optics"
    ]
  },
  {
    "objectID": "electromagnetic-waves/Electromagnetic Optics.html#plane-waves-spherical-waves",
    "href": "electromagnetic-waves/Electromagnetic Optics.html#plane-waves-spherical-waves",
    "title": "Electromagnetic Optics",
    "section": "Plane Waves, Spherical Waves",
    "text": "Plane Waves, Spherical Waves\n\nPlane Waves\nWe will first have a look at elementary solutions of the wave equation again as we have done that in the wave optics sections. First of all we can write the solution of the wave equation as a product of a spatial and a temporal amplitude, i.e.\n\\[\\begin{eqnarray}\n\\vec{\\mathcal{E}}(\\vec{r},t)&=&\\mathcal{Re}\\lbrace \\vec{E}(\\vec{r})e^{-i\\omega t}\\rbrace\\\\\n\\vec{\\mathcal{B}}(\\vec{r},t)&=&\\mathcal{Re}\\lbrace \\vec{B}(\\vec{r})e^{-i\\omega t}\\rbrace\n\\end{eqnarray}\\]\nWe use again the complex notation and remember that the measurable physical quantity \\(\\vec{\\mathcal{E}}\\) or \\(\\vec{\\mathcal{B}}\\) has to be a real valued quantity. Therefore we may calculate with the complex quantities, but finally need to calculate the real part (\\(\\mathcal{Re}\\)) if required. In the following we will use the complex notation throughout the calculation and only refer to the real value if this is really useful. When inserting the complex ansatz above into the wave equation, we can take the time derivative which yields for the electric field\n\\[\\begin{equation}\n\\Delta \\vec{E}(\\vec{r})+\\frac{\\omega^2}{c^2}\\vec{E}(\\vec{r})=0\n\\tag{Helmholtz Equation}\n\\end{equation}\\]\nThe latter equation is known as the Helmholtz equation. It is the differential equation for the spatial amplitude of the wave. We may also insert the solutions into the first and the third Maxwell equation which results in\n\\[\\begin{eqnarray}\n\\nabla \\times \\vec{E}&=&i\\omega\\vec{B}\\\\\n\\nabla \\times\\vec{B} &=& -\\epsilon_0\\mu_0 i\\omega \\vec{E}\n\\end{eqnarray}\\]\nWe obtain finally a plane wave with our knowledge from the wave optics section.\n\\[\\begin{eqnarray}\n\\vec{E}(\\vec{r})&=&\\vec{E}_{0}e^{i\\vec{k}\\cdot\\vec{r}}\\\\\n\\vec{B}(\\vec{r})&=&\\vec{B}_{0}e^{i\\vec{k}\\cdot\\vec{r}}\\\\\n\\end{eqnarray}\\]\nTaking the rotation of those two equations yields\n\\[\\begin{eqnarray}\n\\vec{k}\\times \\vec{E}_{0}&=&\\omega \\vec{B}_0\\\\\n\\vec{k}\\times \\vec{B}_{0}&=&-\\frac{\\omega}{c^2} \\vec{E}_0\n\\end{eqnarray}\\]\nThe latter two equations tell essentiall two things. First of all they state that the vectors \\(\\vec{k}\\), \\(\\vec{E}_0\\) and \\(\\vec{B}_{0}\\) stand perpendicular to each other. This is why electromagnetic waves are termed transverse waves. The physical quantity of a transverse wave change sperpendicular to its propagation direction.\nThe second thing is that the amplitudes of the two waves are not independent of each other but rather\n\\[\nB_0=\\frac{1}{c}E_0\n\\]\nThis is quite helpful, as we may just do calculations for the electric field and transfer them with the help of this conversion to the magnetic field.\n\n\n\n\n\n\n\n\n\nPlane Wave\n\n\n\n\n\n\nPlane wave propagating along the y-direction, with the electric field oscillating along the z-direction.\n\n\n\n\n\nSpherical Waves\nSpherical waves are more complex than plane waves and require a different mathematical approach. We can describe them using an auxiliary function called the Vector potential, defined as:\n\\[\n\\vec{A}(\\vec{r})=A_0 U(\\vec{r})\\hat{x}\n\\]\nwhere \\(\\hat{x}\\) is the unit vector in the x-direction, and \\(U(\\vec{r})\\) is the scalar spherical wave function from wave optics:\n\\[\nU(\\vec{r})=\\frac{1}{r}e^{-ik r}\n\\]\nThis vector potential satisfies the Helmholtz equation:\n\\[\n\\Delta\\vec{A}+k^2 \\vec{A}=0\n\\]\nWhen we solve for the electric and magnetic fields in spherical coordinates, and consider large distances where \\(r\\gg\\lambda\\) or \\(k r\\gg2\\pi\\), we get:\n\\[\\begin{eqnarray}\n\\vec{E}(\\vec{r})&=& E_0 \\sin(\\theta) U(\\vec{r}) \\hat{\\theta}\\\\\n\\vec{B}(\\vec{r})&=& B_0 \\sin(\\theta) U(\\vec{r}) \\hat{\\phi}\n\\end{eqnarray}\\]\nThese equations reveal that both the electric and magnetic fields lie tangent to the spherical wavefront. Since the wave propagates radially while the fields are perpendicular to this direction, we can classify spherical waves as transverse electromagnetic waves, just like plane waves.\n\n\n\n\n\n\n\n\n\n\n\n(Left) Definition of the unit vectors in a spherical coordinate system. (Right) Vectors of the electric and magnetic field for a spherical wave.",
    "crumbs": [
      "Electromagnetic Optics",
      "Lecture 12",
      "Electromagnetic Optics"
    ]
  },
  {
    "objectID": "electromagnetic-waves/ABbe.html",
    "href": "electromagnetic-waves/ABbe.html",
    "title": "Abbe Refractometer Working Principle and Operation",
    "section": "",
    "text": "The Abbe refractometer utilizes the phenomenon of total internal reflection to measure refractive indices of liquid or solid samples. The measurement is based on determining the critical angle at the interface between the sample and a prism of known refractive index.\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.patches import Polygon\nimport matplotlib.patches as patches\n\n# Create figure\nfig, ax = plt.subplots(figsize=get_size(12,8))\n\n# Draw prism outline\nprism_points = np.array([[0,0], [3,0], [3,2], [0,2]])\nprism = Polygon(prism_points, facecolor='lightgray', alpha=0.3)\nax.add_patch(prism)\n\n# Draw sample layer\nsample_points = np.array([[0,2], [3,2], [3,2.2], [0,2.2]])\nsample = Polygon(sample_points, facecolor='lightblue', alpha=0.3)\nax.add_patch(sample)\n\n# Draw incident rays\nx = np.linspace(0.5, 2.5, 5)\nfor xi in x:\n    ax.arrow(xi, 3, 0, -0.5, head_width=0.05, head_length=0.1, fc='b', ec='b')\n\n# Draw critical ray\nax.arrow(1.5, 2, 1, 0, head_width=0.05, head_length=0.1, fc='r', ec='r')\n\n# Draw normal line (dashed)\nax.plot([1.5, 1.5], [1.5, 2.5], 'k--', alpha=0.5)\n\n# Add angle labels\nax.text(1.7, 2.1, 'θc', fontsize=10)\n\n# Add labels\nax.text(0.2, 1, 'Prism\\n(n₁)', fontsize=10)\nax.text(0.2, 2.1, 'Sample\\n(n₂)', fontsize=10)\n\n# Set axis limits and remove ticks\nax.set_xlim(-0.5, 3.5)\nax.set_ylim(-0.5, 3.5)\nax.set_xticks([])\nax.set_yticks([])\n\nplt.show()\n\n\n\n\n\nSchematic diagram of an Abbe refractometer showing the critical angle principle.\n\n\n\n\n\n\n\n\nMeasuring Prism: Made of high-refractive-index glass (typically n₁ ≈ 1.7)\n\nPrecisely polished surfaces\nKnown refractive index\nTemperature controlled\n\nIlluminating Prism: Directs light into the sample\n\nUsually made of the same glass\nCreates diffuse illumination\n\nSample Layer: Thin film between prisms\n\nLiquid samples: few drops\nSolid samples: requires contact liquid\n\nLight Source:\n\nTypically sodium D-line (589.3 nm)\nSome models use white light with compensator\n\n\n\n\n\nThe relationship between the measured critical angle θc and the sample’s refractive index n₂ follows from Snell’s law:\n\nAt the critical angle: \\[n_2\\sin(90°) = n_1\\sin(\\theta_c)\\]\nTherefore: \\[n_2 = n_1\\sin(\\theta_c)\\]\n\n\n\n\n\n\n\nNote\n\n\n\nThe scale of the refractometer is typically calibrated to read n₂ directly, eliminating the need for calculations.\n\n\n\n\n\n\nCalibration\n\nClean prisms with alcohol/ether\nCheck zero point with distilled water\nAdjust if necessary using calibration screw\n\nSample Preparation\n\nClean and dry prisms\nApply 2-3 drops of sample\nClose prism assembly\n\nMeasurement\n\nAdjust eyepiece for sharp view\nAlign crosshairs with boundary line\nRead refractive index directly\nTake multiple readings for precision\n\n\n\n\nCode\n# Create figure\nfig, ax = plt.subplots(figsize=get_size(8,8))\n\n# Create gradient background\nx = np.linspace(0, 100, 100)\ny = np.linspace(0, 100, 100)\nX, Y = np.meshgrid(x, y)\nZ = Y\n\n# Plot gradient\nplt.imshow(Z, cmap='Greys', extent=[0, 100, 0, 100])\n\n# Add crosshair\nplt.axhline(y=50, color='r', linestyle='-', linewidth=1)\nplt.axvline(x=50, color='r', linestyle='-', linewidth=1)\n\n# Add scale\nfor i in range(0, 101, 10):\n    plt.text(i, 10, f'{1.33 + i/1000:.3f}', rotation=90, fontsize=8)\n\n# Remove axes\nplt.axis('off')\n\nplt.show()\n\n\n\n\n\nTypical view through Abbe refractometer eyepiece\n\n\n\n\n\n\n\n\nTemperature Effects\n\nRefractive index is temperature dependent\nTemperature should be controlled ±0.2°C\nTemperature corrections may be needed\n\nSample Purity\n\nContamination affects readings\nProper cleaning between samples crucial\n\nOptical Contact\n\nPoor contact causes diffuse boundary\nInsufficient sample volume\nAir bubbles\n\nOperator Error\n\nIncorrect boundary identification\nParallax in reading scale\nPoor illumination adjustment\n\n\n\n\n\n\nQuality Control\n\nFood industry (oils, syrups)\nChemical manufacturing\nPharmaceutical products\n\nResearch\n\nSolution concentration studies\nPolymer characterization\nMaterial science\n\nClinical\n\nProtein content in blood serum\nUrine analysis\nBody fluid studies\n\n\n\n\n\n\n\n\nImportant\n\n\n\nModern digital Abbe refractometers automate many aspects of measurement but still rely on the same physical principles.\n\n\n\n\n\n\n\n\nParameter\nRange/Value\n\n\n\n\nMeasuring Range\n1.300 - 1.700\n\n\nAccuracy\n±0.0002\n\n\nResolution\n0.0001\n\n\nTemperature Range\n0-70°C\n\n\nSample Volume\n0.1-0.2 mL"
  },
  {
    "objectID": "electromagnetic-waves/ABbe.html#abbe-refractometer-working-principle-and-operation",
    "href": "electromagnetic-waves/ABbe.html#abbe-refractometer-working-principle-and-operation",
    "title": "Abbe Refractometer Working Principle and Operation",
    "section": "",
    "text": "The Abbe refractometer utilizes the phenomenon of total internal reflection to measure refractive indices of liquid or solid samples. The measurement is based on determining the critical angle at the interface between the sample and a prism of known refractive index.\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.patches import Polygon\nimport matplotlib.patches as patches\n\n# Create figure\nfig, ax = plt.subplots(figsize=get_size(12,8))\n\n# Draw prism outline\nprism_points = np.array([[0,0], [3,0], [3,2], [0,2]])\nprism = Polygon(prism_points, facecolor='lightgray', alpha=0.3)\nax.add_patch(prism)\n\n# Draw sample layer\nsample_points = np.array([[0,2], [3,2], [3,2.2], [0,2.2]])\nsample = Polygon(sample_points, facecolor='lightblue', alpha=0.3)\nax.add_patch(sample)\n\n# Draw incident rays\nx = np.linspace(0.5, 2.5, 5)\nfor xi in x:\n    ax.arrow(xi, 3, 0, -0.5, head_width=0.05, head_length=0.1, fc='b', ec='b')\n\n# Draw critical ray\nax.arrow(1.5, 2, 1, 0, head_width=0.05, head_length=0.1, fc='r', ec='r')\n\n# Draw normal line (dashed)\nax.plot([1.5, 1.5], [1.5, 2.5], 'k--', alpha=0.5)\n\n# Add angle labels\nax.text(1.7, 2.1, 'θc', fontsize=10)\n\n# Add labels\nax.text(0.2, 1, 'Prism\\n(n₁)', fontsize=10)\nax.text(0.2, 2.1, 'Sample\\n(n₂)', fontsize=10)\n\n# Set axis limits and remove ticks\nax.set_xlim(-0.5, 3.5)\nax.set_ylim(-0.5, 3.5)\nax.set_xticks([])\nax.set_yticks([])\n\nplt.show()\n\n\n\n\n\nSchematic diagram of an Abbe refractometer showing the critical angle principle.\n\n\n\n\n\n\n\n\nMeasuring Prism: Made of high-refractive-index glass (typically n₁ ≈ 1.7)\n\nPrecisely polished surfaces\nKnown refractive index\nTemperature controlled\n\nIlluminating Prism: Directs light into the sample\n\nUsually made of the same glass\nCreates diffuse illumination\n\nSample Layer: Thin film between prisms\n\nLiquid samples: few drops\nSolid samples: requires contact liquid\n\nLight Source:\n\nTypically sodium D-line (589.3 nm)\nSome models use white light with compensator\n\n\n\n\n\nThe relationship between the measured critical angle θc and the sample’s refractive index n₂ follows from Snell’s law:\n\nAt the critical angle: \\[n_2\\sin(90°) = n_1\\sin(\\theta_c)\\]\nTherefore: \\[n_2 = n_1\\sin(\\theta_c)\\]\n\n\n\n\n\n\n\nNote\n\n\n\nThe scale of the refractometer is typically calibrated to read n₂ directly, eliminating the need for calculations.\n\n\n\n\n\n\nCalibration\n\nClean prisms with alcohol/ether\nCheck zero point with distilled water\nAdjust if necessary using calibration screw\n\nSample Preparation\n\nClean and dry prisms\nApply 2-3 drops of sample\nClose prism assembly\n\nMeasurement\n\nAdjust eyepiece for sharp view\nAlign crosshairs with boundary line\nRead refractive index directly\nTake multiple readings for precision\n\n\n\n\nCode\n# Create figure\nfig, ax = plt.subplots(figsize=get_size(8,8))\n\n# Create gradient background\nx = np.linspace(0, 100, 100)\ny = np.linspace(0, 100, 100)\nX, Y = np.meshgrid(x, y)\nZ = Y\n\n# Plot gradient\nplt.imshow(Z, cmap='Greys', extent=[0, 100, 0, 100])\n\n# Add crosshair\nplt.axhline(y=50, color='r', linestyle='-', linewidth=1)\nplt.axvline(x=50, color='r', linestyle='-', linewidth=1)\n\n# Add scale\nfor i in range(0, 101, 10):\n    plt.text(i, 10, f'{1.33 + i/1000:.3f}', rotation=90, fontsize=8)\n\n# Remove axes\nplt.axis('off')\n\nplt.show()\n\n\n\n\n\nTypical view through Abbe refractometer eyepiece\n\n\n\n\n\n\n\n\nTemperature Effects\n\nRefractive index is temperature dependent\nTemperature should be controlled ±0.2°C\nTemperature corrections may be needed\n\nSample Purity\n\nContamination affects readings\nProper cleaning between samples crucial\n\nOptical Contact\n\nPoor contact causes diffuse boundary\nInsufficient sample volume\nAir bubbles\n\nOperator Error\n\nIncorrect boundary identification\nParallax in reading scale\nPoor illumination adjustment\n\n\n\n\n\n\nQuality Control\n\nFood industry (oils, syrups)\nChemical manufacturing\nPharmaceutical products\n\nResearch\n\nSolution concentration studies\nPolymer characterization\nMaterial science\n\nClinical\n\nProtein content in blood serum\nUrine analysis\nBody fluid studies\n\n\n\n\n\n\n\n\nImportant\n\n\n\nModern digital Abbe refractometers automate many aspects of measurement but still rely on the same physical principles.\n\n\n\n\n\n\n\n\nParameter\nRange/Value\n\n\n\n\nMeasuring Range\n1.300 - 1.700\n\n\nAccuracy\n±0.0002\n\n\nResolution\n0.0001\n\n\nTemperature Range\n0-70°C\n\n\nSample Volume\n0.1-0.2 mL"
  },
  {
    "objectID": "electromagnetic-waves/Metals.html",
    "href": "electromagnetic-waves/Metals.html",
    "title": "Electromagnetic Waves in Metals",
    "section": "",
    "text": "Metals have free charges, which modify the propagation of light. Their influence is large and gives metals their characteristic reflection and color. In this case, we have to include the free charge density \\(\\rho_f\\) and the current density \\(\\vec{j}\\) in the Maxwell equations and derive the wave equation accordingly. Instead of modifying the wave equation, we would like to go a different way here. We would like to derive the dielectric function for metals based on a microscopic description, which is only approximate but captures some basic features.",
    "crumbs": [
      "Electromagnetic Optics",
      "Lecture 17",
      "Electromagnetic Waves in Metals"
    ]
  },
  {
    "objectID": "electromagnetic-waves/Metals.html#drude-model",
    "href": "electromagnetic-waves/Metals.html#drude-model",
    "title": "Electromagnetic Waves in Metals",
    "section": "Drude Model",
    "text": "Drude Model\nThe model we would like to put forward is the Drude model. It considers the motion of a charge in the electromagnetic field of a wave. As compared to our previous attempts on bound electrons in atoms, there is no direct restoring force for the free charges in the metal. The equation of motion therefore looks as\n\\[\nm_e\\frac{d^2\\vec{r}}{dt^2}+m_e\\Gamma \\frac{d\\vec{r}}{dt}=e\\vec{E}_0 e^{i\\omega t}\n\\]\nHere, the coefficient \\(\\Gamma\\) is given by\n\\[\n\\Gamma=\\frac{v_f}{l}=\\frac{1}{\\tau}\n\\]\nwhere \\(v_f\\) is the Fermi velocity and \\(l\\) is the mean free path electrons travel before colliding with a lattice site inside the metal. To obtain an expression for the refractive index, we use again the ansatz\n\\[\n\\vec{r}=\\vec{r}_0 e^{i\\omega t}\n\\]\nfrom which we obtain an expression for \\(\\vec{r}_0\\). With his solution we can again calculate the polarization density and finally also the dielectric function\n\\[\n\\epsilon_r(\\omega)=n^2=1-\\frac{\\omega_p^2}{\\omega^2-i\\Gamma \\omega}\n\\]\nwith\n\\[\n\\omega_p=\\sqrt{\\frac{Ne^2}{\\epsilon_0 m}}\n\\]\nwhich is called the plasma frequency. It is a characteristic for each metal, since the density of free charges in the metal enters the equation. It is located in the UV region of the electromagnetic spectrum.\n\n\n\n\n\n\n\n\n\n\n\nParameter\nSymbol\nGold Value\nSilver Value\nCopper Value\nUnits\n\n\n\n\nFree electron density\n\\(N\\)\n5.9 × 10²⁸\n5.86 × 10²⁸\n8.47 × 10²⁸\nm⁻³\n\n\nElectron mass\n\\(m_e\\)\n9.109 × 10⁻³¹\n9.109 × 10⁻³¹\n9.109 × 10⁻³¹\nkg\n\n\nElementary charge\ne\n1.602 × 10⁻¹⁹\n1.602 × 10⁻¹⁹\n1.602 × 10⁻¹⁹\nC\n\n\nResulting plasma frequency\n\\(\\omega_p\\)\n13.8 × 10¹⁵\n13.7 × 10¹⁵\n16.5 × 10¹⁵\nrad/s\n\n\nFrequency\n\\(f\\)\n2.18 × 10¹⁵\n2.18 × 10¹⁵\n2.62 × 10¹⁵\nHz\n\n\nPlasma wavelength\n\\(\\lambda_p\\)\n138\n138\n114\nnm\n\n\n\nThe complex refractive index \\(n\\) is composed of two parts: the real part \\(n_r\\) which describes the phase velocity of light in the material, and the imaginary part \\(\\kappa\\) (kappa) which describes the absorption. These are related by:\n\\[\nn=n_r-i\\kappa\n\\]\nSince the dielectric function \\(\\epsilon\\) is equal to the square of the refractive index \\(n\\), we can expand this relationship to separate the real and imaginary components:\n\\[\nn^2=n_r^2-\\kappa^2-2i n_r \\kappa=\\epsilon^{\\prime}+i\\epsilon^{\\prime\\prime}\n\\]\nHere, \\(\\epsilon^{\\prime}\\) represents the real part of the dielectric function, which determines how much polarization occurs in response to an applied electric field, while \\(\\epsilon^{\\prime\\prime}\\) represents the imaginary part, which determines how much energy is absorbed by the material. From the Drude model, we can express these components explicitly:\n\\[\n\\epsilon^{\\prime}=n_r^2-\\kappa^2=1-\\frac{\\tau^2 (\\omega^2-\\omega_p^2)}{1+\\omega^2\\tau^2}\n\\]\n\\[\n\\epsilon^{\\prime\\prime}=2n_r\\kappa=\\frac{\\omega_p^2\\tau}{\\omega(1+\\omega^2\\tau^2)}\n\\]\nThese equations directly connect the optical properties (\\(n_r\\) and \\(\\kappa\\)) to the physical parameters of the metal like the plasma frequency ωp and the relaxation time \\(\\tau\\). When \\(\\epsilon^{\\prime}\\) is negative, which occurs below the plasma frequency, the metal reflects light strongly. When \\(\\epsilon^{\\prime\\prime}\\) is large, the metal absorbs light efficiently. Together, these components fully characterize how the metal interacts with electromagnetic radiation.\n\n\nCode\nomega_p_d=13.8e15\ngamma_d=1.075e14\n\n#wavelength range\nwavelength=np.arange(400,1000,1)\n\n\ndef epsilon_d(omega,gamma,omega_p):\n    return(1-omega_p**2/(omega**2+1j*gamma*omega))\n\n#conversion from wavelength in angular frequency\ndef freq(lam): # supply wavelength in nm\n    c=299792458 # speed of light m/s\n    return(2*np.pi*c/(lam*1e-9))\n\n\n#dielectric function, complex!\nepsilon=epsilon_d(freq(wavelength),gamma_d,omega_p_d)\n\nfig=plt.figure(figsize=get_size(12,6))\nplt.subplot(121)\nplt.plot(wavelength,np.real(epsilon),label=r'Re($\\epsilon_{D}$)')\nplt.xlabel('wavelength [nm]')\nplt.ylabel(r'$\\epsilon_{r,D}$')\nplt.legend()\n\nplt.subplot(122)\nplt.plot(wavelength,np.imag(epsilon),label=r'Im($\\epsilon_{D}$)')\nplt.xlabel('wavelength [nm]')\nplt.ylabel(r'$\\epsilon_{r,D}$')\nplt.legend()\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nFigure 1— Real (left) and imaginary part (right) of the dielectric function according to the Drude model. The dashed line in the left plot corresponds to the plasma frequency. The calculations are for Gold.\n\n\n\n\n\nThe figure above shows the dielectric function for Gold as determined from the parameters \\(\\omega_{p}=13.8\\times 10^{15}\\, \\rm{s}^{-1}\\) and \\(\\Gamma=1.075\\times 10^{14}\\, \\rm{s}^{-1}\\). The real value of the dielectric function is negative over the whole visible range stating that there is no propagating wave inside the matal. It just becomes positive below the plasma frequency. The imaginary part increases continuously with the wavelength.\n\nConductivity\nAls we calculate the position \\(\\vec{r}\\) of the electrons in the oscillating electric field, we may also obtain its velocity, which helps us to calculate a new quantity, which is the conductivity \\(\\sigma\\) of the metal. This conductivity will be frequency dependent as well as the charges will not follow the electric field oscillations in the same way at different frequencies. The conductivity is following from Ohm’s law, which is given by\n\\[\n\\vec{j}=\\sigma \\vec{E}=N e \\vec{v}\n\\]\nwhere we explicity wrote the current density on the right side. Following this relation, the conductivity is obtained as\n\\[\n\\sigma=\\epsilon_0 \\omega_p^2\\frac{\\tau(1+i\\omega\\tau)}{1+\\omega^2\\tau^2}\n\\]\nfrom the Drude model and we may express the real and imaginary parts of the dielectric function also in relation to the conductivity by\n\\[\n\\epsilon^{\\prime}=1-\\frac{\\mathcal{R}(\\sigma)\\tau}{\\epsilon_0}\n\\]\n\\[\n\\epsilon^{\\prime\\prime}=\\frac{\\mathcal{Im}(\\sigma)}{\\epsilon_0 \\omega^2 \\tau}\n\\]\nwhich readily tells us, that we obtain information on the conductivity at high frequencies from optical measurements.",
    "crumbs": [
      "Electromagnetic Optics",
      "Lecture 17",
      "Electromagnetic Waves in Metals"
    ]
  },
  {
    "objectID": "electromagnetic-waves/Metals.html#optical-properties-of-metals",
    "href": "electromagnetic-waves/Metals.html#optical-properties-of-metals",
    "title": "Electromagnetic Waves in Metals",
    "section": "Optical Properties of Metals",
    "text": "Optical Properties of Metals\n\nReflectivity of Metals\nThe reflectivity of a metal is closely related to its dielectric function. The reflectivity \\(R\\) of a metal can be calculated from the complex dielectric function \\(\\epsilon\\) using the Fresnel equations:\n\\[\nR = \\left|\\frac{n - 1}{n + 1}\\right|^2\n\\]\nwhere \\(n = \\sqrt{\\epsilon}\\) is the complex refractive index.\nThe plot below shows the square of complex refractive index \\(n\\) for gold according to the Drude model. Interestingly the square of the real part of the refractive index is negative below the plasma frequency. This means that the wave is evanescent and cannot propagate in the metal. This is the reason why metals are opaque in the visible range.\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef drude_epsilon(omega, omega_p, gamma):\n    \"\"\"Calculate complex dielectric function using Drude model\"\"\"\n    return 1 - omega_p**2/(omega**2 - 1j*gamma*omega)\n\n# Parameters for Gold\nomega_p = 13.8e15  # plasma frequency\ngamma = 1.075e14   # damping constant\n\n# Wavelength range\nwavelength = np.linspace(10, 400, 1000)  # wavelength in nm\nc = 299792458  # speed of light in m/s\nomega = 2*np.pi*c/(wavelength*1e-9)  # angular frequency\n\n# Calculate n²\nn_squared = drude_epsilon(omega, omega_p, gamma)\n\n# Plot\nplt.figure(figsize=get_size(8, 6))\nplt.plot(wavelength, np.real(n_squared), 'b-', label=r'Re($n^2$)')\nplt.plot(wavelength, np.imag(n_squared), 'r--', label=r'Im($n^2$)')\nplt.xlabel('Wavelength (nm)')\nplt.ylabel(r'$n^2$')\nplt.legend()\n\n# Add plasma wavelength\nplasma_wavelength = 2*np.pi*c/omega_p * 1e9  # convert to nm\nplt.axvline(plasma_wavelength, color='gray', linestyle=':', alpha=0.5)\nplt.text(plasma_wavelength*1.1, 0-1, r'$\\omega_p$', fontsize=10)\n\n\n#plt.axvspan(400, 750, color='yellow', alpha=0.1)\n#plt.text(575, plt.ylim()[0]+10, 'Visible', rotation=90)\n\n# Add zero line\nplt.axhline(y=0, color='k', linestyle='-', alpha=0.2)\n\nplt.tight_layout()\nplt.show()\n\n# Print some values\n#print(\"\\nWavelength (nm) | Re(n²) | Im(n²)\")\n#for i in range(0, len(wavelength), 200):\n#    print(f\"{wavelength[i]:13.1f} | {np.real(n_squared)[i]:6.2f} | {np.imag(n_squared)[i]:6.2f}\")\n\n\n\n\n\n\n\n\nFigure 2— Real and imaginary parts of n² for gold according to the Drude model. The dashed line indicates the plasma frequency.\n\n\n\n\n\n\n\n\nTbl 1— Real and imaginary components of the refractive index squared (n²) at different wavelengths\n\n\n\n\n\nWavelength (nm)\nRe(n²)\nIm(n²)\n\n\n\n\n10.0\n0.99\n-0.00\n\n\n88.1\n0.58\n-0.00\n\n\n166.2\n-0.48\n-0.01\n\n\n244.2\n-2.20\n-0.04\n\n\n322.3\n-4.57\n-0.10\n\n\n\n\n\n\nFrom the square of the refractive index, we can calculate the reflectivity of the metal. The plot below shows the reflectivity of gold with and without damping. Without damping, the reflectivity is exactly 1 below the plasma frequency and drops sharply above it. The damping broadens the reflectivity curve and reduces the reflectivity below the plasma frequency.\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef drude_epsilon(omega, omega_p, gamma):\n    \"\"\"Calculate complex dielectric function using Drude model\"\"\"\n    return 1 - omega_p**2/(omega**2 - 1j*gamma*omega)\n\ndef reflectivity_from_epsilon(epsilon):\n    \"\"\"Calculate reflectivity from complex dielectric function\"\"\"\n    n_complex = np.sqrt(epsilon)\n    r = (n_complex - 1)/(n_complex + 1)\n    return np.abs(r)**2\n\n# Parameters\nomega_p = 13.8e15  # plasma frequency\ngamma = 1.075e14   # damping constant\n\n# Frequency range\nwavelength = np.linspace(100, 1000, 1000)  # wavelength in nm\nc = 299792458  # speed of light in m/s\nomega = 2*np.pi*c/(wavelength*1e-9)  # angular frequency\n\n# Calculate reflectivity with and without damping\nR_with_damping = reflectivity_from_epsilon(drude_epsilon(omega, omega_p, gamma))\nR_no_damping = reflectivity_from_epsilon(drude_epsilon(omega, omega_p, 0))\n\n# Plot\nplt.figure(figsize=get_size(8, 6))\nplt.plot(wavelength, R_with_damping, 'b-', label='With damping')\nplt.plot(wavelength, R_no_damping, 'r--', label='Without damping')\nplt.xlabel('wavelength [nm]')\nplt.ylabel('reflectivity')\nplt.legend()\n\n# Add plasma wavelength\nplasma_wavelength = 2*np.pi*c/omega_p * 1e9  # convert to nm\nplt.axvline(plasma_wavelength, color='gray', linestyle=':', alpha=0.5)\nplt.text(plasma_wavelength*1.1, 0.5, r'$\\omega_p$', fontsize=10)\n\n# Add visible range\nplt.axvspan(400, 750, color='yellow', alpha=0.1)\nplt.text(575, plt.ylim()[0]+0.4, 'Visible', rotation=90)\n\nplt.tight_layout()\nplt.show()\n\n# Print some values\n#print(\"\\nWavelength (nm) | R (with damping) | R (no damping)\")\n#for i in range(0, len(wavelength), 200):\n#    print(f\"{wavelength[i]:13.1f} | {R_with_damping[i]:15.3f} | {R_no_damping[i]:12.3f}\")\n\n\n\n\n\n\n\n\nFigure 3— Comparison of metal reflectivity with and without damping. Without damping (γ = 0), the reflectivity is exactly 1 below the plasma frequency and drops sharply above it.\n\n\n\n\n\n\n\n\nTbl 2— Comparison of reflectivity (R) values with and without damping effects at different wavelengths\n\n\n\n\n\nWavelength (nm)\nR (with damping)\nR (no damping)\n\n\n\n\n100.0\n0.036\n0.036\n\n\n280.2\n0.982\n1.000\n\n\n460.4\n0.984\n1.000\n\n\n640.5\n0.984\n1.000\n\n\n820.7\n0.984\n1.000\n\n\n\n\n\n\n\n\nDispersion Relation in Metals\nTo understand how electromagnetic waves propagate in metals, we need to derive the dispersion relation. Starting from Maxwell’s equations and using the dielectric function we derived from the Drude model, we can obtain the wave equation in metals:\n\\[\n\\nabla^2\\vec{E}-\\frac{1}{c^2}\\frac{\\partial^2\\vec{E}}{\\partial t^2}=\\mu_0\\frac{\\partial\\vec{j}}{\\partial t}\n\\]\nFor a plane wave solution \\(\\vec{E}=\\vec{E}_0e^{i(kx-\\omega t)}\\), and using the relation between current density and electric field through conductivity \\(\\vec{j}=\\sigma\\vec{E}\\), we get:\n\\[\n-k^2\\vec{E}+\\frac{\\omega^2}{c^2}\\vec{E}+i\\omega\\mu_0\\sigma\\vec{E}=0\n\\]\nThis leads to the dispersion relation:\n\\[\nk^2=\\frac{\\omega^2}{c^2}\\left(1+i\\frac{\\sigma}{\\epsilon_0\\omega}\\right)=\\frac{\\omega^2}{c^2}\\epsilon_r(\\omega)\n\\]\nUsing the Drude model expression for \\(\\epsilon_r(\\omega)\\), we can write:\n\\[\nk^2=\\frac{\\omega^2}{c^2}\\left(1-\\frac{\\omega_p^2}{\\omega^2-i\\Gamma\\omega}\\right)\n\\]\nThis dispersion relation shows two important regimes:\n\nFor \\(\\omega &lt; \\omega_p\\): The wave vector \\(k\\) becomes imaginary, meaning the waves are evanescent and decay exponentially into the metal. This explains why metals are reflective at visible frequencies.\nFor \\(\\omega &gt; \\omega_p\\): The wave vector \\(k\\) is real, and electromagnetic waves can propagate through the metal. This typically occurs in the ultraviolet region for most metals.\n\nThe penetration depth (skin depth) \\(\\delta\\) of the electromagnetic wave into the metal can be calculated from the imaginary part of \\(k\\):\n\\[\n\\delta=\\frac{1}{\\text{Im}(k)}\n\\]\nThis skin depth is typically on the order of tens of nanometers in the visible region, explaining why metals are opaque even in thin films.\n\n\nCode\ndef k_metal(omega, omega_p, gamma):\n    \"\"\"Calculate complex wave vector in metal using Drude model\"\"\"\n    eps_r = 1 - omega_p**2/(omega**2 - 1j*gamma*omega)\n    return omega/c * np.sqrt(eps_r)\n\n# Constants\nc = 299792458  # speed of light in m/s\nomega_p = 13.8e15  # plasma frequency for Gold\ngamma = 1.075e14   # damping constant for Gold\n\n# Frequency range (normalized to plasma frequency)\nomega_range = np.linspace(0.1, 2*omega_p, 1000)\n\n# Calculate wave vector\nk = k_metal(omega_range, omega_p, gamma)\n\n# Create plot\nplt.figure(figsize=get_size(8,6))\nplt.plot(np.real(k)*c/omega_p, omega_range/omega_p, 'b-', label='Real(k)')\nplt.plot(np.imag(k)*c/omega_p, omega_range/omega_p, 'r-', label='Imag(k)')\nplt.plot(omega_range/omega_p, omega_range/omega_p, 'k--', label='Light line')\n\nplt.axhline(y=1, color='gray', linestyle=':', alpha=0.5)\nplt.text(0.5, 1.05, r'$\\omega_p$', fontsize=10)\n\nplt.xlabel(r'$kc/\\omega_p$')\nplt.ylabel(r'$\\omega/\\omega_p$')\nplt.legend()\nplt.grid(True, alpha=0.3)\nplt.xlim(-2, 2)\nplt.ylim(0, 2)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nFigure 4— Dispersion relation for electromagnetic waves in a metal according to the Drude model. The light line (dashed) represents the dispersion in vacuum. Note how below the plasma frequency, no propagating waves exist in the metal.\n\n\n\n\n\nThe figure above shows the dispersion relation for electromagnetic waves in a metal according to the Drude model. Several important features can be observed:\n\nBelow the plasma frequency (\\(\\omega &lt; \\omega_p\\)), the real part of \\(k\\) is zero while the imaginary part is large, indicating evanescent waves that decay exponentially into the metal.\nAbove the plasma frequency (\\(\\omega &gt; \\omega_p\\)), the real part of \\(k\\) becomes dominant, allowing wave propagation through the metal.\nThe light line (dashed) represents the dispersion relation in vacuum (\\(\\omega = ck\\)). The metal’s dispersion relation deviates significantly from this line, especially near and below the plasma frequency.\nThe presence of damping (\\(\\gamma\\)) leads to a smooth transition around \\(\\omega_p\\) rather than an abrupt change.\n\nThis behavior explains why metals are highly reflective at frequencies below the plasma frequency (typically in the visible range) but can become transparent at higher frequencies in the ultraviolet region.\nIn the simple interpretation of the Drude model, we often say that below the plasma frequency, waves cannot propagate in the metal because the dielectric function is negative. However, this is only strictly true when we ignore damping (\\(\\Gamma = 0\\)).\nWhen we include damping (\\(\\Gamma \\neq 0\\)), the dielectric function becomes complex:\n\\[\n\\epsilon_r(\\omega)=1-\\frac{\\omega_p^2}{\\omega^2-i\\Gamma \\omega}\n\\]\nIn the low-frequency limit ($&lt;&lt; _p), this becomes:\n\\[\n\\epsilon_r(\\omega) \\approx 1-\\frac{\\omega_p^2}{-i\\Gamma \\omega} \\approx -\\frac{\\omega_p^2}{-i\\Gamma \\omega} = \\frac{\\omega_p^2}{\\Gamma \\omega}i\n\\]\nThe wave vector is then:\n\\[\nk = \\frac{\\omega}{c}\\sqrt{\\epsilon_r} \\approx \\frac{\\omega}{c}\\sqrt{\\frac{\\omega_p^2}{\\Gamma \\omega}i} = \\frac{\\omega}{c}(1+i)\\sqrt{\\frac{\\omega_p^2}{2\\Gamma \\omega}}\n\\]\nThis shows that both the real and imaginary parts of \\(k\\) are non-zero and equal in magnitude in this limit. This represents a heavily damped wave that can propagate a short distance into the metal.\nThe wave in the metal has the form:\n\\[\nE(x) = E_0 e^{ikx} = E_0 e^{i\\text{Re}(k)x}e^{-\\text{Im}(k)x}\n\\]\nThe skin depth is then:\n\\[\n\\delta = \\frac{1}{\\text{Im}(k)} = \\frac{c}{\\omega}\\sqrt{\\frac{2\\Gamma \\omega}{\\omega_p^2}}\n\\]\n\n\nCode\ndef skin_depth_full(omega, omega_p, gamma):\n\n    eps_r = 1 - omega_p**2/(omega**2 - 1j*gamma*omega)\n    k = omega/c * np.sqrt(eps_r)\n    return 1/abs(np.imag(k))  # Using abs to ensure positive values\n\ndef skin_depth_low(omega, omega_p, gamma):\n    return c/omega * np.sqrt(2*gamma*omega/omega_p**2)\n\nc = 299792458\nomega_p = 13.8e15\ngamma = 1.075e14\n\nfreq = np.logspace(12, 16, 1000)  # Hz\nomega = 2*np.pi*freq\n\ndelta_full = skin_depth_full(omega, omega_p, gamma)\ndelta_low = skin_depth_low(omega, omega_p, gamma)\n\nplt.figure(figsize=get_size(8,6))\n\n#print(\"Sample values:\")\n#print(\"freq (Hz) | delta_full (nm) | delta_low (nm)\")\n#for i in range(0, len(freq), 200):\n#    print(f\"{freq[i]:.2e} | {delta_full[i]*1e9:.2f} | {delta_low[i]*1e9:.2f}\")\n\nplt.loglog(freq, delta_full*1e9, 'b-', label='Full model')\nplt.loglog(freq, delta_low*1e9, 'r--', label='Low freq. approx.')\n\nplt.xlabel(r'frequency $\\omega$ [Hz]')\nplt.ylabel('skin depth [nm]')\nplt.legend()\n\n# Add vertical line at plasma frequency\nplt.axvline(omega_p/(2*np.pi), color='gray', linestyle=':', alpha=0.5)\nplt.text(omega_p/(2*np.pi)*1.1, 4, r'$\\omega_p$', fontsize=10)\n\n# Add frequency markers for visible light\nplt.axvspan(4e14, 8e14, color='yellow', alpha=0.1)\nplt.text(5e14, plt.ylim()[0]*50, 'Visible', rotation=90)\n\nplt.ylim(1, 1e4)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nFigure 5— Skin depth as a function of frequency for a metal (Gold parameters). The dashed line shows the typical one over square root of frequency behavior at low frequencies.\n\n\n\n\n\n\n\n\nTbl 3— Penetration depth (delta) comparison between full model and low frequency approximation at different frequencies\n\n\n\n\n\nfreq (Hz)\ndelta_full (nm)\ndelta_low (nm)\n\n\n\n\n1.00e+12\n123.63\n127.08\n\n\n6.32e+12\n44.97\n50.54\n\n\n4.00e+13\n23.13\n20.10\n\n\n2.53e+14\n21.91\n8.00\n\n\n1.60e+15\n31.64\n3.18\n\n\n\n\n\n\n\n\nSkin Depth\nAt low frequencies, the skin depth can be approximated as:\n\\[\n\\delta \\approx \\sqrt{\\frac{2}{\\omega_p^2\\Gamma}}\\frac{c}{\\sqrt{\\omega}} = \\sqrt{\\frac{2}{\\sigma_0\\mu_0\\omega}}\n\\]\nwhere \\(\\sigma_0 = \\frac{\\omega_p^2\\epsilon_0}{\\Gamma}\\) is the DC conductivity. This shows the characteristic \\(\\delta \\propto 1/\\sqrt{\\omega}\\) behavior.\nSome important observations from the plot:\n\nAt low frequencies (below the plasma frequency), the skin depth follows the \\(1/\\sqrt{\\omega}\\) dependence\nFor visible light (\\(\\omega \\approx 10^{14}-10^{15} Hz\\)), the skin depth is typically tens of nanometers\nAbove the plasma frequency, the skin depth increases rapidly as the metal becomes transparent\nFor Gold at room temperature and visible frequencies, the skin depth is approximately 20-30 nm\n\nThis small skin depth explains why:\n\nThin metal films (&gt;100 nm) are opaque\nSurface effects dominate in metals at optical frequencies\nMetal nanoparticles can support localized surface plasmons\nWhy RF shielding requires only thin metal layers\n\nThe skin effect is crucial in many applications:\n\nRF and microwave engineering\nElectromagnetic shielding\nDesign of electrical conductors for AC applications\nPlasmonic devices",
    "crumbs": [
      "Electromagnetic Optics",
      "Lecture 17",
      "Electromagnetic Waves in Metals"
    ]
  },
  {
    "objectID": "electromagnetic-waves/Metals.html#plasmonics",
    "href": "electromagnetic-waves/Metals.html#plasmonics",
    "title": "Electromagnetic Waves in Metals",
    "section": "Plasmonics",
    "text": "Plasmonics\nOne of the exciting fields of research in modern optics is plasmonics. Plasmons are collective oscillations of free electrons in a metal that can interact strongly with light. These interactions lead to fascinating phenomena, such as enhanced light-matter interactions, subwavelength imaging, and sensing applications.\n\nLocalized Surface Plasmons\nIn metal nanoparticles, the confined electron oscillations create localized surface plasmons (LSPs). These are non-propagating excitations of the conduction electrons coupled to the electromagnetic field. The resonance condition depends strongly on the particle size, shape, and dielectric environment. A striking demonstration of LSPs can be observed in solutions of gold nanoparticles, where the interaction between light and the collective electron oscillations creates vivid colors.\n\n\n\n\n\n\nFigure 6— Backscattering and transmission through a 65 nm gold nanoparticle solution. The backscattering is green due to the surface plasmon resonance of the conduction band electrons, while the transmission is red, since the green light is removed by scattering.\n\n\n\n\n\nSurface Plasmon Polaritons\nSurface plasmon polaritons (SPPs) are electromagnetic excitations propagating along a metal-dielectric interface. These waves result from the coupling of the electromagnetic fields to oscillations of the conductor’s electron plasma. The dispersion relation for SPPs is given by:\n\\[\nk_{SPP} = \\frac{\\omega}{c}\\sqrt{\\frac{\\epsilon_m\\epsilon_d}{\\epsilon_m + \\epsilon_d}}\n\\]\nwhere \\(\\epsilon_m\\) and \\(\\epsilon_d\\) are the dielectric functions of the metal and dielectric, respectively. This unique dispersion relation allows SPPs to concentrate light into subwavelength volumes, enabling applications in sensing, waveguiding, and imaging beyond the diffraction limit.\n\nSurface Plasmon Polariton Sensor\nA surface plasmon polariton sensor is a device that exploits the sensitivity of SPPs to changes in the local refractive index. By monitoring the resonance condition of the SPPs, one can detect minute changes in the dielectric environment near the metal surface. This principle forms the basis of label-free biosensing, where the binding of biomolecules to the metal surface can be detected in real-time.\n\n\n\n\n\n\nFigure 7— Two different excitation schemes of surface plasmon polaritons for sensing applications. The prism coupling method (left) uses total internal reflection to excite SPPs, while the Kretschmann configuration (right) involves a thin metal film on a dielectric substrate.\n\n\n\nTo observe SPPs, one can use a prism coupling method or the Kretschmann configuration. In both cases, the resonance condition is sensitive to changes in the refractive index near the metal surface, making SPP sensors highly versatile and sensitive.\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef fresnel_rp(theta, eps1, eps2, eps3, d, k0):\n    kz1 = np.sqrt(eps1 * k0**2 - (np.sqrt(eps1) * k0 * np.sin(theta))**2 + 0j)\n    kz2 = np.sqrt(eps2 * k0**2 - (np.sqrt(eps1) * k0 * np.sin(theta))**2 + 0j)\n    kz3 = np.sqrt(eps3 * k0**2 - (np.sqrt(eps1) * k0 * np.sin(theta))**2 + 0j)\n\n    r12 = (eps2 * kz1 - eps1 * kz2)/(eps2 * kz1 + eps1 * kz2)\n    r23 = (eps3 * kz2 - eps2 * kz3)/(eps3 * kz2 + eps2 * kz3)\n\n    numerator = r12 + r23 * np.exp(2j * kz2 * d)\n    denominator = 1 + r12 * r23 * np.exp(2j * kz2 * d)\n\n    return numerator/denominator\n\n# Parameters\nwavelength = 532e-9  # green laser wavelength\nk0 = 2*np.pi/wavelength\n\n# Layer properties\neps_glass = 2.25  # glass prism\neps_air = 1.0    # air\nd = 50e-9        # 50 nm film thickness\n\n# Dielectric constants at 532 nm\neps_gold = -4.8 + 2.4j   # gold\neps_silver = -11.7 + 0.4j  # silver\n\n\ntheta_deg = np.linspace(0, 90, 1000)\ntheta_rad = theta_deg * np.pi/180\n\nRp_au = np.abs(fresnel_rp(theta_rad, eps_glass, eps_gold, eps_air, d, k0))**2\nRp_ag = np.abs(fresnel_rp(theta_rad, eps_glass, eps_silver, eps_air, d, k0))**2\n\nplt.figure(figsize=get_size(8,6))\nplt.plot(theta_deg, Rp_au, 'g-', label='Gold')\nplt.plot(theta_deg, Rp_ag, 'b-', label='Silver')\n\nplt.xlabel(r'incident angle $theta$ [°]')\nplt.ylabel('reflectivity R')\nplt.legend()\n\ntheta_c = np.arcsin(np.sqrt(eps_air/eps_glass)) * 180/np.pi\nplt.axvline(theta_c, color='gray', linestyle=':', alpha=0.5)\nplt.text(theta_c-3, 0.4, r'$\\theta_c$', fontsize=10)\n\nspr_angle_au = theta_deg[np.argmin(Rp_au)]\nspr_angle_ag = theta_deg[np.argmin(Rp_ag)]\nplt.plot(spr_angle_au, np.min(Rp_au), 'go')\nplt.plot(spr_angle_ag, np.min(Rp_ag), 'bo')\nplt.text(spr_angle_au+1, 0.4, f'Au: {spr_angle_au:.1f}°', fontsize=10)\nplt.text(spr_angle_ag-12, 0.1, f'Ag: {spr_angle_ag:.1f}°', fontsize=10)\n\nplt.ylim(0, 1)\nplt.xlim(30,70)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nFigure 8— Comparison of reflectivity versus incident angle for 50 nm gold and silver films on glass at 532 nm. Silver shows a sharper and deeper resonance due to lower losses.\n\n\n\n\n\n\n\n\nTbl 4— Comparison of surface plasmon resonance (SPR) characteristics for gold and silver films at 532 nm wavelength\n\n\n\n\n\n\n\n\n\n\n\nMetal\nSPR Angle (°)\nMinimum Reflectivity\nDielectric Constant (ε) at 532 nm\n\n\n\n\nGold\n48.6\n0.107\n-4.8 + 2.4i\n\n\nSilver\n44.2\n0.044\n-11.7 + 0.4i\n\n\n\n\n\n\n\n\n\nHistorical and Modern Applications\nThe use of plasmonic effects in materials dates back to ancient times, though the underlying physics was not understood. Perhaps the most famous example is the Lycurgus Cup from the 4th century AD. This remarkable artifact appears green in reflected light but red in transmitted light due to the presence of gold and silver nanoparticles embedded in the glass matrix.\n\n\n\n\n\n\nFigure 9— The Lycurgus Cup demonstrates the dramatic optical effects of metallic nanoparticles. When viewed in reflected light (left), the cup appears green, while in transmitted light (right), it glows ruby red due to the surface plasmon resonance of embedded gold and silver nanoparticles.\n\n\n\nModern applications of plasmonics have expanded far beyond decorative uses. Surface plasmon resonance sensors enable highly sensitive biochemical detection by monitoring changes in the local refractive index near metal surfaces. Plasmonic waveguides can guide light in dimensions far below the diffraction limit, promising applications in next-generation optical computing and telecommunications. In medicine, plasmonic nanoparticles are being developed for targeted therapy and diagnostic imaging.\nThe field of metamaterials leverages plasmonic effects to create artificial materials with properties not found in nature, such as negative refractive indices and perfect lensing. These developments continue to push the boundaries of what’s possible in optics and photonics, leading to innovations in solar energy harvesting, quantum information processing, and ultrasensitive chemical detection.",
    "crumbs": [
      "Electromagnetic Optics",
      "Lecture 17",
      "Electromagnetic Waves in Metals"
    ]
  },
  {
    "objectID": "electromagnetic-waves/Dipole Radiation.html",
    "href": "electromagnetic-waves/Dipole Radiation.html",
    "title": "Dipole Radiation",
    "section": "",
    "text": "We would like to examine the origin of electromagnetic radiation in a classical picture. Especially we would like to understand why the electromagnetic fields that are radiated are transverse to the direction of propagation. We will consider for this purpose the radiation generated by an accelerated charge."
  },
  {
    "objectID": "electromagnetic-waves/Dipole Radiation.html#electric-field-of-an-accelerated-charge",
    "href": "electromagnetic-waves/Dipole Radiation.html#electric-field-of-an-accelerated-charge",
    "title": "Dipole Radiation",
    "section": "Electric field of an accelerated charge",
    "text": "Electric field of an accelerated charge\nWe will follow for the derivation of transverse electric field the basic steps of the derivation by Larmor. We consider a charge, which is initially at rest in the point \\(O\\) as sketched below. The charge is then accelerated for a very short period \\(\\Delta t\\) to the point \\(O'\\) and reaches a final speed \\(u\\), which is small compared to the speed of light \\(u \\ll c\\). The charge then moves with that speed up to a point \\(O''\\) for a time \\(t\\).\n\n\n\n\n\n\nFigure 1— Setup of the accelerated charge.\n\n\n\nWhat will be important for our consideration is the fact that any information about a system’s change of state is limited in its propagation to the speed of light. Thus, the information that the charge \\(q\\) has been accelerated has propagated from \\(O\\) a distance \\(r=c(t+\\Delta t)\\), when the charge has reached the point \\(O''\\). The fact that the charge stopped accelerating, which is originating from point \\(O'\\) has traveled a distance \\(r'=ct\\).\nConsider now the field line of the electric field that exists outside the outer circle which would trace back to point \\(O\\). This field line has now moved with the charge and is inside the inner circle corresponding to the red line. This field line needs to be connected to the remaining part outside the outer circle, as it is the same field line. Thus the field line needs to bend accordingly in the shell between the circles as indicated by the red line.\nThe bent part of the field vector can be decomposed into a field component perpendicular (\\(E_\\perp\\)) to the direction from \\(O\\) and one parallel to this radial direction (\\(E_{||}\\)). The perpendicular component is the new thing and we would like to calculate it.\nThe ratio of perpendicular and parallel component is then given by\n\\[\n\\frac{E_{\\perp}}{E_{||}}=\\frac{u_{\\perp}t}{c\\Delta t}=\\frac{a_{\\perp}\\Delta t t }{c\\Delta t}\n\\]\nwhere the ratio of the electric fields is the same as of the velocity components. The velocity \\(u_{\\perp}\\) thereby follows directly from the component of the acceleration perpendicular to the radial direction \\(a_{\\perp}\\). The result of this calculation is then independent of the time period \\(\\Delta t\\) and we obtain\n\\[\nE_{\\perp}=\\frac{a_{\\perp}r}{c^2}E_{||}\n\\]\nwhere we replaced the time \\(t\\) by \\(t=r/c\\). To obtain \\(E_{\\perp}\\) we now need to know the value of \\(E_{\\parallel}\\), which we can obtain by Gauss’s theorem considering a “pillbox” around the boundary of the sphere emanating from \\(O\\). Since the field lines from \\(O\\) are radially outwards, this calculation yields\n\\[\nE_{\\perp}=-\\frac{a_{\\perp}}{c^2}\\frac{q}{4\\pi \\epsilon_0 r^2}=-\\frac{a_{\\perp} q}{c^24\\pi \\epsilon_0 r}\n\\]\nThis electric field that is generated is now not anymore radially pointing outwards from the source, but it is tangential to a sphere around \\(O\\). It further decays with the distance as \\(1/r\\) and not \\(1/r^2\\) as the common Coulomb field. The distance dependence is consistent with the one developed earlier for spherical waves. As we know that this electric field \\(E_{\\perp}\\) is tangential to the sphere surface we may write down the radiated field of the accelerated charge as\n\\[\n\\vec{E}(\\vec{r},t)=-\\frac{a_{\\perp}q}{c^2 4\\pi \\epsilon_0 r}\\hat{\\theta}\n\\]\nand the corresponding magnetic field as\n\\[\n\\vec{B}(\\vec{r},t)=\\frac{\\vec{E}}{c}=-\\frac{a_{\\perp}q}{c^3 4\\pi \\epsilon_0 r}\\hat{\\phi}\n\\]\nwhere \\(\\hat{\\theta}\\) and \\(\\hat{\\phi}\\) are the unit vectors along the polar and azimuthal direction.\nNote that in the above equation the electric field is observed at time \\(t\\) but the acceleration has happened a time \\(t-\\frac{r}{c}\\) earlier as it propagates with finite speed. This will finally lead to our wavelike propagation."
  },
  {
    "objectID": "electromagnetic-waves/Dipole Radiation.html#energy-flow",
    "href": "electromagnetic-waves/Dipole Radiation.html#energy-flow",
    "title": "Dipole Radiation",
    "section": "Energy flow",
    "text": "Energy flow\nWith the help of the Poynting vector\n\\[\n\\vec{S}(\\vec{r},t)=\\frac{1}{\\mu_0} \\vec{E} \\times \\vec{B}\n\\]\nwe may now have a look at the energy flow from the accelerated charge. Since the electric and the magnetic field are orthogonal we can readily obtain the magnitude of the Poynting vector\n\\[\nS(\\vec{r},t)=\\frac{a_{\\perp}^2 q^2}{\\mu_0 c^5 (4\\pi \\epsilon_0)^2 r^2}\n\\]\nfrom which now follows with \\(a_{\\perp}=a\\sin{\\theta}\\)\n\\[\nS(\\vec{r},t)=\\frac{a^2 q^2\\sin^2(\\theta)}{\\mu_0 c^5 (4\\pi \\epsilon_0)^2 r^2}\n\\]\nor\n\\[\nS(\\vec{r},t)=\\frac{a^2 q^2\\sin^2(\\theta)}{c^3 (4\\pi \\epsilon_0)^2 r^2}\n\\]\nThe total power that is then radiated by the accelerated charge is given as the integral of the Poynting vector over a closed surface around the charge, i.e.\n\\[\nP=\\int\\int S dA=\\frac{a^2 q^2\\sin^2(\\theta)}{c^3 (4\\pi \\epsilon_0)^2}\\int_0^{2\\pi}\\int_{0}^{\\pi}\\frac{\\sin^2(\\theta)}{r^2}r^2 \\sin(\\theta) d\\theta d\\phi\n\\]\nwhich upon integration finally yields Larmor’s formula\n\\[\nP=\\frac{q^2a^2}{6\\pi c^3 \\epsilon_0}\n\\]\nThis is the total radiated power of an accelerated charge."
  },
  {
    "objectID": "electromagnetic-waves/Dipole Radiation.html#oscillating-dipole",
    "href": "electromagnetic-waves/Dipole Radiation.html#oscillating-dipole",
    "title": "Dipole Radiation",
    "section": "Oscillating Dipole",
    "text": "Oscillating Dipole\nWith the previous section we are now ready to have a look at a situation where the charge is oscillating, for example, around a fixed positive charge. This situation can occur when an atom is polarized by the electric field of an incident light wave. Since this electric field is in the visible range of a wavelength much longer than the size of the atom, we may consider the atom as being in a homogeneous oscillating electric field as we did already earlier. This approximation is called the Rayleigh limit and the process is termed Rayleigh Scattering. Let’s assume the charge is oscillating at a frequency \\(\\omega\\) such that its displacement from the positive charge is\n\\[\nx=x_0 e^{i\\omega t}\n\\]\nfrom which we obtain the velocity\n\\[\n\\dot{x}=ix_0 \\omega e^{i\\omega t}\n\\]\nand finally the required acceleration\n\\[\n\\ddot{x}=a=-x_0 \\omega^{2}e^{i\\omega t}\n\\]\nThe product of charge and acceleration which enters the generated electric field can then be expressed as\n\\[\nq a=-q x_{0}\\omega^{2}e^{i\\omega t} = -p \\omega^{2}e^{i\\omega t}\n\\]\nsince the dipole moment is given by \\(p=q x_0\\). Consequently, the electric field radiated by an oscillating dipole is given by\n\\[\nE(\\vec{r},t)=-\\frac{a_{\\perp} q}{c^24\\pi \\epsilon_0 r}=\\frac{p\\omega^2 \\sin^2(\\theta)}{c^2 4\\pi\\epsilon_0 r}e^{i\\omega t}\n\\]\nThe direction of the electric and also the magnetic field can now be constructed with the appropriate unit vector in the radial direction as well as the direction of the dipole moment \\(\\vec{p}\\). The perpendicular component of the dipole moment including its direction is given by \\((\\hat{e}_r\\times \\vec{p})\\times \\hat{e}_r\\) such that we obtain the electric and magnetic field in its vectorial beauty\n\\[\\begin{eqnarray}\n\\vec{E}(\\vec{r},t) & = &\\frac{\\omega^2}{4\\pi \\epsilon_0 c^2 r}(\\hat{e}_r\\times \\vec{p})\\times \\hat{e}_r e^{i(k r - \\omega t)}\\\\\n\\vec{B}(\\vec{r},t) & = &\\frac{\\omega^2}{4\\pi \\epsilon_0 c r}(\\hat{e}_r\\times \\vec{p}) e^{i(k r - \\omega t)}\n\\end{eqnarray}\\]\nThis corresponds to the radiated field of an oscillating dipole at large distances (\\(r \\gg \\lambda\\)), which is called the far field. In the near field, there are additional components of the electric field which are not propagating and quickly decaying. The total electric field of an oscillating dipole is given by\n\\[\n\\vec{E}(\\vec{r},t)=\\frac{\\omega^3}{4\\pi \\epsilon_0 c^3} \\left [ ((\\hat{e}_r\\times \\vec{p})\\times \\hat{e}_r)\\frac{1}{k r}+3(\\hat{e}_r(\\hat{e}_r\\cdot \\vec{p})-\\vec{p})\\left(\\frac{1}{(k r)^3}-\\frac{i}{(kr)^2} \\right)\\right] e^{i(kr -i \\omega t)}\n\\]\nWith the help of the dipole field we thus obtain the intensity radiated by an oscillating dipole at\n\\[\nI(\\theta)=\\frac{\\omega^4|\\vec{p}|^2}{32\\pi^2 \\epsilon_0 c^3}(1-\\cos^2(\\theta))\n\\]\nand the radiated power is given by\n\\[\nP=\\frac{\\omega^4 |\\vec{p}|^2}{12\\pi \\epsilon_0 c^3}=\\left (\\frac{2\\pi}{\\lambda}\\right )^4\\frac{c|\\vec{p}|^2}{12\\pi \\epsilon_0}\n\\tag{radiated power of an oscillating dipole}\n\\]\nAs frequencies are not as intuitive in our daily color language, we have converted that expression to contain the wavelength of light, which tells us that the power radiated scales with the inverse of the wavelength to the power of four. This means for visible light that blue light is scattered much stronger than red light.\nThis \\(\\lambda^{-4}\\) dependence, known as Rayleigh scattering, explains why the sky appears blue during the day. As sunlight travels through the atmosphere, it encounters molecules much smaller than its wavelength. These molecules scatter blue light (\\(\\lambda \\approx 450\\, nm\\)) about 10 times more strongly than red light (\\(\\lambda \\approx 700\\, nm\\)), causing the sky’s characteristic blue color.\nThe same effect explains why sunsets appear red. When the Sun is near the horizon, sunlight travels through more atmosphere to reach our eyes, approximately through a path length \\(L \\propto 1/\\cos{\\theta}\\), where \\(\\theta\\) is the angle from the zenith. The increased scattering of blue light along this longer path, following \\(I \\propto L\\lambda^{-4}\\), leaves primarily red wavelengths to travel directly to the observer.\nThis fundamental process governs not only our sky’s appearance but can also be observed in other natural phenomena. For instance, scattered light in colloidal suspensions follows the same wavelength dependence when the scattering particles are much smaller than the wavelength of light (\\(d \\ll \\lambda\\)), creating similar color effects in smoke and certain liquids.\n\n\n\n\n\n\nMie Scattering and Complex Materials\n\n\n\n\n\nWhen particles become comparable to or larger than the wavelength of light (\\(d \\geq \\lambda\\)), Rayleigh scattering no longer adequately describes the physics. In this regime, Mie scattering becomes dominant. For a dielectric sphere with relative permittivity \\(\\epsilon_r\\), the scattered intensity can be expressed as a series solution to Maxwell’s equations:\n\\[I(\\theta) = \\frac{\\lambda^2}{4\\pi^2r^2}(|S_1(\\theta)|^2 + |S_2(\\theta)|^2)\\]\nwhere \\(S_1\\) and \\(S_2\\) are complex scattering amplitudes containing Bessel functions and Legendre polynomials. The size parameter \\(x = 2\\pi r/\\lambda\\) and the relative refractive index \\(m = \\sqrt{\\epsilon_r}\\) determine the scattering behavior. For dielectric particles, \\(m\\) is real, leading to primarily directive scattering. The scattering cross-section \\(\\sigma\\) for intermediate-sized dielectric particles can be approximated as:\n\\[\\sigma \\approx \\pi r^2 \\left(2 - \\frac{4}{x}\\sin{x} + \\frac{4}{x^2}(1-\\cos{x})\\right)\\]\nModern materials engineering has extended these concepts to metamaterials, where engineered structures create effective medium properties not found in nature. For these materials, both \\(\\epsilon_r\\) and the relative permeability \\(\\mu_r\\) can be complex and frequency-dependent:\n\\[\\epsilon_r(\\omega) = 1 - \\frac{\\omega_p^2}{\\omega^2 + i\\gamma\\omega}, \\quad \\mu_r(\\omega) = 1 - \\frac{F\\omega^2}{\\omega^2 - \\omega_0^2 + i\\gamma\\omega}\\]\nHere, \\(\\omega_p\\) is the plasma frequency, \\(\\omega_0\\) the resonance frequency, and \\(\\gamma\\) the damping factor. These materials can exhibit negative refractive indices or epsilon-near-zero behavior, leading to unusual scattering patterns and applications in perfect lenses or electromagnetic cloaking. The Mie theory has been extended to these cases by allowing complex values of \\(m\\), though the mathematical framework remains similar.\nThis generalized theory explains phenomena ranging from atmospheric optics to the design of nanophotonic devices and metamaterial-based sensors. The interaction between light and matter becomes particularly intricate when dealing with plasmonic materials or structures with engineered electromagnetic responses."
  },
  {
    "objectID": "electromagnetic-waves/Polarization of EM Waves.html",
    "href": "electromagnetic-waves/Polarization of EM Waves.html",
    "title": "Polarization of EM Waves",
    "section": "",
    "text": "The vectorial nature of electric and magnetic fields are the new property that we inserted into our description of wave propagation. Elecric and magnetic fields, while propagating along a certain direction, have a specific direction in the lab frame, which can change over time in specific ways. This stationary state of the direcion of the elecric field vector is termed polarization. You may also use teh magnetic field to define polarization, by commonly this is done using the electric field direction.\nWe differentiate between different states of polarization, e.g. linear, circular, elliptical polarization. But we may, depending on the properties of the light source also have unpolarized light.\nThe polarization of light is important for many applications including for example 3D cinema or TV. The polarization state is commonly changed when light interacts with matter, therefore polarization is also a very important tool to characterize materials. For example, the technique of ellipsometry is studying the polarization state of light reflected from a material therby gaining important information about the electronic properties of the material. This is an important tool on solid-state physics. The polarization of light is also important for interence as two wave of orthogonal directions of the elecric field cannot interference (please check this idea yourself). It can be also used to encode information for quantum cryptography.\nIn the following sections we will shortly define these different polarization states.",
    "crumbs": [
      "Electromagnetic Optics",
      "Lecture 12",
      "Polarization of EM Waves"
    ]
  },
  {
    "objectID": "electromagnetic-waves/Polarization of EM Waves.html#linearly-polarized-waves",
    "href": "electromagnetic-waves/Polarization of EM Waves.html#linearly-polarized-waves",
    "title": "Polarization of EM Waves",
    "section": "Linearly Polarized Waves",
    "text": "Linearly Polarized Waves\nLight is called linearly polarized if the electric field vector oscillates in a single plane during light propagation. The picture below, which we introduced earlier for a plane wave shows such a linearly polarized wave.\n\nWe can generalize this description a bit more. Our plane wave shall be given by\n\\[\n\\vec{E}=\\vec{E}_0e^{i(\\omega t-kz)}\n\\]\nThe wave propagates along the z-direction. The polarization is given by the vector \\(\\vec{E}_0\\). This vector can be split into its components along the x- and the y-direction\n\\[\n\\vec{E}_0=E_{0x}\\hat{e}_x+E_{oy}\\hat{e}_y\n\\]\nFor a linearly polarized elecromagnetic wave, the magnitude of \\(E_{0x}\\) and \\(E_{0y}\\) are fixed over time, such that the angle of the electric field vector with the x-axis, for example, is fixed in time. This also requires that the phase of the total electric field components is the same, i.e.\n\\[\\begin{eqnarray}\nE_{x}&=&E_{0x}e^{i(\\omega t-kz)}\\\\\nE_{y}&=&E_{0y}e^{i(\\omega t-kz)}\\\\\n\\end{eqnarray}\\]\nThe linear polarization state, independent of the polarization direction is also called \\(\\pi\\)-polarization. We will use this term later in the description of light-atom interaction.",
    "crumbs": [
      "Electromagnetic Optics",
      "Lecture 12",
      "Polarization of EM Waves"
    ]
  },
  {
    "objectID": "electromagnetic-waves/Polarization of EM Waves.html#circularly-polarized-waves",
    "href": "electromagnetic-waves/Polarization of EM Waves.html#circularly-polarized-waves",
    "title": "Polarization of EM Waves",
    "section": "Circularly Polarized Waves",
    "text": "Circularly Polarized Waves\nIn circular polarized light, the end of the electric field vector describe a circle around the propagation direction. This means the elecric field vector is rotating around the propagation direction.\n\nTo obtain circularly polarized light we can consider our two polarization components again but with an additional phase shift of \\(\\pm\\pi/2\\) of one of the components (here the y-component) together with constraining the amplitude of the components to teh same value.\n\\[\\begin{eqnarray}\nE_{x}&=&E_{0x}e^{i(\\omega t-kz)}\\\\\nE_{y}&=&E_{0y}e^{i(\\omega t-kz\\pm\\frac{\\pi}{2})}\\\\\nE_{0y}&=&E_{0x}\n\\end{eqnarray}\\]\nThe consequence of that additional phase shift of one component is, that \\(E_y\\) reaches its maximum amplitude at a different position \\(z\\), when keeping the time fixed, i.e. making a snapshot. If \\(z\\) is fixed, the above formulas describe a rotation of the electric field around the direction of \\(\\vec{k}\\) (here z-direction). The third equation ensures that during rotation the magnitude of the electric field vector is unchanged und thus the end of the electric field vectors describes a circle (bottom row of figure) around the direction of propagation.\nRight circularly polarized light is also known as \\(\\sigma^{+}\\) polarization, while left circularly polarized light is \\(\\sigma_{-}\\) polarization.",
    "crumbs": [
      "Electromagnetic Optics",
      "Lecture 12",
      "Polarization of EM Waves"
    ]
  },
  {
    "objectID": "electromagnetic-waves/Polarization of EM Waves.html#elliptically-polarized",
    "href": "electromagnetic-waves/Polarization of EM Waves.html#elliptically-polarized",
    "title": "Polarization of EM Waves",
    "section": "Elliptically Polarized",
    "text": "Elliptically Polarized\nIf both components of the electric field carry an additional phase delay \\(\\delta_1\\) and \\(\\delta_2\\) and both component amplitudes are different \\(E_0x\\neq E_0y\\), then we find elliptically polarized light\n\\[\\begin{eqnarray}\nE_{x}&=&E_{0x}e^{i(\\omega t-kz+\\delta_1)}\\\\\nE_{y}&=&E_{0y}e^{i(\\omega t-kz+\\delta_2)}\\\\\nE_{0y}&\\neq&E_{0x}\n\\end{eqnarray}\\]\nwhich means that the end point of the electric field vector describes an ellipse around the propagation direction.\n\nThe ellipse is then described by\n\\[\n\\frac{E_x(z,t)^2}{E_{0x}^2}+\\frac{E_y(z,t)^2}{E_{0y}^2}-\\frac{2E_{x}(z,t)E_y(z,t)}{E_{0x}E_{0y}}\\cos(\\delta)=\\sin^2(\\delta)\n\\]\nwhere \\(\\delta=\\delta_2-\\delta_1\\). The ellipse is in general not oriented along a specific axis but has an angle \\(\\Psi\\) with the x-axis, which is fixed in time. This angle can be calculated by\n\\[\n\\tan(2\\Psi)=\\frac{2E_{0x}E_{0y}}{E^2_{0x}-E_{0y}^2}\\cos(\\delta)\n\\]\nThe circular polarized state is a special case of the elliptically polarized state of light.",
    "crumbs": [
      "Electromagnetic Optics",
      "Lecture 12",
      "Polarization of EM Waves"
    ]
  },
  {
    "objectID": "electromagnetic-waves/Polarization of EM Waves.html#unpolarized-light",
    "href": "electromagnetic-waves/Polarization of EM Waves.html#unpolarized-light",
    "title": "Polarization of EM Waves",
    "section": "Unpolarized Light",
    "text": "Unpolarized Light\nUnpolarized light is obtained when the electric field vector fluctuates in polarization statistically.",
    "crumbs": [
      "Electromagnetic Optics",
      "Lecture 12",
      "Polarization of EM Waves"
    ]
  },
  {
    "objectID": "electromagnetic-waves/Polarization of EM Waves.html#analyzing-polarization",
    "href": "electromagnetic-waves/Polarization of EM Waves.html#analyzing-polarization",
    "title": "Polarization of EM Waves",
    "section": "Analyzing Polarization",
    "text": "Analyzing Polarization\nThe polarization state of light is analyzed with the help of polarizers. These can be thin polymeric films, where the order of the polymer chain in the film provides a preferential axis or polarizers can also be made of other birefringent materials like Mica, for example. Those materials are called anisotropic as they have a refractive index, which depends on the direction of the electric field in the material. Depending on the design of the polarizer, you may generate linearly polarized light, you may change the polarization direction or even create circularly polarized light. We will cover aisotropic materials in a later lecture.\n\nIn mathematical terms, a linear polarizer projects the electric field vector to a specific direction. If \\(\\vec{E}(z,t)\\) is our electric field vector of the electromagnetic wave and \\(\\hat{e}_{p}\\) is the unit vector in the polarization direction the resulting electric field after the light has trasmitted through the polarizer is given by\n\\[\n\\vec{E}_t(z,t)=(\\vec{E}(z,t)\\cdot \\hat{e}_p)\\hat{e}_p=E(z,t)\\cos(\\theta)\\hat{e}_p\n\\]\nwhere \\(\\theta\\) is the angle between the electric field vector and the polarizers orientation. This means the the intensity of a linearly polarized wave transmitted through a linear polarizer only disappears if polarizer and electric field are orthogonal (\\(\\theta=90{^\\circ}\\))\n\nLaw of Malus\nThe above description is also the essence of the Law of Malus, which concerns the transmission intensity. Taking the magnitude square of the left and the right side of the above equation yields\n\\[\nI_t=I_0\\cos^2(\\theta)\n\\]\nIf follows that the intensity drops to \\(50\\) %, when we adjust an angle of \\(45^{\\circ}\\). As soon as we have a lecture in the lecture hall again, we will have a look at some nice demonstrations that illustrate Malu’s law similar to the picture below.",
    "crumbs": [
      "Electromagnetic Optics",
      "Lecture 12",
      "Polarization of EM Waves"
    ]
  },
  {
    "objectID": "test.html",
    "href": "test.html",
    "title": "Proof that a Mirror Must Have a Parabolic Shape",
    "section": "",
    "text": "We would like to show in the following, that a parabolic mirror is a shape which reflects all light rays parallel to the principal axis to a single point, the focus. This is a fundamental property of parabolic mirrors and is used in many optical systems, such as telescopes, satellite dishes, and car headlights.\nFor this purpose, we would like to use Fermat’s principle. We examine a light ray originating from a point \\(x,y_0\\) and travelling parallel to the principal axis. The light ray is reflected at a point \\((x,y)\\) on the mirror and travels to the focus at \\((0,p)\\). The light path is therefore consisting out of two linear segments \\(A\\) and \\(B\\) for which we have to calculate the time of travel. The total duration of the light’s journey is then: \\[\nt = t_A + t_B\n\\]\nwhere:\n\n\\(t_A\\) is the time taken to travel from \\(x,y_0\\) to the mirror.\n\\(t_B\\) is the time taken to travel from \\((x,y)\\) to \\((0,p)\\).\n\n\nTime for Path A\nThe distance covered in path A is equal to \\(y_0 - y\\), where \\(y\\) represents the y-coordinate of the point where the ray meets the mirror. Consequently, the time taken for the light to traverse path A can be expressed as:\n\\[\nt_A = \\frac{y_0 - y}{c}\n\\]\nIn this equation, \\(c\\) represents the speed of light in the medium.\n\n\nTime for Path B\nAfter reflection, the light ray travels from the point \\((x, y)\\) on the mirror’s surface to the focal point located at \\((0, p)\\). The length of this segment of the path can be calculated using the distance formula:\n\\[\n\\sqrt{x^2 + (y - p)^2}\n\\]\nConsequently, the time required for the light to traverse path B is expressed as:\n\\[\nt_B = \\frac{\\sqrt{x^2 + (y - p)^2}}{c}\n\\]\n\n\nTotal Time\nThe total time for the light ray’s journey is the sum of times for paths A and B:\n\\[\nt = \\frac{y_0 - y}{v} + \\frac{\\sqrt{x^2 + (y - p)^2}}{c}\n\\]\nAccording to Fermat’s principle, all light rays should take the same time. We can express this by setting the total time equal to a constant \\(t_c\\):\n\\[\n\\frac{y_0 - y}{v} + \\frac{\\sqrt{x^2 + (y - p)^2}}{v} = t_c\n\\]\nFor a ray traveling along the y-axis, reflecting at \\((0, 0)\\), the total distance is \\(y_0 + p\\). The time for this ray is:\n\\[\n\\frac{y_0 + p}{c}\n\\]\nThis gives us \\(t_c = \\frac{y_0 + p}{c}\\). Substituting into our general equation:\n\\[\n\\frac{y_0 - y}{v} + \\frac{\\sqrt{x^2 + (y - p)^2}}{c} = \\frac{y_0 + p}{c}\n\\]\nMultiplying by \\(c\\) and rearranging:\n\\[\ny_0 - y + \\sqrt{x^2 + (y - p)^2} = y_0 + p\n\\]\n\\[\n\\sqrt{x^2 + (y - p)^2} = y + p\n\\]\nSquaring both sides and simplifying:\n\\[\nx^2 + (y - p)^2 = (y + p)^2\n\\]\n\\[\nx^2 + y^2 - 2py + p^2 = y^2 + 2py + p^2\n\\]\n\\[\nx^2 = 4py\n\\]\nor\n\\[\ny=\\frac{1}{4p}x^2\n\\]\nThis final equation describes a parabola with its focus at \\((0, p)\\).\nMatrix Representation For a thin lens of focal length f, the matrix is:\n\\[M_{thin} = \\begin{bmatrix} 1 & 0 \\\\ -1/f & 1 \\end{bmatrix}\\]\nEquivalent Thin Lens: We want our thick lens matrix to be equivalent to a thin lens sandwiched between two translations:\n\\[\\begin{bmatrix} 1 & -H' \\\\ 0 & 1 \\end{bmatrix}\n   \\begin{bmatrix} 1 & 0 \\\\ -1/f & 1 \\end{bmatrix}\n   \\begin{bmatrix} 1 & H \\\\ 0 & 1 \\end{bmatrix}\n   = \\begin{bmatrix} A & B \\\\ C & D \\end{bmatrix}\\]"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "geometrical-optics/Microscope.html",
    "href": "geometrical-optics/Microscope.html",
    "title": "Optical Instruments",
    "section": "",
    "text": "Historical Context of Microscope Development\n\n\n\n\n\nOptical Microscopy has a rich history of development, and is a very important tool in the fields of biology, materials science, and nanotechnology. Here are some key milestones in the history of microscopy:\nAncient Times - 13th Century: Simple magnifying glasses - The concept of magnification was known to ancient civilizations. - In the 13th century, Italian craftsmen created the first wearable glasses.\n1590: Compound Microscope - Hans and Zacharias Janssen, Dutch spectacle makers, created the first compound microscope.\n1665: Robert Hooke’s “Micrographia” - Hooke published detailed observations made with his improved compound microscope. - He coined the term “cell” after observing cork tissue.\n1670s: Antonie van Leeuwenhoek’s Single-Lens Microscopes - Developed high-quality single-lens microscopes with up to 270x magnification. - First to observe and describe bacteria, yeast, and other microorganisms.\n\n\n\nImage of Leeuwenhoek’s microscope\n\n\n18th-19th Centuries: Achromatic Lenses - Joseph Jackson Lister developed achromatic lenses, reducing chromatic aberration.\n1830s: Ernst Abbe’s Theoretical Work - Formulated the Abbe Sine Condition, crucial for modern lens design.\nLate 19th Century: Oil Immersion Lenses - Allowed for higher resolution in light microscopy.\n1931: Electron Microscope - Ernst Ruska and Max Knoll developed the first electron microscope.\n1950s-1960s: Phase Contrast and Fluorescence Microscopy - Frits Zernike invented phase contrast microscopy. - Development of fluorescence microscopy techniques.\n1981: Scanning Tunneling Microscope - Gerd Binnig and Heinrich Rohrer invented the STM, allowing imaging at the atomic level.\n1980s-Present: Digital and Computational Microscopy - Integration of CCD cameras and digital imaging. - Development of confocal microscopy, super-resolution techniques, and computational methods like ptychography.\n\n\n\nIn this section we will analyze the optical properties of microscopes from the perspective of geometrical optics which explains image formation. Yet, the key to the performance of a microscope is the understanding provided by wave optics. We will discuss this in a later section. The simplest form of a microscope consists of an objective lens with a focal distance \\(f_1\\) and a magnifying glass called eye-piece with a focal length \\(f_2\\). In this system of two lenses (which are itself systems of lenses in modern microscopes, see below),\n\n\n\nFig.: Cut through a microscope objective lens (left) and an eye-piece.\n\n\nthe object is placed at a distance \\(f_1&lt; a_1&lt;2f_1\\) from the objective lens creating a real and reversed image at a distance \\(b_1\\) behind the lens. This reversed image is observed by the eye through the eye-piece. The image of the objective lens is thereby adjusted to appear at the focal distance of the eye-piece.\n\n\n\nFig.: Sketch of a simple microscope. The strange object on the right is an eye.\n\n\nFor this simple microscope system we may calculate first the intermediate image position \\(b_1\\):\n\\[\n\\frac{1}{f_1}=\\frac{1}{a_1}+\\frac{1}{b_1}\n\\]\nresulting in\n\\[\nb_1=\\frac{a_1 f_1}{a_1-f_1}.\n\\]\nIf we assume a \\(\\delta\\) to be the distance of the object from the focal point of the objective lens, we even find for \\(\\delta \\rightarrow 0\\)\n\\[\nb_1=\\frac{a_1 f_1}{\\delta}.\n\\]\nThe intermediate image of size \\(B_1\\) is now imaged by a magnifying glass of focal distance \\(f_2\\). According to what we calculated earlier, we have now the observation angle\n\\[\n\\tan(\\epsilon)=\\frac{B_1}{f_2}=\\frac{Ab_1}{a_1 f_2}.\n\\]\nIf we observe the object of a size \\(A\\) and the clear visual distance \\(s_0\\), it would cover an angle of\n\\[\n\\tan(\\epsilon_0)=\\frac{A}{s_0}\n\\]\nand we may obtain the total angular magnification\n\\[\nV=\\frac{A b_1 s_0}{A a_1 f_2}=\\frac{b_1 s_0}{a_1 f_2}.\n\\]\nIf we set the distance between the two lenses to \\(D=b_1+f_2\\) and \\(a_1\\approx f_1\\) then we obtain\n\\[\nV=\\frac{(D-f_2)s_0}{f_1 f_2}\n\\]\nwhich says that the magnification is the result of the two focal length \\(f_1,f_2\\).\n\n\nWhile the description above accurately represents the simplest microscope design, contemporary microscopes employ more intricate light paths and generally utilize what is known as infinity corrected optics. This system incorporates an objective lens that projects images of objects in the focal plane to infinity. Such an objective lens is invariably paired with a secondary lens, called the tube lens. Together, these lenses are engineered to provide a magnification level that is specified on the objective lens housing.\n\n\n\nFig.: Infinity optics vs. normal microscopy optics.\n\n\nInfinity optics allows you to have a free length with a parallel optical path where you can insert optical elements. There is no fixed tube length as in the case sketched above, where the distance of the intermediate image has to be considered. Therefore, it has tremendous technical advantages. Common optical microscopes are further today coupled to CCD cameras to record images digitally. Yet, an eye-piece may still be available in many cases. The sketch below shows the light path for a simple fluorescence microscope recording fluorescence images with a camera.\n\n\n\nFig.: Simple fluorescence microscope.\n\n\n\n\n\nThe possibility to digitally record images creates endless possibilities to computationally enhance and combine images. Nowadays the field of optics is one of the fastest developing fields in physics with numerous new techniques appearing every week. In this field of imaging methods of machine learning also play an increasingly important role. While I’m not ablields in physics with numerous new techniques appearing every week. In this field of imaging methods of machine learning also play an increasingly important role. While I am not able to refer to all possible optical microscopy techniques he to refer to all possible optical microscopy techniques here, I will exemplarily show some data from the Waller group at Berkley using computational methods to enhance the resolution by keeping at the same time a large field of view for imaging. This technique is called ptychography and can be understood if you consider Fourier Optics (a field of optics describing ligh propagation in terms Fourier transforms).\n\n\n\nFig.: Ptychographic imaging with LED arrays.\n\n\nThere is a massive amount of other techniques with increadible images being generated. Have a look around.\n\n\n\n\n\n\nAdvanced Microscopy Techniques\n\n\n\n\n\nWhile traditional light microscopy has been invaluable, it’s limited by the diffraction of light, restricting resolution to about 200 nm as will be discussed in a later part of this course. Modern techniques have pushed beyond this limit, revolutionizing our ability to visualize microscopic structures.\n\n\n\nSuper resolution Imaging Methods Overview (Schermelleh, L. et al. Super-resolution microscopy demystified. Nat. Cell Biol. 21, 72–84 (2019))\n\n\n\n\nConfocal microscopy uses point illumination and a pinhole in an optically conjugate plane in front of the detector to eliminate out-of-focus signal.\n\n\n\nConfocal Microscope.\n\n\n\nKey Features:\n\nImproved optical resolution and contrast\nAbility to collect serial optical sections from thick specimens\nWidely used in biological sciences\n\nOvercoming Limitations:\n\nEliminates background information away from the focal plane\nAllows for 3D reconstruction of samples\n\n\n\n\n\nSuper-resolution techniques bypass the diffraction limit, achieving resolutions down to tens of nanometers.\n\nStimulated Emission Depletion (STED) Microscopy\n\nUses two laser beams: one to excite fluorescent molecules, another to suppress fluorescence around the excitation spot\nOvercoming Limitations: Achieves resolution as fine as 20-50 nm by precisely controlling which fluorophores are allowed to fluoresce\n\nPhotoactivated Localization Microscopy (PALM)\n\nRelies on selective activation and sampling of sparse subsets of photoactivatable fluorescent molecules\nOvercoming Limitations: Locates individual molecules with nanometer precision by isolating their signals over time\n\nStochastic Optical Reconstruction Microscopy (STORM)\n\nSimilar to PALM, but uses photoswitchable fluorophores\nOvercoming Limitations: Achieves resolutions of ~20 nm by precisely locating the centers of single fluorescent molecules\n\nStructured Illumination Microscopy (SIM)\n\nUses patterned illumination to create moiré fringes, which are computationally processed to reconstruct super-resolution images\nOvercoming Limitations: Doubles the resolution of traditional light microscopy to ~100 nm\n\nSuperresolution Photothermal Infrared Imaging\n\nSuperresolution photothermal infrared imaging is a novel technique that brings the advantages of superresolution microscopy to the infrared regime.\nOvercoming Limitations: Achieves resolutions of ~300 nm for infrared imaging at wavelength of 10 µm by using photothermal lensing effects.",
    "crumbs": [
      "Geometrical Optics",
      "Lecture 5",
      "Optical Instruments- Microscope"
    ]
  },
  {
    "objectID": "geometrical-optics/Microscope.html#microscope",
    "href": "geometrical-optics/Microscope.html#microscope",
    "title": "Optical Instruments",
    "section": "",
    "text": "Historical Context of Microscope Development\n\n\n\n\n\nOptical Microscopy has a rich history of development, and is a very important tool in the fields of biology, materials science, and nanotechnology. Here are some key milestones in the history of microscopy:\nAncient Times - 13th Century: Simple magnifying glasses - The concept of magnification was known to ancient civilizations. - In the 13th century, Italian craftsmen created the first wearable glasses.\n1590: Compound Microscope - Hans and Zacharias Janssen, Dutch spectacle makers, created the first compound microscope.\n1665: Robert Hooke’s “Micrographia” - Hooke published detailed observations made with his improved compound microscope. - He coined the term “cell” after observing cork tissue.\n1670s: Antonie van Leeuwenhoek’s Single-Lens Microscopes - Developed high-quality single-lens microscopes with up to 270x magnification. - First to observe and describe bacteria, yeast, and other microorganisms.\n\n\n\nImage of Leeuwenhoek’s microscope\n\n\n18th-19th Centuries: Achromatic Lenses - Joseph Jackson Lister developed achromatic lenses, reducing chromatic aberration.\n1830s: Ernst Abbe’s Theoretical Work - Formulated the Abbe Sine Condition, crucial for modern lens design.\nLate 19th Century: Oil Immersion Lenses - Allowed for higher resolution in light microscopy.\n1931: Electron Microscope - Ernst Ruska and Max Knoll developed the first electron microscope.\n1950s-1960s: Phase Contrast and Fluorescence Microscopy - Frits Zernike invented phase contrast microscopy. - Development of fluorescence microscopy techniques.\n1981: Scanning Tunneling Microscope - Gerd Binnig and Heinrich Rohrer invented the STM, allowing imaging at the atomic level.\n1980s-Present: Digital and Computational Microscopy - Integration of CCD cameras and digital imaging. - Development of confocal microscopy, super-resolution techniques, and computational methods like ptychography.\n\n\n\nIn this section we will analyze the optical properties of microscopes from the perspective of geometrical optics which explains image formation. Yet, the key to the performance of a microscope is the understanding provided by wave optics. We will discuss this in a later section. The simplest form of a microscope consists of an objective lens with a focal distance \\(f_1\\) and a magnifying glass called eye-piece with a focal length \\(f_2\\). In this system of two lenses (which are itself systems of lenses in modern microscopes, see below),\n\n\n\nFig.: Cut through a microscope objective lens (left) and an eye-piece.\n\n\nthe object is placed at a distance \\(f_1&lt; a_1&lt;2f_1\\) from the objective lens creating a real and reversed image at a distance \\(b_1\\) behind the lens. This reversed image is observed by the eye through the eye-piece. The image of the objective lens is thereby adjusted to appear at the focal distance of the eye-piece.\n\n\n\nFig.: Sketch of a simple microscope. The strange object on the right is an eye.\n\n\nFor this simple microscope system we may calculate first the intermediate image position \\(b_1\\):\n\\[\n\\frac{1}{f_1}=\\frac{1}{a_1}+\\frac{1}{b_1}\n\\]\nresulting in\n\\[\nb_1=\\frac{a_1 f_1}{a_1-f_1}.\n\\]\nIf we assume a \\(\\delta\\) to be the distance of the object from the focal point of the objective lens, we even find for \\(\\delta \\rightarrow 0\\)\n\\[\nb_1=\\frac{a_1 f_1}{\\delta}.\n\\]\nThe intermediate image of size \\(B_1\\) is now imaged by a magnifying glass of focal distance \\(f_2\\). According to what we calculated earlier, we have now the observation angle\n\\[\n\\tan(\\epsilon)=\\frac{B_1}{f_2}=\\frac{Ab_1}{a_1 f_2}.\n\\]\nIf we observe the object of a size \\(A\\) and the clear visual distance \\(s_0\\), it would cover an angle of\n\\[\n\\tan(\\epsilon_0)=\\frac{A}{s_0}\n\\]\nand we may obtain the total angular magnification\n\\[\nV=\\frac{A b_1 s_0}{A a_1 f_2}=\\frac{b_1 s_0}{a_1 f_2}.\n\\]\nIf we set the distance between the two lenses to \\(D=b_1+f_2\\) and \\(a_1\\approx f_1\\) then we obtain\n\\[\nV=\\frac{(D-f_2)s_0}{f_1 f_2}\n\\]\nwhich says that the magnification is the result of the two focal length \\(f_1,f_2\\).\n\n\nWhile the description above accurately represents the simplest microscope design, contemporary microscopes employ more intricate light paths and generally utilize what is known as infinity corrected optics. This system incorporates an objective lens that projects images of objects in the focal plane to infinity. Such an objective lens is invariably paired with a secondary lens, called the tube lens. Together, these lenses are engineered to provide a magnification level that is specified on the objective lens housing.\n\n\n\nFig.: Infinity optics vs. normal microscopy optics.\n\n\nInfinity optics allows you to have a free length with a parallel optical path where you can insert optical elements. There is no fixed tube length as in the case sketched above, where the distance of the intermediate image has to be considered. Therefore, it has tremendous technical advantages. Common optical microscopes are further today coupled to CCD cameras to record images digitally. Yet, an eye-piece may still be available in many cases. The sketch below shows the light path for a simple fluorescence microscope recording fluorescence images with a camera.\n\n\n\nFig.: Simple fluorescence microscope.\n\n\n\n\n\nThe possibility to digitally record images creates endless possibilities to computationally enhance and combine images. Nowadays the field of optics is one of the fastest developing fields in physics with numerous new techniques appearing every week. In this field of imaging methods of machine learning also play an increasingly important role. While I’m not ablields in physics with numerous new techniques appearing every week. In this field of imaging methods of machine learning also play an increasingly important role. While I am not able to refer to all possible optical microscopy techniques he to refer to all possible optical microscopy techniques here, I will exemplarily show some data from the Waller group at Berkley using computational methods to enhance the resolution by keeping at the same time a large field of view for imaging. This technique is called ptychography and can be understood if you consider Fourier Optics (a field of optics describing ligh propagation in terms Fourier transforms).\n\n\n\nFig.: Ptychographic imaging with LED arrays.\n\n\nThere is a massive amount of other techniques with increadible images being generated. Have a look around.\n\n\n\n\n\n\nAdvanced Microscopy Techniques\n\n\n\n\n\nWhile traditional light microscopy has been invaluable, it’s limited by the diffraction of light, restricting resolution to about 200 nm as will be discussed in a later part of this course. Modern techniques have pushed beyond this limit, revolutionizing our ability to visualize microscopic structures.\n\n\n\nSuper resolution Imaging Methods Overview (Schermelleh, L. et al. Super-resolution microscopy demystified. Nat. Cell Biol. 21, 72–84 (2019))\n\n\n\n\nConfocal microscopy uses point illumination and a pinhole in an optically conjugate plane in front of the detector to eliminate out-of-focus signal.\n\n\n\nConfocal Microscope.\n\n\n\nKey Features:\n\nImproved optical resolution and contrast\nAbility to collect serial optical sections from thick specimens\nWidely used in biological sciences\n\nOvercoming Limitations:\n\nEliminates background information away from the focal plane\nAllows for 3D reconstruction of samples\n\n\n\n\n\nSuper-resolution techniques bypass the diffraction limit, achieving resolutions down to tens of nanometers.\n\nStimulated Emission Depletion (STED) Microscopy\n\nUses two laser beams: one to excite fluorescent molecules, another to suppress fluorescence around the excitation spot\nOvercoming Limitations: Achieves resolution as fine as 20-50 nm by precisely controlling which fluorophores are allowed to fluoresce\n\nPhotoactivated Localization Microscopy (PALM)\n\nRelies on selective activation and sampling of sparse subsets of photoactivatable fluorescent molecules\nOvercoming Limitations: Locates individual molecules with nanometer precision by isolating their signals over time\n\nStochastic Optical Reconstruction Microscopy (STORM)\n\nSimilar to PALM, but uses photoswitchable fluorophores\nOvercoming Limitations: Achieves resolutions of ~20 nm by precisely locating the centers of single fluorescent molecules\n\nStructured Illumination Microscopy (SIM)\n\nUses patterned illumination to create moiré fringes, which are computationally processed to reconstruct super-resolution images\nOvercoming Limitations: Doubles the resolution of traditional light microscopy to ~100 nm\n\nSuperresolution Photothermal Infrared Imaging\n\nSuperresolution photothermal infrared imaging is a novel technique that brings the advantages of superresolution microscopy to the infrared regime.\nOvercoming Limitations: Achieves resolutions of ~300 nm for infrared imaging at wavelength of 10 µm by using photothermal lensing effects.",
    "crumbs": [
      "Geometrical Optics",
      "Lecture 5",
      "Optical Instruments- Microscope"
    ]
  },
  {
    "objectID": "geometrical-optics/Lens Systems and Optical Instruments.html",
    "href": "geometrical-optics/Lens Systems and Optical Instruments.html",
    "title": "Lens Systems and Optical Instruments",
    "section": "",
    "text": "Lens Systems\nMost of the optical instruments consist of multiple lenses that are used to image objects or to magnify them. They are combined at distances, which are either larger or smaller than the sum of their focal distances. The image below shows for example an artifical image of a lens system contained in a single microscope objctive lens, where you see multiple elements e.g. doublets and triplets of lenses. These elements as joined objects may considerably improve the performance of the optics, e.g. correct for imaging errors.\n\n\n\n\n\n\n\n\nFig.: System of of lenses inside a microscope objective lens.\n\n\n\nWe will consider first a pair of two bi-convex lenses that are at a distance \\(D&gt;f_1+f_2\\)m where \\(f_1\\) and \\(f_2\\) are their focal distances.\n\n\n\n\n\n\n\n\n\n\n\nFig.: System of two bi-convex lenses at a distance larger than the sum of their focal distances.\n\n\n\nHere the first lens creates an image at a position\n\\[b_1=\\frac{a_1 f_1}{(a_1-f_1)}\\]\nAccordingly the object distance for lens 2 is then \\(a_2=D-b_1\\).\nThe second lens then images this intermediate object into\n\\[b_2=\\frac{a_2 f_2}{a_2-f_2}=\\frac{(D-b_1) f_2}{D-b_1-f_2}\\]\nfrom which we can finally calculate the image location and also size with the help of \\(b_1\\).\nInstead of doing a lengthy transformation I would like to draw your attention to a simple method which arises from the linearization of Snells law. This is called matrix optics. Matrix optics relates the outgoing angle \\(\\theta_2\\) and height \\(y_2\\) of an optical element to its incident angle \\(\\theta_1\\) and \\(y_1\\) via a matrix operation. Let’s have a look at an example of a bi-convex lens with a focal length \\(f\\). An incident ray is then expressed by a vector\n\\[\\begin{bmatrix}\ny_1\\\\\n\\theta_1\n\\end{bmatrix}\\]\nwhich is converted by the lens into an outgoing ray vector\n\\[\\begin{bmatrix}\ny_2\\\\\n\\theta_2\n\\end{bmatrix}\\]\nIf you have two 2D vectors which you want to transform by a linear operation into each other, then the transformation can be described by a 2x2 matrix, which is given for a lens with\n\\[\\begin{bmatrix}\nA & B\\\\\nC & D\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n1 & 0\\\\\n-\\frac{1}{f} & 1\n\\end{bmatrix}\n\\]\nSimilarly we can also define a free space propagation matrix for a propagation by a distance \\(D\\), which is\n\\[\\begin{bmatrix}\nA & B\\\\\nC & D\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n1 & D\\\\\n0 & 1\n\\end{bmatrix}\n\\]\nThe propagation of light through two lenses, which are seprarated by a distance \\(D\\) is then the product of two matrices for the lenses and one for the free space. The transformation then in addition requires to multiply from the right side the incdent vector and we obtain on the left side the outgoing ray vector.\n\\[\\begin{bmatrix}\ny_2\\\\\n\\theta_2\\\\\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n1 & 0\\\\\n-\\frac{1}{f_2} & 1 \\\\\n\\end{bmatrix}\n\\begin{bmatrix}\n1 & D\\\\\n0 & 1\n\\end{bmatrix}\n\\begin{bmatrix}\n1 & 0\\\\\n-\\frac{1}{f_1} & 1\n\\end{bmatrix}\n\\begin{bmatrix}\ny_1\\\\\n\\theta_1\n\\end{bmatrix}\\]\nIf you multiply the 2x2 matrices with each other, you will obtain a new 2x2 matrix with a matrix element \\(C\\), which should correspond to the effective focal length of that system. This is the case since the element \\(C=-\\frac{1}{f}\\)\nThe result of that calculation is\n\\[\\frac{1}{f}=\\frac{1}{f_1}+\\frac{1}{f_2}-\\frac{D}{f_1 f_2}\\]\nwhich gives the effective focal length of two bi-convex lenses at a distance \\(D\\).\nFollowing this equation the inverse of the total focal length of the combined lenses is just the sum of its inverse focal distances minus a term, which depends on the distance of the two lenses. If this distance is small as compared to the focal length, i.e. the lenses are close to each other, the total inverse focal is just given by the first two terms. The inverse focal distances characterize the refractive power of a lens. The larger the invserse value, the smaller is the focal distance. This refractive power is commonly measured in the unit diopter. One diopter corresponds to 1 dpt=1 \\(m^{-1}\\).\nThe image above shows also, that in the case of the combined lenses and a real inverted intermediate image, the final image will be upright again. Thus, if the first lens has a magnification \\(M_1=-b_1/a_1\\) and the second lens a magnification \\(M_2=-b_2/a_2\\) the total magnification is the product, which is\n\\[M=\\frac{b_1}{a_1}\\frac{b_2}{a_2}\\]\nfrom which we may finally obtain with \\(M=\\frac{f}{f-a}\\)\n\\[M=\\frac{1}{1-\\frac{a_1}{f_1}-\\frac{a_1+D}{f_2}+\\frac{a_1D}{f_1 f_2}}\\]\nFor more than two lenses, there is a versatile framework called Matrix Optics, which treats each optical element as a 2x2 matrix. This becomes possible as we derived earlier equations which were linear in \\(y\\) and \\(\\theta\\). A whole system of different lenses, plates and other optical elements can thus be treated as a matrix multiplication, which is quite useful."
  },
  {
    "objectID": "geometrical-optics/introduction.html",
    "href": "geometrical-optics/introduction.html",
    "title": "Geometrical Optics",
    "section": "",
    "text": "In this section, we will explore the fundamental principles that govern how light behaves when it encounters different media and surfaces.",
    "crumbs": [
      "Geometrical Optics",
      "Introduction"
    ]
  },
  {
    "objectID": "geometrical-optics/introduction.html#learning-objectives",
    "href": "geometrical-optics/introduction.html#learning-objectives",
    "title": "Geometrical Optics",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nBy the end of this section, you should be able to:\n\nUnderstand and apply the laws of reflection and refraction.\nAnalyze image formation by mirrors, lenses, and prisms.\nDescribe the working principles of various optical instruments.\nExplain phenomena such as dispersion and imaging errors.",
    "crumbs": [
      "Geometrical Optics",
      "Introduction"
    ]
  },
  {
    "objectID": "geometrical-optics/introduction.html#topics-covered",
    "href": "geometrical-optics/introduction.html#topics-covered",
    "title": "Geometrical Optics",
    "section": "Topics Covered",
    "text": "Topics Covered\n\nReflection Explore how light reflects off surfaces following the law of reflection.\nRefraction and Total Internal Reflection Understand how light bends when passing through different media and the conditions for total internal reflection.\nMirrors,Prisms and Lenses  Learn about various optical elements and how they form images.\nOptical Instruments Study devices like telescopes and microscopes that utilize mirrors and lenses.\nDispersion Discover how different wavelengths of light refract differently, leading to phenomena like rainbows.\nImaging Errors Examine common aberrations in optical systems and methods to correct them.",
    "crumbs": [
      "Geometrical Optics",
      "Introduction"
    ]
  },
  {
    "objectID": "geometrical-optics/introduction.html#introduction",
    "href": "geometrical-optics/introduction.html#introduction",
    "title": "Geometrical Optics",
    "section": "Introduction",
    "text": "Introduction\nGeometrical optics is an approximate description of light propagation in the limit of infinitely small wavelength, where all wave phenomena like diffraction can be neglected.\n\n\n\nLight rays passing through a lens system generated with Tantalum\n\n\nLight interacts with materials in predictable ways, allowing us to design optical systems for imaging, magnification, and more.",
    "crumbs": [
      "Geometrical Optics",
      "Introduction"
    ]
  },
  {
    "objectID": "geometrical-optics/introduction.html#assumptions-of-geometrical-optics",
    "href": "geometrical-optics/introduction.html#assumptions-of-geometrical-optics",
    "title": "Geometrical Optics",
    "section": "Assumptions of Geometrical Optics",
    "text": "Assumptions of Geometrical Optics\nGeometrical optics provides an approximate description of light behavior and is based on several key assumptions. These assumptions simplify the complex nature of light while still allowing for accurate predictions in many practical scenarios.\n\n\n\n\n\n\nCore Assumptions\n\n\n\n\nLight Sources and Detection:\n\nLight rays emerge from a light source\nLight rays are detected by a detector\n\nLight-Matter Interaction:\n\nInteraction is characterized by a refractive index \\(n\\)\nThe speed of light in a medium is given by \\(c=c_0/n\\), where \\(c_0\\) is the speed of light in vacuum\nThe speed in vacuum is 299.792.458 m/s and is connected to the definition of the meter\n\nLight Propagation:\n\nLight propagates in straight line paths (rays) in a homogeneous medium\nLight bends to a curved path in inhomogeneous media with varying refractive index \\(n(\\textbf{r})\\)\n\nBehavior at Interfaces:\n\nRays may be reflected and refracted at interfaces between media\n\n\nThese assumptions form the foundation for understanding and predicting light behavior in the context of geometrical optics.",
    "crumbs": [
      "Geometrical Optics",
      "Introduction"
    ]
  },
  {
    "objectID": "geometrical-optics/Rainbow.html",
    "href": "geometrical-optics/Rainbow.html",
    "title": "Rainbow",
    "section": "",
    "text": "As the last topic of the optical elements we would like to have a look at a phenomenon, which has nothing to do with optical elements but is fun and just fits to the topic of dispersion. We will explore the rainbow and in addition a DIY version, the glassbow."
  },
  {
    "objectID": "geometrical-optics/Rainbow.html#single-drop-analysis",
    "href": "geometrical-optics/Rainbow.html#single-drop-analysis",
    "title": "Rainbow",
    "section": "Single Drop Analysis",
    "text": "Single Drop Analysis\nTo understand the rainbow we will have first a look at the reflection of rays from a single droplet.\n\n\n\nReflection of rays in a single drop\n\n\nIn the sketch above a light ray of white light is entering the droplet under an angle \\(\\alpha\\) to the surface normal on the top. The ray is refracted and enters the droplet under an angle \\(\\beta\\) to the surface normal. The angle can be calculated from Snell’s law\n\\[n_{\\rm air}\\sin(\\alpha)=n_{\\rm water}\\sin(\\beta).\\]\nInside the droplet, the ray is now hitting the water/air surface at the backside from which it gets reflected. There, the incident angle is also \\(\\beta\\) and the ray is reflected under an angle \\(\\beta\\) as well. At that point, most of the light will, however, exit the drop on the backside, so that only a small fraction is reflected and traveling further to hit a second time the water/air surface at the angle \\(\\beta\\). The light refracted out at that point leaves the droplet under an angle \\(\\alpha\\) with the surface normal due to the reversiblity of the light path. We are, however, interested in the angle \\(\\phi\\) that the ray makes with the incident direction.\nThis angle \\(\\phi\\) can be calculated from the above sketch to be\n\\[\\phi=4\\beta-2\\alpha.\\]\nSince\n\\[\\beta=\\sin^{-1}\\left (\\frac{n_{\\rm air}}{n_{\\rm water}}\\sin(\\alpha) \\right)\\]\nsuch that finally\n\\[\\phi=4\\sin^{-1}\\left (\\frac{n_{\\rm air}}{n_{\\rm water}}\\sin(\\alpha) \\right)-2\\alpha\\]\nSo let us have a look at this dependence of the deflection angle as a function of the incidence angle.\n\n\nCode\nalpha=np.linspace(0,np.pi/2,10000)\nh2o=pd.read_csv(\"data/H2O.csv\",delimiter=\",\")\nn=np.interp(0.500,h2o.wl,h2o.n)\n\ndef rainbow(alpha,n):\n    return(4*np.arcsin(np.sin(alpha)/n)-2*alpha)\n\nplt.figure(figsize=(4,3))\nplt.plot(alpha*180/np.pi,rainbow(alpha,n)*180/np.pi)\nplt.xlabel(r\"incident angle $\\alpha$ [°]\")\nplt.ylabel(r\"deflection angle $\\phi$ [°]\")\nplt.show()\n\n\n\n\n\nDeflection angle of a light ray in a water droplet as a function of the incidence angle. The refractive index of water is taken from the data file H2O.csv.\n\n\n\n\nThe dependence seems to show a maximum deflection angle at an incidence angle of around \\(\\alpha=60^{\\circ}\\). This is an important finding, as the whole appearance of the rainbow depends on that.\n\n\nMaximum deflection angle  41.78815648670841\n\n\n\nColor Formation and Dispersion\nThe color of the rainbow is the result of the fact that the maximum deflection angle depends on the color of the light due to the dispersion. Since we have a refraction, reflection and another refraction, the largest maximum deflection angle is observed for red light, while the smallest one appears for blue light. The diagrams below show this result, which is in general true for materials with normal dispersion.\n\n\nCode\nplt.figure(figsize=(8,4))\nplt.subplot(1,2,1)\nfor wl in np.linspace(0.400,0.700,100):\n    c=wavelength_to_rgb(wl*1000, gamma=0.8)\n    n=np.interp(wl,h2o.wl,h2o.n)\n    plt.plot(alpha*180/np.pi,rainbow(alpha,n)*180/np.pi,c=c,alpha=1,lw=1)\nplt.xlabel(r\"incident angle $\\alpha$ [°]\")\nplt.ylabel(r\"deflection angle $\\phi$ [°]\")\n\nplt.subplot(1,2,2)\nfor wl in np.linspace(0.400,0.700,100):\n    c=wavelength_to_rgb(wl*1000, gamma=0.8)\n    n=np.interp(wl,h2o.wl,h2o.n)\n    plt.plot(alpha*180/np.pi,rainbow(alpha,n)*180/np.pi,c=c,alpha=1,lw=1)\nplt.xlabel(r\"incident angle $\\alpha$ [°]\")\nplt.ylabel(r\"deflection angle $\\phi$ [°]\")\nplt.xlim(45,70)\nplt.ylim(40,43)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\nCaption\n\n\n\n\nThis order of the colors is actually true for all incident angles, which raises the question, why the rainbow is actually colored. The blue color of a certain incidence angle would actually overlap with the green color of a different incidence angle and the red color of an even different incidence angle. If you select a specific outgoing angle under which you observe the rainbow, let us say \\(41^{\\circ}\\), then you find under this observation angle all color and, therefore, should observe always white light.\nThis is actually true if you look at the inside of a rainbow. You clearly recognize that inside the rainbow it is much brighter than outside. Yet when you reach the maximum angle of each color, you have a region, where even for larger angles for the incidence angles, the deflection angle does not change. Thus, if you assume you send in rays at constantly spaced incidence angles, you will have more rays with a deflection angle close to the maximum. The diagram below just counts the number of deflection angles in the different for each color and you clearly see that around the maximum deflection angles for each color you have a strong peak.\n\n\nCode\nplt.figure(figsize=(6,4))\nfor wl in np.linspace(0.400,0.700,4):\n    c=wavelength_to_rgb(wl*1000, gamma=0.8)\n    n=np.interp(wl,h2o.wl,h2o.n)\n    plt.hist(rainbow(alpha,n)*180/np.pi,bins=400,color=c,alpha=0.6,lw=1);\nplt.xlabel(r\"deflection angle $\\alpha$ [°]\")\nplt.ylabel(r\"intensity [a.u.]\")\n\nplt.xlim(30,45)\nplt.ylim(0,150)\nplt.show()\n\n\n\n\n\nHistogram of the deflection angle of light rays in a water droplet for different colors. The refractive index of water is taken from the data file H2O.csv.\n\n\n\n\nThus, around each droplet on the sky, there is a cone of deflected light reflected back from the sun. On the outside of that cone is red light under an angle of almost \\(42^{\\circ}\\) while on the inside edge we find blue light and finally white light (see left image below). We just have to connect that to the observer now. This is shown in the right sketch. The rainbow, therefore, results from the fact that we look at different height at different edges of the cone.\n\n\n\n\n\n\n\n\n\n\n\n(a) Deflection cones\n\n\n\n\n\n\n\n\n\n\n\n(b) Resulting rainbow\n\n\n\n\n\n\n\nFigure 1: Deflection cones of different colors on a single drop in a rainbow (left) and the resulting rainbow as observed from these cones (right).\n\n\n\n\n\nPrimary and Secondary Rainbows\nThe photos below show a remarkable example of both primary and secondary rainbows. Between these two bows, a careful observer will notice a darker region known as Alexander’s dark band, first described by Alexander of Aphrodisias in 200 AD. This dark band occurs because no light is scattered back to the observer at angles between approximately \\(42^{\\circ}\\) (maximum angle of primary rainbow) and \\(50^{\\circ}\\) (minimum angle of secondary rainbow).\n\n\n\nDouble rainbow over Grand Canyon. (Frank Cichos)\n\n\nThe primary rainbow results from one internal reflection within each water droplet, while the secondary rainbow involves two internal reflections. This double reflection explains both the reversed color order and the reduced brightness of the secondary rainbow, as each reflection decreases the light intensity.\n\n\n\nZoom into the Rainbow fotograph showing Alexanders dark band."
  },
  {
    "objectID": "geometrical-optics/Rainbow.html#glassbow",
    "href": "geometrical-optics/Rainbow.html#glassbow",
    "title": "Rainbow",
    "section": "Glassbow",
    "text": "Glassbow\nA beatiful demonstration of rainbow physics can be created at home using glass beads of about \\(200\\, \\mu m\\) diameter (available from our lab). When these beads are placed on a black background and illuminated with a flash lamp, they create what we call a “glassbow” - a rainbow-like pattern produced by glass instead of water droplets.\nThe main difference between a glassbow and a natural rainbow lies in the observation angle, due to the different refractive index of glass (\\(n \\approx 1.5\\)) compared to water (\\(n \\approx 1.33\\)). Using the same deflection angle equation:\n\\[\n\\phi=4\\sin^{-1}\\left (\\frac{n_{\\rm air}}{n_{\\rm glass}}\\sin(\\alpha) \\right)-2\\alpha\n\\]\nwe can calculate why the glassbow appears at a different angle than its atmospheric counterpart.\n\n\n\nA glassbow created by light reflection and refraction in microscopic glass beads on a black surface. (c) Picture by Axel Märcker"
  },
  {
    "objectID": "geometrical-optics/Magnifying Glass.html",
    "href": "geometrical-optics/Magnifying Glass.html",
    "title": "Optical Instruments",
    "section": "",
    "text": "Optical instruments now combine a number of optical elements or even consist only out of a single one as in the case of the magnifying glass or the eye.",
    "crumbs": [
      "Geometrical Optics",
      "Lecture 5",
      "Optical Instruments- Magnifying Glass"
    ]
  },
  {
    "objectID": "geometrical-optics/Magnifying Glass.html#magnifying-glass",
    "href": "geometrical-optics/Magnifying Glass.html#magnifying-glass",
    "title": "Optical Instruments",
    "section": "Magnifying Glass",
    "text": "Magnifying Glass\nA magnifying glass has several applications. First of all, it allows to see objects with details that would otherwise be too small to be observed with the eye even of the eye lens can accommodate to the distances. Such magnifying glasses are also used in microscopes as the so-called eye-piece as we will later see in the section on microscopes.\nConsider the sketch below. The sketch shows an object of a size \\(A\\) which is at a distance of \\(s_0\\) from the eye. The object makes an angle \\(\\epsilon_0\\) with the optical axis. If we insert now a lens into the space between object and eye and the lens is positioned in a way that it is exactly at a distance \\(f\\) (the focal distance of the lens) from the object then we are able to observe the object under a different angle \\(\\epsilon\\).\n\n\n\nMagnifying glass at the focal distance.\n\n\nThe magnification of this magnifying glass can the be calculated from the angles \\(\\epsilon\\approx A/f\\) and \\(\\epsilon_0\\approx A/s_0\\):\n\\[\nV=\\frac{\\tan(\\epsilon)}{\\tan(\\epsilon_0)}\\approx \\frac{\\epsilon}{\\epsilon_0}=\\frac{A}{f}\\frac{s_0}{A}=\\frac{s_0}{f}.\n\\]\nThe angular magnification is, thus, just given by the ratio of the clear visual range to the focal distance of the lens. If the focal distance \\(f\\) becomes much smaller than \\(s_0\\), large magnifications are possible.\nA second very useful effect is that when the object is placed inside the focal distance from the lens, the eye images a virtual image at infinite distance to the retina (see sketch). This means the eye muscle can stay relaxed when observing the object, while it would otherwise probably have to accommodate to the distance.\nYet, placing the object at exactly the focal distance is rather tedious when holding the magnifying glass by hand. If the object is now placed inside the focal distance of the magnifying glass, we may also calculate a magnification in this case knowing the virtual image size \\(B\\) created in this case (see sketch below)\n\n\n\nMagnifying glass for an object inside the focal range of the lens.\n\n\nIf \\(a\\) is the distance of the object from the principle plane of the magnifying glass and \\(b\\) and \\(B\\) are the distance and the size of the virtual image, respectively, we obtain\n\\[\nV=\\frac{\\tan(\\epsilon)}{\\tan(\\epsilon_0)}\\approx \\frac{\\epsilon}{\\epsilon_0}=\\frac{B}{b}\\frac{s_0}{A}=\\frac{s_0}{a}.\n\\]\nUsing the imaging equation\n\\[\n\\frac{1}{f}=\\frac{1}{a}+\\frac{1}{b}\n\\]\nwe may finally arrive at\n\\[\nV=\\frac{s_0(b-f)}{b\\,f}\n\\]\nin this case. If we place the virtual image directly at the clear visual range, i.e., \\(b=-s_0\\), we find\n\\[\nV=\\frac{s_0}{f}+1.\n\\]",
    "crumbs": [
      "Geometrical Optics",
      "Lecture 5",
      "Optical Instruments- Magnifying Glass"
    ]
  },
  {
    "objectID": "geometrical-optics/NA Derivation.html",
    "href": "geometrical-optics/NA Derivation.html",
    "title": "Experimental Physics 3 Course on Optics and Quantum Mechanics",
    "section": "",
    "text": "We start with Snell’s law at the core-cladding interface:\n\\[n_1 \\sin \\theta_1 = n_2 \\sin \\theta_2\\]\nwhere \\(n_1\\) is the core refractive index and \\(n_2\\) is the cladding refractive index.\nFor total internal reflection, the critical angle \\(\\theta_c\\) occurs when \\(\\theta_2 = 90°\\):\n\\[n_1 \\sin \\theta_c = n_2 \\sin 90° = n_2\\]\nThus, we can express the critical angle as:\n\\[\\sin \\theta_c = \\frac{n_2}{n_1}\\]\nIn the fiber, the maximum angle for total internal reflection is \\((90° - \\theta_c)\\):\n\\[\\cos \\theta_c = \\sin(90° - \\theta_c)\\]\nUsing the trigonometric identity \\(\\cos^2 \\theta + \\sin^2 \\theta = 1\\):\n\\[\\cos^2 \\theta_c = 1 - \\sin^2 \\theta_c = 1 - \\left(\\frac{n_2}{n_1}\\right)^2\\]\nAt the air-core interface, we apply Snell’s law again:\n\\[\\sin \\theta_a = n_1 \\sin(90° - \\theta_c) = n_1 \\cos \\theta_c\\]\nSubstituting the result from step 5:\n\\[\\sin \\theta_a = n_1 \\sqrt{1 - \\left(\\frac{n_2}{n_1}\\right)^2} = \\sqrt{n_1^2 - n_2^2}\\]\nThis final result is the Numerical Aperture (NA):\n\\[NA = \\sin \\theta_a = \\sqrt{n_1^2 - n_2^2}\\]\nThis formula relates the maximum acceptance angle \\(\\theta_a\\) to the refractive indices of the core (\\(n_1\\)) and cladding (\\(n_2\\)). It’s a crucial parameter in fiber optics, determining the light-gathering ability and the range of angles over which the fiber can accept or emit light."
  },
  {
    "objectID": "geometrical-optics/NA Derivation.html#derivation-of-numerical-aperture-for-optical-fibers",
    "href": "geometrical-optics/NA Derivation.html#derivation-of-numerical-aperture-for-optical-fibers",
    "title": "Experimental Physics 3 Course on Optics and Quantum Mechanics",
    "section": "",
    "text": "We start with Snell’s law at the core-cladding interface:\n\\[n_1 \\sin \\theta_1 = n_2 \\sin \\theta_2\\]\nwhere \\(n_1\\) is the core refractive index and \\(n_2\\) is the cladding refractive index.\nFor total internal reflection, the critical angle \\(\\theta_c\\) occurs when \\(\\theta_2 = 90°\\):\n\\[n_1 \\sin \\theta_c = n_2 \\sin 90° = n_2\\]\nThus, we can express the critical angle as:\n\\[\\sin \\theta_c = \\frac{n_2}{n_1}\\]\nIn the fiber, the maximum angle for total internal reflection is \\((90° - \\theta_c)\\):\n\\[\\cos \\theta_c = \\sin(90° - \\theta_c)\\]\nUsing the trigonometric identity \\(\\cos^2 \\theta + \\sin^2 \\theta = 1\\):\n\\[\\cos^2 \\theta_c = 1 - \\sin^2 \\theta_c = 1 - \\left(\\frac{n_2}{n_1}\\right)^2\\]\nAt the air-core interface, we apply Snell’s law again:\n\\[\\sin \\theta_a = n_1 \\sin(90° - \\theta_c) = n_1 \\cos \\theta_c\\]\nSubstituting the result from step 5:\n\\[\\sin \\theta_a = n_1 \\sqrt{1 - \\left(\\frac{n_2}{n_1}\\right)^2} = \\sqrt{n_1^2 - n_2^2}\\]\nThis final result is the Numerical Aperture (NA):\n\\[NA = \\sin \\theta_a = \\sqrt{n_1^2 - n_2^2}\\]\nThis formula relates the maximum acceptance angle \\(\\theta_a\\) to the refractive indices of the core (\\(n_1\\)) and cladding (\\(n_2\\)). It’s a crucial parameter in fiber optics, determining the light-gathering ability and the range of angles over which the fiber can accept or emit light."
  },
  {
    "objectID": "geometrical-optics/Telescope.html",
    "href": "geometrical-optics/Telescope.html",
    "title": "Telescopes",
    "section": "",
    "text": "Other than the microscope, the telescope is made to observe distant objects, which would appear under a very small observation angle. This can be achieved with different optical designs. The most common telescopes are refracting telescopes, which use lenses to magnify the angle under which the object is observed. The second type of telescopes are reflecting telescopes, which use mirrors to magnify the angle under which the object is observed.\n\nRefracting Telescopes\nThe telescope is therefore made to magnify the angle under which the object is observed. In the same way as a microscope, the telescope consists of two lenses with the focal distances \\(f_1,f_2\\).\n\n\n\nKepler telescope with two biconvex lenses, creating a reversed image of distance objects.\n\n\nAs indicated in the sketch above, the first lens generates an image at the focal length of the first lens. This intermediate image is the magnified by an eye-piece as well acting as a magnifying glass. We may therefore apply the same kind of techniques as earlier for the calculation of the angular magnification. The angle of observation for the object of size \\(D\\) is given by\n\\[\n2\\epsilon_0=\\frac{D}{f_1}\n\\]\nwhile the angle of observation through the telescope is given as\n\\[\n2\\epsilon=\\frac{D}{f_2}\n\\]\nCorrespondingly, the angular magnification is given by\n\\[\nV=\\frac{\\epsilon}{\\epsilon_0}=\\frac{D}{f_2}\\frac{f_1}{D}=\\frac{f_1}{f_2}\n\\]\nThe magnification is therefore given by the ration of the focal length of the entrance lens and the eye-piece. The above telescope is also termed astronomical telescope or Kepler telescope, since it has been used for astromical observations. It creates an image which is reversed.\nA telescope with an upright image may be created with the help of a concave lens. This type of telescope is called Galilei telescope and obeyes the same magnification formula as above. Due to the fact that a concave lens has a negative focal length, the total magnification will be negative as well being indicative for an upright image.\n\n\n\nGalilei telescope for imaging objects into upright images with the help of a concave and a convex lens.\n\n\n\n\nReflecting Telescopes\nModern powerful telescopes also use mirrors instead of refracting optical elements, as reflecting elements with nearly 100 percent reflectivity can be built with a much smaller mass than large glass elements. Such telescopes come in different setups. The one below is a Cassegrain telescope, where a secondary convex miror is used for imaging the intermediate image to the eye.\n\n\n\n\n\n\n\n\n\n\n\n\nReflective optics is commonly used in modern high quality telescopes for the advantage of weight. The image and sketch shows the optics of a so-called Cassegrain telescope.\n\n\n\n\n\n\n\nAdaptive Optics\nWhen observing objects from the ground, the atmosphere can distort the image. This is due to the fact that the atmosphere is not homogeneous and the refractive index of the air is changing with time. This leads to a distortion of the image, which can be corrected with the help of adaptive optics. The principle of adaptive optics is to measure the distortion of the image with the help of a laser beam and to correct the image with the help of a deformable mirror. The deformable mirror is a mirror with a number of actuators, which can change the shape of the mirror in order to correct the distortion of the image. The principle of adaptive optics is shown in the figure below.\n\n\n\nPrinciple of adaptive optics. The image of a star is distorted by the atmosphere. The distortion is measured with the help of a laser beam and corrected with the help of a deformable mirror.\n\n\n\n\nSpace-Based Telescopes\nPlacing telescopes in space eliminates atmospheric interference completely. The Hubble Space Telescope revolutionized astronomy with its crystal-clear views of the universe.\n\n\n\nLight path in the Hubble space telescope.\n\n\nIts successor, the James Webb Space Telescope (launched in 2021), operates in the infrared spectrum and can peer even further into space and time. Being above the atmosphere not only provides clearer images but also allows these telescopes to observe wavelengths that are normally blocked by Earth’s atmosphere, particularly in the infrared and ultraviolet regions.",
    "crumbs": [
      "Geometrical Optics",
      "Lecture 5",
      "Optical Instruments- Telescope"
    ]
  },
  {
    "objectID": "geometrical-optics/ContentsL6.html",
    "href": "geometrical-optics/ContentsL6.html",
    "title": "Contents",
    "section": "",
    "text": "The contents of lecture 6 will only be presented in the lectures and not part of the online publications.",
    "crumbs": [
      "Geometrical Optics",
      "Lecture 6",
      "Contents"
    ]
  },
  {
    "objectID": "quantum-mechanics/Franck_Hertz.html",
    "href": "quantum-mechanics/Franck_Hertz.html",
    "title": "Experimental Physics 3 Course on Optics and Quantum Mechanics",
    "section": "",
    "text": "In 1914 James Franck and Gustav Hertz demonstrated that energy quantization plays a major role in collision processes. A vacuum tube filled with mercury vapor contained a cathode emitting electrons and a wire mesh for accelerating electrons with energy \\(e \\cdot U\\). The electron collector has a potential of \\(U_{\\mathrm{Col}} = U -\\Delta U\\). Thus, electrons are decelerated after passing the mesh. Only electrons with energy equal to or greater than \\(e \\cdot \\Delta U\\) can reach the collector. Measuring the electron current at the collector as a function of acceleration voltage produces a characteristic curve.\n\n\n\nScheme of the apparatus used by Franck and Hertz showing wire mesh (M) used to accelerate electrons emitted from the cathode (left). After passing the mesh the electrons are decelerated before reaching the collector. An example measured curve along with expected results without inelastic scattering (right).\n\n\nFrom 0 to 4.9 eV the current rises, then decreases after passing 5 V. For higher accelerating voltages, the current increases again until reaching the next local maximum at around 9.8 V. This pattern results from inelastic collisions and energy transfer from electrons to mercury atoms. The distance between local maxima corresponds to the excitation energy of mercury. This demonstrates that atoms can absorb energy only in quantized amounts. The excited Hg atoms then decay to lower energy states by emitting light, producing bright rings within the vacuum tube."
  },
  {
    "objectID": "quantum-mechanics/Franck_Hertz.html#franck-hertz-experiment",
    "href": "quantum-mechanics/Franck_Hertz.html#franck-hertz-experiment",
    "title": "Experimental Physics 3 Course on Optics and Quantum Mechanics",
    "section": "",
    "text": "In 1914 James Franck and Gustav Hertz demonstrated that energy quantization plays a major role in collision processes. A vacuum tube filled with mercury vapor contained a cathode emitting electrons and a wire mesh for accelerating electrons with energy \\(e \\cdot U\\). The electron collector has a potential of \\(U_{\\mathrm{Col}} = U -\\Delta U\\). Thus, electrons are decelerated after passing the mesh. Only electrons with energy equal to or greater than \\(e \\cdot \\Delta U\\) can reach the collector. Measuring the electron current at the collector as a function of acceleration voltage produces a characteristic curve.\n\n\n\nScheme of the apparatus used by Franck and Hertz showing wire mesh (M) used to accelerate electrons emitted from the cathode (left). After passing the mesh the electrons are decelerated before reaching the collector. An example measured curve along with expected results without inelastic scattering (right).\n\n\nFrom 0 to 4.9 eV the current rises, then decreases after passing 5 V. For higher accelerating voltages, the current increases again until reaching the next local maximum at around 9.8 V. This pattern results from inelastic collisions and energy transfer from electrons to mercury atoms. The distance between local maxima corresponds to the excitation energy of mercury. This demonstrates that atoms can absorb energy only in quantized amounts. The excited Hg atoms then decay to lower energy states by emitting light, producing bright rings within the vacuum tube."
  },
  {
    "objectID": "quantum-mechanics/Rutherford Trajectories.html",
    "href": "quantum-mechanics/Rutherford Trajectories.html",
    "title": "Rutherford trajectory simulation",
    "section": "",
    "text": "This notebook should show the solution of the equation of motion for a charged \\(\\alpha\\) particle, scattered on a spatially fixed charged gold nucleus. This resembles to be Rutherford Scattering or Coulomb Scattering in general.\n\nEquation of motion of the \\(\\alpha\\) particle\nForce on the \\(\\alpha\\) particle at a distance \\(r\\) frokm the gold atom\n\\[\\begin{equation}\nF=\\frac{1}{4\\pi \\epsilon_{0}}\\frac{qQ}{r^2}\n\\end{equation}\\]\nSplit up the position into \\(x\\) and \\(y\\) coordinates with the equation of motion\n\\[\\begin{equation}\n\\ddot{x}=\\frac{kQq}{m}\\frac{x}{(x^2+y^2)^{3/2}}\n\\end{equation}\\]\nand\n\\[\\begin{equation}\n\\ddot{y}=\\frac{kQq}{m}\\frac{y}{(x^2+y^2)^{3/2}}\n\\end{equation}\\]\nand the force constant for Coulomb interactions\n\\[\\begin{equation}\nk=\\frac{1}{4\\pi \\epsilon_{0}}\n\\end{equation}\\]\n\n# import some required modules\nimport numpy as np\nfrom scipy.integrate import odeint\nimport matplotlib.pyplot as plt\nfrom matplotlib import animation\n\n%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\n\n\n# this defines the equation of motions in odeint style\ndef rutherford(state,t):\n    g0=state[1] # x velocity\n    g1=k*Q*q*state[0]/m/(state[0]**2+state[2]**2)**(3/2) # x-acceleration\n    g2=state[3] # y velocity\n    g3=k*Q*q*state[2]/m/(state[0]**2+state[2]**2)**(3/2) # y-acceleration\n    return np.array([g0,g1,g2,g3])\n\n\n#define some fundamental constants\nepsilon_0=8.654e-12 # C^2 N^-1 m^-2\nk=1/(4*np.pi*epsilon_0) # force constant\nm=6.64465723e-27 # mass of the alpha particle\ne=1.6021766208e-19 # elementary charge\nq=2*e # charge of the alpha particle\nQ=79*e # charge of the gold atom\nrga=67.5e-12 # size of the gold atom\n\n#define the initial state\nstate=np.zeros(4)\nstate[0]=-100e-12 # x starting position in m\nstate[1]=1.55e6    # x velocity in m/s, 5MeV\nstate[2]=-10e-12  # y starting position in m\nstate[3]=0        # y velocity in m/s\n\nplt.figure(figsize=(10,9))\n\ntime=np.abs(2*state[0]/state[1])  # total time to be simulated (in seconds), adopt to x-range and velocity\nN=100000   # number of timesteps for the simulation\nt=np.linspace(0,time,N) # times at which the amplitudes shall be calculated\n\n# range of impact parameters b\nb_range=np.linspace(-30e-12,30e-12,50)\n\n#solve the differential equations\nfor b in b_range:    \n    state[2]=b\n    answer=odeint(rutherford,state,t)    \n    xpos=answer[:,0]\n    ypos=answer[:,2]\n    plt.plot(xpos*1e12,ypos*1e12)\n\nplt.xlabel('x [pm]', fontsize=16)\nplt.ylabel('y [pm]',fontsize=16)\nplt.xlim(-100,100)\nplt.ylim(-100,100)\nplt.tick_params(labelsize=14)\nplt.show()\n\n\n\n\n\n\n\n\n\n\nPlum pudding model by Thomson\nThe plum pudding model by Thomson assumes homogeneously distributed positive and negative charges in atom.\nFor the plum pudding model by Thomson, the equations of motion of the \\(\\alpha\\) particle look\n\\[\\begin{equation}\n\\ddot{x}=\\frac{kQq}{m}\\frac{x}{r_{ga}^3}\n\\end{equation}\\]\nand\n\\[\\begin{equation}\n\\ddot{y}=\\frac{kQq}{m}\\frac{y}{r_{ga}^3}\n\\end{equation}\\]\nwhere \\(r_{ga}\\) is the radius of the gold atom.\n\ndef plumpudding(state,t):\n    g0=state[1] # x velocity\n    if np.sqrt(state[0]**2+state[2]**2)&lt;rga:\n        g1=k*Q*q*state[0]/m/rga**3 # x-acceleration\n        g3=k*Q*q*state[2]/m/rga**3 # y-acceleration\n    else:\n        #g1=k*Q*q*state[0]/m/(state[0]**2+state[2]**2)**(3/2) # x-acceleration\n        #g3=k*Q*q*state[2]/m/(state[0]**2+state[2]**2)**(3/2) # y-acceleration\n        g1=0\n        g3=0\n    g2=state[3] # y velocity\n\n    return np.array([g0,g1,g2,g3])\n\n\n#define some fundamental constants\nepsilon_0=8.654e-12 # C^2 N^-1 m^-2\nk=1/(4*np.pi*epsilon_0) # force constant\nm=6.64465723e-27 # mass of the alpha particle\ne=1.6021766208e-19 # elementary charge\nq=2*e # charge of the alpha particle\nQ=79*e # charge of the gold atom\nrga=67.5e-12 # size of the gold atom in m\n\n#define the initial state\nstate=np.zeros(4)\nstate[0]=-100e-12 # x starting position in m\nstate[1]=1.55e4    # x velocity in m/s, 5MeV\nstate[2]=-10e-12  # y starting position in m\nstate[3]=0        # y velocity in m/s\n\nplt.figure(figsize=(10,9))\n\ntime=np.abs(2*state[0]/state[1])  # total time to be simulated (in seconds), adopt to x-range and velocity\nN=100000   # number of timesteps for the simulation\nt=np.linspace(0,time,N) # times at which the amplitudes shall be calculated\n\n# range of impact parameters b\nb_range=np.linspace(-30e-12,30e-12,20)\n\n#solve the differential equations\nfor b in b_range:    \n    state[2]=b\n    state[0]=-100e-12\n    answer=odeint(plumpudding,state,t)    \n    xpos=answer[:,0]\n    ypos=answer[:,2]\n    plt.plot(xpos*1e12,ypos*1e12)\n\nplt.xlabel('x [pm]', fontsize=16)\nplt.ylabel('y [pm]',fontsize=16)\nplt.ylim(-100,100)\nplt.tick_params(labelsize=14)\nplt.show()"
  },
  {
    "objectID": "quantum-mechanics/wien.html",
    "href": "quantum-mechanics/wien.html",
    "title": "Experimental Physics 3 Course on Optics and Quantum Mechanics",
    "section": "",
    "text": "There have then been several attemps to explore the thermodynamics of blackbody radiation and to compare with measurements. Some of these approaches have been carried out by Stefan and Wien but also by Lord Rayleigh."
  },
  {
    "objectID": "quantum-mechanics/wien.html#wiens-displacement-law",
    "href": "quantum-mechanics/wien.html#wiens-displacement-law",
    "title": "Experimental Physics 3 Course on Optics and Quantum Mechanics",
    "section": "Wien’s Displacement Law",
    "text": "Wien’s Displacement Law\nIn 1896 Wien published how the spectrum of cavity radiation changes with altered temperature. Today this law is often not referred to the overall shape of the spectrum, but rather to the maximum of the spectrum. In 1896 the Stefan-Boltzmann law was already published stating that the emitted radiance depends on the apparent temperature to the power of 4 (\\(\\propto T^4\\)). However, the actual spectral distribution of the energy was unknown.\nOn the basis of thermodynamic concepts and the Stefan-Boltzmann law Wien derived a relation between the wavelength \\(\\lambda\\) and the spectral energy at a particular wavelength \\(\\varphi \\left(\\lambda\\right)\\)\n\\[\n\\varphi \\cdot \\mathrm{d} \\lambda = \\varphi_0 \\cdot \\mathrm{d} \\lambda_0\n\\]\nand\n\\[\n\\mathrm{d} \\lambda = \\frac{T_0}{T} \\; \\mathrm{d} \\lambda_0 \\mathrm{.}\n\\]\nThe last equation can be reformulated into the shape of\n\\[\n\\lambda_{\\mathrm{peak}} = b \\cdot \\frac{1}{T}\n\\]\nwith \\(b\\) being the proportionality or Wien’s displacement constant (\\(b = 2.898 \\cdot 10^{-3} \\, \\mathrm{m}\\cdot\\mathrm{K}\\)).\nWien further examined the integration with the result for the energy profile \\(\\varphi = \\varphi_0 \\; \\frac{\\mathrm{d} \\lambda_0}{\\mathrm{d} \\lambda} = \\varphi_0 \\; \\frac{\\mathrm{d} T}{\\mathrm{d} T_0}\\). In addition with the known relation from the Stefan-Boltzmann law \\(\\varphi \\propto \\frac{T^4}{T_0^4}\\), Wien proposed the spectral shape at a particular temperature on the basis of the spectral shape at a known temperature \\(\\varphi = \\varphi_0 \\frac{T^5}{T_0^5}\\). So far the exact spectral shape still remained unknown; however, by means of adjusting the parameter \\(\\varphi_0\\) theory was successfully brought into coincidence with experimental results and the spectrum for small wavelengths could be predicted."
  },
  {
    "objectID": "quantum-mechanics/wien.html#wiens-distribution-law-or-wien-approximation",
    "href": "quantum-mechanics/wien.html#wiens-distribution-law-or-wien-approximation",
    "title": "Experimental Physics 3 Course on Optics and Quantum Mechanics",
    "section": "Wien’s distribution law or Wien approximation",
    "text": "Wien’s distribution law or Wien approximation\nIn his original publication in 1896 Wien employed the wavelength dependence of the blackbody radiation and the Maxwell-Boltzmann distribution for the speed of molecules. On the basis of thermodynamic arguments he derived a formula for the radiance\n\\[\nS^{\\ast}_{\\lambda} \\left(\\lambda, T \\right) = \\frac{C_1}{\\lambda^5} \\; \\mathrm{e}^{- \\frac{C_2}{\\lambda T}} \\mathrm{.}\n\\]\nwith \\(C_1\\) and \\(C_2\\) being constants. As to be expected the curve described by this formula exhibits a maximum. In the case of short wavelength, experimental results from cavity radiation can be well described. For long wavelengths, instead, the Wien approximation underestimated the radiance.\n\n\n\nComparison between blackbody radiation (solid lines) and Wien approximation (dashed lines) at different temperatures."
  },
  {
    "objectID": "quantum-mechanics/Structure_of_matter.html",
    "href": "quantum-mechanics/Structure_of_matter.html",
    "title": "The Structure of Matter - Historical Experiments",
    "section": "",
    "text": "Building upon our study of electromagnetic waves and classical mechanics, we now turn to the fundamental structure of matter itself. Our journey will follow three key discoveries among many others that revolutionized physics: First, we will examine evidence showing that matter is composed of discrete atoms and that atoms contain charged particles, based on groundbreaking 19th century experiments. Second, we will see how phenomena like the photoelectric effect revealed that light behaves not just as waves, but also as particles called photons. Third, we will explore how matter itself exhibits wave-like properties, leading to the Schrödinger equation and the foundations of quantum mechanics.\nThis exploration begins with the historical experiments that first proved the existence of atoms. We will examine Dalton’s law of chemical combinations and Gay-Lussac’s law of gaseous reactions, before investigating the internal structure of atoms through Thomson’s and Rutherford’s seminal experiments.\nThe concept of matter being composed of indivisible particles dates back to ancient Greece. The philosophers Leucippus and Democritus (5th century BCE) first proposed that all matter consists of infinitesimally small, space-filling particles that differ in size and shape. They argued that the properties of macroscopic objects arise from the arrangement of these fundamental particles, which they named “\\(\\alpha \\tau o \\mu o \\zeta\\)” (atoms) meaning “indivisible.” A century later, Epicurus* advanced this atomic theory by proposing that these particles also possessed mass, adding to their spatial properties.",
    "crumbs": [
      "Quantum Mechanics",
      "Lecture 19",
      "Structure of Matter"
    ]
  },
  {
    "objectID": "quantum-mechanics/Structure_of_matter.html#atoms-and-molecules",
    "href": "quantum-mechanics/Structure_of_matter.html#atoms-and-molecules",
    "title": "The Structure of Matter - Historical Experiments",
    "section": "Atoms and molecules",
    "text": "Atoms and molecules\n\nDalton’s law\nBased on precise quantitative analyses of chemical reactions, John Dalton published “A New System of Chemical Philosophy” in 1808, establishing three key postulates:\n\nAll chemical elements are composed of indivisible atomic particles\nAtoms of the same element are identical in all properties, while atoms of different elements have different properties\nChemical compounds form when atoms combine in simple whole-number ratios\n\n\n\n\n\n\n\nExample: Formation of Water \\((H_2O)\\)\n\n\n\nLet’s look at the formation of water \\((H_2O)\\) as a classic example of Dalton’s law:\n\nHydrogen \\((H)\\) atoms and Oxygen \\((O)\\) atoms combine in a fixed \\(2:1\\) ratio\nTwo hydrogen atoms always combine with one oxygen atom to form one water molecule\nThis ratio never varies - you’ll never find water molecules with three hydrogen atoms or two oxygen atoms\n\nThis demonstrates Dalton’s three key postulates because:\n\nThe hydrogen and oxygen atoms are indivisible units\nEach hydrogen atom is identical to every other hydrogen atom, and each oxygen atom is identical to every other oxygen atom\nThey combine in a simple whole-number ratio \\((2:1)\\)\n\nChemical equation: \\[2H + O \\rightarrow H_2O\\]\nThis consistent \\(2:1\\) ratio holds true whether you’re making one molecule of water or a gallon of it - it’s a fundamental principle that demonstrates Dalton’s law of definite proportions.\n\n\n\n\nThe law of Gay-Lussac\nIn 1805, building upon Dalton’s atomic theory, Joseph Louis Gay-Lussac and Alexander von Humboldt discovered that hydrogen and oxygen at equal pressure and temperature combine to form water in a precise volume ratio of 2:1. This observation led Gay-Lussac to a more general law: when gases react at equal pressure and temperature, they do so in simple, whole-number volume ratios. This discovery provided further evidence for Dalton’s atomic theory, as these integer ratios suggested that gases must be composed of discrete particles combining in simple proportions.\n\n\n\n\n\n\nExample: Formation of Water from Hydrogen and Oxygen Gases\n\n\n\nLet’s examine how hydrogen and oxygen gases combine to form water vapor:\n\n\\(2\\) volumes of hydrogen gas \\((H_2) + 1\\) volume of oxygen gas \\((O_2) \\rightarrow 2\\) volumes of water vapor \\((H_2O)\\)\nAt equal temperature and pressure:\n\nIf you start with \\(2L\\) of hydrogen gas\nAnd \\(1L\\) of oxygen gas\nYou’ll get \\(2L\\) of water vapor\n\n\nThis perfectly demonstrates Gay-Lussac’s law because:\n\nThe gases combine in simple, whole-number ratios \\((2:1)\\)\nThe relationship holds true regardless of the actual volumes used (as long as they maintain the ratio)\nThe reaction must occur at the same temperature and pressure\n\nChemical equation: \\[2H_2 + O_2 \\rightarrow 2H_2O\\]\nIf you were to scale this up or down, the ratio would remain constant. For example: \\[\n\\begin{aligned}\n4L\\: H_2 + 2L\\: O_2 &\\rightarrow 4L\\: H_2O \\\\\n6L\\: H_2 + 3L\\: O_2 &\\rightarrow 6L\\: H_2O\n\\end{aligned}\n\\]\n\n\n\n\nThe Avogadro number\nIn 1811 Amedeo Avogadro introduced the term “molecule” as the smallest particle of a gas that retains the characteristics of that gas. He hypothesized that at identical pressure and temperature, equal volumes of different gases contain the same number of molecules. This fundamental insight laid the groundwork for connecting molecular-scale properties to macroscopic measurements. The Avogadro number (\\(N_{\\mbox{A}} = 6.022 \\cdot 10^{23} \\mbox{ mol}^{-1}\\)) serves as a crucial bridge between these scales - it allows us to relate the mass of individual atoms and molecules to measurable quantities like grams, and connect microscopic properties like molecular energies to macroscopic properties like temperature and pressure. From these relationships emerged the concept of “molar volume” - the volume occupied by 1 mol of a gas at standard conditions (\\(p = 1013\\mbox{ hPa}, T = 0 \\mbox{ °C}\\)), where the mass in grams corresponds to the molecular weight of the gas molecules. The modern, general definition of 1 mol is the number of particles that corresponds to 12 g of carbon \\({}^{12}\\mbox{C}\\), which applies to both gaseous and non-gaseous substances. The molar volume is \\(V_{\\mathrm{M}} = 22.414\\mbox{ l}\\).\nWithout the Avogadro number, we would be unable to quantitatively connect the behavior of individual particles to the bulk properties we can measure in the laboratory, making it one of the most important constants bridging quantum and classical physics.\n\n\n\n\n\n\nOil spot experiment\n\n\n\nOne simple and pratical method to determine the Avogadro number is the oil spot experiment. A small drop of oil with known volume \\(V\\) spreads on a water surface to form a thin film of thickness \\(h\\) equal to one molecule’s diameter. If \\(A\\) is the area of the circular film, then:\n\\(h = \\frac{V}{A}\\)\nSince we know the oil’s density \\(\\rho\\) and molar mass \\(M\\), we can calculate the number of molecules in the drop:\n\\(N = \\frac{\\rho V}{M} N_A\\)\nThe volume of one molecule is:\n\\(v = \\frac{V}{N} = \\frac{M}{\\rho N_A}\\)\nSince the thickness \\(h\\) equals the diameter of one molecule, we can write:\n\\(h^3 = \\frac{6M}{\\pi \\rho N_A}\\)\nSolving for \\(N_A\\):\n\\(N_A = \\frac{6M}{\\pi \\rho h^3}\\)\nUsing oleic acid (\\(\\mathrm{C_{18}H_{34}O_2}\\)), this method typically yields results within an order of magnitude of the accepted value.\n\n\n\n\n\n\n\n\nOther Experimental Methods for Determining Avogadro’s Number\n\n\n\n\n\n\nMillikan Oil Drop Experiment\nThe Millikan oil drop experiment measures elementary electric charge \\((e)\\) and uses Faraday’s constant \\((F)\\) to calculate Avogadro’s number through the relationship: \\[N_A = F/e\\]\n\n\nX-ray Crystallography\nThis method determines atomic spacing in crystals and combines density measurements with molar mass. The calculation uses density \\((\\rho)\\), unit cell volume \\((V_{unit})\\), molar mass \\((M)\\), and number of atoms per unit cell \\((n_{atoms})\\): \\[N_A = \\frac{\\rho V_{unit}}{M} \\times n_{atoms}\\]\n\n\nBrownian Motion\nEinstein’s analysis of Brownian motion relates particle movement to Avogadro’s number using temperature \\((T)\\), gas constant \\((R)\\), viscosity \\((\\eta)\\), particle radius \\((r)\\), and diffusion coefficient \\((D)\\): \\[N_A = \\frac{RT}{6\\pi\\eta rD}\\]\n\n\nBlack Body Radiation\nThis approach uses the relationship between the gas constant \\((R)\\) and Boltzmann constant \\((k_B)\\): \\[N_A = \\frac{R}{k_B}\\]\nModern measurements typically combine multiple methods for increased accuracy, with the current accepted value being approximately \\(6.022 \\times 10^{23}\\) mol\\(^{-1}\\).\n\n\n\n\nThese experimental findings and concepts paved the way for the modern understanding that matter is generally composed of atoms.",
    "crumbs": [
      "Quantum Mechanics",
      "Lecture 19",
      "Structure of Matter"
    ]
  },
  {
    "objectID": "quantum-mechanics/Structure_of_matter.html#the-structure-of-atoms",
    "href": "quantum-mechanics/Structure_of_matter.html#the-structure-of-atoms",
    "title": "The Structure of Matter - Historical Experiments",
    "section": "The Structure of atoms",
    "text": "The Structure of atoms\n\nIndication of charged particles within atoms\nAt the end of the 19th century experimental findings accumulated indicating matter bears charged particles. The main results were:\n\nExperiments on electrolytic current demonstrated that molecules can dissociate, whereas the resulting ions migrate in opposite directions and transport charges and mass.\nGas discharging phenomena are influenced through electric and magnetic fields. Thus, discharging is correlated to motion of charged particles.\nMagnetic phenomena arise from electric conduction in metals and semiconductors.\n\\(\\alpha\\) and \\(\\beta\\) radiation are deflected through magnetic fields; \\(\\alpha\\) and \\(\\beta\\) particles are positively charged,\n\nheavy particles and negatively charged, light particles, respectively. Consequently the concept of matter being composed of atoms was extended. Atoms in turn consist of positively and negatively charged particles which bear mass and charge.\nJohann Wilhelm Hittorf observed in gas discharge tubes that particles emitted from a cathode propagate in straight lines. Moreover, these particles can be deflected with the aid of a magnet. As a consequence of the emission from the cathode and the direction of the magnetic poles, these particles had to be negatively charged. Later in 1897, Joseph John Thomson determined the charge-to-mass ratio \\(e/m\\) and demonstrated that this ratio is independent of the cathode material. In contrast to charged particles emitted from the cathode, Eugen Goldstein observed in 1886 a ray emitted from the anode which is propagating in the opposite direction than the cathode ray. In 1887 Wilhelm Wien reported from a \\(10^{-4}\\) reduced charge-to-mass ratio of this anode ray and concluded that these particles are charged gas ions.\nIn 1899 Thomson and Charles Wilson studied sinking droplets of condensed water vapor. The speed of falling was depending on the size of the droplets and the viscosity of the retarding gas. While measuring the amount of water and charges Thomson and Wilson were able to estimate the elementary charge of about \\(10^{-19} \\mbox{ C}\\). In 1910 Robert Andrews Millikan refined this approach with his famous oil drop experiment. He sprayed tiny oil droplets into a chamber between two horizontal metal plates that could be charged to create an electric field. The droplets became electrically charged through friction and X-ray ionization. By carefully adjusting the electric field strength, Millikan could balance the gravitational force with the electromagnetic force, causing droplets to hover in place. By measuring the voltage needed to suspend droplets of different sizes, and accounting for air resistance, he discovered that the charges always occurred in discrete multiples of what we now know as the elementary charge: \\(e = 1.602\\cdot 10^{-19} \\mbox{ C}\\).\n\n\n\n\n\n\nCharge-to-Mass Ratio (Q/m)\n\n\n\n\n\nThe charge-to-mass ratio \\((Q/m)\\) of an object is the charge divided by the mass of the same object. This quantity is generally useful only for objects that may be treated as particles. For extended objects, total charge, charge density, total mass, and mass density are often more useful.\nThe charge to mass ratio can be measured in an experiment where a charged particle is accelerated by an electric field and deflected by a magnetic field. The ratio of the electric field strength to the magnetic field strength is equal to the charge-to-mass ratio of the particle.\n\n\n\n\n\n\nFigure 1— Principle Setup of the measurement of the charge to mass ratio. A charged particle is accelerated by an electric field and deflected by a magnetic field. The ratio of the electric field strength to the magnetic field strength is equal to the charge-to-mass ratio of the particle.\n\n\n\nThis method was used by Thomson to determine the charge-to-mass ratio of the electron and is still used today in modern experiments to measure the charge-to-mass ratio of particles with the help of mass spectrometers.\n\nDerivation\nStarting from the equality of magnetic and centripetal forces:\n\\[qvB = m\\frac{v^2}{r}\\]\nThis can be rearranged to:\n\\[\\frac{q}{m} = \\frac{v}{Br}\\]\nSince electric and magnetic forces are equal:\n\\[F_{electric} = F_{magnetic}\\] \\[Eq = Bqv\\]\nThis gives us:\n\\[v = \\frac{E}{B}\\]\nCombining these equations yields:\n\\[\\frac{q}{m} = \\frac{E}{B^2r}\\]\nwhere:\n\n\\(q\\) is charge\n\\(m\\) is mass\n\\(v\\) is velocity\n\\(B\\) is magnetic field strength\n\\(r\\) is radius of circular path\n\\(E\\) is electric field strength\n\n\n\n\n\nConcerning the mass of an electron, its value is still only accessible via the charge-to-mass ratio. A precise measurement of the \\(e/m\\) ratio is possible with a Wien filter. To do so, an electron is accelerated by means of a voltage, whereas perpendicular to the propagation direction an electric field deflects the electron beam. In addition a magnetic field is used to compensate the deflection. Thus, the \\(e/m\\) ratio depends only on the applied accelerating voltage and the electric and magnetic fields.\n\n\nThe Thomson model\nAt the beginning of the 20th century only negatively charged electrons as cathode rays and positively charged \\(\\alpha\\) particles were available for scattering experiments. However, if \\(\\alpha\\) particles are scattered at atoms, the electrons will have only a minor effect. The scattering depends for the most part on the spatial arrangement of positive charges within the atoms.\nAs a first attempt, in 1904 Thomson proposed the “Plum Pudding Model”. According to this model every atom consists of a number of \\(Z\\) electrons with a cumulative charge of \\(-Z\\cdot e\\) and a number of \\(Z\\) positive charges. Thus, the atoms appear neutral on the macroscopic scale. This model aligned with Paul Drude’s earlier theory of electrical conduction in metals (1900), which treated electrons as a freely moving “gas” within a positive background charge - essentially applying Thomson’s atomic model to bulk materials. Both models shared the concept of mobile electrons moving through a positively charged background.\n\n\n\n\n\n\nFigure 2— Model of an atom as proposed by Thomson. The equal amount of positive and negative charges are distributed across the atom volume.\n\n\n\nIndication of a not-sufficient description is provided on the basis of simple calculations. If the \\(Z\\) electrons are equally distributed within a sphere with the radius \\(R\\) the electron density would measure \\[\nn_e = \\frac{Z}{\\frac{4}{3}\\pi R^3}\n\\]\nThen, the plasma frequency would result in\n\\[\n\\omega_p = \\sqrt{\\frac{n_e \\cdot e^2}{\\epsilon_0 \\cdot m_e}} = \\sqrt{\\frac{3 Z e^2}{4 \\pi \\epsilon_0 R^3 m_e}}\n\\]\nThis plasma frequency equation, derived from the uniform electron distribution in Thomson’s model, would predict specific absorption and emission frequencies. However, these predicted frequencies did not match the sharp spectral lines observed experimentally in atomic spectra, indicating a fundamental flaw in Thomson’s model.\n\n\nThe Rutherford Model\nIn 1908, Rutherford, Geiger, and Marsden began their famous scattering experiments of α particles (helium nuclei) on extremely thin gold foil, only a few atoms thick. Using a new, turnable apparatus, they were able to detect scattering angles up to 180°. The surprising observation that approximately 1 in 8000 α particles was scattered at large angles directly contradicted Thomson’s plum pudding model, which predicted only small-angle deflections. The fact that most particles passed straight through the foil indicated that atoms are mostly empty space.\nIn 1911, Rutherford therefore proposed a new atomic model: all positive charge and most of the mass must be concentrated in a tiny volume (later called the nucleus) at the center of the atom, with electrons orbiting around it. Using this model, Rutherford derived the scattering formula for α particles, which successfully described the experimental data. The Rutherford scattering formula is based on the Coulomb force between the α particle and the nucleus, and it provides the differential cross section for scattering at a given angle.\nTo look into the scattering experiment we would like to define some basic quantity, the differential scattering cross section, which is not only important for the Rutherford scattering but also for other scattering experiments. The differential cross section means geometrically:\n\nParticles with impact parameters between \\(b\\) and \\(b + db\\) form a ring of area \\(d\\sigma = 2\\pi b db\\)\nThese particles are scattered into a ring on a sphere of radius \\(R\\) with area \\(dA = 2\\pi R^2sin(\\theta)d\\theta\\)\nThe solid angle is \\(d\\Omega = dA/R^2 = 2\\pi sin(\\theta)d\\theta\\)\n\nThe differential cross section is defined as: \\[\n\\frac{d\\sigma}{d\\Omega} = \\frac{b\\,db}{sin(\\theta)d\\theta}\n\\]\nwhich can be rewritten as: \\[\n\\frac{d\\sigma}{d\\Omega} = \\frac{b}{\\sin(\\theta)}\\frac{db}{d\\theta}\n\\]\nThe key physical insight is that particles hitting the target within a ring of radius \\(b\\) and width \\(db\\) are scattered into a corresponding angular range \\(d\\theta\\), and the cross section describes this relationship. As the scattering process involves the interaction potential between the particle and the target, the differential cross section provides a quantitative measure of the scattering process and the interaction between the particles.\n\n\n\n\n\n\nDifferential cross section and interaction potential\n\n\n\n\n\nFor a central potential \\(V(r)\\), we can use conservation laws. The energy conservation gives:\n\\[\nE = \\frac{1}{2}\\mu v^2 + V(r)\n\\]\nAnd the angular momentum conservation yields:\n\\[\nL = \\mu r^2\\dot{\\phi} = \\mu v b\n\\]\nas we used in Rutherford scattering.\nThe scattering angle \\(\\vartheta\\) can be expressed through an integral formula:\n\\[\n\\vartheta = \\pi - 2\\int_{r_{min}}^{\\infty} \\frac{b\\,dr}{r^2\\sqrt{1-\\frac{b^2}{r^2}-\\frac{2V(r)}{E}}}\n\\]\nwhere \\(r_{min}\\) is the distance of closest approach.\nThis relates the impact parameter b to the scattering angle \\(\\vartheta\\). For the Coulomb potential \\(V(r) = \\frac{kqQ}{r}\\), this gives us the Rutherford result.\nThe general relation for the differential cross section remains:\n\\[\n\\frac{d\\sigma}{d\\Omega} = \\frac{b}{\\sin\\vartheta}\\frac{db}{d\\vartheta}\n\\]\nDifferent potentials \\(V(r)\\) will lead to different \\(b(\\vartheta)\\) relations and thus different angular dependencies of the cross section.\n\n\n\n\n\n\n\n\n\nRutherford scattering\n\n\n\nWe consider the scattering of a charged particle in a Coulomb potential. The force between a particle A and the scattering center B is:\n\\[\nF = \\frac{q\\,Q}{4\\pi\\varepsilon_0\\,r^2} = \\frac{a}{r^2}\n\\]\nwhere \\(q\\) is the charge of the particle and \\(Q\\) the charge of the scattering center.\n\n\n\n\n\n\nFigure 3— Sketch of the Rutherford scattering experiment. The \\(\\alpha\\) particles A are scattered by the Coulomb potential of the nucleus (B at the origin). The parameter \\(b\\) is called the impact parameter. The angle \\(\\theta\\) the scattering angle.\n\n\n\nIn the center of mass frame the angular momentum is:\n\\[\nL =\\mu r^2 \\frac{\\mathrm d \\varphi}{\\mathrm dt} =  \\mu r v \\sin\\varphi\\stackrel{(r\\rightarrow-\\infty)}{=} \\mu v_0 b\n\\tag{1}\\]\nwith the reduced mass \\(\\mu=m_1 m_2/(m_1+m_2)\\). The particle is deflected by the force in \\(y\\)-direction:\n\\[\nF_y = \\frac{a\\,\\sin\\varphi}{r^2} = \\mu \\frac{\\mathrm d v_y}{\\mathrm d t}\n\\]\nWith Equation 1 we get:\n\\[\n\\frac{\\mathrm d v_y}{\\mathrm d t} = \\frac{a\\,\\sin\\varphi}{\\mu v_0 b} \\frac{\\mathrm d\\varphi}{\\mathrm d t}\n\\]\nTo get the total deflection \\(\\vartheta\\) we need to integrate from \\(\\mathrm A(-\\infty)\\) to \\(\\mathrm A(+\\infty)\\):\n\\[\n\\begin{aligned}\n\\int\\limits_{0}^{v_0 \\sin\\vartheta} \\mathrm d v_y &=\n    \\frac{a}{\\mu v_0 b} \\int\\limits_{0}^{\\pi - \\vartheta} \\sin \\varphi \\; \\mathrm d\\varphi\\\\\nv_0 \\sin \\vartheta &= \\frac{a}{\\mu v_0 b} \\left(1 + \\cos\\vartheta \\right)\n\\end{aligned}\n\\]\nUsing \\((1 + \\cos\\vartheta) / \\sin\\vartheta = 1/(\\tan(\\vartheta/2))\\) we find:\n\\[\nb = \\frac{a}{\\mu v_0^2} \\frac{1}{\\tan(\\vartheta/2)}\n\\tag{2}\\]\nFrom this, we can now calculate the differential cross section\n\\[\n\\frac{\\mathrm d\\sigma}{\\mathrm d\\Omega} = \\frac{b}{\\sin\\vartheta}\\frac{\\mathrm db}{\\mathrm d\\vartheta}\n\\]\nUsing \\(\\sin\\vartheta=2\\sin(\\vartheta/2)\\cos(\\vartheta/2)\\) we can rewrite Equation 2 as follows:\n\\[\n\\frac{b}{\\sin\\vartheta} = \\frac{1}{2}\\frac{a}{\\mu v_0^2}\\frac{1}{\\sin^2(\\vartheta/2)}\n\\]\nThe derivative of Equation 2 with respect to \\(\\vartheta\\) gives:\n\\[\n\\frac{\\mathrm db}{\\mathrm d\\vartheta} = \\frac{1}{2}\\frac{a}{\\mu v_0^2}\\frac{1}{\\sin^2(\\vartheta/2)}\n\\]\nThus, for the differential cross section we get:\n\\[\n\\frac{\\mathrm d\\sigma}{\\mathrm d\\Omega} = \\frac{1}{4}\\left(\\frac{a}{\\mu v_0^2}\\right)^2\\frac{1}{\\sin^4(\\vartheta/2)} = \\frac{1}{4}\\left(\\frac{q\\,Q}{4\\pi\\varepsilon_0\\,\\mu v_0^2}\\right)^2\\frac{1}{\\sin^4(\\vartheta/2)}\n\\]\nwhich is the Rutherford scattering formula. This formula successfully described the experimental data except at very large angles (small impact parameters), where deviations indicated that nuclei, while much smaller than atoms (&lt; \\(10^{-14}\\) m), are not point-like. This groundbreaking experiment established the nuclear model of the atom and provided the first evidence for nuclear structure.\n\n\nIn an experiment, one would send \\(\\alpha\\) particles from a source to a thin gold foil. The \\(\\alpha\\) particles are scattered at the gold atoms and detected by a detector. The detector is placed at a distance \\(R\\) from the foil. The detector is often a scintillation counter or a photographic plate. In a scintillation counter, the \\(\\alpha\\) particles hit a scintillator, which emits light when hit by a charged particle. The light is detected by a photomultiplier tube, which converts the light into an electrical signal. The signal is then processed and counted by a computer. The number of scattered particles is counted as a function of the scattering angle \\(\\vartheta\\). The Rutherford scattering formula describes the angular distribution of the scattered particles.\nTo quantitatively describe the scattering in terms of detected counts on a detector, we need to consider the following quantities:\n\n\\(\\dot{N} \\cdot A\\): number of particles per unit time hitting area \\(A\\) of scattering volume \\(V\\)\n\\(\\Delta \\dot{N}(\\vartheta, \\Omega)\\): number of particles per unit time scattered into solid angle \\(\\Delta \\Omega\\) around angle \\(\\vartheta\\)\n\nThe fraction of scattered particles is given by:\n\\[\n\\frac{\\Delta \\dot{N}}{\\dot{N} \\cdot A} = n_B \\; \\Delta x \\; \\frac{\\mathrm{d} \\sigma}{\\mathrm{d} \\Omega} \\; \\Delta \\Omega\n\\]\nwhere \\(n_B\\) is the density of scattering centers, \\(\\Delta x\\) is the scattering path length, and \\(\\frac{\\mathrm{d} \\sigma}{\\mathrm{d} \\Omega}\\) is the differential scattering cross section.\nThe detector area at distance \\(R\\) is:\n\\[\n\\Delta A_D = R^2 \\sin \\left( \\vartheta \\right) \\; \\Delta \\Omega\n\\]\nUsing the differential scattering cross section:\n\\[\n\\frac{\\mathrm{d}\\sigma}{\\mathrm{d}\\Omega} = b \\cdot \\frac{\\mathrm{d}b}{\\mathrm{d}\\vartheta}  \\frac{1}{\\sin \\left( \\vartheta \\right)}\n\\]\nand calculating \\(\\frac{\\mathrm{d}b}{\\mathrm{d}\\vartheta}\\), we obtain the Rutherford scattering formula:\n\\[\n\\frac{\\Delta \\dot{N}}{\\dot{N} \\cdot A} = n_{\\mathrm{Gold}} \\; \\Delta x \\; \\frac{1}{4 R^2} \\; \\left( \\frac{qQ}{8 \\pi \\epsilon_0 E_{\\mathrm{kin}}} \\right)^2 \\; \\frac{\\Delta A_{\\mathrm{d}}}{\\sin^4 \\left( \\frac{\\vartheta}{2} \\right)}\n\\]\n\n\nExperimental verification\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 4— Graphical representation of Geiger and Marsden’s experimental results for Rutherford scattering of \\(\\alpha\\)-particles on a gold foil. The scattering rate \\(\\dot{N}\\) is plotted as a function of the scattering angle \\(\\vartheta\\) for a given energy of the \\(\\alpha\\) particles in the left plot. The solid curve represents the theoretical prediction for Coulomb scattering. \\(\\alpha\\) particles with a constant scattering angle of 60 degrees deviate from Rutherford scattering above a kinetic energy of approximately 25 MeV due to a change of the scattering potential as the \\(\\alpha\\) particles penetrate the nucleus. The y-axis shows arbitrary units (scattering on gold).",
    "crumbs": [
      "Quantum Mechanics",
      "Lecture 19",
      "Structure of Matter"
    ]
  },
  {
    "objectID": "quantum-mechanics/Structure_of_matter.html#rutherford-scattering-trajectories",
    "href": "quantum-mechanics/Structure_of_matter.html#rutherford-scattering-trajectories",
    "title": "The Structure of Matter - Historical Experiments",
    "section": "Rutherford Scattering Trajectories",
    "text": "Rutherford Scattering Trajectories\nThe graph below shows the calculated Rutherford scattering trajectories for \\(\\alpha\\) particles scattered by a gold atom. The trajectories are calculated for different impact parameters \\(b\\) and show the deflection of the \\(\\alpha\\) particles as they pass the gold atom using the above described forces.\n\n\nCode\ndef rutherford(state,t):\n    g0=state[1] # x velocity\n    g1=k*Q*q*state[0]/m/(state[0]**2+state[2]**2)**(3/2) # x-acceleration\n    g2=state[3] # y velocity\n    g3=k*Q*q*state[2]/m/(state[0]**2+state[2]**2)**(3/2) # y-acceleration\n    return np.array([g0,g1,g2,g3])\n\n#define some fundamental constants\nepsilon_0=8.854e-12 # C^2 N^-1 m^-2\nk=1/(4*np.pi*epsilon_0) # force constant\nm=6.64465723e-27 # mass of the alpha particle\ne=1.6021766208e-19 # elementary charge\nq=2*e # charge of the alpha particle\nQ=79*e # charge of the gold atom\nrga=67.5e-12 # size of the gold atom\n\n#define the initial state\nstate=np.zeros(4)\nstate[0]=-100e-12 # x starting position in m\nstate[1]=1.55e6    # x velocity in m/s, 5MeV\nstate[2]=-10e-12  # y starting position in m\nstate[3]=0        # y velocity in m/s\n\nplt.figure(figsize=get_size(12,9))\n\ntime=np.abs(2*state[0]/state[1])  # total time to be simulated (in seconds), adopt to x-range and velocity\nN=100000   # number of timesteps for the simulation\nt=np.linspace(0,time,N) # times at which the amplitudes shall be calculated\n\n# range of impact parameters b\nb_range=np.linspace(-30e-12,30e-12,50)\n\n#solve the differential equations\nfor b in b_range:\n    state[2]=b\n    answer=odeint(rutherford,state,t)\n    xpos=answer[:,0]\n    ypos=answer[:,2]\n    plt.plot(xpos*1e12,ypos*1e12)\n\nplt.xlabel('x [pm]')\nplt.ylabel('y [pm]')\nplt.xlim(-100,100)\nplt.ylim(-100,100)\nplt.show()\n\n\n\n\n\nRutherford scattering trajectory simulation",
    "crumbs": [
      "Quantum Mechanics",
      "Lecture 19",
      "Structure of Matter"
    ]
  },
  {
    "objectID": "quantum-mechanics/Structure_of_matter.html#spectroscopic-evidence",
    "href": "quantum-mechanics/Structure_of_matter.html#spectroscopic-evidence",
    "title": "The Structure of Matter - Historical Experiments",
    "section": "Spectroscopic Evidence",
    "text": "Spectroscopic Evidence\nThe development of optical tools like spectroscopy has provided further evidence for the inner structure of atoms. Of particular importance are the observation of sharp spectral lines in atomic emission and absorption spectra which seem to be a fingerprint of the atom’s inner structure.\nThe image below shows the emission spectra of a number of basic elements revealing the characteristic spectral lines.\n\n\n\nEmission spectra of Hydrogen, Sodium, Helium, Neon and Mercury\n\n\nThese lines have to be explained with models that also comply with the structure of the atoms that is determined by scattering experiments. The Bohr model, which will be discussed in on of the next lectures, was the first model that could explain the spectral lines of hydrogen. It was based on the Rutherford model and the quantization of angular momentum.",
    "crumbs": [
      "Quantum Mechanics",
      "Lecture 19",
      "Structure of Matter"
    ]
  },
  {
    "objectID": "course-info/schedule.html",
    "href": "course-info/schedule.html",
    "title": "Course Schedule",
    "section": "",
    "text": "Lectures\nThe course will be held in two weekly lectures, starting 14.10.2024. The lectures will be held in the Large Lecture Hall (GHS) at the Linnéstr. 5. The course will be held in English.\n\n\n\n\n\n\nLecture Times\n\n\n\n\nMonday 11:15 am – 12:45 pm GHS\nThursday 11:15 am – 12:45 pm GHS\n\n\n\nThe course and the material are available online on this website. You may come back to study whenever it is suitable for you. Please note that the lectures are a place to give feedback on your understanding he topics. No feedback means all is good.\n\n\nSeminars\nSeminars are an essential part of the course. They help you to understand the material better and to prepare for the final exam. Our experience shows that students who regularly work on the assignments have a better understanding of the material and are more successful in the final exam.\n\n\n\n\n\n\nSeminar Start\n\n\n\nThe seminars will start on October 22 The solutions to the exercise sheets have to be handed in on Thursdays before the lecture.\n\n\n\n\n\n\n\n\nSeminar Times\n\n\n\n\nTuesday 11:15 am – 12:45 pm, SR 224\nTuesday 15:15 am – 16:45 pm, ThHS\n\n\n\nThe seminar will be held by Diptabrata Paul and Markus Anton.",
    "crumbs": [
      "Course Info",
      "Schedule"
    ]
  },
  {
    "objectID": "course-info/exam.html",
    "href": "course-info/exam.html",
    "title": "Exam",
    "section": "",
    "text": "The exam will take place on February 24, 2025, 09:00–12:00 in the Large Lecture Hall. We also intent to create a mock exam to help you prepare for the exam.\n\n\n\n\n\n\nExam Format\n\n\n\nThis course will end with a written exam of 180 minutes duration.\n\n\n\n\n\n\n\n\nExam Eligibility\n\n\n\nTo take part in the exam, you need to qualify by earning 50% of the possible points from the exercises handed out weekly.",
    "crumbs": [
      "Course Info",
      "Exam"
    ]
  },
  {
    "objectID": "course-info/assignments.html",
    "href": "course-info/assignments.html",
    "title": "Seminars & Assignments",
    "section": "",
    "text": "Assignments are an essential part of the course. They help you to understand the material better and to prepare for the final exam. Our experience shows that students who regularly work on the assignments have a better understanding of the material and are more successful in the final exam.\nAll of the assignments for the lecture will be handled online. An assignment will be handed out every week starting October 17, 2024 on the Moodle page of the course (see below).\nWe will use future seminars to discuss without any announcement problems that are similar to some questions we will use in the exam.\nAll assignments will be corrected, and the solutions to the individual problems will be discussed in the seminar one week later. There will be no online versions of the solutions available. Science is about discussing and understanding, so use the seminar to ask questions and to understand the solutions.",
    "crumbs": [
      "Course Info",
      "Assignments"
    ]
  },
  {
    "objectID": "course-info/assignments.html#moodle-page",
    "href": "course-info/assignments.html#moodle-page",
    "title": "Seminars & Assignments",
    "section": "Moodle Page",
    "text": "Moodle Page\nYou can find the current assignments on the Moodle page of the course. The Moodle page is available at Moodle.",
    "crumbs": [
      "Course Info",
      "Assignments"
    ]
  },
  {
    "objectID": "foundations-of-quantum-physics/index.html",
    "href": "foundations-of-quantum-physics/index.html",
    "title": "EXP3 Quarto",
    "section": "",
    "text": "This is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites."
  },
  {
    "objectID": "wave-optics/Diffraction.html",
    "href": "wave-optics/Diffraction.html",
    "title": "Diffraction",
    "section": "",
    "text": "Formulated by Christiaan Huygens in 1678, Huygens’ principle states that every point on a wavefront acts as a source of secondary spherical wavelets that spread out in the forward direction. The new position of the wavefront at any later time is found by constructing a surface tangent to these secondary wavelets. This principle provides a powerful method for analyzing wave propagation and explains various wave phenomena such as reflection, refraction, and diffraction.\n\n\n\nIllustration of Huygens’ principle for a plane wave incident with a wave vector \\(\\vec{k}\\). Each point on the wavefront acts as a source of secondary wavelets, and the new wavefront is the envelope of these wavelets.\n\n\nHuygens’ principle can be demonstrated numerically and visually. By placing a large number of spherical wave sources closely along a line and allowing their waves to interfere, we can reconstruct a plane wavefront propagating in the forward direction, illustrating how a plane wave advances according to Huygens’ concept.\n\n\n\nNumerical demonstration of Huygens’ principle used to recreate a plane wave from a set of spherical waves. The graph on the left shows the amplitude of a single spherical wave of wavelength \\(\\lambda=532\\) nm. By arranging 500 spherical wave sources densely along the x-axis at \\(z=0\\), all in phase (representing the phase of the incident plane wave at \\(z=0\\)), we can recreate the plane wavefronts for \\(z&gt;0\\) (middle) and the constant intensity distribution (right).\n\n\nMathematically, this phenomenon can be described using our earlier treatment of multi-wave interference. Consider \\(M\\) spherical wave sources arranged along the x-axis at \\(z=0\\), each separated by a small distance \\(d\\) from its neighbor. At a point far away from the sources (in the far-field approximation), the path difference between waves from adjacent sources leads to a phase difference given by:\n\\[\n\\Delta \\phi = \\frac{2\\pi d \\sin \\theta }{\\lambda}\n\\]\nwhere \\(\\theta\\) is the angle relative to the z-axis (the forward direction), and \\(\\lambda\\) is the wavelength of the waves. The superposition of these waves results in an intensity pattern described by:\n\\[\nI(\\theta) = I_0 \\frac{\\sin^2\\left ( M \\frac{\\pi d \\sin \\theta }{\\lambda} \\right )}{\\sin^2\\left ( \\frac{\\pi d \\sin \\theta }{\\lambda} \\right )}\n\\]\nThis expression arises from the interference of \\(M\\) waves with a constant phase difference \\(\\Delta \\phi\\) between neighboring waves. The numerator represents the constructive and destructive interference due to the finite number of sources, and the denominator accounts for the spacing between them.\nThis mathematical framework serves as the foundation for understanding diffraction phenomena, particularly in two important cases:\n\nSingle-Slit Diffraction: When Huygens’ wavelets are confined to a finite width (the slit width), the interference between these wavelets produces a characteristic diffraction pattern with a central maximum and diminishing side lobes.\nDiffraction Gratings: When multiple slits are arranged periodically, the interference of the transmitted waves leads to sharp diffraction maxima at specific angles, making diffraction gratings powerful tools for spectroscopic analysis.\n\nWhile we commonly use the term “diffraction” to describe these phenomena, they are fundamentally due to the interference of waves, as explained by Huygens’ principle. By considering every point on a wavefront as a source of secondary wavelets, we can understand and predict the complex patterns that arise when waves encounter obstacles or apertures.",
    "crumbs": [
      "Wave Optics",
      "Lecture 10",
      "Diffraction"
    ]
  },
  {
    "objectID": "wave-optics/Diffraction.html#huygens-principle",
    "href": "wave-optics/Diffraction.html#huygens-principle",
    "title": "Diffraction",
    "section": "",
    "text": "Formulated by Christiaan Huygens in 1678, Huygens’ principle states that every point on a wavefront acts as a source of secondary spherical wavelets that spread out in the forward direction. The new position of the wavefront at any later time is found by constructing a surface tangent to these secondary wavelets. This principle provides a powerful method for analyzing wave propagation and explains various wave phenomena such as reflection, refraction, and diffraction.\n\n\n\nIllustration of Huygens’ principle for a plane wave incident with a wave vector \\(\\vec{k}\\). Each point on the wavefront acts as a source of secondary wavelets, and the new wavefront is the envelope of these wavelets.\n\n\nHuygens’ principle can be demonstrated numerically and visually. By placing a large number of spherical wave sources closely along a line and allowing their waves to interfere, we can reconstruct a plane wavefront propagating in the forward direction, illustrating how a plane wave advances according to Huygens’ concept.\n\n\n\nNumerical demonstration of Huygens’ principle used to recreate a plane wave from a set of spherical waves. The graph on the left shows the amplitude of a single spherical wave of wavelength \\(\\lambda=532\\) nm. By arranging 500 spherical wave sources densely along the x-axis at \\(z=0\\), all in phase (representing the phase of the incident plane wave at \\(z=0\\)), we can recreate the plane wavefronts for \\(z&gt;0\\) (middle) and the constant intensity distribution (right).\n\n\nMathematically, this phenomenon can be described using our earlier treatment of multi-wave interference. Consider \\(M\\) spherical wave sources arranged along the x-axis at \\(z=0\\), each separated by a small distance \\(d\\) from its neighbor. At a point far away from the sources (in the far-field approximation), the path difference between waves from adjacent sources leads to a phase difference given by:\n\\[\n\\Delta \\phi = \\frac{2\\pi d \\sin \\theta }{\\lambda}\n\\]\nwhere \\(\\theta\\) is the angle relative to the z-axis (the forward direction), and \\(\\lambda\\) is the wavelength of the waves. The superposition of these waves results in an intensity pattern described by:\n\\[\nI(\\theta) = I_0 \\frac{\\sin^2\\left ( M \\frac{\\pi d \\sin \\theta }{\\lambda} \\right )}{\\sin^2\\left ( \\frac{\\pi d \\sin \\theta }{\\lambda} \\right )}\n\\]\nThis expression arises from the interference of \\(M\\) waves with a constant phase difference \\(\\Delta \\phi\\) between neighboring waves. The numerator represents the constructive and destructive interference due to the finite number of sources, and the denominator accounts for the spacing between them.\nThis mathematical framework serves as the foundation for understanding diffraction phenomena, particularly in two important cases:\n\nSingle-Slit Diffraction: When Huygens’ wavelets are confined to a finite width (the slit width), the interference between these wavelets produces a characteristic diffraction pattern with a central maximum and diminishing side lobes.\nDiffraction Gratings: When multiple slits are arranged periodically, the interference of the transmitted waves leads to sharp diffraction maxima at specific angles, making diffraction gratings powerful tools for spectroscopic analysis.\n\nWhile we commonly use the term “diffraction” to describe these phenomena, they are fundamentally due to the interference of waves, as explained by Huygens’ principle. By considering every point on a wavefront as a source of secondary wavelets, we can understand and predict the complex patterns that arise when waves encounter obstacles or apertures.",
    "crumbs": [
      "Wave Optics",
      "Lecture 10",
      "Diffraction"
    ]
  },
  {
    "objectID": "wave-optics/Diffraction.html#single-slit-diffraction",
    "href": "wave-optics/Diffraction.html#single-slit-diffraction",
    "title": "Diffraction",
    "section": "Single Slit Diffraction",
    "text": "Single Slit Diffraction\nWe now apply our interference formula to study the diffraction of an incident plane wave (wavevector \\(\\vec{k}\\)) on a single slit of width \\(b\\). We can model this by placing a series of Huygens sources along the slit opening. While the sketch below shows just 3 sources for clarity, we’ll generalize this to \\(M\\) sources.\n\n\n\n\n\nWe divide the slit into segments of width \\(\\Delta b\\) such that we have \\(M=b/\\Delta b\\) Huygens sources, each with amplitude \\(A_0=\\sqrt{I_0}\\). Applying our previous multi-wave interference formula with spacing \\(d=\\Delta b\\), we obtain:\n\\[\nI=I_0 \\frac{\\sin^2\\left (M\\pi\\frac{\\Delta b}{\\lambda}\\sin(\\theta)\\right)}{\\sin^2\\left (\\pi\\frac{\\Delta b}{\\lambda}\\sin(\\theta)\\right)}\n\\]\nSince \\(M\\Delta b = b\\), we can rewrite this as:\n\\[\nI=I_0 \\frac{\\sin^2\\left (\\pi\\frac{b}{\\lambda}\\sin(\\theta)\\right)}{\\sin^2\\left (\\pi\\frac{b}{M\\lambda}\\sin(\\theta)\\right)}\n\\]\nFor convenience, let’s substitute \\(x=\\pi \\frac{b}{\\lambda}\\sin(\\theta)\\), giving:\n\\[\nI=I_0\\frac{\\sin^2(x)}{\\sin^2(x/M)}\n\\]\nIn reality, we have a continuous distribution of sources across the slit width, corresponding to \\(M\\to\\infty\\). In this limit, for the denominator, \\(x/M\\) becomes very small, and we can use the small-angle approximation:\n\\[\n\\sin^2\\left (\\frac{x}{M}\\right) \\approx \\left(\\frac{x}{M}\\right)^2\n\\]\nTherefore, our final expression becomes:\n\\[\nI(\\theta)=I_s\\frac{\\sin^2\\left (\\pi \\frac{b}{\\lambda}\\sin(\\theta)\\right)}{\\left(\\pi \\frac{b}{\\lambda}\\sin(\\theta)\\right)^2}\n\\]\nwhere \\(I_s=M^2I_0\\) represents the total intensity from all sources. This expression is often written using the sinc function (sinus cardinalis):\n\\[\nI(\\theta)=I_s\\,\\text{sinc}^2\\left(\\pi \\frac{b}{\\lambda}\\sin(\\theta)\\right)\n\\]\nThis formula describes the characteristic diffraction pattern of a single slit, with a central maximum and symmetric side lobes of decreasing intensity.\n\n\n\n\n\n\nSingle Slit Diffraction\n\n\n\n\n\nThe intensity distribution generated by the diffraction of monochromatic light on a single slit and observed in the far field is given by\n\\[\nI(\\theta)=I_s\\frac{\\sin^2\\left (\\pi \\frac{b}{\\lambda}\\sin(\\theta)\\right)}{\\left( \\pi \\frac{b}{\\lambda}\\sin(\\theta)\\right)^2}\n\\]\nwhere \\(\\lambda\\) is the wavelength of the light and \\(b\\) the width of the slit. The angle of observation is given by \\(\\theta\\). Note that the diffraction pattern on any aperture is resulting from the fact that you remove Huygens sources that would be normally needed to form a plane wavefront for example.\nFourier Transform and Diffraction\nThe intensity distribution generated by the diffraction of monochromatic light on a single slit and observed in the far field is given by\n\\[\nI(\\theta)=I_s\\frac{\\sin^2\\left (\\pi \\frac{b}{\\lambda}\\sin(\\theta)\\right)}{\\left( \\pi \\frac{b}{\\lambda}\\sin(\\theta)\\right)^2}\n\\]\nwhere \\(\\lambda\\) is the wavelength of the light and \\(b\\) the width of the slit. The angle of observation is given by \\(\\theta\\). Note that the diffraction pattern on any aperture is resulting from the fact that you remove Huygens sources that would be normally needed to form a plane wavefront for example.\nThis diffraction pattern can be understood as the Fourier transform of the aperture function. In the case of a single slit, the aperture function is a rectangular function, and its Fourier transform is a sinc function. This relationship between the aperture and its diffraction pattern is a fundamental concept in wave optics and is widely used in various applications, including imaging and signal processing.\n\n\n\n\n\n\nTotal wave amplitude behind a slit (b=2µm) for an incident wave of 532 nm wavelength. The plot in the middle shows the intensity in the space behind the slit. The graph on the right displays the diffraction pattern at a screen at 100 µm distance from the slit.\n\n\nLet’s have a look at some of the properties of the intensity distribution.\n\n\nCode\n#\ndef single_slit(d,theta,wl):\n    d=np.pi*d/wl*np.sin(theta)\n    return((np.sin(d)/d)**2)\n\nwl=532e-9\nb=5e-6\ntheta=np.linspace(-np.pi/6,np.pi/6,1000)\n\nplt.figure(figsize=get_size(18,7))\nplt.subplot(1,2,1)\nplt.plot(np.sin(theta),single_slit(b,theta,532e-9),'green',lw=2,label=\"532 nm\")\nplt.plot(np.sin(theta),single_slit(b,theta,700e-9),'red',lw=2,label=\"700 nm\")\nplt.annotate('first minimum 700 nm',xy=(0.14, 0),xytext=(0.14, 0.25),arrowprops=dict(facecolor='black', width=0.5,headwidth=6))\nplt.xlabel(r'$\\sin(\\theta)$')\nplt.ylabel('$I/I_s$')\nplt.legend()\nplt.subplot(1,2,2)\nplt.plot(np.sin(theta),single_slit(b/2,theta,532e-9),'green',lw=2,label=\"532 nm\")\nplt.plot(np.sin(theta),single_slit(b/2,theta,700e-9),'red',lw=2,label=\"700 nm\")\nplt.xlabel(r'$\\sin(\\theta)$')\nplt.ylabel('$I/I_s$')\nplt.legend()\nplt.show()\n\n\n\n\n\nCaption\n\n\n\n\nThe single-slit diffraction pattern shows characteristic features that we can observe in both theoretical calculations and experimental measurements. The intensity distribution is described by an oscillating function with decreasing amplitude. The oscillations arise from the \\(\\sin^2\\) term in the numerator, while the decay comes from the square term in the denominator.\n\n\n\nDiffraction patterns as a function of the sine of the diffraction angle. The minima of the diffraction pattern in this plot are at integer multiples of \\(\\lambda/b\\).\n\n\nThe graphs above illustrate two key relationships in single-slit diffraction:\n\nThe effect of wavelength: When comparing patterns for different wavelengths (with fixed slit width \\(b=5\\,\\mathrm{\\mu m}\\)), longer wavelengths produce broader diffraction patterns\nThe effect of slit width: For the same wavelength, reducing the slit width to \\(b=2.5\\,\\mathrm{\\mu m}\\) results in a broader diffraction pattern\n\nThese observations can be quantified by analyzing the positions of intensity minima. The intensity goes to zero when the argument of the sine function in the numerator equals multiples of π:\n\\[\n\\pi \\frac{b}{\\lambda}\\sin(\\theta) = m\\pi\n\\]\nwhere \\(m\\) is an integer. This simplifies to:\n\\[\n\\sin(\\theta)=m\\frac{\\lambda}{b}\n\\]\nThis relationship reveals a fundamental principle in diffraction: the angular spread of the pattern is proportional to the ratio of wavelength to the size of the diffracting object (\\(\\lambda/b\\)). While the exact mathematical form may vary for different geometries, this basic scaling remains valid.\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 1— Diffraction patterns on a single slit as observed in the lecture. The left image shows the diffraction pattern for red light, while the right image combines two different wavelengths (red, blue), where one clearly recognizes the wider diffraction peaks for the longer red wavelength.\n\n\n\nThe experimental observations above clearly demonstrate these principles, particularly showing how red light (longer wavelength) produces a broader diffraction pattern than blue light (shorter wavelength).",
    "crumbs": [
      "Wave Optics",
      "Lecture 10",
      "Diffraction"
    ]
  },
  {
    "objectID": "wave-optics/Diffraction.html#circular-aperture",
    "href": "wave-optics/Diffraction.html#circular-aperture",
    "title": "Diffraction",
    "section": "Circular Aperture",
    "text": "Circular Aperture\nFor a circular aperture, the diffraction pattern follows a more complex mathematical form involving Bessel functions. The intensity distribution is given by:\n\\[\nI(\\theta)=I_0\\left( \\frac{2J_1(x)}{x} \\right )^2\n\\]\nwhere \\(J_1\\) is the Bessel function of the first kind, and\n\\[\nx=\\frac{2\\pi R}{\\lambda}\\sin(\\theta)\n\\]\nHere, \\(R\\) is the radius of the aperture. While similar to the sine function, the Bessel function has zeros at different positions: \\(x_1=1.22\\pi\\), \\(x_2=2.23\\pi\\), and so on.\n\n\n\nDiffraction pattern of a circular aperture of radius \\(5\\) µm. Note that the intensity scale is saturated. The diffraction rings would otherwise not be visible. The minima of the diffraction pattern in this plot are at integer multiples of \\(0.61\\lambda/R\\).\n\n\nThe first minimum of the diffraction pattern occurs when:\n\\[\nx_1=1.22\\pi=\\frac{2\\pi R}{\\lambda}\\sin(\\theta_1)\n\\]\nSolving for \\(\\sin(\\theta_1)\\):\n\\[\n\\sin(\\theta_1)=0.61\\frac{\\lambda}{R}\n\\]\nThis follows the same general principle we’ve seen before: the angular spread is proportional to wavelength divided by aperture size. The central bright region up to this first minimum is known as the Airy disc, and in microscopy, this defines a resolution element or resel.",
    "crumbs": [
      "Wave Optics",
      "Lecture 10",
      "Diffraction"
    ]
  },
  {
    "objectID": "wave-optics/Diffraction.html#application-diffraction-grating",
    "href": "wave-optics/Diffraction.html#application-diffraction-grating",
    "title": "Diffraction",
    "section": "Application: Diffraction Grating",
    "text": "Application: Diffraction Grating\nWe now combine the concepts of single-slit diffraction and multiple-wave interference to understand the behavior of diffraction gratings. Diffraction gratings are important in spectroscopy and the compression of short laser pulses.\nConsider a diffraction grating with \\(N\\) slits, each of width \\(b\\), and separated by a distance \\(d\\). Each slit acts as a source of diffraction, producing an intensity pattern that oscillates with decreasing amplitude. The width of this diffraction pattern is determined by \\(\\lambda/b\\), and the pattern is given by:\n\\[\nI(\\theta) = I_s \\frac{\\sin^2\\left(\\pi \\frac{b}{\\lambda} \\sin(\\theta)\\right)}{\\left(\\pi \\frac{b}{\\lambda} \\sin(\\theta)\\right)^2}\n\\]\nNow, we have multiple slits, each separated by a distance \\(d\\). The interference of waves from these slits is described by:\n\\[\nI = I_0 \\frac{\\sin^2(N \\phi / 2)}{\\sin^2(\\phi / 2)}\n\\]\nwhere the phase difference \\(\\phi\\) between waves from neighboring slits is given by:\n\\[\n\\phi = k \\Delta s = \\frac{2\\pi}{\\lambda} d \\sin(\\theta)\n\\]\nCombining these expressions, the intensity distribution for a diffraction grating is:\n\\[\nI(\\theta) = I_0 \\frac{\\sin^2\\left(\\pi \\frac{b}{\\lambda} \\sin(\\theta)\\right)}{\\left(\\pi \\frac{b}{\\lambda} \\sin(\\theta)\\right)^2} \\frac{\\sin^2\\left(N \\pi \\frac{d}{\\lambda} \\sin(\\theta)\\right)}{\\sin^2\\left(\\pi \\frac{d}{\\lambda} \\sin(\\theta)\\right)}\n\\]\nThis formula describes the intensity pattern produced by a diffraction grating, which is the product of the single-slit diffraction pattern and the multiple-slit interference pattern.\n\n\n\n\n\n\nDiffraction Grating\n\n\n\nThe intensity distribution generated by a diffraction grating from monochromatic light and observed in the far field is given by\n\\[\nI(\\theta) = I_0 \\frac{\\sin^2\\left(\\pi \\frac{b}{\\lambda} \\sin(\\theta)\\right)}{\\left(\\pi \\frac{b}{\\lambda} \\sin(\\theta)\\right)^2} \\frac{\\sin^2\\left(N \\pi \\frac{d}{\\lambda} \\sin(\\theta)\\right)}{\\sin^2\\left(\\pi \\frac{d}{\\lambda} \\sin(\\theta)\\right)}\n\\]\nwhere \\(\\lambda\\) is the wavelength of the light, \\(b\\) is the width of the slit, \\(d\\) is the distance between the slits, and \\(N\\) is the number of slits illuminated. The angle of observation is given by \\(\\theta\\).\n\n\n\nProperties of the Diffraction Pattern\nLet’s examine the properties of this intensity distribution. The graph below shows the intensity distribution for a diffraction grating with \\(N=8\\) slits, a slit distance of \\(d=4\\) µm, a slit width of \\(b=2\\) µm, and a wavelength of 532 nm. We observe the following general properties:\n\nThe intensity pattern consists of main maxima, called diffraction orders, characterized by integer numbers. The central peak is the 0th order peak, the first main peak to the right is the 1st diffraction order, and so on.\nThe main peaks are separated by \\(N-2\\) secondary peaks and \\(N-1\\) minima.\nThe intensity distribution is characterized by an envelope, which is the diffraction pattern of a single slit (dashed line). In the example below, the 2nd order peak is suppressed. The envelope becomes wider if the slits become narrower.\n\n\n\nPosition of the Main Peaks\nThe position of the main peaks is determined by the condition that the denominator of the multiple-slit interference term is zero. This occurs when the argument is an integer multiple of \\(\\pi\\), i.e., \\(\\pi \\frac{d}{\\lambda} \\sin(\\theta) = m\\pi\\), or:\n\\[\n\\sin(\\theta) = m \\frac{\\lambda}{d}\n\\]\nwhere \\(m\\) is an integer. The first-order diffraction maximum is found at \\(\\sin(\\theta) = \\frac{\\lambda}{d}\\), independent of the number of slits \\(N\\). This means that the position of the main peaks increases linearly with the wavelength \\(\\lambda\\) and decreases with increasing slit distance \\(d\\).\n\n\nCode\n# Parameters\nN = 8  # Number of slits\nb = 2e-6  # Slit width in meters\nd = 4e-6  # Separation between slits in meters\nwavelength = 532e-9  # Wavelength of light in meters\n\n# Diffraction angle range\ntheta = np.linspace(-np.pi/2, np.pi/2, 1000)\nsin_theta = np.sin(theta)\n\n# Calculate the intensity\nbeta = (np.pi * b / wavelength) * sin_theta\ngamma = (np.pi * d / wavelength) * sin_theta\n\nsingle_slit = (np.sin(beta) / beta)**2\nmulti_slit = (np.sin(N * gamma) / np.sin(gamma))**2\n\n# Handle division by zero for beta and gamma\nsingle_slit[np.isnan(single_slit)] = 1\nmulti_slit[np.isnan(multi_slit)] = N**2\n\nintensity = single_slit * multi_slit\n\n# Plot the intensity\nplt.figure(figsize=get_size(12, 8))\nplt.plot(sin_theta, intensity/np.max(intensity),label='Intensity')\nplt.plot(sin_theta, single_slit, 'r--',label='Single Slit')\nplt.xlabel(r'$\\sin(\\theta)$')\nplt.ylabel(r'$I/I_{max}$')\nplt.xlim(-0.5,0.5)\nplt.show()\n\n\n\n\n\nDiffraction pattern of a grating where 8 slits with a width of 2 µm and a distance of 4 micrometers are illuminated by a wavelength of 532 nm.\n\n\n\n\n\n\nInfluence of the Slit Width\nThe two plots below show the influence of the slit width while keeping the slit distance the same. We have \\(N=8\\) slits with \\(d=4\\) µm, while the slit width is \\(b=2\\) µm on the left side and \\(b=1\\) µm on the right side. The result is an increased width of the envelope. The first minimum of the slit diffraction pattern occurs at \\(\\sin(\\theta) = \\frac{\\lambda}{b}\\).\n\n\nCode\n# Parameters\nN = 8  # Number of slits\nd = 4e-6  # Separation between slits in meters\nwavelength = 532e-9  # Wavelength of light in meters\n\n# Diffraction angle range\ntheta = np.linspace(-np.pi / 2, np.pi / 2, 1000)\nsin_theta = np.sin(theta)\n\ndef calculate_intensity(N, b, d, wavelength, sin_theta):\n    beta = (np.pi * b / wavelength) * sin_theta\n    gamma = (np.pi * d / wavelength) * sin_theta\n\n    # Single slit intensity pattern using sinc function\n    single_slit = (np.sinc(beta / np.pi))**2\n\n    # Multi-slit interference pattern\n    multi_slit = np.ones_like(gamma)\n    gamma_nonzero = gamma != 0\n    multi_slit[gamma_nonzero] = (np.sin(N * gamma[gamma_nonzero]) / np.sin(gamma[gamma_nonzero]))**2\n    multi_slit[~gamma_nonzero] = N**2\n\n    intensity = single_slit * multi_slit\n\n    return single_slit, intensity\n\n# Plotting\nfig, ax = plt.subplots(1, 2, figsize=get_size(18, 8))\n\n# First plot with b = 2e-6\nb = 2e-6\nsingle_slit, intensity = calculate_intensity(N, b, d, wavelength, sin_theta)\nax[0].plot(sin_theta, intensity / np.max(intensity), label='Intensity')\nax[0].plot(sin_theta, single_slit, 'r--', label='Single Slit')\nax[0].set_xlabel(r'$\\sin(\\theta)$')\nax[0].set_ylabel(r'$I/I_{max}$')\nax[0].set_xlim(-0.5, 0.5)\nax[0].legend()\n\n# Second plot with b = 1e-6\nb = 1e-6\nsingle_slit, intensity = calculate_intensity(N, b, d, wavelength, sin_theta)\nax[1].plot(sin_theta, intensity / np.max(intensity), label='Intensity')\nax[1].plot(sin_theta, single_slit, 'r--', label='Single Slit')\nax[1].set_xlabel(r'$\\sin(\\theta)$')\nax[1].set_ylabel(r'$I/I_{max}$')\nax[1].set_xlim(-0.5, 0.5)\nax[1].legend()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\nDiffraction pattern of a grating with \\(N=8\\) slits (\\(d=4\\) µm, \\(b=1\\) µm) with \\(\\lambda=532\\) nm.\n\n\n\n\n\n\nInfluence of the Slit Number\nWhen increasing the number of slits, the main diffraction peaks become sharper. The location of the main peaks for a given wavelength remains unchanged, but there are now \\(N-2\\) secondary maxima in between. This decreased width of the main peaks is important for the spectral resolution of the grating.\n\n\nCode\nN = 100  # Number of slits\nb = 1e-6  # Slit width in meters\nd = 4e-6  # Separation between slits in meters\nwavelength = 532e-9  # Wavelength of light in meters\n\n# Diffraction angle range\ntheta = np.linspace(-np.pi/2, np.pi/2, 10000)\nsin_theta = np.sin(theta)\n\n# Calculate the intensity\nbeta = (np.pi * b / wavelength) * sin_theta\ngamma = (np.pi * d / wavelength) * sin_theta\n\nsingle_slit = (np.sin(beta) / beta)**2\nmulti_slit = (np.sin(N * gamma) / np.sin(gamma))**2\n\n# Handle division by zero for beta and gamma\nsingle_slit[np.isnan(single_slit)] = 1\nmulti_slit[np.isnan(multi_slit)] = N**2\n\nintensity = single_slit * multi_slit\n\n# Plot the intensity\nplt.figure(figsize=get_size(12, 8))\nplt.plot(sin_theta, intensity/np.max(intensity),label='Intensity')\nplt.plot(sin_theta, single_slit, 'r--',label='Single Slit')\nplt.xlabel(r'$\\sin(\\theta)$')\nplt.ylabel(r'$I/I_{max}$')\nplt.xlim(-0.5,0.5)\nplt.show()\n\n\n\n\n\nDiffraction pattern of a grating with \\(N=100\\) slits (\\(d=4\\) µm, \\(b=1\\) µm) with \\(\\lambda=532\\) nm.\n\n\n\n\n\n\nSpectral Resolution\nTo quantify the spectral resolution, we use a criterion similar to the optical resolution of a microscope: two peaks are separable if the second peak is located at the minimum of the first diffraction pattern. Here, the diffraction patterns refer to different wavelengths \\(\\lambda_1\\) and \\(\\lambda_2\\).\n\n\nCode\nN = 100  # Number of slits\nb = 1e-6  # Slit width in meters\nd = 4e-6  # Separation between slits in meters\n\n# Diffraction angle range\ntheta = np.linspace(0.01, 1, 10000)\nsin_theta = np.sin(theta)\n\ndef intensity(sin_theta, wavelength, b, d, N):\n    # Calculate beta and gamma\n    beta = (np.pi * b / wavelength) * sin_theta\n    gamma = (np.pi * d / wavelength) * sin_theta\n\n    # Compute single-slit intensity\n    single_slit = np.where(beta == 0, 1.0, (np.sin(beta) / beta))**2\n\n    # Compute multi-slit interference\n    multi_slit = np.where(gamma == 0, N**2, (np.sin(N * gamma) / np.sin(gamma))**2)\n\n    # Combine intensities\n    intensity = single_slit * multi_slit\n    return intensity\n\ni1 = intensity(sin_theta, 532e-9, b, d, N)\ni2 = intensity(sin_theta, 537e-9, b, d, N)\n\n# Plot the intensity\nfig, ax = plt.subplots(1, 2, figsize=get_size(16, 8))\nax[0].plot(sin_theta, i1 / np.max(i1), label='532 nm')\nax[0].plot(sin_theta, i2 / np.max(i2), label='537 nm')\nax[0].set_xlabel(r'$\\sin(\\theta)$')\nax[0].set_ylabel(r'$I/I_{max}$')\nax[0].set_xlim(0.12, 0.15)\nax[0].legend()\n\nax[1].plot(sin_theta, i1 / np.max(i1), label='532 nm')\nax[1].plot(sin_theta, i2 / np.max(i2), label='537 nm')\nax[1].set_xlabel(r'$\\sin(\\theta)$')\nax[1].set_ylabel(r'$I/I_{max}$')\nax[1].set_xlim(0.255, 0.28)\nax[1].legend()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\nRayleigh resolution limit of a grating with \\(N=100\\) slits (\\(d=4\\) µm, \\(b=1\\) µm) with \\(\\lambda_1=532\\) nm and \\(\\lambda_2=537\\) nm in the first order diffraction peak (left) and the second order peak (right).\n\n\n\n\nConsider the \\(m\\)th order diffraction peak for the wavelength \\(\\lambda_1\\). This occurs at:\n\\[\n\\sin(\\theta) = m \\frac{\\lambda_1}{d}\n\\]\nThe next secondary minimum to larger angles of the diffraction pattern is located where the numerator of the multiple-wave interference term:\n\\[\n\\sin^2\\left(N \\pi \\frac{d}{\\lambda} \\sin(\\theta)\\right)\n\\]\nbecomes zero, or the argument:\n\\[\nN \\pi \\frac{d}{\\lambda} \\sin(\\theta) = l \\pi\n\\]\nbecomes a multiple \\(l\\) of \\(\\pi\\). For the first-order main peak, we have \\(N-2\\) intermediate peaks as well as the 0th and now the first-order peak. Therefore, \\(m = l/N\\), and the next minimum after the 1st order peak is at:\n\\[\n\\sin(\\theta_1) = \\frac{l+1}{N} \\frac{\\lambda_1}{d}\n\\]\nThis angle must correspond to the position of the main peak of the first-order diffraction of the wavelength \\(\\lambda_2\\), so:\n\\[\n\\sin(\\theta_1) = m \\frac{\\lambda_2}{d}\n\\]\nCombining both equations for the two wavelengths yields:\n\\[\n\\left(m + \\frac{1}{N}\\right) \\frac{\\lambda_1}{d} = m \\frac{\\lambda_2}{d}\n\\]\nand after some rearrangements (setting \\(\\lambda_1 = \\lambda\\)):\n\\[\nR = \\frac{\\lambda}{\\Delta \\lambda} = mN\n\\]\nThis is the resolving power \\(R\\) of a grating. The ability to resolve two wavelengths increases with the diffraction order \\(m\\) and the number of slits used for the diffraction. However, the intensity of higher diffraction orders rapidly decreases due to the grating envelope. Therefore, the main parameter to change is the number of illuminated slits.\nOur finding is illustrated in the figure above, where we achieve a resolution of about 5 nm when using \\(N=100\\) slits at a distance of \\(d=4\\) µm.\n\n\n\n\n\n\n\n\nDiffraction pattern observed for a grating in the lecture with red light (left) and white light (right).\n\n\n\n\n\n\n\nDiffraction pattern observed for a grating in the lecture with red light (left) and white light (right).\n\n\n\n\n\n\nFigure 2— Diffraction pattern observed for a grating in the lecture with red light (left) and white light (right).\n\n\n\n\n\n\n\n\n\nDiffraction Grating Playground\n\n\n\n\n\n\n  Wavelength (nm):\n  \n  532 nm\n  \n  Slit Width (µm):\n  \n  2 µm\n  \n  Number of Slits:\n  \n  8\n\n\n\n\n\n\nApp to play with the parameters of a grating with a slit distance of 4 µm and a slit width of 2 µm.",
    "crumbs": [
      "Wave Optics",
      "Lecture 10",
      "Diffraction"
    ]
  },
  {
    "objectID": "wave-optics/LIGO.html",
    "href": "wave-optics/LIGO.html",
    "title": "LIGO",
    "section": "",
    "text": "The Laser Interferometer Gravitational-Wave Observatory (LIGO) is designed to detect gravitational waves—ripples in spacetime caused by massive accelerating objects, such as merging black holes or neutron stars. LIGO uses a Michelson interferometer configuration with two perpendicular arms, each several kilometers long. A laser beam is split into two beams that travel down these arms, reflect off mirrors at the ends, and then recombine at the beam splitter. Under normal conditions, the lengths of the arms are such that the beams interfere destructively, resulting in no light reaching the detector.\nWhen a gravitational wave passes through the interferometer, it causes a tiny but measurable change in the lengths of the arms. This change alters the interference pattern of the recombined beams, allowing the detection of the gravitational wave. The sensitivity of LIGO is such that it can detect changes in arm length smaller than a thousandth of the diameter of a proton.\nThe phase shift \\(\\Delta \\phi\\) caused by a gravitational wave can be expressed as:\n\\[\n\\Delta \\phi = \\frac{4 \\pi \\Delta L}{\\lambda}\n\\]\nwhere \\(\\Delta L\\) is the change in the length of the interferometer arms due to the gravitational wave, and \\(\\lambda\\) is the wavelength of the laser light used in the interferometer.\n\n\nTo understand the phase shift in LIGO, consider the effect of a gravitational wave passing through the interferometer. The wave causes a differential change in the lengths of the two arms, denoted as \\(\\Delta L\\). This change in length affects the travel time of the laser beams in each arm.\nThe time difference \\(\\Delta T\\) between the beams traveling in the two arms can be expressed as:\n\\[\n\\Delta T = \\frac{\\Delta L}{c}\n\\]\nThe phase shift \\(\\Delta \\phi\\) is then related to this time difference by the equation:\n\\[\n\\Delta \\phi = \\frac{2 \\pi \\Delta T}{T} = \\frac{4 \\pi \\Delta L}{\\lambda}\n\\]\nThis phase shift alters the interference pattern observed at the detector, allowing LIGO to measure the presence and properties of gravitational waves. The extraordinary precision of LIGO’s measurements enables it to detect incredibly small disturbances in spacetime, providing valuable insights into some of the most energetic events in the universe."
  },
  {
    "objectID": "wave-optics/LIGO.html#ligo-interferometer-overview",
    "href": "wave-optics/LIGO.html#ligo-interferometer-overview",
    "title": "LIGO",
    "section": "",
    "text": "The Laser Interferometer Gravitational-Wave Observatory (LIGO) is designed to detect gravitational waves—ripples in spacetime caused by massive accelerating objects, such as merging black holes or neutron stars. LIGO uses a Michelson interferometer configuration with two perpendicular arms, each several kilometers long. A laser beam is split into two beams that travel down these arms, reflect off mirrors at the ends, and then recombine at the beam splitter. Under normal conditions, the lengths of the arms are such that the beams interfere destructively, resulting in no light reaching the detector.\nWhen a gravitational wave passes through the interferometer, it causes a tiny but measurable change in the lengths of the arms. This change alters the interference pattern of the recombined beams, allowing the detection of the gravitational wave. The sensitivity of LIGO is such that it can detect changes in arm length smaller than a thousandth of the diameter of a proton.\nThe phase shift \\(\\Delta \\phi\\) caused by a gravitational wave can be expressed as:\n\\[\n\\Delta \\phi = \\frac{4 \\pi \\Delta L}{\\lambda}\n\\]\nwhere \\(\\Delta L\\) is the change in the length of the interferometer arms due to the gravitational wave, and \\(\\lambda\\) is the wavelength of the laser light used in the interferometer.\n\n\nTo understand the phase shift in LIGO, consider the effect of a gravitational wave passing through the interferometer. The wave causes a differential change in the lengths of the two arms, denoted as \\(\\Delta L\\). This change in length affects the travel time of the laser beams in each arm.\nThe time difference \\(\\Delta T\\) between the beams traveling in the two arms can be expressed as:\n\\[\n\\Delta T = \\frac{\\Delta L}{c}\n\\]\nThe phase shift \\(\\Delta \\phi\\) is then related to this time difference by the equation:\n\\[\n\\Delta \\phi = \\frac{2 \\pi \\Delta T}{T} = \\frac{4 \\pi \\Delta L}{\\lambda}\n\\]\nThis phase shift alters the interference pattern observed at the detector, allowing LIGO to measure the presence and properties of gravitational waves. The extraordinary precision of LIGO’s measurements enables it to detect incredibly small disturbances in spacetime, providing valuable insights into some of the most energetic events in the universe."
  },
  {
    "objectID": "wave-optics/Diffraction Integral Dummy.html",
    "href": "wave-optics/Diffraction Integral Dummy.html",
    "title": "Diffraction Integral",
    "section": "",
    "text": "In the last section about Fresnel zones and the zone plate, we considered how different paths contribute to the intensity at a point on the optical axis. We would like to generalize this idea to an integral formulation that allows us to calculate any kind of diffraction pattern.\nAssume we have a light source \\(S\\) as shown in the image above, which emits a spherical wave (though it does not necessarily have to be a spherical wave). The spatial amplitude of this wave at the point \\(P(x,y)\\) at a tiny aperture element \\(d\\sigma\\) is given by:\n\\[\nU_s(x,y) = U_0(x,y)e^{i\\phi(x,y)}\n\\]\nwhere\n\\[\nU_0 = \\frac{A}{R} = \\frac{A}{\\sqrt{g^2 + x^2 + y^2}}\n\\]\nand\n\\[\n\\phi(x,y) = -kR\n\\]\nThis represents the amplitude of the Huygens wave, which emanates from the point \\(P(x,y)\\) and propagates towards the screen at \\(P(x',y')\\). This Huygens wave contributes a fraction of an amplitude \\(dU_p\\) to the total amplitude at point \\(P(x',y')\\), which is given by:\n\\[\ndU_p = C \\frac{U_s d\\sigma}{r} e^{-ikr}\n\\]\nwith \\(C = \\frac{i \\cos(\\theta)}{\\lambda}\\), known as the obliquity factor, found through a more detailed calculation.\nThe total amplitude at the point \\(P(x',y')\\) is then given by the integral over all contributions:\n\\[\nU_p = \\iint C U_s \\frac{e^{-ikr}}{r} dx dy\n\\]\nwhere \\(dx dy = d\\sigma\\). The integral runs over all positions in the aperture plane \\((x,y)\\) where there is an opening. This integral is called the Fresnel-Kirchhoff diffraction integral and allows us to calculate complex scalar diffraction patterns.\nThis formulation generalizes the concept of Fresnel zones and provides a powerful tool for analyzing and predicting diffraction patterns for various aperture shapes and configurations."
  },
  {
    "objectID": "wave-optics/Diffraction Integral Dummy.html#fresnel-approximation",
    "href": "wave-optics/Diffraction Integral Dummy.html#fresnel-approximation",
    "title": "Diffraction Integral",
    "section": "Fresnel Approximation",
    "text": "Fresnel Approximation\nThe diffraction integral does not always need to be calculated in full; we can use approximations to obtain diffraction patterns in different regimes. One such approximation is the Fresnel approximation, which yields the diffraction pattern in the near field.\nThe distance \\(r\\) from the point \\(P(x,y)\\) to the point \\(P(x',y')\\) can be written as:\n\\[\nr = \\sqrt{z_0^2 + (x - x')^2 + (y - y')^2}\n\\]\nUsing a binomial expansion for small angles, we can approximate this as:\n\\[\nr \\approx z_0 \\left(1 + \\frac{(x - x')^2}{2z_0^2} + \\frac{(y - y')^2}{2z_0^2} + \\ldots \\right)\n\\]\nIn this approximation, we assume that \\(\\cos(\\theta) = z_0 / r \\approx 1\\) and \\(C = i / \\lambda\\), considering small diffraction angles. Using this approximation, we find the amplitude of the wave at a point \\(P(x',y')\\):\n\\[\nU(x', y', z_0) = i \\frac{e^{-ikz_0}}{\\lambda z_0} \\iint U_s(x, y) \\exp \\left[ -\\frac{ik}{2z_0} \\left( (x - x')^2 + (y - y')^2 \\right) \\right] dx dy\n\\]\nAs the integration is over \\(x\\) and \\(y\\), we can factor out all screen coordinate elements, yielding:\n\\[\nU(x', y', z_0) = i \\frac{e^{-ikz_0}}{\\lambda z_0} e^{-\\frac{ik}{2z_0}(x'^2 + y'^2)} \\iint U_s(x, y) e^{-\\frac{ik}{2z_0}(x^2 + y^2)} e^{\\frac{ik}{2z_0}(xx' + yy')} dx dy\n\\]\nThis is the Fresnel approximation. It simplifies the calculation of the diffraction pattern in the near field by making reasonable assumptions about the geometry and angles involved."
  },
  {
    "objectID": "wave-optics/Diffraction Integral Dummy.html#fraunhofer-approximation",
    "href": "wave-optics/Diffraction Integral Dummy.html#fraunhofer-approximation",
    "title": "Diffraction Integral",
    "section": "Fraunhofer Approximation",
    "text": "Fraunhofer Approximation\nIf we further assume that the aperture is small as compared to the distance at which we observe the diffraction pattern, we can further simplify the Fresnel approximation to yield the Fraunhofer approximation giving the diffraction patter in the far field. The condition is\n\\[\nz_0\\gg\\frac{1}{\\lambda}(x^2+y^2)\n\\]\nIn this case we can neglect the term\n\\[\ne^{ -\\frac{ik}{2z_0}(x^2+y^2)} \\approx 1\n\\]\nwhich results in\n\\[\nU(x^{\\prime},y^{\\prime},z_0)=i\\frac{e^{-ikz_0}}{\\lambda z_0} e^{-\\frac{ik}{2z_0}(x^{\\prime 2}+y^{\\prime 2})}\n\\iint U_{s}(x,y)\ne^{\\frac{ik}{2z_0}(xx^{\\prime}+yy^{\\prime})} dx dy\n\\]\n\n\n\nDiffraction pattern of a slit in the near field (Fresnel diffraction, left) and the far field (Fraunhofer diffraction, right).\n\n\nWhile these formulas provide the mathematical tools, we may obtain a more intuitive idea about the different approximation in the following way. Consider the image below, where we would like to know about the diffraction intensity of a slit of width \\(b\\) at the optical axis at a distance \\(D\\).\n\n\n\nIllustration of the importance of additional geometrical path length difference for the discrimination of Fresnel (near-field) and Fraunhofer (far-field) diffraction.\n\n\nThe waves from the center of the slit and the edge have to travel towards that point a different pathlength, whcih we may calculate to\n\\[\\begin{eqnarray}\n\\Delta s &=&  \\sqrt{\\frac{b^2}{4}+D^2}-D\\\\\n&=& D\\sqrt{\\frac{b^2}{4D^2}+1}-D\n\\end{eqnarray}\\]\nWe may develop the square root into a Taylor series and obtain\n\\[\\begin{eqnarray}\n\\Delta s &=& \\frac{b^2}{8D}-\\frac{b^4}{128 D^3}+O(4)\\\\\n&\\approx & \\frac{b^2}{8D}\n\\end{eqnarray}\\]\nThe second order correction term \\(\\frac{b^2}{8D}\\) decreases quadratic with the distance \\(D\\) of the point, which means that at large distances, we can safely assume \\(\\Delta s=0\\) on the axis, i.e. all waves arriving at that point have to travel the same distance. This corresponds to the far-field approximation. To be more specific we require\n\\[\n\\frac{b^2}{8D^2}&lt;\\frac{\\lambda}{8}\n\\]\nor\n\\[\n\\frac{b^2}{\\lambda D}&lt;1\n\\]\nto be fullfilled to be in the far field.\n\\[\nF=\\frac{b^2}{\\lambda D}\n\\begin{cases}\n\\ll 1 ,&\\textrm{Fraunhofer}\\\\\n\\approx 1,& \\textrm{Fresnel}\\\\\n\\gg 1, & \\textrm{Full vector}\n\\end{cases}\n\\]\nThis number \\(F\\) is called the Frensel number and gives us an idea by how far the dimensions of the opening contribute to the diffraction pattern rather than the direction of the wave propagation only."
  },
  {
    "objectID": "wave-optics/Diffraction Integral Dummy.html#babinets-principle",
    "href": "wave-optics/Diffraction Integral Dummy.html#babinets-principle",
    "title": "Diffraction Integral",
    "section": "Babinet’s Principle",
    "text": "Babinet’s Principle\nThe above considerations of diffraction have some intruiging consequence. Consider the two apertures in the image below.\n\n\n\nTwo complementary apertures, which have the same diffraction pattern in the far field.\n\n\nThe left aperture will create in the far field an amplitude distribution \\(U_h\\), while the inverse aperture on the right will cause an amplitude \\(U_d\\). If we combine both amplitudes in the far field, we obtain a total amplitude distribution\n\\[\nU=U_h+U_d\n\\]\nIn the case when we have two complementary apertures, that total amplitude has to be zeor, when hole and dot are placed at the same position. We therefore obtain\n\\[\nU_h=-U_d\n\\]\nand therefore\n\\[\nI_h=I_d\n\\]\nThis is the Principle of Babinet which states:\n\n\n\n\n\n\nBabinet’s Principle\n\n\n\nBabinet’s principle states that the far-field diffraction intensity distribution of complementary apertures is identical. This means that an opaque object and its complementary aperture (where the object is replaced by a transparent region and vice versa) produce the same diffraction pattern in the far field.\n\n\nThe images below show an experimental demonstration of Babinet’s principle on a slit and a wire.\n\n\n\nBabinet’s principle demonstrated experimentally on a slit (left) and a wire (right)."
  },
  {
    "objectID": "wave-optics/Fourier.html",
    "href": "wave-optics/Fourier.html",
    "title": "Experimental Physics 3 Course on Optics and Quantum Mechanics",
    "section": "",
    "text": "Fourier Transform and Diffraction\n\n\n\n\n\nIn the context of wave optics, the diffraction pattern observed in the far field (Fraunhofer diffraction) can be understood as the Fourier transform of the aperture function. For a single slit, the aperture function is a rectangular function.\n\nAperture Function of a Slit\nConsider a single slit of width \\(b\\) centered at \\(x = 0\\). The aperture function \\(A(x)\\) can be described as:\n\\[\nA(x) = \\begin{cases}\n1 & \\text{if } -\\frac{b}{2} \\leq x \\leq \\frac{b}{2} \\\\\n0 & \\text{otherwise}\n\\end{cases}\n\\]\nThis is a rectangular function, often denoted as \\(\\text{rect}\\left(\\frac{x}{b}\\right)\\).\n\n\nFourier Transform of the Aperture Function\nThe Fourier transform of the aperture function \\(A(x)\\) gives us the amplitude distribution in the far field. The Fourier transform \\(\\mathcal{F}\\{A(x)\\}\\) is defined as:\n\\[\n\\mathcal{F}\\{A(x)\\} = \\int_{-\\infty}^{\\infty} A(x) e^{-i 2 \\pi f x} \\, dx\n\\]\nFor the rectangular function \\(A(x) = \\text{rect}\\left(\\frac{x}{b}\\right)\\), the Fourier transform is:\n\\[\n\\mathcal{F}\\left\\{\\text{rect}\\left(\\frac{x}{b}\\right)\\right\\} = \\int_{-\\frac{b}{2}}^{\\frac{b}{2}} e^{-i 2 \\pi f x} \\, dx\n\\]\n\n\nEvaluating the Integral\nLet’s evaluate the integral:\n\\[\n\\mathcal{F}\\left\\{\\text{rect}\\left(\\frac{x}{b}\\right)\\right\\} = \\int_{-\\frac{b}{2}}^{\\frac{b}{2}} e^{-i 2 \\pi f x} \\, dx\n\\]\nThis integral can be solved as follows:\n\\[\n\\mathcal{F}\\left\\{\\text{rect}\\left(\\frac{x}{b}\\right)\\right\\} = \\left[ \\frac{e^{-i 2 \\pi f x}}{-i 2 \\pi f} \\right]_{-\\frac{b}{2}}^{\\frac{b}{2}}\n\\]\nSubstituting the limits:\n\\[\n\\mathcal{F}\\left\\{\\text{rect}\\left(\\frac{x}{b}\\right)\\right\\} = \\frac{1}{-i 2 \\pi f} \\left( e^{-i 2 \\pi f \\frac{b}{2}} - e^{i 2 \\pi f \\frac{b}{2}} \\right)\n\\]\nUsing Euler’s formula \\(e^{i \\theta} - e^{-i \\theta} = 2i \\sin(\\theta)\\):\n\\[\n\\mathcal{F}\\left\\{\\text{rect}\\left(\\frac{x}{b}\\right)\\right\\} = \\frac{1}{-i 2 \\pi f} \\cdot (-2i \\sin(\\pi f b))\n\\]\nSimplifying:\n\\[\n\\mathcal{F}\\left\\{\\text{rect}\\left(\\frac{x}{b}\\right)\\right\\} = \\frac{2 \\sin(\\pi f b)}{2 \\pi f} = \\frac{\\sin(\\pi f b)}{\\pi f}\n\\]\n\n\nSinc Function\nThe result can be expressed in terms of the sinc function. The sinc function is defined as:\n\\[\n\\text{sinc}(x) = \\frac{\\sin(\\pi x)}{\\pi x}\n\\]\nTherefore, the Fourier transform of the rectangular aperture function is:\n\\[\n\\mathcal{F}\\left\\{\\text{rect}\\left(\\frac{x}{b}\\right)\\right\\} = b \\cdot \\text{sinc}(b f)\n\\]"
  },
  {
    "objectID": "wave-optics/Diffraction2.html",
    "href": "wave-optics/Diffraction2.html",
    "title": "Diffraction in Applications",
    "section": "",
    "text": "The human eye provides an excellent real-world example of circular aperture diffraction through the pupil (the opening in the iris). By examining how light diffracts as it enters the eye, we can understand fundamental limits on visual resolution and how the eye is naturally optimized to these constraints.\nCalculating the Diffraction Limit of the Eye\nWhen light passes through the circular aperture of the pupil, it undergoes diffraction, producing an Airy disk pattern on the retina. The angle to the first minimum (dark ring) of the diffraction pattern is given by:\n\\[\n\\sin(\\theta_1) = 0.61\\, \\frac{\\lambda}{R}\n\\]\nwhere: - \\(\\theta_1\\) is the angle to the first minimum, - \\(\\lambda\\) is the wavelength of the light, - \\(R\\) is the radius of the aperture (pupil).\nFor an average pupil radius of \\(R = 2.5\\, \\text{mm}\\) and green light with a wavelength of \\(\\lambda = 532\\, \\text{nm}\\) (to which the human eye is most sensitive), we have:\n\\[\n\\sin(\\theta_1) = 0.61 \\times \\frac{532 \\times 10^{-9}\\, \\text{m}}{2.5 \\times 10^{-3}\\, \\text{m}} = 0.61 \\times 2.128 \\times 10^{-4} \\approx 1.298 \\times 10^{-4}\n\\]\nThus, the angle to the first minimum is approximately:\n\\[\n\\theta_1 \\approx \\sin^{-1}(1.298 \\times 10^{-4}) \\approx 0.00744^\\circ\n\\]\nDetermining the Size of the Airy Disk on the Retina\nThe distance from the pupil to the retina (the image plane) is approximately \\(L = 20\\, \\text{mm}\\) (or \\(2\\, \\text{cm}\\)). The linear radius \\(r\\) of the Airy disk on the retina is calculated by:\n\\[\nr = L \\sin(\\theta_1) = 20\\, \\text{mm} \\times 1.298 \\times 10^{-4} = 2.596 \\times 10^{-3}\\, \\text{mm} = 2.596\\, \\mu\\text{m}\n\\]\nSo, the diameter \\(D\\) of the Airy disk (central bright spot) is:\n\\[\nD = 2r = 2 \\times 2.596\\, \\mu\\text{m} = 5.192\\, \\mu\\text{m}\n\\]\nThis means that the smallest spot of light that can be formed on the retina due to diffraction is about \\(5.19\\, \\mu\\text{m}\\) in diameter.\nComparing with Photoreceptor Spacing in the Fovea\nThe fovea is a small region in the retina responsible for sharp central vision. It contains a high density of cone photoreceptor cells. The average density of cones in the fovea is approximately \\(150,000\\) cells per square millimeter. To find the average spacing \\(d\\) between these cells, we proceed as follows:\nArea per Cell:\n\\[\n   \\text{Area per cell} = \\frac{1\\, \\text{mm}^2}{150,000} = 6.667 \\times 10^{-6}\\, \\text{mm}^2 = 6.667\\, \\mu\\text{m}^2\n   \\]\nLinear Spacing Between Cells:\nAssuming a square packing (for simplicity), the linear spacing \\(d\\) is:\n\\[\n   d = \\sqrt{\\text{Area per cell}} = \\sqrt{6.667\\, \\mu\\text{m}^2} \\approx 2.58\\, \\mu\\text{m}\n   \\]\nIn reality, the photoreceptors are more closely packed in a hexagonal arrangement, but this calculation gives a good approximation.\n\n\n\n\n\n\nAnalysis of the Results\n\n\n\n\n\nThe analysis reveals that the diameter of the Airy disk is approximately \\(5.192\\, \\mu\\text{m}\\), while the center-to-center spacing of photoreceptors in the human eye is about \\(2.58\\, \\mu\\text{m}\\). This observation is significant because the diameter of the Airy disk is roughly twice the photoreceptor spacing, indicating that the central maximum of the diffraction pattern spans about two photoreceptors.\nThe close correspondence between the diffraction limit of the eye and the spacing of photoreceptor cells is noteworthy for several reasons. Firstly, the diffraction limit establishes the fundamental constraint on the resolving power of the eye, determining the smallest angular separation between two points of light that can be distinguished. Secondly, the density of photoreceptors is sufficiently high to sample the details provided by the optical system up to this diffraction limit.\nIncreasing the density of photoreceptors within the area of the Airy disk would not enhance visual resolution due to two primary factors. The first factor is the physical limitation imposed by the diffraction limit, which is a fundamental constraint arising from the wave nature of light and the size of the pupil. Consequently, resolution cannot be improved beyond this limit merely by increasing photoreceptor density. The second factor is related to signal intensity. Adding more photoreceptors in the same area would result in each cell receiving less light, given that the total light intensity is fixed. This reduction in light per photoreceptor could potentially decrease the signal-to-noise ratio, making it more challenging to detect light.\n\n\nThe design of the human eye exemplifies a natural optimization process. The density of photoreceptors is matched to the optical resolving power of the eye, ensuring that the visual system extracts the maximum amount of information without unnecessary redundancy. This efficient use of resources reflects an evolutionary adaptation, where biological systems have evolved to align anatomical structures with physical laws, optimizing functions such as vision to confer survival advantages. Over time, this alignment has resulted in a visual system that is finely tuned to the constraints and capabilities imposed by the physics of light and the anatomy of the eye.\n\nLand, M. F., & Nilsson, D.-E. (2012). Animal Eyes (2nd ed.). Oxford University Press.\nWilliams, D. R. (1988). Topography of the foveal cone mosaic in the living human eye. Vision Research, 28(3), 433–454.",
    "crumbs": [
      "Wave Optics",
      "Lecture 11",
      "Diffraction"
    ]
  },
  {
    "objectID": "wave-optics/Diffraction2.html#application-diffraction-in-the-human-eye",
    "href": "wave-optics/Diffraction2.html#application-diffraction-in-the-human-eye",
    "title": "Diffraction in Applications",
    "section": "",
    "text": "The human eye provides an excellent real-world example of circular aperture diffraction through the pupil (the opening in the iris). By examining how light diffracts as it enters the eye, we can understand fundamental limits on visual resolution and how the eye is naturally optimized to these constraints.\nCalculating the Diffraction Limit of the Eye\nWhen light passes through the circular aperture of the pupil, it undergoes diffraction, producing an Airy disk pattern on the retina. The angle to the first minimum (dark ring) of the diffraction pattern is given by:\n\\[\n\\sin(\\theta_1) = 0.61\\, \\frac{\\lambda}{R}\n\\]\nwhere: - \\(\\theta_1\\) is the angle to the first minimum, - \\(\\lambda\\) is the wavelength of the light, - \\(R\\) is the radius of the aperture (pupil).\nFor an average pupil radius of \\(R = 2.5\\, \\text{mm}\\) and green light with a wavelength of \\(\\lambda = 532\\, \\text{nm}\\) (to which the human eye is most sensitive), we have:\n\\[\n\\sin(\\theta_1) = 0.61 \\times \\frac{532 \\times 10^{-9}\\, \\text{m}}{2.5 \\times 10^{-3}\\, \\text{m}} = 0.61 \\times 2.128 \\times 10^{-4} \\approx 1.298 \\times 10^{-4}\n\\]\nThus, the angle to the first minimum is approximately:\n\\[\n\\theta_1 \\approx \\sin^{-1}(1.298 \\times 10^{-4}) \\approx 0.00744^\\circ\n\\]\nDetermining the Size of the Airy Disk on the Retina\nThe distance from the pupil to the retina (the image plane) is approximately \\(L = 20\\, \\text{mm}\\) (or \\(2\\, \\text{cm}\\)). The linear radius \\(r\\) of the Airy disk on the retina is calculated by:\n\\[\nr = L \\sin(\\theta_1) = 20\\, \\text{mm} \\times 1.298 \\times 10^{-4} = 2.596 \\times 10^{-3}\\, \\text{mm} = 2.596\\, \\mu\\text{m}\n\\]\nSo, the diameter \\(D\\) of the Airy disk (central bright spot) is:\n\\[\nD = 2r = 2 \\times 2.596\\, \\mu\\text{m} = 5.192\\, \\mu\\text{m}\n\\]\nThis means that the smallest spot of light that can be formed on the retina due to diffraction is about \\(5.19\\, \\mu\\text{m}\\) in diameter.\nComparing with Photoreceptor Spacing in the Fovea\nThe fovea is a small region in the retina responsible for sharp central vision. It contains a high density of cone photoreceptor cells. The average density of cones in the fovea is approximately \\(150,000\\) cells per square millimeter. To find the average spacing \\(d\\) between these cells, we proceed as follows:\nArea per Cell:\n\\[\n   \\text{Area per cell} = \\frac{1\\, \\text{mm}^2}{150,000} = 6.667 \\times 10^{-6}\\, \\text{mm}^2 = 6.667\\, \\mu\\text{m}^2\n   \\]\nLinear Spacing Between Cells:\nAssuming a square packing (for simplicity), the linear spacing \\(d\\) is:\n\\[\n   d = \\sqrt{\\text{Area per cell}} = \\sqrt{6.667\\, \\mu\\text{m}^2} \\approx 2.58\\, \\mu\\text{m}\n   \\]\nIn reality, the photoreceptors are more closely packed in a hexagonal arrangement, but this calculation gives a good approximation.\n\n\n\n\n\n\nAnalysis of the Results\n\n\n\n\n\nThe analysis reveals that the diameter of the Airy disk is approximately \\(5.192\\, \\mu\\text{m}\\), while the center-to-center spacing of photoreceptors in the human eye is about \\(2.58\\, \\mu\\text{m}\\). This observation is significant because the diameter of the Airy disk is roughly twice the photoreceptor spacing, indicating that the central maximum of the diffraction pattern spans about two photoreceptors.\nThe close correspondence between the diffraction limit of the eye and the spacing of photoreceptor cells is noteworthy for several reasons. Firstly, the diffraction limit establishes the fundamental constraint on the resolving power of the eye, determining the smallest angular separation between two points of light that can be distinguished. Secondly, the density of photoreceptors is sufficiently high to sample the details provided by the optical system up to this diffraction limit.\nIncreasing the density of photoreceptors within the area of the Airy disk would not enhance visual resolution due to two primary factors. The first factor is the physical limitation imposed by the diffraction limit, which is a fundamental constraint arising from the wave nature of light and the size of the pupil. Consequently, resolution cannot be improved beyond this limit merely by increasing photoreceptor density. The second factor is related to signal intensity. Adding more photoreceptors in the same area would result in each cell receiving less light, given that the total light intensity is fixed. This reduction in light per photoreceptor could potentially decrease the signal-to-noise ratio, making it more challenging to detect light.\n\n\nThe design of the human eye exemplifies a natural optimization process. The density of photoreceptors is matched to the optical resolving power of the eye, ensuring that the visual system extracts the maximum amount of information without unnecessary redundancy. This efficient use of resources reflects an evolutionary adaptation, where biological systems have evolved to align anatomical structures with physical laws, optimizing functions such as vision to confer survival advantages. Over time, this alignment has resulted in a visual system that is finely tuned to the constraints and capabilities imposed by the physics of light and the anatomy of the eye.\n\nLand, M. F., & Nilsson, D.-E. (2012). Animal Eyes (2nd ed.). Oxford University Press.\nWilliams, D. R. (1988). Topography of the foveal cone mosaic in the living human eye. Vision Research, 28(3), 433–454.",
    "crumbs": [
      "Wave Optics",
      "Lecture 11",
      "Diffraction"
    ]
  },
  {
    "objectID": "wave-optics/Diffraction2.html#application-resolution-of-an-optical-microscope",
    "href": "wave-optics/Diffraction2.html#application-resolution-of-an-optical-microscope",
    "title": "Diffraction in Applications",
    "section": "Application: Resolution of an Optical Microscope",
    "text": "Application: Resolution of an Optical Microscope\nThe resolution of an optical microscope is fundamentally limited by the diffraction of light as it passes through the optical components, particularly the objective lens. Diffraction causes point sources of light to produce blurred images rather than perfect points, affecting the microscope’s ability to distinguish between two closely spaced objects.\n\nRayleigh’s Criterion for Resolution\nKey Question: How close can two point sources be while still being perceived as distinct entities by an optical system?\nTo answer this, we need to consider two essential aspects of how a lens modifies light:\n\nWavefront Transformation: A lens alters the curvature of incoming wavefronts, focusing parallel rays (plane waves) to a point in the focal plane.\nFinite Aperture Effects: The lens has a finite size and acts as a circular aperture, introducing diffraction effects that spread the image of a point source into a diffraction pattern known as the Airy disk.\n\nVisual Representation:\n\n\n\nIllustration showing two point sources and their overlapping diffraction patterns as they approach each other.\n\n\nEach point source produces its own diffraction pattern. As the sources move closer, their patterns begin to overlap, making it harder to distinguish between them.\nRayleigh’s Resolution Criterion:\n\nTwo point sources are considered just resolvable when the principal maximum (center) of one Airy pattern coincides with the first minimum (dark ring) of the other.\n\n\n\n\nGraph depicting Rayleigh’s criterion, showing the intensity profiles of two overlapping Airy patterns.\n\n\nFor incoherent light sources (where the light waves are not in phase), this criterion corresponds to a 26% dip in intensity between the two peaks, which is generally sufficient for the human eye or detectors to distinguish the two sources as separate.\nAngle to the First Minimum:\nThe angle \\(\\theta_1\\) to the first minimum of the diffraction pattern from a circular aperture of radius \\(R\\) is given by:\n\\[\n   \\sin(\\theta_1) = 1.22\\, \\frac{\\lambda}{2R}\n   \\]\nSince the diameter of the aperture \\(D = 2R\\), this can also be written as:\n\\[\n   \\sin(\\theta_1) = 1.22\\, \\frac{\\lambda}{D}\n   \\]\nThe factor 1.22 arises from the first zero of the Bessel function \\(J_1\\) that describes the diffraction pattern of a circular aperture.\nSmall Angle Approximation:\nFor small angles (common in optical systems), \\(\\sin(\\theta_1) \\approx \\theta_1\\) in radians.\nRelating Angular to Linear Separation in the Image Plane:\nThe angular resolution \\(\\theta_1\\) corresponds to a linear separation \\(\\Delta x\\) in the image plane (at image distance \\(b\\)):\n\\[\n   \\theta_1 = \\frac{\\Delta x}{b}\n   \\]\nCombining the Equations:\nSubstituting \\(\\theta_1\\):\n\\[\n   \\frac{\\Delta x}{b} = 1.22\\, \\frac{\\lambda}{D}\n   \\]\nSolving for \\(\\Delta x\\):\n\\[\n   \\Delta x = 1.22\\, \\frac{\\lambda b}{D}\n   \\]\nConsidering the Object Plane:\nThe magnification \\(M\\) of the optical system is:\n\\[\n   M = \\frac{b}{g}\n   \\]\nwhere \\(g\\) is the object distance. The corresponding separation in the object plane (\\(\\Delta d\\)) is:\n\\[\n   \\Delta d = \\frac{\\Delta x}{M} = \\frac{\\Delta x \\, g}{b}\n   \\]\nSubstituting \\(\\Delta x\\):\n\\[\n   \\Delta d = 1.22\\, \\frac{\\lambda b}{D} \\times \\frac{g}{b} = 1.22\\, \\frac{\\lambda g}{D}\n   \\]\nIntroducing Numerical Aperture (NA):\nThe numerical aperture (NA) of the lens is defined as:\n\\[\n   \\text{NA} = n \\sin(\\alpha)\n   \\]\nwhere:\n\n\\(n\\) is the refractive index of the medium between the object and the lens.\n\\(\\alpha\\) is the half-angle of the maximum cone of light that can enter or exit the lens.\n\nSince \\(\\sin(\\alpha) = \\frac{R}{g}\\), we have:\n\\[\n   D = 2R = 2 g \\sin(\\alpha)\n   \\]\nSubstituting \\(D\\) into \\(\\Delta d\\):\n\\[\n   \\Delta d = 1.22\\, \\frac{\\lambda g}{2 g \\sin(\\alpha)} = \\frac{1.22\\, \\lambda}{2 \\sin(\\alpha)} = \\frac{0.61\\, \\lambda}{\\sin(\\alpha)}\n   \\]\nTherefore, incorporating the refractive index \\(n\\):\n\\[\n   \\Delta d = \\frac{0.61\\, \\lambda}{n \\sin(\\alpha)} = \\frac{0.61\\, \\lambda}{\\text{NA}}\n   \\]\nUnder Rayleigh’s resolution criterion, several key factors influence the resolving power of an optical system.\nFirstly, a higher numerical aperture (NA) improves resolution. This increase can be achieved by enhancing either the refractive index \\(n\\) of the medium between the object and the lens or the sine of the collection angle \\(\\sin(\\alpha)\\). Since the NA is defined as \\(\\text{NA} = n \\sin(\\alpha)\\), a larger NA allows the lens to gather more diffracted light, thereby resolving finer details in the image. In air, where the refractive index is approximately \\(n \\approx 1\\), the maximum achievable NA is less than 1, which limits the resolution. This limitation arises because the maximum value of \\(\\sin(\\alpha)\\) is 1 (when \\(\\alpha = 90^\\circ\\)), so the NA in air cannot exceed 1. In practical systems, the collection angle \\(\\alpha\\) is much less than \\(90^\\circ\\), further reducing the NA and thus the resolution. Immersion lenses, which use a medium with a higher refractive index (such as water or oil), can achieve higher NAs, overcoming this limitation and improving resolution.\nSecondly, using shorter wavelengths \\((\\lambda)\\) of light leads to better resolution. According to the formula \\(\\Delta d = \\frac{0.61\\, \\lambda}{\\text{NA}}\\), the minimum resolvable distance \\(\\Delta d\\) is directly proportional to the wavelength. Therefore, decreasing the wavelength reduces \\(\\Delta d\\), allowing the optical system to distinguish smaller features of the object.\n\n\n\n\n\n\nNote\n\n\n\n\n\nRayleigh’s Resolution Criterion\nTwo incoherent point sources can be resolved when their minimum separation \\(\\Delta d\\) satisfies:\n\\[\n\\Delta d \\geq \\frac{0.61\\, \\lambda}{\\text{NA}}\n\\]\nWhere:\n\n\\(\\Delta d\\) is the minimum resolvable distance between the two point sources.\n\\(\\lambda\\) is the wavelength of the light used for imaging.\n\\(\\text{NA} = n \\sin(\\alpha)\\) is the numerical aperture of the optical system.\n\n\\(n\\) is the refractive index of the medium.\n\\(\\alpha\\) is the half-angle of the maximum cone of light entering the lens.\n\n\n\n\n\n\n\nAbbe’s Criterion for Resolution\nLimitations of Rayleigh’s Criterion:\n\nRayleigh’s criterion applies to incoherent light sources, where the intensities of the diffraction patterns add directly.\nIt does not fully account for the effects of coherence and interference in the imaging process.\n\nErnst Abbe developed a theory that considers the imaging of coherent light sources, where the phases of the waves are correlated. It emphasizes the importance of diffracted orders and spatial frequencies in the formation of images.\nThe key concepts in Abbe’s theory are\nDiffraction Grating Analogy:\n\nAn object with fine details can be thought of as a diffraction grating that scatters light into multiple diffraction orders.\nThe ability to resolve these fine details depends on the optical system’s capacity to capture these diffracted orders.\n\nSpatial Frequencies:\n\nThe finer the details in the object, the higher the spatial frequency.\nHigh spatial frequencies correspond to larger angles in the diffraction pattern.\n\nOptical Transfer Function:\n\nDescribes how different spatial frequencies are transmitted through the optical system.\nAn optical system with a larger NA can transmit higher spatial frequencies, improving resolution.\n\nFollowing that analogy, Abbe’s criterion states that the minimum resolvable distance \\(\\Delta d\\) between two points in the object plane is given by:\n\\[\n\\Delta d = \\frac{\\lambda}{2 \\text{NA}}\n\\]\n\n\n\n\n\n\nRayleigh’s and Abbe’s criteria\n\n\n\n\nAbbe’s Limit:\n\n\\(\\Delta d = \\frac{\\lambda}{2 \\text{NA}}\\)\nEmphasizes coherent imaging and the transmission of at least two diffracted orders (zeroth and first) for resolution.\n\nRayleigh’s Limit:\n\n\\(\\Delta d = \\frac{0.61\\, \\lambda}{\\text{NA}}\\)\nBased on the visibility of intensity dips in the overlapping Airy patterns of incoherent sources.\n\n\nImplications in Microscopy:\nCoherent Illumination:\n\nTechniques like phase-contrast or interference microscopy rely on coherent light.\nAbbe’s criterion is more appropriate for these methods.\n\nIncoherent Illumination:\n\nCommon in conventional bright-field microscopy.\nRayleigh’s criterion provides a practical resolution limit.\n\nImportance of Abbe’s Criterion:\n\nHighlights the role of interference between diffracted waves in image formation.\nDemonstrates that resolution is fundamentally limited by the wavelength of light and the NA of the system.\nSuggests that capturing higher spatial frequencies (larger NA) leads to better resolution.",
    "crumbs": [
      "Wave Optics",
      "Lecture 11",
      "Diffraction"
    ]
  },
  {
    "objectID": "wave-optics/Diffraction2.html#using-huygens-sources-for-more",
    "href": "wave-optics/Diffraction2.html#using-huygens-sources-for-more",
    "title": "Diffraction in Applications",
    "section": "Using Huygens Sources for more",
    "text": "Using Huygens Sources for more\nThe Huygens principle is a powerful tool to calculate the diffraction pattern of an aperture. The idea is to consider the aperture as a collection of point sources, which emit spherical waves. The superposition of all these waves will then give the total wave field. Below is a Python code which demonstrates the calculation of the diffraction pattern of a spherical mirror. It uses Huygens sources placed on an arc (see left). The right image shows the resulting diffraction pattern in the focal plane of the mirror.\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef spherical_wave(k, omega, r, r0, t):\n    k_norm = np.linalg.norm(k)\n    d = np.linalg.norm(r - r0[:, np.newaxis, np.newaxis], axis=0)\n    return np.exp(1j * (k_norm * d - omega * t)) / d\n\n# Parameters\nwavelength = 532e-9  # Wavelength in meters (green light)\nk0 = 2 * np.pi / wavelength  # Wave number\nc = 299792458  # Speed of light in m/s\nomega0 = k0 * c  # Angular frequency\nt = 0  # Time\n\nx = np.linspace(-15e-6, 15e-6, 900)  # x-axis from -5 µm to 5 µm\nz = np.linspace(-15e-6, 15e-6, 900)  # z-axis from -5 µm to 5 µm\nX, Z = np.meshgrid(x, z)\nr = np.array([X, np.zeros_like(X), Z])  # Observation points in 3D space (y=0)\n\nnum_sources = 100  # Number of point sources along the arc\narc_angle = np.deg2rad(100)  # Total arc angle in radians (60 degrees)\ntheta_sources = np.linspace(-arc_angle / 2, arc_angle / 2, num_sources)  # Source angles\nradius = 10e-6  # Radius of the arc (10 µm)\n\ntotal_field = np.zeros_like(X, dtype=complex)\n\nfor theta in theta_sources:\n    # Calculate source position (x0, z0) on the arc\n    x0 = radius * np.cos(theta)\n    z0 = radius * np.sin(theta)\n    r0 = np.array([x0, 0, z0])  # Source position in 3D space\n    field = spherical_wave(k0, omega0, r, r0, t)\n    total_field += field\n\nintensity = np.abs(total_field)**2\n\nintensity/=intensity[450,450]\nfig,ax=plt.subplots(1,2,figsize=get_size(18, 10))\n\nextent = [np.min(z)*1e6, np.max(z)*1e6, np.min(x)*1e6, np.max(x)*1e6]\nax[1].imshow(intensity.transpose(), extent=extent, origin='lower', cmap='gray_r',vmax=1)\nax[1].set_xlabel('z [µm]')\nax[1].set_ylabel('x [µm]')\nax[1].set_xlim(-5, 5)\nax[1].set_ylim(-5, 5)\n\nextent = [np.min(z)*1e6, np.max(z)*1e6, np.min(x)*1e6, np.max(x)*1e6]\nax[0].imshow(intensity.transpose(), extent=extent, origin='lower', cmap='gray_r',vmax=1)\nax[0].set_xlabel('z [µm]')\nax[0].set_ylabel('x [µm]')\nax[0].set_xlim(-15, 15)\nax[0].set_ylim(-15, 15)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nThe pattern changes with increasing angle of the arc, which is consistent with our knowledge of the numerical aperature defining the resolution of and optical system. The changes are especially visible along the vertical axis.\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef spherical_wave(k, omega, r, r0, t):\n    k_norm = np.linalg.norm(k)\n    d = np.linalg.norm(r - r0[:, np.newaxis, np.newaxis], axis=0)\n    return np.exp(1j * (k_norm * d - omega * t)) / d\n\n# Parameters\nwavelength = 532e-9  # Wavelength in meters (green light)\nk0 = 2 * np.pi / wavelength  # Wave number\nc = 299792458  # Speed of light in m/s\nomega0 = k0 * c  # Angular frequency\nt = 0  # Time\n\nx = np.linspace(-15e-6, 15e-6, 900)  # x-axis from -5 µm to 5 µm\nz = np.linspace(-15e-6, 15e-6, 900)  # z-axis from -5 µm to 5 µm\nX, Z = np.meshgrid(x, z)\nr = np.array([X, np.zeros_like(X), Z])  # Observation points in 3D space (y=0)\n\nnum_sources = 100  # Number of point sources along the arc\narc_angle = np.deg2rad(150)  # Total arc angle in radians (60 degrees)\ntheta_sources = np.linspace(-arc_angle / 2, arc_angle / 2, num_sources)  # Source angles\nradius = 10e-6  # Radius of the arc (10 µm)\n\ntotal_field = np.zeros_like(X, dtype=complex)\n\nfor theta in theta_sources:\n    # Calculate source position (x0, z0) on the arc\n    x0 = radius * np.cos(theta)\n    z0 = radius * np.sin(theta)\n    r0 = np.array([x0, 0, z0])  # Source position in 3D space\n    field = spherical_wave(k0, omega0, r, r0, t)\n    total_field += field\n\nintensity = np.abs(total_field)**2\n\nintensity/=intensity[450,450]\nfig,ax=plt.subplots(1,2,figsize=get_size(18, 10))\n\nextent = [np.min(z)*1e6, np.max(z)*1e6, np.min(x)*1e6, np.max(x)*1e6]\nax[1].imshow(intensity.transpose(), extent=extent, origin='lower', cmap='gray_r',vmax=1)\nax[1].set_xlabel('z [µm]')\nax[1].set_ylabel('x [µm]')\nax[1].set_xlim(-5, 5)\nax[1].set_ylim(-5, 5)\n\nextent = [np.min(z)*1e6, np.max(z)*1e6, np.min(x)*1e6, np.max(x)*1e6]\nax[0].imshow(intensity.transpose(), extent=extent, origin='lower', cmap='gray_r',vmax=1)\nax[0].set_xlabel('z [µm]')\nax[0].set_ylabel('x [µm]')\nax[0].set_xlim(-15, 15)\nax[0].set_ylim(-15, 15)\nplt.tight_layout()\nplt.show()",
    "crumbs": [
      "Wave Optics",
      "Lecture 11",
      "Diffraction"
    ]
  },
  {
    "objectID": "wave-optics/FabryPerot.html",
    "href": "wave-optics/FabryPerot.html",
    "title": "Fabry Perot Interferometer",
    "section": "",
    "text": "The Fabry-Perot interferometer demonstrates multiple-wave interference with decreasing amplitude. It consists of two parallel mirrors separated by a distance \\(d\\), creating multiple reflections of incident light.\n\n\n\nSimplified Sketch of a Fabry-Perot Interferometer.\n\n\nWhen light with amplitude \\(A_0\\) enters the interferometer, it undergoes a series of transmissions and reflections. The first transmitted wave has amplitude:\n\\[\nU_1=A_0t_1 t_2\n\\]\nwhere \\(t_1\\) and \\(t_2\\) are the transmission coefficients of the first and second mirrors. The second transmitted wave includes reflections from both mirrors (\\(r_1\\) and \\(r_2\\)) and a phase shift \\(\\Delta\\phi\\):\n\\[\nU_2=A_0t_1 t_2 r_1 r_2 e^{i\\phi}=U_1 r_1 r_2 e^{i\\Delta\\phi}\n\\]\nThis follows our earlier treatment of multiple-wave interference with decreasing amplitude, where \\(\\sqrt{I_0}=A_0 t_1 t_2\\) and \\(r=r_1r_2\\). The phase shift between successive reflections is:\n\\[\n\\phi=\\frac{2\\pi}{\\lambda} \\Delta s = \\frac{2\\pi}{\\lambda} 2d\\cos(\\theta)\n\\]\nwhere \\(\\Delta s=2d\\cos(\\theta)\\) represents the path difference between adjacent rays.\nThe resulting intensity distribution is:\n\\[\nI=|U|^2=\\frac{I_{0}}{|1-re^{i\\phi}|^2}=\\frac{I_0}{(1-r)^2+4r\\sin^2\\left (\\frac{2\\pi}{\\lambda} d\\cos(\\theta)\\right)}\n\\]\n\n\n\nFabry Perot Interferometer.\n\n\n\nFinesse and Spectral Properties\nThe quality of interference in a Fabry-Perot interferometer is characterized by the Finesse \\(\\mathcal{F}\\):\n\\[\n\\mathcal{F}=\\frac{\\pi \\sqrt{r}}{1-r}\n\\]\nwhere \\(r=r_1r_2\\) is the product of the mirrors’ reflection coefficients. As \\(r\\) approaches 1 (higher reflectivity), the Finesse increases, resulting in sharper interference peaks.\nFor normal incidence (\\(\\theta=0\\)), the phase difference simplifies to:\n\\[\n\\Delta\\phi=\\frac{4\\pi d}{\\lambda}\n\\]\nConstructive interference occurs when \\(\\Delta\\phi=m2\\pi\\) (where \\(m\\) is an integer), giving us the wavelengths of transmission maxima:\n\\[\n\\lambda_m=\\frac{2d}{m}\n\\]\n\nFree Spectral Range\nThe spacing between adjacent transmission peaks in an optical system can be expressed in terms of either wavelength or frequency. This spacing is known as the free spectral range (FSR).\nIn Wavelength:\nThe difference in wavelength between adjacent transmission peaks is given by:\n\\[\n   \\delta \\lambda = \\lambda_{m} - \\lambda_{m+1} = \\frac{\\lambda_m}{m+1}\n   \\]\nHere, \\(\\lambda_m\\) is the wavelength corresponding to the \\(m\\)-th transmission peak.\nIn Frequency:\nThe difference in frequency between adjacent transmission peaks is given by:\n\\[\n   \\delta \\nu = \\nu_{m+1} - \\nu_m = \\frac{c}{2d}\n   \\]\nHere, \\(c\\) is the speed of light, and \\(d\\) is the distance between the reflecting surfaces in the optical system.\nThe free spectral range (FSR) represents the interval between successive transmission peaks and is a crucial parameter in the design and analysis of optical systems, such as Fabry-Pérot interferometers and optical resonators.\n\n\nSpectral Resolution\nThe spectral resolution of an interferometer is determined by the width of its interference peaks, which indicates the instrument’s ability to distinguish between closely spaced wavelengths. This width is often characterized by the full width at half maximum (FWHM) of the peaks.\nTo find the FWHM, we start with the intensity ratio at half maximum:\n\\[\n\\frac{I}{I_{\\rm max}} = \\frac{1}{2} = \\frac{1}{1 + \\left( \\frac{\\mathcal{F}}{\\pi} \\right)^2 \\Delta \\phi_{1/2}^2 }\n\\]\nSolving for the phase difference \\(\\Delta \\phi_{1/2}\\) at half maximum, we can determine the corresponding frequency width:\n\\[\n\\Delta \\nu = \\frac{c}{2d \\mathcal{F}} = \\frac{\\delta \\nu}{\\mathcal{F}}\n\\]\nHere, \\(\\delta \\nu\\) is the free spectral range, \\(c\\) is the speed of light, \\(d\\) is the distance between the reflecting surfaces, and \\(\\mathcal{F}\\) is the finesse of the interferometer.\nThe finesse \\(\\mathcal{F}\\) is defined as the ratio of the free spectral range to the FWHM:\n\\[\n\\mathcal{F} = \\frac{\\delta \\nu}{\\Delta \\nu} = \\frac{\\lambda}{\\Delta \\lambda}\n\\]\nThis ratio provides a measure of the interferometer’s spectral resolution, indicating how well it can separate two closely spaced spectral lines.\nThe overall resolving power \\(\\mathcal{R}\\) of the interferometer is given by:\n\\[\n\\mathcal{R} = m \\mathcal{F}\n\\]\nwhere \\(m\\) is the order of the interference. The resolving power \\(\\mathcal{R}\\) quantifies the ability of the interferometer to resolve spectral features, with higher values indicating better resolution.\n\n\n\nTwo different wavelengths interfering constructively in a Fabry Perot interferometer.\n\n\n\n\n\n\n\n\nFree Spectral Range and Spectral Resolution\n\n\n\n\n\nFree Spectral Range (FSR):\nThe free spectral range is the spacing between adjacent transmission maxima in a Fabry-Perot interferometer. It can be expressed in terms of wavelength or frequency:\n\nIn wavelength: \\[\n\\delta \\lambda = \\lambda_{m} - \\lambda_{m+1} = \\frac{\\lambda_m}{m+1}\n\\]\nIn frequency: \\[\n\\delta \\nu = \\nu_{m+1} - \\nu_m = \\frac{c}{2d}\n\\]\n\nThe FSR indicates the range over which the interferometer can distinguish between different wavelengths or frequencies before the next order of interference occurs.\nSpectral Resolution:\nThe spectral resolution of a Fabry-Perot interferometer is determined by the width of the interference peaks. It is often quantified by the Finesse (\\(\\mathcal{F}\\)), which is the ratio of the free spectral range to the full width at half maximum (FWHM) of the peaks:\n\\[\n\\mathcal{F} = \\frac{\\delta \\nu}{\\Delta \\nu} = \\frac{\\lambda}{\\Delta \\lambda}\n\\]\nThe resolving power (\\(\\mathcal{R}\\)) of the interferometer is given by:\n\\[\n\\mathcal{R} = m \\mathcal{F}\n\\]\nwhere \\(m\\) is the interference order. The resolving power indicates the ability of the interferometer to distinguish between closely spaced spectral lines.\n\n\n\n\n\n\nRing Pattern Formation\nWhen a Fabry-Perot interferometer is used with an extended monochromatic light source and appropriate optics, it produces a characteristic ring pattern:\n\n\n\nFabry Perot Interferometer and interference pattern observed in the lecture.\n\n\nThe rings represent contours of constant phase difference, becoming more closely spaced with increasing radius as demonstrated in these experimental observations:\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 1— Fabry Perot Interferometer and interference pattern observed in the lecture.\n\n\n\nThis ring pattern is a powerful tool for spectroscopic analysis, as different wavelengths produce distinct ring patterns, allowing precise wavelength measurements and spectral analysis.\n\n\n\n\n\n\nApplications in Modern Research and Technology\n\n\n\n\n\nSpectroscopy:\n\nHigh-Resolution Spectroscopy: Fabry-Perot interferometers are used to achieve high spectral resolution, allowing precise measurements of spectral lines. This is crucial in fields like astrophysics, where detailed analysis of stellar spectra can reveal information about the composition, temperature, and motion of celestial objects.\n\n\n\n\nSodium D Lines measured as 593.0 +/- 4.5 nm, 591.1 +/- 5.0 nm with a difference of 0.604 +/- 0.025 (matching the accepted values of 589.5924 nm, 588.9951 with a difference of 0.5973 nm). Also courtesy of Lake Forest College\n\n\n\nLaser Spectroscopy: They are used to analyze the spectral properties of lasers, including linewidth, mode structure, and stability.\n\nOptical Communications:\n\nWavelength Division Multiplexing (WDM): Fabry-Perot filters are used in WDM systems to separate and combine different wavelength channels, increasing the data-carrying capacity of optical fibers.\nLaser Stabilization: They help stabilize the wavelength of lasers used in optical communication systems, ensuring consistent performance and reducing signal degradation.\n\nMetrology:\n\nPrecision Measurement: Fabry-Perot interferometers are used for precise distance and displacement measurements. They can measure changes in length with sub-nanometer accuracy, making them valuable in applications like semiconductor manufacturing and materials science.\nRefractive Index Measurement: They are used to measure the refractive index of gases, liquids, and solids with high precision.\n\nLaser Technology:\n\nMode-Locking: Fabry-Perot cavities are used in mode-locked lasers to produce ultra-short pulses of light, which are essential for applications in time-resolved spectroscopy, medical imaging, and telecommunications.\nLaser Tuning: They are used to tune the wavelength of lasers, enabling precise control over the output wavelength for various applications.\n\nEnvironmental Monitoring:\n\nGas Analysis: Fabry-Perot interferometers are used in gas analyzers to detect and quantify trace gases in the atmosphere. This is important for monitoring air quality, greenhouse gas emissions, and industrial processes.\nRemote Sensing: They are used in remote sensing instruments to analyze the spectral properties of reflected or emitted light from the Earth’s surface and atmosphere, providing valuable data for climate studies and environmental monitoring.\n\nAstronomy:\n\nInterferometric Imaging: Fabry-Perot interferometers are used in telescopes to enhance the resolution of astronomical images. They can be used to study fine details of celestial objects, such as the structure of galaxies and the dynamics of star-forming regions.\nDoppler Spectroscopy: They are used to measure the Doppler shift of spectral lines, allowing astronomers to determine the radial velocity of stars and planets, which is crucial for the detection of exoplanets.\n\nBiomedical Applications:\n\nOptical Coherence Tomography (OCT): Fabry-Perot interferometers are used in OCT systems to achieve high-resolution cross-sectional imaging of biological tissues. This is valuable for medical diagnostics, particularly in ophthalmology and dermatology. \nFluorescence Microscopy: They are used to enhance the spectral resolution of fluorescence microscopes, enabling detailed analysis of biological samples.\n\nQuantum Optics:\n\nCavity Quantum Electrodynamics (CQED): Fabry-Perot cavities are used to study the interaction between light and matter at the quantum level. This research is fundamental for the development of quantum information technologies and quantum computing.\nSingle-Photon Sources: They are used to create and manipulate single-photon sources, which are essential for quantum communication and cryptography.\n\nThese applications highlight the versatility and importance of Fabry-Perot interferometers in advancing scientific research and technological innovation across various fields."
  },
  {
    "objectID": "wave-optics/Wave Optics.html",
    "href": "wave-optics/Wave Optics.html",
    "title": "Wave Optics",
    "section": "",
    "text": "Historical Development of Scalar Wave Optics\n\n\n\n\n\nWave optics represents a fundamental shift in our understanding of light’s nature. Here are the key developments in its history:\nAncient Times - 16th Century: Geometric Optics Dominance - Ancient civilizations understood basic reflection and refraction. - Focus was primarily on ray-based descriptions of light.\n1660s: Robert Hooke’s Wave Theory - Proposed that light might be a rapid vibrational motion. - Observed interference effects in thin films (“Newton’s Rings,” though named later).\n1690: Christiaan Huygens’ Wave Theory - Published “Traité de la Lumière” (Treatise on Light). - Introduced the concept of wavefronts. - Developed principle for wave propagation (Huygens’ Principle).\n1704: Newton’s “Opticks” - Despite observing interference effects, favored particle theory. - His authority led to wave theory being largely dismissed for nearly a century.\n1801: Thomas Young’s Double-Slit Experiment - Demonstrated interference of light definitively. - Measured wavelengths of different colors. - Introduced the concept of transverse waves.\n\n\n\nYoung’s double-slit experiment\n\n\n1818: Augustin-Jean Fresnel - Developed comprehensive mathematical theory of diffraction. - Explained polarization through transverse waves. - Created Fresnel equations for reflection and refraction.\nWave optics extends our understanding beyond the limitations of geometric optics by treating light as a wave phenomenon. This approach explains effects that cannot be accounted for by ray tracing alone, such as:\nLight is part of the electromagnetic spectrum, which spans an enormous range of frequencies. The visible region, extending approximately from 400 nm (violet) to 700 nm (red), represents only a small fraction of this spectrum. This wave description is essential for understanding many optical phenomena that geometric optics cannot explain, particularly when dealing with structures comparable in size to the wavelength of light.\nIn the following, we would like to introduce wave by discarding the fact, that light is related to electric and magnetic fields. This is useful as the vectorial nature of the electric and magnetic field further complicates the calculations, but we do not need those yet. Accordingly we also do not understand how light really interacts with matter and we therefore have to introduce some postulates as well.",
    "crumbs": [
      "Wave Optics",
      "Lecture 7",
      "Wave Optics"
    ]
  },
  {
    "objectID": "wave-optics/Wave Optics.html#postulates-of-wave-optics",
    "href": "wave-optics/Wave Optics.html#postulates-of-wave-optics",
    "title": "Wave Optics",
    "section": "Postulates of Wave Optics",
    "text": "Postulates of Wave Optics\n\n\n\n\n\n\nWave\n\n\n\nA wave corresponds to a physical quantity which oscillates in space and time. Its energy current density is related to the square magnitude of the amplitude.\n\n\n\nWave equation\n\\[\n\\nabla^2 u - \\frac{1}{c^2}\\frac{\\partial^2 u}{\\partial t^2}=0\n\\]\nwhere the Laplace operator \\(\\nabla^2\\) is defined as:\n\\[\n\\nabla^2 =\\frac{\\partial^2}{\\partial x^2}+\\frac{\\partial^2}{\\partial y^2}+\\frac{\\partial^2}{\\partial z^2}\n\\]\nThe wave equation is a linear differential equation, which implies that the superposition principle holds. Specifically, if \\(u_1(\\mathbf{r},t)\\) and \\(u_2(\\mathbf{r},t)\\) are solutions of the wave equation, then any linear combination:\n\\[\nu(\\mathbf{r},t)=a_1u_1(\\mathbf{r},t)+a_2u_2(\\mathbf{r},t)\n\\]\nis also a solution, where \\(a_1\\) and \\(a_2\\) are arbitrary constants.\n\n\nMonochromatic Wave\nA monochromatic wave consists of a single frequency \\(\\omega\\). By definition, such a wave must be infinite in time and free from phase disturbances (such as sudden jumps). The mathematical expression for a monochromatic wave is:\n\\[u(\\mathbf{r},t)=a(\\mathbf{r})\\cos(\\omega t + \\phi(\\mathbf{r}))\\]\nwhere:\n\n\\(a(\\mathbf{r})\\) represents the amplitude\n\\(\\phi(\\mathbf{r})\\) represents the spatial phase\n\\(\\omega\\) represents the angular frequency\n\n\n\n\n\n\n\nFigure 2— Representation of a wavefunction over time (constant position) denoting the phase \\(\\phi\\) and the period \\(T=1/\\nu\\)\n\n\n\n\nComplex Amplitude\nThe wave can be represented in complex form as:\n\\[\nU(\\mathbf{r},t)=a(\\mathbf{r})e^{i\\phi(\\mathbf{r})}e^{i\\omega t}\n\\]\nThis is known as the complex wavefunction.\n\n\n\n\n\n\nFigure 3— Phasor diagram of the complex amplitude \\(U(\\mathbf{r})\\) (left) and \\(U(t)\\) (right)\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nA phasor displays the complex amplitude with magnitude and phase as a vector in the complex plane.\n\n\nThe relationship between the complex and real wavefunctions is:\n\\[\nu(\\mathbf{r},t)=\\text{Re}\\{U(\\mathbf{r},t)\\}=\\frac{1}{2}[U(\\mathbf{r},t)+U^*(\\mathbf{r},t)]\n\\]\nThe complex wavefunction satisfies the same wave equation:\n\\[\n\\nabla^2 U - \\frac{1}{c^2}\\frac{\\partial^2 U}{\\partial t^2}=0\n\\]\nWe can separate the complex wavefunction into spatial and temporal components:\n\\[\nU(\\mathbf{r},t)=U(\\mathbf{r})e^{i\\omega t}\n\\]\nwhere\n\\[\nU(\\mathbf{r})=a(\\mathbf{r})e^{i\\phi(\\mathbf{r})}\n\\]\nHere, \\(\\phi\\) represents the spatial phase of the wavefunction. Substituting this into the wave equation and noting that the time derivatives bring down factors of \\(i\\omega\\):\n\\[\\nabla^2 [U(\\mathbf{r})e^{i\\omega t}] - \\frac{1}{c^2}\\frac{\\partial^2}{\\partial t^2}[U(\\mathbf{r})e^{i\\omega t}] = 0\\] \\[\\nabla^2 U(\\mathbf{r})e^{i\\omega t} + \\frac{\\omega^2}{c^2}U(\\mathbf{r})e^{i\\omega t} = 0\\]\nThe time dependence \\(e^{i\\omega t}\\) factors out, leaving us with the Helmholtz equation:\n\\[\\nabla^2 U(\\mathbf{r}) + k^2U(\\mathbf{r}) = 0\\]\nwhere \\(k = \\omega/c\\) is the wave number. This equation describes the spatial behavior of monochromatic waves.\n\n\nIntensity of Waves\nThe intensity of a wave at position \\(\\mathbf{r}\\) and time \\(t\\) is defined as:\n\\[\nI(\\mathbf{r},t)=2\\langle u^2(\\mathbf{r},t)\\rangle\n\\]\nwhere \\(I\\) is measured in units of \\(\\left[\\frac{W}{m^2}\\right]\\). The angle brackets \\(\\langle \\ldots \\rangle\\) represent a time average over one oscillation cycle of \\(u\\). For visible light, this averaging occurs over an extremely brief period - for example, light with a wavelength of 600 nm has a cycle duration of just 2 femtoseconds.\nThe optical power \\(P\\) of a wave can be calculated by integrating the intensity over a surface area \\(A\\):\n\\[\nP=\\int_A I(\\mathbf{r},t) \\, dA\n\\]\nInserting the seperation of the complex wavefunction into spatial and temporal components leads to the following expression for the intensity:\n\\[\nI(\\mathbf{r})=|U(\\mathbf{r})|^2\n\\]\nThus the physical quantity forming the spatial and temporal oscillation of the wavefunction is also providing the intensity of the wave when its magnitude is squared. This is a fundamental property of wavefunctions and for example not the case when temperature oscillates in space and time in a medium.\n\n\nWavefronts\nWavefronts are surfaces in space where the phase is constant:\n\\[\n\\phi(\\mathbf{r})=\\text{const}\n\\]\nTypically, this constant is chosen to represent points of maximum spatial amplitude, such that:\n\\[\n\\phi(\\mathbf{r})=2\\pi q\n\\]\nwhere \\(q\\) is an integer.\nThe direction normal to these wavefronts can be described by the gradient vector:\n\\[\n\\mathbf{n}=\\nabla\\phi=\\left(\\frac{\\partial \\phi}{\\partial x},\\frac{\\partial \\phi}{\\partial y},\\frac{\\partial \\phi}{\\partial z}\\right)\n\\]\nThis vector \\(\\mathbf{n}\\) is always perpendicular to the wavefront surface and points in the direction of wave propagation. The evolution of these wavefronts in time provides important information about the wave’s propagation characteristics.",
    "crumbs": [
      "Wave Optics",
      "Lecture 7",
      "Wave Optics"
    ]
  },
  {
    "objectID": "wave-optics/Wave Optics.html#plane-waves",
    "href": "wave-optics/Wave Optics.html#plane-waves",
    "title": "Wave Optics",
    "section": "Plane Waves",
    "text": "Plane Waves\nA plane wave represents a fundamental solution of the homogeneous wave equation. In its complex form, it is expressed as:\n\\[\\begin{equation}\nU(\\mathbf{r},t)=Ae^{-i\\mathbf{k}\\cdot \\mathbf{r}}e^{i\\omega t}\n\\end{equation}\\]\nwhere:\n\nThe first exponential term contains the spatial phase\nThe second exponential term contains the temporal phase\n\\(A\\) is the (potentially complex) amplitude of the plane wave\n\nThe wavefront of a plane wave is defined by:\n\\[\\mathbf{k}\\cdot \\mathbf{r}=2\\pi q + \\text{arg}(A)\\]\nwhere \\(1\\) is an integer. It just means that the projection of the position vector \\(\\mathbf{r}\\) onto the wavevector \\(\\mathbf{k}\\) is a multiple of \\(2\\pi\\). This equation describes a plane perpendicular to the wavevector \\(\\mathbf{k}\\). Adjacent wavefronts are separated by the wavelength \\(\\lambda=2\\pi/k\\), where \\(k\\) represents the spatial frequency of the wave oscillation.\nThe spatial component of the plane wave is given by:\n\\[\\begin{equation}\nU(\\mathbf{r})=Ae^{-i\\mathbf{k}\\cdot \\mathbf{r}}\n\\end{equation}\\]\nIn vacuum, the wavevector \\(\\mathbf{k}=\\mathbf{k}_0\\) is real-valued and can be written as:\n\\[\\begin{equation}\n\\mathbf{k}_0=\n\\begin{pmatrix}\nk_{0x} \\\\\nk_{0y}\\\\\nk_{0z}\\\\\n\\end{pmatrix}\n\\end{equation}\\]\n\n\nCode\ndef plane_wave(k,omega,r,t):\n    return(np.exp(1j*(np.dot(k,r)-omega*t)))\n\nwavelength=532e-9\nk0=2*np.pi/wavelength\nc=299792458\nomega0=k0*c\n\nvec=np.array([0.0,0.,1.])\nvec=vec/np.sqrt(np.dot(vec,vec))\n\nk=k0*vec\n\nx=np.linspace(-2.5e-6,2.5e-6,300)\nz=np.linspace(0,5e-6,300)\n\nX,Z=np.meshgrid(x,z)\nr=np.array([X,0,Z],dtype=object)\n\nplt.figure(figsize=get_size(6,6))\n\nfield=plane_wave(k,omega0,r,0)\n\nextent = np.min(z)*1e6, np.max(z)*1e6,np.min(x)*1e6, np.max(x)*1e6\nplt.imshow(np.real(field.transpose()),extent=extent,vmin=-1,vmax=1,cmap='seismic')\nplt.xlabel('z-position [µm]')\nplt.ylabel('x-position [µm]')\n\nplt.show()\n\n\n\n\n\nPlane wave",
    "crumbs": [
      "Wave Optics",
      "Lecture 7",
      "Wave Optics"
    ]
  },
  {
    "objectID": "wave-optics/Wave Optics.html#dispersion-relation",
    "href": "wave-optics/Wave Optics.html#dispersion-relation",
    "title": "Wave Optics",
    "section": "Dispersion Relation",
    "text": "Dispersion Relation\nUsing the plane wave solution\n\\[\\begin{equation}\nU(\\mathbf{r},t)=Ae^{-i\\mathbf{k}\\cdot \\mathbf{r}}e^{i\\omega t}\n\\end{equation}\\]\nwe can write down the sum of the spatial and temporal phase as\n\\[\n\\phi(r,t)=\\omega t-\\mathbf{k}\\cdot \\mathbf{r}\n\\]\nIf we select a point on the wavefront \\(\\mathbf{r}_{m}\\), and follow that over time, the phase \\(\\phi(t)=\\text{const}\\). Taking the time derivative results in\n\\[\n\\mathbf{k}\\cdot \\frac{d\\mathbf{r}_{m}}{dt}=\\omega\n\\]\nIf we choose the direction of the wavevector for measuring the propagation speed, i.e. \\(\\mathbf{r}_{m}=r_{m}\\mathbf{e}_k\\) then we find for the propagation speed\n\\[\n\\frac{dr_{m}}{dt}=\\frac{\\omega}{k}\n\\]\nor in vacuum\n\\[\\begin{equation}\nc_0=\\frac{\\omega}{k_0}\n\\end{equation}\\]\nThis fundamental relationship connects:\n\nThe momentum (\\(k\\)),\nThe energy (\\(\\omega\\))\n\nand is called a dispersion relation despite the fact, that we do not really understand why those quantities are related to energy and momentum.\n\n\n\n\n\n\nNote\n\n\n\nLight in free space exhibits a linear dispersion relation, i.e. the frequency of light changes linearly with the wavevector magnitude.\n\n\nNote that if we choose a different propagation direction \\(\\mathbf{e}\\) than the one along the wavevector \\(\\mathbf{e}_k\\), we can write the phase velocity as\n\\[\n\\mathbf{k}\\cdot\\mathbf{e} \\frac{dr}{dt}=k\\cos(\\measuredangle\\mathbf{k},\\mathbf{e}) \\frac{dr}{dt}=\\omega\n\\]\nor\n\\[\n\\frac{dr}{dt}=\\frac{\\omega}{k\\cos(\\measuredangle\\mathbf{k},\\mathbf{e})}\n\\]\nwhich means that if you observe the wavepropagation not in the direction of the wavevector, the phase velocity is actually bigger than the speed of light and even tends to infinity if the angle between the wavevector and the observation direction tends to 90°.",
    "crumbs": [
      "Wave Optics",
      "Lecture 7",
      "Wave Optics"
    ]
  },
  {
    "objectID": "wave-optics/Wave Optics.html#propagation-in-a-medium",
    "href": "wave-optics/Wave Optics.html#propagation-in-a-medium",
    "title": "Wave Optics",
    "section": "Propagation in a Medium",
    "text": "Propagation in a Medium\nWhen a wave propagates through a medium:\n\nThe frequency \\(\\omega\\) remains constant (determined by the source)\nThe wave speed changes according to: \\[\nc=\\frac{c_0}{n}\n\\] where \\(n\\) is the refractive index of the medium\n\nThis leads to changes in:\n\nthe wavelength, which becomes shorter in the medium \\[\n\\lambda=\\frac{\\lambda_0}{n}\n\\]\nthe length of the wavevector, which increases in the medium \\[\nk=nk_0\n\\]",
    "crumbs": [
      "Wave Optics",
      "Lecture 7",
      "Wave Optics"
    ]
  },
  {
    "objectID": "wave-optics/Wave Optics.html#snells-law",
    "href": "wave-optics/Wave Optics.html#snells-law",
    "title": "Wave Optics",
    "section": "Snells Law",
    "text": "Snells Law\nThe change in the length of the wavevector has some simple consequence for Snells law. We can write Snells law as\n\\[\nn_1k_0\\sin(\\theta_1)=n_2k_0\\sin(\\theta_2)\n\\]\nwhere \\(k_0\\) is the wavevector length in vacuum. As the \\(n_1k_0\\) is the magnitude of the wavevector in medium 1, and \\(n_2k_0\\) is the magnitude of the wavevector in medium 2, we can rewrite Snells law as\n\\[\nk_1\\sin(\\theta_1)=k_2\\sin(\\theta_2)\n\\]\nwhich means that the component of the wavevector parallel to the interface is conserved. If the wavevector has constant length then the wavevector incident at different angles is between a point on a circle and the origin in the diagram below. The circle corresponds to an isofrequency surface.\n\nCode\ntheta_upper = np.linspace(0, np.pi, 100)  # Upper half circle\ntheta_lower = np.linspace(np.pi, 2*np.pi, 100)  # Lower half circle\n\n# Radii for the circles\nr1 = 1.51  # Radius for upper half circle\nr2 = 1.01  # Radius for lower half circle\n\nx_upper = r1 * np.cos(theta_upper)\ny_upper = r1 * np.sin(theta_upper)\n\nx_lower = r2 * np.cos(theta_lower)\ny_lower = r2 * np.sin(theta_lower)\n\n# Create the plot\nplt.figure(figsize=get_size(4, 3))\nplt.plot(x_upper, y_upper, 'b-', label=f'Upper radius = {r1}')\nplt.plot(x_lower, y_lower, 'r-', label=f'Lower radius = {r2}')\n\n# Add arrow\n# Calculate arrow start point (on the upper circle at 135 degrees)\narrow_start_x = r1 * np.cos(3*np.pi/4.2)  # 135 degrees in radians\narrow_start_y = r1 * np.sin(3*np.pi/4.2)\n# Add arrow to origin (0,0)\nplt.arrow(arrow_start_x, arrow_start_y, -arrow_start_x, -arrow_start_y,\n          head_width=0.1, head_length=0.2, fc='b', ec='b',\n          length_includes_head=True, label='45° arrow')\n\ndy=np.sqrt(r2**2-arrow_start_x**2)\nplt.arrow(0, 0, -arrow_start_x, -dy,\n          head_width=0.1, head_length=0.2, fc='r', ec='r',\n          length_includes_head=True, label='45° arrow')\n\nplt.axhline(y=0, color='k', linestyle='-', alpha=0.3)\nplt.axvline(x=0, color='k', linestyle='-', alpha=0.3)\nplt.axvline(x=-arrow_start_x, color='k', linestyle='--',lw=0.5)\nplt.axvline(x=arrow_start_x, color='k', linestyle='--', lw=0.5)\n\nplt.axis('square')\n\nplt.grid(True, alpha=0.3)\nplt.xlabel(r'$k_x/k_0$')\nplt.ylabel(r'$k_y/k_0$')\nplt.xlim(-2,2 )\nplt.ylim(-2,2 )\n\n# Show the plot\nplt.show()\n\n\n\n\n\n\n\n\nSnells law construction using the conservation of the wavevector component parallel to the interface. The vertical dashed lines indicate the parallal component of the wavevector in the two media.\n\n\n\n\n\n\n\n\nElectron microscopy image of a 2D photonic crystal\n\n\n\n\n\n\n\nIsofrequency surfaces of a photonic crystal\n\n\n\n\n\nIsofrequency surfaces can have non-spherical shape. In anisotropic media, they can be ellipsoids. In photonic crystals, i.e. crystals with a periodic structure on the scale of the wavelength, they can have a more complex shape.",
    "crumbs": [
      "Wave Optics",
      "Lecture 7",
      "Wave Optics"
    ]
  },
  {
    "objectID": "wave-optics/Wave Optics.html#spherical-waves",
    "href": "wave-optics/Wave Optics.html#spherical-waves",
    "title": "Wave Optics",
    "section": "Spherical Waves",
    "text": "Spherical Waves\nA spherical wave, like a plane wave, consists of spatial and temporal components, but with wavefronts forming spherical surfaces. For spherical waves, \\(|\\mathbf{k}||\\mathbf{r}|=kr=\\text{const}\\). Given a source at position \\(\\mathbf{r}_0\\), the spherical wave can be expressed as:\n\\[\\begin{equation}\nU=\\frac{A}{|\\mathbf{r}-\\mathbf{r}_0|}e^{-ik|\\mathbf{r}-\\mathbf{r}_0|} e^{i\\omega t}\n\\end{equation}\\]\n\n\n\n\n\n\nImportant\n\n\n\nThe \\(1/|\\mathbf{r}-\\mathbf{r}_0|\\) factor in the amplitude is necessary for energy conservation - ensuring that the total energy flux through any spherical surface centered on the source remains constant.\n\n\n\n\nCode\ndef spherical_wave(k,omega,r,r0,t):\n    k=np.linalg.norm(k)\n    d=np.linalg.norm(r-r0)\n    return( np.exp(1j*(k*d-omega*t))/d)\n\nplt.figure(figsize=get_size(5,5))\n\nx=np.linspace(-5e-6,5e-6,300)\nz=np.linspace(-5e-6,5e-6,300)\n\nX,Z=np.meshgrid(x,z)\nr=np.array([X,0,Z],dtype=object)\n\nwavelength=532e-9\nk0=2*np.pi/wavelength\nc=299792458\nomega0=k0*c\n\nk=k0*np.array([0,0,1.])\nr0=np.array([0,0,0])\n\nfield=spherical_wave(k,omega0,r,r0,0)\n\nextent = np.min(z)*1e6, np.max(z)*1e6,np.min(x)*1e6, np.max(x)*1e6\nplt.imshow(np.real(field.transpose()),extent=extent,vmin=-5e6,vmax=5e6,cmap='seismic')\n\nplt.xlabel('z [µm]')\nplt.ylabel('x [µm]')\nplt.show()\n\n\n\n\n\nSpherical wave propagation. The wave is emitted from the origin and propagates in the positive z-direction. The wavefronts are spherical surfaces. The wave is visualized in the xz-plane.\n\n\n\n\n\n\n\n\n\n\nFigure 5— Spherical wave amplitude and intensity of the spherical wave as a function of distance from the source\n\n\n\nThe plots demonstrate that:\n\nThe field amplitude decays rapidly with distance\nThe intensity follows a \\(1/r^2\\) law (with slight deviations at small distances due to discretization artifacts)\n\nNote: The direction of wave propagation can be reversed by changing the sign of the wavenumber \\(k\\).",
    "crumbs": [
      "Wave Optics",
      "Lecture 7",
      "Wave Optics"
    ]
  },
  {
    "objectID": "wave-optics/Interferometers.html",
    "href": "wave-optics/Interferometers.html",
    "title": "Interferometers and other Coherence Applications",
    "section": "",
    "text": "Michelson Interferometer\nThe Michelson interferometer is an essential optical instrument used to measure the interference of light waves. It consists of a coherent light source, such as a laser, which emits a beam directed towards a beam splitter. The beam splitter divides the light into two beams: one reflected towards a fixed mirror and the other transmitted towards a movable mirror. After reflecting off their respective mirrors, the beams are recombined at the beam splitter, where they interfere.\n\n\n\nMichelson Interferometer\n\n\nThe interference pattern depends on the difference in the optical path lengths of the two beams. Constructive interference occurs when the path lengths are equal or differ by an integer multiple of the wavelength \\(\\lambda\\), given by the condition \\(2d = m\\lambda\\), where \\(d\\) is the path length difference and \\(m\\) is an integer. Destructive interference occurs when the path lengths differ by an odd multiple of half the wavelength, given by \\(2d = (m + \\frac{1}{2})\\lambda\\).\nBy adjusting the position of the movable mirror, the path length difference changes, altering the interference pattern. This sensitivity to path length variations makes the Michelson interferometer useful for precise measurements, such as determining the wavelength of light, measuring small distances, and detecting changes in refractive index. It also played a crucial role in the Michelson-Morley experiment, which provided evidence against the existence of the luminiferous ether and supported the theory of special relativity.\n\nLIGO Interferometer Overview\nThe Laser Interferometer Gravitational-Wave Observatory (LIGO) is designed to detect gravitational waves—ripples in spacetime caused by massive accelerating objects, such as merging black holes or neutron stars. LIGO uses a Michelson interferometer configuration with two perpendicular arms, each several kilometers long. A laser beam is split into two beams that travel down these arms, reflect off mirrors at the ends, and then recombine at the beam splitter. Under normal conditions, the lengths of the arms are such that the beams interfere destructively, resulting in no light reaching the detector.\n\n\n\nVirgo detector of LIGO\n\n\nWhen a gravitational wave passes through the interferometer, it causes a tiny but measurable change in the lengths of the arms. This change alters the interference pattern of the recombined beams, allowing the detection of the gravitational wave. The sensitivity of LIGO is such that it can detect changes in arm length smaller than a thousandth of the diameter of a proton.\nThe phase shift \\(\\Delta \\phi\\) caused by a gravitational wave can be expressed as:\n\\[\n\\Delta \\phi = \\frac{4 \\pi \\Delta L}{\\lambda}\n\\]\nwhere \\(\\Delta L\\) is the change in the length of the interferometer arms due to the gravitational wave, and \\(\\lambda\\) is the wavelength of the laser light used in the interferometer.\n\nDerivation of the Phase Shift\nTo understand the phase shift in LIGO, consider the effect of a gravitational wave passing through the interferometer. The wave causes a differential change in the lengths of the two arms, denoted as \\(\\Delta L\\). This change in length affects the travel time of the laser beams in each arm.\nThe time difference \\(\\Delta T\\) between the beams traveling in the two arms can be expressed as:\n\\[\n\\Delta T = \\frac{\\Delta L}{c}\n\\]\nThe phase shift \\(\\Delta \\phi\\) is then related to this time difference by the equation:\n\\[\n\\Delta \\phi = \\frac{2 \\pi \\Delta T}{T} = \\frac{4 \\pi \\Delta L}{\\lambda}\n\\]\nThis phase shift alters the interference pattern observed at the detector, allowing LIGO to measure the presence and properties of gravitational waves. The extraordinary precision of LIGO’s measurements enables it to detect incredibly small disturbances in spacetime, providing valuable insights into some of the most energetic events in the universe.\n\n\n\n\n\n\nLIGO Technical Details\n\n\n\n\n\nLIGO consists of two large interferometers located in the United States: one in Hanford, Washington, and the other in Livingston, Louisiana. These facilities are operated by the LIGO Scientific Collaboration (LSC), which includes scientists from various institutions around the world. Here is a link to the LIGO website and a direct link to an overview document.\n\nInterferometer Design\n\nMichelson Interferometer Configuration:\n\nLIGO uses a Michelson interferometer configuration with 4-kilometer-long arms.\nEach interferometer has two perpendicular arms, forming an “L” shape.\nA laser beam is split into two beams that travel down the arms, reflect off mirrors, and recombine at the beam splitter.\n\nFabry-Pérot Cavities:\n\nEach arm of the interferometer contains a Fabry-Pérot cavity to increase the effective path length of the laser beams.\nThe cavities are formed by highly reflective mirrors placed at the ends of the arms.\nThe laser beams bounce back and forth multiple times within the cavities, effectively increasing the arm length to several hundred kilometers.\n\nLaser System:\n\nLIGO uses a high-power, stabilized laser operating at a wavelength of 1064 nm (infrared).\nThe laser power is typically around 200 watts, but the effective power in the interferometer arms is increased to several kilowatts using power recycling techniques.\n\nSuspension and Isolation:\n\nThe mirrors and other optical components are suspended by a system of pendulums to isolate them from ground vibrations and other noise sources.\nThe suspension system includes multiple stages of isolation, including active and passive damping mechanisms.\n\nVacuum System:\n\nThe interferometer arms are housed in ultra-high vacuum tubes to eliminate air molecules that could scatter the laser beams and introduce noise.\nThe vacuum system maintains a pressure of around \\(10^{-9}\\) torr.\n\n\n\n\nDetection Principle\n\nGravitational Waves:\n\nGravitational waves are ripples in spacetime caused by accelerating massive objects, such as merging black holes or neutron stars.\nAs a gravitational wave passes through the interferometer, it stretches and compresses the spacetime along the arms, causing tiny changes in the arm lengths.\n\nInterference Pattern:\n\nThe changes in arm lengths cause a phase shift in the laser beams when they recombine at the beam splitter.\nThis phase shift results in a change in the interference pattern, which is detected by photodetectors.\n\nSensitivity:\n\nLIGO is designed to detect changes in arm lengths as small as \\(10^{-19}\\) meters, which is less than one-thousandth the diameter of a proton.\nThe sensitivity is achieved through advanced noise reduction techniques, including seismic isolation, thermal noise reduction, and quantum noise reduction.\n\n\n\n\nData Analysis\n\nSignal Processing:\n\nThe data from the photodetectors are processed to identify potential gravitational wave signals.\nAdvanced algorithms and computational techniques are used to filter out noise and extract the signals.\n\nEvent Detection:\n\nWhen a potential gravitational wave event is detected, the data are analyzed to determine the properties of the source, such as the masses and spins of merging black holes or neutron stars.\nThe detection is confirmed by comparing data from both LIGO detectors and, if available, data from other gravitational wave observatories like Virgo.\n\n\n\n\n\n\n\n\n\n\nMach Zehnder Interferometer\nThe Mach-Zehnder interferometer is an optical device used to measure phase shifts between two light beams. It consists of a coherent light source, such as a laser, which emits a beam that is split into two paths by a beam splitter. Each beam travels along a different path, encountering mirrors that redirect them towards a second beam splitter where they are recombined. The recombined beams then interfere, producing an interference pattern that can be observed at the output ports.\n\n\n\nMach Zehnder Interferometer\n\n\nThe interference pattern depends on the phase difference between the two beams, which is influenced by the optical path lengths they travel. If the path lengths are equal, constructive interference occurs, resulting in maximum intensity at one output port and minimum intensity at the other. If the path lengths differ, the phase difference causes a shift in the interference pattern, leading to varying intensities at the output ports.\nThe phase difference \\(\\Delta \\phi\\) between the two beams is given by \\(\\Delta \\phi = \\frac{2\\pi \\Delta L}{\\lambda}\\), where \\(\\Delta L\\) is the difference in path lengths and \\(\\lambda\\) is the wavelength of the light. By introducing a phase shift in one of the paths, such as by changing the length of the path or altering the refractive index of the medium through which the beam travels, the interference pattern can be controlled and measured.\n\n\n\n\n\n\n\n\n\nMach Zehnder Interferometer with a Gaussian\n\n\n\n\n\n\n\nMach Zehnder Interferometer with a Bessel Beam\n\n\n\n\n\nThe Mach-Zehnder interferometer is widely used in applications requiring precise measurements of phase shifts, such as in optical communication systems, quantum mechanics experiments, and the study of optical properties of materials.\n\n\n\nNetwork of Mach Zehnder Interferometers forming an all optical neural network. Zhou, H. et al. Photonic matrix multiplication lights up photonic accelerator and beyond. Light: Sci. Appl. 11, 30 (2022).\n\n\n\n\nSagnac Interferometer Overview\nA Sagnac interferometer operates by splitting a beam of light into two separate beams that travel in opposite directions around a closed loop. These beams are then recombined at the end of the loop, resulting in an interference pattern. If the interferometer is rotating, the path lengths of the two beams differ, leading to a phase shift.\n\n\n\nSagnac Interferometer\n\n\nThe phase shift, denoted as \\(\\Delta \\phi\\), can be calculated using the formula:\n\\[\n\\Delta \\phi = \\frac{8 \\pi A \\Omega}{\\lambda c}\n\\]\nwhere \\(A\\) represents the area enclosed by the light path, \\(\\Omega\\) is the angular velocity of the rotation, \\(\\lambda\\) is the wavelength of the light, and \\(c\\) is the speed of light.\n\n\n\nSagnac interferometer made of a fibre rolled up on a cylinder taken from here\n\n\n\nDerivation of the Phase Shift\nTo derive the phase shift, we start by considering the path length difference. Assume a loop with a perimeter \\(L\\) and an area \\(A\\). In the absence of rotation, the time taken for light to travel around the loop is given by \\(T = \\frac{L}{c}\\).\nWhen the interferometer rotates with an angular velocity \\(\\Omega\\), the effective path length changes. For the beam traveling in the direction of rotation, the path length increases, while for the beam traveling opposite to the direction of rotation, the path length decreases.\nThe time difference \\(\\Delta T\\) between the two beams can be expressed as:\n\\[\n\\Delta T = \\frac{4 A \\Omega}{c^2}\n\\]\nThe phase shift \\(\\Delta \\phi\\) is related to this time difference by the equation:\n\\[\n\\Delta \\phi = \\frac{2 \\pi \\Delta T}{T} = \\frac{8 \\pi A \\Omega}{\\lambda c}\n\\]\n\n\n\n\n\n\nDerivation Details\n\n\n\n\n\nTo derive the formula for the time difference \\(\\Delta T\\) between two counter-propagating beams in a Sagnac interferometer, we start by considering a loop of perimeter \\(L\\) and area \\(A\\). The interferometer is rotating with an angular velocity \\(\\Omega\\). Light travels in opposite directions around the loop, creating two counter-propagating beams.\nIn a non-rotating frame, the time taken for light to travel around the loop is \\(T = \\frac{L}{c}\\). When the interferometer rotates with angular velocity \\(\\Omega\\), the effective path lengths for the two beams differ due to the rotation. For the beam traveling in the direction of rotation, the effective path length increases, while for the beam traveling opposite to the direction of rotation, the effective path length decreases.\nThe relative velocity of light with respect to the rotating frame is \\(c \\pm v\\), where \\(v = \\Omega R\\) is the tangential velocity at the perimeter of the loop. For small angular velocities, we can approximate the effect using the area \\(A\\) and the angular velocity \\(\\Omega\\).\nThe time taken for the beam traveling in the direction of rotation is: \\[\nT_+ = \\frac{L}{c + v}\n\\] and the time taken for the beam traveling opposite to the direction of rotation is: \\[\nT_- = \\frac{L}{c - v}\n\\]\nFor small \\(v\\), we can use the binomial expansion to approximate the times: \\[\nT_+ \\approx \\frac{L}{c} \\left(1 - \\frac{v}{c}\\right)\n\\] \\[\nT_- \\approx \\frac{L}{c} \\left(1 + \\frac{v}{c}\\right)\n\\]\nThe time difference between the two beams is: \\[\n\\Delta T = T_+ - T_- = \\frac{L}{c} \\left(1 - \\frac{v}{c}\\right) - \\frac{L}{c} \\left(1 + \\frac{v}{c}\\right)\n\\] \\[\n\\Delta T = \\frac{L}{c} \\left(- \\frac{v}{c} - \\frac{v}{c}\\right)\n\\] \\[\n\\Delta T = -\\frac{2Lv}{c^2}\n\\]\nThe tangential velocity \\(v\\) is related to the angular velocity \\(\\Omega\\) and the radius \\(R\\) of the loop: \\[\nv = \\Omega R\n\\]\nThe area \\(A\\) of the loop is related to the radius \\(R\\) and the perimeter \\(L\\): \\[\nA = \\pi R^2\n\\]\nCombining these, we get: \\[\nR = \\frac{L}{2\\pi}\n\\] \\[\nv = \\Omega \\frac{L}{2\\pi}\n\\]\nSubstituting \\(v = \\Omega \\frac{L}{2\\pi}\\) into the expression for \\(\\Delta T\\): \\[\n\\Delta T = -\\frac{2L \\left(\\Omega \\frac{L}{2\\pi}\\right)}{c^2}\n\\] \\[\n\\Delta T = -\\frac{2L^2 \\Omega}{2\\pi c^2}\n\\] \\[\n\\Delta T = -\\frac{L^2 \\Omega}{\\pi c^2}\n\\]\nUsing the relationship \\(L^2 = 4A\\), we get: \\[\nL^2 = 4A\n\\]\nSubstituting \\(L^2 = 4A\\) into the expression for \\(\\Delta T\\): \\[\n\\Delta T = -\\frac{4A \\Omega}{c^2}\n\\]\nSince the time difference \\(\\Delta T\\) is typically considered in magnitude, we take the absolute value: \\[\n\\Delta T = \\frac{4 A \\Omega}{c^2}\n\\]",
    "crumbs": [
      "Wave Optics",
      "Lecture 11",
      "Interferometers"
    ]
  },
  {
    "objectID": "wave-optics/Double Slit.html",
    "href": "wave-optics/Double Slit.html",
    "title": "Double Slit Interference",
    "section": "",
    "text": "Two Point Sources - Double Slit Interference\nThe interference of two point sources is a classic example of wave interference. It is often referred to as double slit interference. The interference pattern is created by two point sources that emit waves with the same wavelength and amplitude. The intereference of the two waves depends then on the path length difference between the two waves\n\nCode\ndef plot_angle(ax, pos, angle, length=0.95, acol=\"C0\", **kwargs):\n    vec2 = np.array([np.cos(np.deg2rad(angle)), np.sin(np.deg2rad(angle))])\n    xy = np.c_[[length, 0], [0, 0], vec2*length].T + np.array(pos)\n    ax.plot(*xy.T, color=acol,ls=\"--\")\n    return AngleAnnotation(pos, xy[0], xy[2], ax=ax, **kwargs)\n\n\n\nplt.figure(figsize=get_size(12,12))\n\n# Point sources positions\nd = 2  # source separation\ny1, z1 = 0, -d/2  # source 1\ny2, z2 = 0, d/2   # source 2\n\n# Draw circular wavefronts\ntheta = np.linspace(0, 2*np.pi, 100)\nn_circles = 5\nwavelength = 2  # spacing between wavefronts\n\nfor i in range(n_circles):\n    r = i * wavelength\n    # Wavefronts from source 1\n    plt.plot(r*np.cos(theta) + y1, r*np.sin(theta) + z1, 'b:', alpha=0.5)\n    # Wavefronts from source 2\n    plt.plot(r*np.cos(theta) + y2, r*np.sin(theta) + z2, 'r:', alpha=0.5)\n\n# Draw screen\nscreen_z = np.linspace(-10, 10, 100)\nscreen_y = np.ones_like(screen_z) * 16\nplt.plot(screen_y, screen_z, 'k-', linewidth=2, label='Screen')\n\n# Example point on screen\nP = np.array([16, 4])  # point coordinates [y, z]\n\n# Draw paths from sources to point P\nplt.plot([y1, P[0]], [z1, P[1]], 'b-', label='Path 1')\nplt.plot([y2, P[0]], [z2, P[1]], 'r-', label='Path 2')\nplt.plot([0, P[0]], [z2, P[1]], 'k-', label='Path 2')\n\n# Calculate and show path lengths\nr1 = np.sqrt((P[0]-y1)**2 + (P[1]-z1)**2)\nr2 = np.sqrt((P[0]-y2)**2 + (P[1]-z2)**2)\npath_diff = abs(r2 - r1)\n\n# Add sources\nplt.plot(y1, z1, 'bo', label='Source 1')\nplt.plot(y2, z2, 'ro', label='Source 2')\n\n# Label source separation\nplt.plot([y1-0.5, y1-0.5], [z1, z2], 'k-', linewidth=1)\nplt.text(y1-2, -.2, 'd', fontsize=12)\n\n# Add angle annotation\ncenter = np.array([0, 0])  # center between sources\nangle = np.arctan2(P[1], P[0])  # angle to point P\nkw = dict(size=500, unit=\"points\", text=r\"$\\theta$\")\nplot_angle(plt.gca(), center, angle*180/np.pi, length=16,acol=\"k\",textposition=\"inside\", **kw)\n\nplt.xlabel('y')\nplt.ylabel('z')\nplt.axis(\"equal\")\nplt.axis('off')\n\nplt.show()\n\n\n\n\n\n\n\n\nDouble slit interference as the interference from two point sources on the left and the wave amplitudes on the right. The interference pattern is created by two point sources that emit waves with the same wavelength and amplitude. The intereference of the two waves depends then on the path length difference between the two waves.\n\n\n\n\n\n\n    Wave Interference Pattern\n    \n    \n\n\n\n    \n    \n        Source Separation: \n        \n    \n    \n        Wavelength: \n        \n    \n\n\n\n\n\n\n\nThe interference pattern depends on the relative phase of the two waves. The phase difference can be calculated from the path length difference between the two waves and the path length difference can be calculated considering the angle \\(\\theta\\) between the line connecting the two sources and the line connecting the sources to the point on the screen. The path length difference is then given by\n\\[\n\\Delta s = s_2 - s_1 = d \\sin(\\theta)\n\\]\nand consequently the phase difference is given by\n\\[\n\\Delta \\phi = \\frac{2\\pi}{\\lambda} \\Delta s = \\frac{2\\pi}{\\lambda} d \\sin(\\theta)\n\\]\n\n\n\n\n\n\nCorrect path length difference\n\n\n\n\n\nThe path length difference given above is only approximately correct. The exact calculation would involve the geometry of the problem and the path length difference would be calculated as \\(\\Delta s = \\sqrt{d^2 + L^2 - 2dL \\cos(\\theta)} - \\sqrt{d^2 + L^2 - 2dL \\cos(\\theta)}\\). Note that when observing the pattern on the screen with the help of a lens that is placed at the focal distance from the screen, the two path would correspond to parallel rays and the path length difference assumed above would be correct.\n\n\n\nAs constructive interference occurs when the phase difference is a multiple of, i.e. \\(m 2\\pi\\), the constructive interference will be observed when\n\\[\n\\sin(\\theta) = m \\frac{\\lambda}{d}\n\\]\n\n\n\n\n\n\nConstructive interference from two sources\n\n\n\nConstructive interference from two sources separated by a distance \\(d\\) will be observed at an angle \\(\\theta\\) when \\(\\sin(\\theta) = m \\frac{\\lambda}{d}\\), where \\(m\\) is an integer. The orders of the constructive interference are labeled as \\(m = 0, 1, 2, 3, \\ldots\\) and the \\(m=0\\) constructive interference is the central maximum. The first order constructive interference angle with scale with the wavelength as \\(\\lambda\\) and the inverse distance between the sources as \\(1/d\\), i.e. larger wavelength will lead to larger angles and larger source separation will lead to smaller angles.\nThis scaling is a common feature in many interference applications and the foundation of spectrocopy!\n\n\nIf the screen is at a distance \\(L\\) from the sources, the angle \\(\\theta\\) can be calculated as \\(\\theta = \\arctan(y/L)\\), where \\(y\\) is the distance from the center of the screen.\nInserting the phase difference into the intensity formula, we get\n\\[\nI = 2 I_1 + 2 I_2 + 2 \\sqrt{I_1 I_2} \\cos\\left(\\frac{2\\pi d}{\\lambda} \\sin(\\theta)\\right)\n\\]\nor when assuming the same intensity from the two sources\n\\[\nI= 4I_0\\cos^2\\left(\\frac{d\\pi}{\\lambda}\\sin(\\theta)\\right)\n\\]\nThe plot below shows this intensity pattern for two sources separated by a distance \\(d = 2\\) µm and a wavelength of \\(\\lambda = 0.532\\) micrometers.\n\n\nCode\n# Plot intensity pattern\nL = 16  # screen distance\ny = np.linspace(-20, 20, 1000)  # screen positions\ntheta = np.arctan(y/L)  # angles\nwavelength = 0.532  # wavelength in micrometers\nd = 2  # source separation\n\n# Calculate phase difference\ndelta_phi = (2*np.pi/wavelength) * d * np.sin(theta)\n\n# Calculate intensity (assuming I1 = I2 = 1)\nI = 2 * (1 + np.cos(delta_phi))\n\nplt.figure(figsize=get_size(10,6))\nplt.plot(y, I)\nplt.xlabel('position y on screen')\nplt.ylabel('intensity ')\nplt.grid(True, alpha=0.3)\nplt.show()\n\n\n\n\n\nIntensity pattern of two sources at a screen at a distance L. The sources are separated by a distance d and the wavelength of the waves is \\(\\lambda\\).\n\n\n\n\nThe interference from two point sources has immediate consequences for the resolution of optical instruments. The resolution of an optical instrument is the ability to distinguish between two closely spaced objects. The Abbe criterion states the the minimum resolvable distance \\(d\\) between two objects is given by\n\\[\nd = \\frac{\\lambda}{2 \\sin(\\theta)}\n\\]\nwhere \\(\\lambda\\) is the wavelength of the light and \\(\\theta\\) is the angle subtended by the two objects at the lens. The Abbe criterion is derived from the condition that the microscopy lens has to collect at least the first minimum of the interference pattern of the two objects. This first destructive interference is the information that is needed to separate the two objects from one object.\n\n\n\n\n\n\nFresnel double mirror and biprism experiment\n\n\n\n\n\nOne of the first experiments that demonstrated the wave nature of light was the Fresnel double mirror experiment. In this experiment, a light source is placed in front of two tilted mirrors. The light is reflected from this mirror to a screen. The interference pattern that is observed on the screen is due to the interference of the light that is reflected from the two mirrors. The interference pattern is similar to the one that is observed in the Young’s double slit experiment as the two mirrors “immitate” two virtual light sources behind the tilted mirror.\n\n\n\nFresnel double mirror experiment\n\n\nA similar experiment is done with the so-called Fresnel biprism. The Fresnel biprism is a prism that is cut in half and the two halves are separated by a small distance. The light that is incident on the biprism is split into two beams that are then recombined on a screen. The interference pattern that is observed on the screen is due to the interference of the two beams.\n\n\n\nFresnel double mirror experiment",
    "crumbs": [
      "Wave Optics",
      "Lecture 8",
      "Double Slit Interference"
    ]
  },
  {
    "objectID": "wave-optics/Interference.html",
    "href": "wave-optics/Interference.html",
    "title": "Interference",
    "section": "",
    "text": "Interference is a fundamental physical phenomenon that demonstrates the superposition principle for linear systems. This principle, which states that the net response to multiple stimuli is the sum of the individual responses, is central to our understanding of wave physics. Interference appears across many domains of physics: in optics where it enables high-precision measurements and holography, in quantum mechanics where it reveals the wave nature of matter, and in acoustics where it forms the basis for noise cancellation technology. The ability of waves to interfere constructively (amplifying each other) or destructively (canceling each other) has profound practical applications, from the anti-reflective coatings on optical elements to the operational principles of interferometric gravitational wave detectors like LIGO. Understanding interference is therefore not just of theoretical interest but crucial for modern technology and experimental physics.\nWhen two wave solutions \\(U_1(\\mathbf{r})\\) and \\(U_2(\\mathbf{r})\\) combine, their superposition gives:\n\\[\nU(\\mathbf{r})=U_1(\\mathbf{r})+U_2(\\mathbf{r})\n\\]\nThe resulting intensity is:\n\\[\\begin{eqnarray}\nI &= &|U|^2\\\\\n&= &|U_1+U_2|^2\\\\\n&= &|U_1|^2+|U_2|^2+U^{*}_1 U_2 + U_1 U^{*}_2\n\\end{eqnarray}\\]\nThe individual wave intensities are given by \\(I_1=|U_1|^2\\) and \\(I_2=|U_2|^2\\). Using this, we can express each complex wave amplitude in polar form, separating its magnitude (related to intensity) and phase:\n\\[\nU_1=\\sqrt{I_1}e^{i\\phi_1}\n\\] \\[\nU_2=\\sqrt{I_2}e^{i\\phi_2}\n\\]\nSubstituting these expressions back into our interference equation and performing the algebra, the total intensity becomes:\n\\[\nI=I_1+I_2+2\\sqrt{I_1 I_2}\\cos(\\Delta \\phi)\n\\]\nwhere \\(\\Delta \\phi=\\phi_2-\\phi_1\\) is the phase difference between the waves. This equation is known as the interference formula and contains three terms:\n\n\\(I_1\\) and \\(I_2\\): the individual intensities\n\\(2\\sqrt{I_1 I_2}\\cos(\\Delta \\phi)\\): the interference term that can be positive or negative\n\nA particularly important special case occurs when the interfering waves have equal intensities (\\(I_1=I_2=I_0\\)). The equation then simplifies to:\n\\[\nI=2I_0(1+\\cos(\\Delta \\phi))=4I_0\\cos^2\\left(\\frac{\\Delta \\phi}{2}\\right)\n\\]\nThis last form clearly shows that:\n\nMaximum intensity (\\(4I_0\\)) occurs when \\(\\Delta \\phi = 2\\pi n\\) (constructive interference)\nZero intensity occurs when \\(\\Delta \\phi = (2n+1)\\pi\\) (destructive interference)\nThe intensity varies sinusoidally with the phase difference\n\n\n\n\n\n\n\nConstructive Interference\n\n\n\nOccurs when \\(\\Delta \\phi=2\\pi m\\) (where \\(m\\) is an integer), resulting in \\(I=4I_0\\)\n\n\n\n\nCode\nx=np.linspace(0,2,1000)\nwavelength=0.532\nk=2*np.pi/0.532\ny1=np.cos(k*x)\n\nfig,[ax1,ax2,ax3]=plt.subplots(3,1,figsize=get_size(10,8))\nax1.plot(x/wavelength,y1,label='Wave 1')\nax2.plot(x/wavelength,y1,label='Wave 1')\nax3.plot(x/wavelength,2*y1,label='Wave 1')\nax3.set_xlabel(r\"distance [$\\lambda$]\")\nax1.set_ylabel(r\"$U_1$\")\nax2.set_ylabel(r\"$U_2$\")\nax3.set_ylabel(r\"$U_1+U_2$\")\nplt.tight_layout()\nplt.show()\n\n\n\n\n\nConstructive interference of two waves (top, middle) and the sum of the two wave amplitudes (bottom)\n\n\n\n\n\n\n\n\n\n\nDestructive Interference\n\n\n\nOccurs when \\(\\Delta \\phi=(2m-1)\\pi\\) (where \\(m\\) is an integer), resulting in \\(I=0\\)\n\n\n\n\nCode\nx=np.linspace(0,2,1000)\nwavelength=0.532\nk=2*np.pi/0.532\ny1=np.cos(k*x)\ny2=np.cos(k*x+np.pi)\n\nfig,[ax1,ax2,ax3]=plt.subplots(3,1,figsize=get_size(10,8))\nax1.plot(x/wavelength,y1,label='Wave 1')\nax2.plot(x/wavelength,y2,label='Wave 1')\nax3.plot(x/wavelength,y1+y2,label='Wave 1')\nax3.set_xlabel(r\"distance [$\\lambda$]\")\nax1.set_ylabel(r\"$U_1$\")\nax2.set_ylabel(r\"$U_2$\")\nax3.set_ylabel(r\"$U_1+U_2$\")\nax3.set_ylim(-1,1)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\nDestructive interference of two waves (top, middle) and the sum of the two wave amplitudes (bottom)\n\n\n\n\n\nPhase and Path Difference\nThe phase difference \\(\\Delta \\phi\\) can be related to the path difference \\(\\Delta s\\) between the two waves. For two waves with the same frequency \\(\\omega\\), we can write their complete phase expressions as:\n\\[\\phi_1(\\mathbf{r},t) = \\mathbf{k}_1\\cdot\\mathbf{r} - \\omega t + \\phi_{01}\\] \\[\\phi_2(\\mathbf{r},t) = \\mathbf{k}_2\\cdot\\mathbf{r} - \\omega t + \\phi_{02}\\]\nwhere:\n\n\\(\\mathbf{k}_i\\) are the wave vectors\n\\(\\mathbf{r}\\) is the position vector\n\\(\\omega\\) is the angular frequency\n\\(\\phi_{0i}\\) are initial phase constants\n\nThe instantaneous phase difference is then:\n\\[\n\\Delta\\phi(\\mathbf{r},t) = \\phi_2(\\mathbf{r},t) - \\phi_1(\\mathbf{r},t) = (\\mathbf{k}_2-\\mathbf{k}_1)\\cdot\\mathbf{r} + (\\phi_{02}-\\phi_{01})\n\\]\nFor stationary interference patterns, we typically observe the time-independent phase difference. When the waves travel along similar paths (same direction), this reduces to:\n\\[\\Delta\\phi = k\\Delta s + \\Delta\\phi_0\\]\nwhere \\(\\Delta s\\) is the path difference and \\(\\Delta\\phi_0\\) is any initial phase difference between the sources.\n\n\n\n\n\n\nPhase Difference and Path Difference\n\n\n\nA path difference \\(\\Delta s\\) corresponds to a phase difference \\(k\\Delta s=2\\pi\\Delta s/\\lambda\\). Path differences of integer multiples of \\(\\lambda\\) result in phase differences of integer multiples of \\(2\\pi\\).\n\n\n\n\nInterference of Waves in Space\n\n\nCode\ndef plane_wave(k,omega,r,t):\n    return(np.exp(1j*(np.dot(k,r)-omega*t)))\n\nwavelength=532e-9\nk0=2*np.pi/wavelength\nc=299792458\nomega0=k0*c\n\nvec=np.array([0.0,0.,1.])\nvec1=np.array([1.0,0.,1.])\nvec=vec/np.sqrt(np.dot(vec,vec))\nvec1=vec1/np.sqrt(np.dot(vec1,vec1))\n\nk=k0*vec\nk1=k0*vec1\n\nx=np.linspace(-2.5e-6,2.5e-6,300)\nz=np.linspace(0,5e-6,300)\n\nX,Z=np.meshgrid(x,z)\nr=np.array([X,0,Z],dtype=object)\n\nfig,ax=plt.subplots(2,2,figsize=get_size(10,10))\nfield=plane_wave(k,omega0,r,0)\nfield1=plane_wave(k1,omega0,r,0)\n\nextent = np.min(z)*1e6, np.max(z)*1e6,np.min(x)*1e6, np.max(x)*1e6\nax[0,0].imshow(np.real(field.transpose()),extent=extent,vmin=-1,vmax=1,cmap='seismic')\nax[0,0].set_title('wave 1')\nax[0,1].imshow(np.real(field1.transpose()),extent=extent,vmin=-1,vmax=1,cmap='seismic')\nax[0,1].set_title('wave 2')\nax[1,0].imshow(np.real(field.transpose()+field1.transpose()),extent=extent,vmin=-1,vmax=1,cmap='seismic')\nax[1,0].set_title('sum')\nax[1,1].imshow(np.abs(field.transpose()+field1.transpose())**2,extent=extent,cmap='gray')\nax[1,1].set_title('intensity')\nax[1,1].set_xlabel('z-position [µm]')\nax[1,0].set_xlabel('z-position [µm]')\nax[1,0].set_ylabel('x-position [µm]')\nax[0,0].set_ylabel('x-position [µm]')\nplt.tight_layout()\nplt.show()\n\n\n\n\n\nInterference of two plane waves propagating under an angle of 45°. The two left graphs show the original waves. The two right show the total amplitude and the intensity pattern.\n\n\n\n\n\n\nCode\ndef spherical_wave(k,omega,r,r0,t):\n    k=np.linalg.norm(k)\n    d=np.linalg.norm(r-r0)\n    return( np.exp(1j*(k*d-omega*t))/d)\n\n\n\nx=np.linspace(-5e-6,5e-6,300)\nz=np.linspace(-5e-6,5e-6,300)\n\nX,Z=np.meshgrid(x,z)\nr=np.array([X,0,Z],dtype=object)\n\nwavelength=532e-9\nk0=2*np.pi/wavelength\nc=299792458\nomega0=k0*c\n\nk=k0*np.array([0,1.0,0])\nr0=np.array([0,2e-6,0])\n\nfield=spherical_wave(k,omega0,r,r0,0)\nfield1=plane_wave(k,omega0,r,0)\n\nextent = np.min(z)*1e6, np.max(z)*1e6,np.min(x)*1e6, np.max(x)*1e6\n\nfig,ax=plt.subplots(2,2,figsize=get_size(10,10))\nax[0,0].imshow(np.real(field.transpose()+0*field1.transpose()),extent=extent,cmap='seismic')\nax[0,0].set_title('Spherical wave')\nax[0,1].imshow(np.real(0*field.transpose()+field1.transpose()),extent=extent,cmap='seismic')\nax[0,1].set_title('Plane wave')\nax[1,0].imshow(np.real(0.00001*field.transpose()+field1.transpose()),extent=extent,cmap='seismic')\nax[0,1].set_title('Sum')\nax[1,1].imshow(np.abs(0.00001*field.transpose()+field1.transpose())**2,extent=extent,cmap='gray')\nax[0,1].set_title('Intensity')\nax[1,0].set_xlabel('z [µm]')\nax[1,1].set_xlabel('z [µm]')\nax[1,0].set_ylabel('x [µm]')\nax[0,0].set_ylabel('x [µm]')\nplt.show()\n\n\n\n\n\nInterference of a spherical wave and a plane wave. The top graphs show the original waves. The two bottom show the total amplitude and the intensity pattern.\n\n\n\n\nThe interference of the spherical and the plane wave (also the one of the two plane waves) give also an interesting result. The intensity resembles to be a snapshot of the shape of the wavefronts of the spherical wave. We can therefore measure the wavefronts of the spherical wave by interfering it with a plane wave. This is also the basic principle behind holography. There we use a reference wave to interfere with the wave that we want to measure. The interference pattern is recorded and can be used to reconstruct the wavefronts of the wave.\n\nA super nice website to try out interference interactively is here.\n\n\n\nCoherence\nIn the earlier consideration we obtained a general description for the phase difference between two waves. TIt is given by and contains the pathlength difference \\(\\Delta s\\) and some intrinsic phase \\(\\Delta\\phi_0\\) that could be part of the wave generation process.\n\\[\\Delta\\phi = k\\Delta s + \\Delta\\phi_0\\]\nTo observe stationary interference, it is important that these two quantities are also stationary, i.e. the phase relation between the two waves is stationary. This relation between the phase of two waves is called coherence and was assumed in all the examples before.\n\n\n\nTwo waves of different frequency over time.\n\n\nThe above image shows the timetrace of the amplitude of two wave with slightly different frequency. Due to the frequency, the waves run out of phase and have acquired a phase different of \\(\\pi\\) after \\(40\\) fs.\nThe temporal coherence of two waves is now defined by the time it takes for the two waves to obtain a phase difference of \\(2\\pi\\). The phase difference between two wave of frequency \\(\\nu_1\\) and \\(\\nu_2\\) is given by\n\\[\n\\Delta \\phi = 2\\pi (\\nu_2-\\nu_1)(t-t_0)\n\\]\nHere \\(t_0\\) refers to the time, when thw two waves were perfectly in sync. Lets assume that the two frequencies are seperarated from a central frequency \\(\\nu_0\\) such that\n\\[\n\\nu_1=\\nu_0-\\Delta \\nu/2\n\\] \\[\n\\nu_2=\\nu_0+\\Delta \\nu/2\n\\]\nInserting this into the first equation yields\n\\[\n\\Delta \\phi = 2\\pi \\Delta \\nu \\Delta t\n\\]\nwith \\(\\Delta t=t-t_0\\). We can now define the coherence time as the time interval over which the phase shift \\(\\Delta \\phi\\) grows to \\(2\\pi\\), i.e. \\(\\Delta \\phi=2\\pi\\). The coherence time is thus\n\\[\n\\tau_{c}=\\Delta t =\\frac{1}{\\Delta \\nu}\n\\]\nThus the temporal coherence and the frequency distribution of the light are intrisincly connected. Monochromatic light has \\(\\Delta nu=0\\) and thus the coherence time is infinitely long. Light with a wide spectrum (white light for example) therefore has and extremly short coherence time.\nThe coherence time is also connected to a coherence length. The coherence length \\(L_c\\) is given by the distance light travels within the coherence time \\(\\tau_c\\), i.e.\n\\[\nL_c=c\\tau_c\n\\]\n\n\n\n\n\n\nCoherence\n\n\n\nTwo waves are called coherent, if they exihibit a fixed phase relation in space or time relation over time. It measures their ability to interfer. The main types of coherence are\n\nTemporal Coherence\n\nMeasures phase correlation of a wave with itself at different times\nCharacterized by coherence time \\(\\tau_c\\) and coherence length \\(L_c = c\\tau_c\\)\nRelated to spectral width: \\(\\tau_c = 1/\\Delta\\nu\\)\nPerfect for monochromatic waves (single frequency)\nLimited for broad spectrum sources (like thermal light)\n\n\n\nSpatial Coherence\n\nMeasures phase correlation between different points in space\nImportant for interference from extended sources\nDetermines ability to form interference patterns\nRelated to source size and geometry\n\nCoherence is a property of the light source and is connected to the frequency distribution of the light. Sources can be:\n\nFully coherent: ideal laser\nPartially coherent: real laser\nIncoherent: thermal light\n\n\n\n\n\n\nMore General Description of Coherence\nWhile the above definition provides an intuitive picture based on frequency spread, we can describe coherence more rigorously using correlation functions. These functions measure how well a wave maintains its phase relationships:\nIn real physical systems, perfect coherence (constant phase relationship) between waves is rare. Partial coherence describes the degree to which waves maintain a consistent phase relationship over time and space. We can characterize this using correlation functions:\n\nTemporal Coherence The complex degree of temporal coherence is given by:\n\n\\[g^{(1)}(\\tau) = \\frac{\\langle U(t)U^*(t+\\tau)\\rangle}{\\sqrt{\\langle|U(t)|^2\\rangle\\langle|U(t+\\tau)|^2\\rangle}}\\]\nwhere:\n\n\\(\\tau\\) is the time delay\n\\(U(t)\\) is the electric field\n\\(\\langle...\\rangle\\) denotes time averaging\n\n\nSpatial Coherence Similarly, spatial coherence between two points is characterized by:\n\n\\[g^{(1)}(\\mathbf{r}_1,\\mathbf{r}_2) = \\frac{\\langle U(\\mathbf{r}_1)U^*(\\mathbf{r}_2)\\rangle}{\\sqrt{\\langle|U(\\mathbf{r}_1)|^2\\rangle\\langle|U(\\mathbf{r}_2)|^2\\rangle}}\\]\nThe obtained correlation functions can be used to calculate the coherence time and length and have the following properties:\n\n\\(|g^{(1)}| = 1\\) indicates perfect coherence\n\\(|g^{(1)}| = 0\\) indicates complete incoherence\n\\(0 &lt; |g^{(1)}| &lt; 1\\) indicates partial coherence\n\nA finite coherence time and length is leads to partial coherence affects interference visibility through:\n\nReduced contrast in interference patterns\nLimited coherence length/area\nSpectral broadening\n\n\n\nCode\nomega0 = 2.0\ndelta_omega = 0.05  # frequency difference\ntau_c = np.pi/delta_omega  # coherence time (corrected)\nbeat_period = 2*np.pi/delta_omega  # time for full beat cycle\n\nt = np.linspace(0, 1000, 10000)\ntau = np.linspace(0, 500, 200)\n\ndef generate_waves(t):\n    wave1 = np.exp(1j * omega0 * t)\n    wave2 = np.exp(1j * (omega0 + delta_omega) * t)\n    return wave1, wave2\n\ndef calc_correlation(wave, tau):\n    g = np.zeros(len(tau), dtype=complex)\n    N = len(wave)\n\n    for i, dt in enumerate(tau):\n        shift = int(dt * 10)\n        if shift &gt;= N:\n            g[i] = 0\n        else:\n            g[i] = np.mean(wave[:(N-shift)] * np.conj(wave[shift:]))\n\n    return g / np.abs(g[0])\n\n\nwave1, wave2 = generate_waves(t)\nwave_total = wave1 + wave2\n\n# Calculate correlation\ng = calc_correlation(wave_total, tau)\n\n# Plot\nfig, (ax1, ax2) = plt.subplots(2, 1, figsize=get_size(10, 8))\n\n# Plot waves\nax1.plot(t[:500], np.real(wave1[:500]), label='Wave 1', alpha=0.7)\nax1.plot(t[:500], np.real(wave2[:500]), label='Wave 2', alpha=0.7)\nax1.plot(t[:500], np.real(wave_total[:500]), 'k', label='Sum', alpha=0.7,lw=0.5)\nax1.set_title('wave superposition')\nax1.set_xlabel('time')\nax1.set_ylabel('amplitude')\nax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n\n\n# Plot correlation\nax2.plot(tau, np.abs(g))\nax2.axvline(x=tau_c, color='r', linestyle='--', label=r'$\\tau_c$ ')\nax2.axvline(x=beat_period, color='g', linestyle=':', label=f'Beat period')\nax2.set_title('|g⁽¹⁾(τ)|')\nax2.set_xlabel('τ')\nax2.set_ylabel('|g⁽¹⁾(τ)|')\nax2.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\nplt.tight_layout()\nplt.subplots_adjust(right=0.85)\n\nplt.show()\n\n\n\n\n\nTemporal correlation for two waves with slightly different frequencies. The vertical line indicates the coherence time τc = π/Δω.\n\n\n\n\nBesides different frequencies the coherence time can also be affected by phase jumps. The following example shows two waves with the same frequency but multiple phase jumps. The temporal correlation function shows the decoherence due to the phase jumps.\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nomega0 = 1.0  # same frequency for both waves\ntau = np.linspace(0, 500, 200)\n\nt = np.linspace(0, 1000, 10000)\n\ndef generate_waves_with_jumps(t, n_jumps=10):\n    # Create two identical waves\n    wave1 = np.exp(1j * omega0 * t)\n    wave2 = np.exp(1j * omega0 * t)  # same frequency\n\n    # Create regularly spaced jumps within first 500 time units\n    jump_positions = np.linspace(0, 500, n_jumps+1)[:-1]  # exclude last point\n    jump_indices = [int(pos * len(t)/t[-1]) for pos in jump_positions]\n    phase_shifts = np.random.uniform(0, 2*np.pi, n_jumps)\n\n    # Apply phase shifts to wave2\n    wave2_with_jumps = wave2.copy()\n    current_phase = 0\n\n    for i in range(n_jumps):\n        start_idx = jump_indices[i]\n        if i &lt; n_jumps-1:\n            end_idx = jump_indices[i+1]\n        else:\n            end_idx = len(t)\n\n        current_phase += phase_shifts[i]\n        wave2_with_jumps[start_idx:end_idx] *= np.exp(1j * current_phase)\n\n    return wave1, wave2_with_jumps, jump_positions\n\n\ndef calc_correlation(wave, tau):\n    g = np.zeros(len(tau), dtype=complex)\n    N = len(wave)\n\n    for i, dt in enumerate(tau):\n        shift = int(dt * 10)\n        if shift &gt;= N:\n            g[i] = 0\n        else:\n            g[i] = np.mean(wave[:(N-shift)] * np.conj(wave[shift:]))\n\n    return g / np.abs(g[0])\n\n# Generate waves with 30 jumps\nwave1, wave2, jump_positions = generate_waves_with_jumps(t, n_jumps=30)\nwave_total = wave1 + wave2\n\ng = calc_correlation(wave_total, tau)\n\n\nfig, (ax1, ax2) = plt.subplots(2, 1, figsize=get_size(10, 8))\n\nax1.plot(t[:2000], np.real(wave1[:2000]), label='Wave 1', alpha=0.9)\nax1.plot(t[:2000], np.real(wave2[:2000]), label='Wave 2', alpha=0.9)\nax1.plot(t[:2000], np.real(wave_total[:2000]), 'k-', label='Sum', lw=0.5)\nax1.set_xlim(0, 200)\n# Add vertical lines for phase jumps in wave plot\nfor pos in jump_positions:\n    ax1.axvline(x=pos, color='r', linestyle='--', alpha=0.3)\n\nax1.set_title('Superposition with Multiple Phase Jumps')\nax1.set_xlabel('time')\nax1.set_ylabel('amplitude')\nax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n\n# Plot correlation\nax2.plot(tau, np.abs(g))\n\nax2.set_title('|g⁽¹⁾(τ)|')\nax2.set_xlabel('τ')\nax2.set_ylabel('|g⁽¹⁾(τ)|')\nax2.set_xlim(0, 200)\nax2.set_ylim(0, 1)\n\n# Adjust layout\nplt.tight_layout()\nplt.subplots_adjust(right=0.85)\n\nplt.show()\n\n\n\n\n\nTemporal correlation for two waves of same frequency showing decoherence due to multiple phase jumps. Vertical lines indicate positions of phase jumps.\n\n\n\n\n\n\n\n\n\n\nCoherence of Thermal radiation\n\n\n\n\n\nThermal radiation is a common example of incoherent light. While it is called incoherent, there is no complete incoherence, but the coherence length of a few 10 micrometers. Sun light, for example, has been measured to have a coherence length of about 50 micrometers (Shawn Divitt and Lukas Novotny, “Spatial coherence of sunlight and its implications for light management in photovoltaics,” Optica 2, 95-103 (2015)). The following factors contribute to the incoherence of thermal radiation:\nRandom Emission Process - Individual atoms/molecules emit light independently - Each emission event has a random phase - The emission timing is random - These random events effectively create continuous phase jumps\nMultiple Emitters - Many atoms/molecules emit simultaneously - Each emitter acts independently - There’s no phase relationship between different emitters - This leads to spatially incoherent radiation\nThermal Motion - Atoms/molecules are in constant thermal motion - This motion causes Doppler shifts - The shifts result in frequency variations - Motion also affects the phase of emitted radiation\nCollision Effects - Frequent atomic/molecular collisions - Each collision can cause phase jumps - At higher temperatures, more frequent collisions - This leads to shorter coherence times\n\n\n\n\n\n\n\n\n\nPartial Coherence in Lasers\n\n\n\n\n\nThe coherence of laser light is limited by various physical mechanisms that cause fluctuations in phase and frequency. While perfect coherence is theoretically impossible, some lasers can achieve remarkable coherence lengths. Single-frequency solid-state lasers, when properly stabilized, are particularly noteworthy in this regard. For instance, a laser with a Lorentzian spectrum of 10 kHz linewidth can achieve a coherence length of 9.5 km.\nThe fundamental limit to laser coherence is set by quantum noise, as described by the Schawlow-Townes linewidth. However, modern laser systems, particularly those developed for optical clocks, have pushed these boundaries further. Some of these systems have been stabilized to achieve linewidths below one hertz, corresponding to coherence lengths exceeding 300,000 km.\nSpontaneous Emission - Not all emission in a laser is stimulated - Some spontaneous emission is always present - Adds random phase jumps to the laser field - Sets fundamental quantum limit to coherence\nTechnical Noise Sources - Mechanical vibrations of cavity mirrors - Thermal fluctuations in gain medium - Pump power fluctuations - Current noise in diode lasers\nGain Medium Properties - Finite linewidth of the lasing transition - Thermal motion of atoms/molecules - Pressure broadening in gas lasers - Population fluctuations\nCavity Effects - Finite cavity lifetime - Multiple longitudinal modes - Temperature-induced length changes",
    "crumbs": [
      "Wave Optics",
      "Lecture 8",
      "Interference and Coherence"
    ]
  },
  {
    "objectID": "thin_film_test.html",
    "href": "thin_film_test.html",
    "title": "Experimental Physics 3 Course on Optics and Quantum Mechanics",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\n\n# Constants\nn1 = 1.0    # refractive index of air\nn2 = 1.33   # refractive index of water\nn3 = n1     # refractive index of bottom medium (air)\n\n# Create arrays for thickness and wavelength\nd_values = np.linspace(90e-9, 200e-9, 500)  # thickness from 50nm to 2µm\nwavelengths = np.linspace(380e-9, 750e-9, 200)  # visible spectrum\n\ndef calculate_reflection(wavelength, d):\n    k = 2 * np.pi / wavelength\n    delta = 2 * n2 * d * k\n    phi_12 = np.pi if n1 &lt; n2 else 0\n    phi_23 = np.pi if n2 &lt; n3 else 0\n    total_phase = delta + phi_12 + phi_23\n    I = 4*np.cos(total_phase/2)**2\n    return I\n\ndef find_interference_maxima(d, wavelengths, intensities):\n    \"\"\"Find wavelengths where interference maxima occur\"\"\"\n    maxima_idx = []\n    for i in range(1, len(wavelengths)-1):\n        if (intensities[i] &gt; intensities[i-1] and\n            intensities[i] &gt; intensities[i+1] and\n            intensities[i] &gt; 2.0):\n            maxima_idx.append(i)\n    return wavelengths[maxima_idx], intensities[maxima_idx]\n\ndef wavelength_to_rgb(wavelength):\n    gamma = 0.8\n    wavelength = wavelength * 1e9\n\n    if wavelength &lt; 380 or wavelength &gt; 750:\n        return (0, 0, 0)\n\n    if wavelength &lt; 440:\n        R = (440 - wavelength) / (440 - 380)\n        G = 0\n        B = 1\n    elif wavelength &lt; 490:\n        R = 0\n        G = (wavelength - 440) / (490 - 440)\n        B = 1\n    elif wavelength &lt; 510:\n        R = 0\n        G = 1\n        B = (510 - wavelength) / (510 - 490)\n    elif wavelength &lt; 580:\n        R = (wavelength - 510) / (580 - 510)\n        G = 1\n        B = 0\n    elif wavelength &lt; 645:\n        R = 1\n        G = (645 - wavelength) / (645 - 580)\n        B = 0\n    else:\n        R = 1\n        G = 0\n        B = 0\n\n    R = np.power(R, gamma) if R &gt; 0 else 0\n    G = np.power(G, gamma) if G &gt; 0 else 0\n    B = np.power(B, gamma) if B &gt; 0 else 0\n\n    return np.array([R, G, B])\n\ndef mix_colors(wavelengths, intensities):\n    if len(wavelengths) == 0:\n        return np.array([0, 0, 0, 0])  # Added alpha channel\n\n    mixed_color = np.zeros(4)  # RGBA\n    max_intensity = 0\n\n    for wave, intensity in zip(wavelengths, intensities):\n        color = wavelength_to_rgb(wave)\n        mixed_color[:3] += color * (intensity/4.0)\n        max_intensity = max(max_intensity, intensity)\n\n    # Set alpha based on maximum intensity\n    mixed_color[3] = max_intensity / 4.0  # normalize to maximum possible intensity\n\n    if np.max(mixed_color[:3]) &gt; 0:\n        if len(wavelengths) &gt; 3:\n            white_factor = min((len(wavelengths) - 3) / 5, 0.7)\n            mixed_color[:3] = mixed_color[:3] * (1 - white_factor) + white_factor\n        else:\n            mixed_color[:3] = mixed_color[:3] / np.max(mixed_color[:3])\n\n    return mixed_color\n\n# Calculate colors for each thickness\nrgba_image = np.zeros((len(d_values), 4))  # RGBA\nfor i, d in enumerate(d_values):\n    intensities = np.array([calculate_reflection(w, d) for w in wavelengths])\n    max_wavelengths, max_intensities = find_interference_maxima(d, wavelengths, intensities)\n    rgba_image[i] = mix_colors(max_wavelengths, max_intensities)\n\n# Create a checkerboard background\nbg_size = 10\nbg = np.zeros((len(d_values), 1, 3))\nbg[::bg_size] = 0.8  # lighter squares\nbg[bg_size//2::bg_size] = 0.2  # darker squares\n\n# Plot with background\nplt.figure(figsize=(2, 6))\nplt.imshow(bg, aspect='auto', origin='lower')  # background\nplt.imshow(rgba_image.reshape(-1, 1, 4), aspect='auto', origin='lower')  # colored film\nplt.ylabel('Thickness (nm)')\ntick_positions = np.linspace(0, len(d_values)-1, 6)\ntick_labels = [f'{d*1e9:.0f}' for d in np.linspace(d_values[0], d_values[-1], 6)]\nplt.yticks(tick_positions, tick_labels)\nplt.xticks([])\nplt.title('Reflected Colors')\nplt.show()\n\n# Print theoretical wavelengths for verification\ntest_thicknesses = [100e-9, 200e-9, 300e-9]\nprint(\"\\nExpected wavelengths of constructive interference:\")\nfor d in test_thicknesses:\n    print(f\"\\nThickness {d*1e9:.0f} nm:\")\n    for m in range(1, 4):\n        wavelength = 4 * n2 * d / (2*m - 1)\n        if 380e-9 &lt;= wavelength &lt;= 750e-9:\n            print(f\"m={m}: {wavelength*1e9:.0f} nm\")\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Constants\nn1 = 1.0    # refractive index of air\nn2 = 1.33   # refractive index of water\nn3 = n1     # refractive index of bottom medium (air)\n\ndef calculate_reflection(wavelength, d):\n    k = 2 * np.pi / wavelength\n    delta = 2 * n2 * d * k\n    phi_12 = np.pi if n1 &lt; n2 else 0\n    phi_23 = np.pi if n2 &lt; n3 else 0\n    total_phase = delta + phi_12 + phi_23\n    I = 4*np.cos(total_phase/2)**2\n    return I\n\n# Calculate reflection for a range of thicknesses\nd_values = np.linspace(0, 500e-9, 1000)  # 0 to 500 nm\nwavelength = 520e-9  # green light\n\nintensities = [calculate_reflection(wavelength, d) for d in d_values]\n\n# Calculate theoretical destructive interference positions\ndef destructive_thickness(m, wavelength):\n    return (2*m - 1) * wavelength/(4*n2)\n\n# Plot reflection intensity vs thickness\nplt.figure(figsize=(10, 6))\nplt.plot(d_values*1e9, intensities)\nplt.xlabel('Thickness (nm)')\nplt.ylabel('Reflection Intensity')\nplt.title('Reflection Intensity vs Film Thickness')\n\n# Mark destructive interference positions\nfor m in range(1, 4):\n    d = destructive_thickness(m, wavelength)\n    plt.axvline(x=d*1e9, color='r', linestyle='--', alpha=0.5)\n    plt.text(d*1e9, 0.5, f'm={m}', rotation=90)\n\nplt.grid(True)\nplt.show()\n\n# Print destructive interference thicknesses\nprint(\"\\nDestructive interference thicknesses:\")\nfor m in range(1, 4):\n    d = destructive_thickness(m, wavelength)\n    print(f\"m={m}: {d*1e9:.1f} nm\")\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Constants\nn1 = 1.0    # refractive index of air\nn2 = 1.33   # refractive index of water\nn3 = n1     # refractive index of bottom medium (air)\n\ndef calculate_reflection(wavelength, d):\n    k = 2 * np.pi / wavelength\n    delta = 2 * n2 * d * k  # path difference phase\n    phi_12 = np.pi if n1 &lt; n2 else 0  # first interface phase shift\n    phi_23 = 0  # second interface phase shift\n    total_phase = delta + phi_12 + phi_23\n    I = 4*np.cos(total_phase/2)**2\n    return I\n\n# Calculate reflection for very thin films\nd_values = np.linspace(0, 200e-9, 1000)  # 0 to 200 nm\nwavelength = 550e-9  # green light\n\nintensities = [calculate_reflection(wavelength, d) for d in d_values]\n\nplt.figure(figsize=(10, 6))\nplt.plot(d_values*1e9, intensities)\nplt.xlabel('Thickness (nm)')\nplt.ylabel('Reflection Intensity')\nplt.title('Reflection Intensity vs Film Thickness')\n\n# Highlight the Newton black film region\nplt.axvspan(0, 20, color='gray', alpha=0.3, label='Newton black film region')\n\nplt.grid(True)\nplt.legend()\nplt.show()\n\n# Print phase contributions for very thin film\nd_thin = 10e-9  # 10 nm\npath_phase = 4 * np.pi * n2 * d_thin / wavelength\nprint(f\"\\nFor d = {d_thin*1e9:.1f} nm:\")\nprint(f\"Path difference phase: {path_phase:.3f} radians\")\nprint(f\"Interface phase shift: π radians\")\nprint(f\"Total phase: {path_phase + np.pi:.3f} radians\")"
  },
  {
    "objectID": "wave-optics/Thin Film Interference.html",
    "href": "wave-optics/Thin Film Interference.html",
    "title": "Thin Film Interference",
    "section": "",
    "text": "The reflection and transmission of waves on a thin film can also be regarded as an interference of two waves. A light wave is incident on a thin film as depicted below. A part of the wave is reflected on the first boundary (1). Another part is transmitted through the first boundary and reflected at the second boundary to be transmitted in the same direction (2) as the first reflected part. Note that the lines and arrows denote the direction of the wavevector \\(\\vec{k}\\) of the partial waves.\nThis picture of a single reflection at each interface is a simplification. In reality, we would have multiple reflections occurring at both interfaces, leading to an infinite number of partial waves. However, for interfaces with weak reflection coefficients (like the air/glass interface where r ≈ 4%), the contribution of higher-order reflections becomes negligible. After two reflections, the amplitude is already reduced to 4% of 4% = 0.16% of the incident wave. Therefore, considering just the first two partial waves provides a good approximation for weak reflections.\nFor the geometry shown in the figure above, we consider a medium with refractive index \\(n_1\\) surrounding a film with \\(n_2\\). The path difference Δs between waves 1 and 2 consists of two contributions:\n\\[\n\\Delta s=\\frac{2n_2d}{\\cos(\\beta)}-2d\\tan(\\beta)\\sin(\\alpha)\n\\]\nThe first term represents the optical path inside the film (wave 2), while the second term accounts for the additional path of wave 1 after reflection (shown by the dotted line).\nUsing Snell’s law, \\(n_1\\sin(\\alpha) = n_2\\sin(\\beta)\\), and setting \\(n_1 = 1\\) and \\(n_2 = n\\), we can simplify the path difference:\n\\[\n\\Delta s =\\frac{2nd}{\\cos(\\beta)}-\\frac{2nd\\sin^2(\\beta)}{\\cos(\\beta)}=2n d \\cos(\\beta)=2d\\sqrt{n^2-\\sin^2(\\alpha)}\n\\]\nThe total phase difference Δφ between the waves includes both the path difference and interface effects:\n\\[\n\\Delta \\phi=\\frac{2\\pi}{\\lambda}\\Delta s +\\pi\n\\]\nThe additional π term arises from the reflection at the first interface where \\(n_1 &lt; n_2\\). This phase jump occurs whenever light reflects from an optically denser medium. No such phase jump occurs at the second interface where \\(n_2 &gt; n_1\\).\nTo get to know the properties of thin film interference a bit better we consider the normal incidence \\(\\alpha=0\\), which leaves us with\n\\[\n\\Delta \\phi=\\frac{2\\pi}{\\lambda}2dn+\\pi\n\\]\nIn case we are searching for constructive interference, this phase shift should correspond to an integer multiple of \\(2\\pi\\), e.g. \\(\\Delta \\phi =m2\\pi\\). From the last equation we see already, that for \\(d=0\\), we have in principle a residual phase shift of \\(\\pi\\), meaning that there is only destructive interference. Yet a film thickness of zero does not really make sense.\nWe would like to discuss two different situations in the following in an example. For that we either look at the thickness under which a constructive interference at a wavelength of \\(\\lambda\\) occurs, or we ask what kind of wavelength do show constructive interference for a fixed thickness.",
    "crumbs": [
      "Wave Optics",
      "Lecture 9",
      "Thin Film Interference"
    ]
  },
  {
    "objectID": "wave-optics/Thin Film Interference.html#newton-rings",
    "href": "wave-optics/Thin Film Interference.html#newton-rings",
    "title": "Thin Film Interference",
    "section": "Newton Rings",
    "text": "Newton Rings\nA similar interference pattern is also observed in the case of a hemi-spherical surface touching a planar surface as sketched in the image below.\n\n\n\nNewton Rings. Interference of waves from a spherical and a planar surface in close contact.\n\n\nIf light is incident normal to the top surface, reflections occur at several interfaces. The important reflections occur at the spherical surface and the planar surface below. The vertical distance between these surfaces is \\(d\\), though refraction will deflect the beam slightly, making the actual path longer. If we stay close to the axis of the spherical surface (\\(r\\ll R\\)), where \\(R\\) is the radius of the spherical surface, we can neglect this refraction effect.\nUnder these conditions, the path length difference between a wave reflected at the curved and the planar surface is\n\\[\n\\Delta s=2d+\\frac{\\lambda}{2}\n\\]\nThe additional term \\(\\lambda/2\\) arises from the phase jump when reflecting at the planar boundary, as this reflection occurs at an optically denser material.\nHaving the path length difference, we can now calculate the condition for destructive interference:\n\\[\n\\Delta s=\\frac{2m+1}{2}\\lambda=2d+\\frac{\\lambda}{2}\n\\]\nwhere \\(m\\) is an integer. The distance \\(d\\) can be expressed as a function of the radial distance \\(r\\) from the contact point between the spherical surface and the plane surface. From the geometry of a circle, we have:\n\\[\nr^2=d(2R-d)\n\\]\nwith \\(R\\) being the radius of the spherical surface. Since \\(d\\ll R\\), the term \\(d^2\\) becomes negligible compared to \\(2Rd\\), allowing us to simplify to:\n\\[\nr^2=2dR\n\\]\nfrom which we obtain:\n\\[\nd=\\frac{r^2}{2R}\n\\]\nInserting this distance into the interference condition yields the radius \\(r_m\\) where destructive interference is observed:\n\\[\nr_m=\\sqrt{m\\lambda R}\n\\]\nThis equation shows that the radius of the interference rings increases with the square root of the integer \\(m\\). Each wavelength creates its own ring pattern, with the radius depending on both the wavelength and the sphere’s radius. This relationship makes Newton rings a useful tool for measuring either the wavelength of light (if \\(R\\) is known) or the radius of curvature of the spherical surface (if \\(\\lambda\\) is known).\n\n\n\nObservation of Newton Rings using white light in the lecture.\n\n\nWhen using white light, as shown above, each wavelength creates its own set of rings, leading to the colored pattern observed. The spacing and size of these rings provide a precise method for optical measurements and quality control of optical surfaces.",
    "crumbs": [
      "Wave Optics",
      "Lecture 9",
      "Thin Film Interference"
    ]
  },
  {
    "objectID": "wave-optics/Dummy.html",
    "href": "wave-optics/Dummy.html",
    "title": "Contents",
    "section": "",
    "text": "The contents of this Topic will only be presented in the lectures and not part of the online publications.",
    "crumbs": [
      "Wave Optics",
      "Lecture 10",
      "Fabry Perot Interferometer"
    ]
  },
  {
    "objectID": "wave-optics/Diffraction Grating.html",
    "href": "wave-optics/Diffraction Grating.html",
    "title": "Diffraction Grating",
    "section": "",
    "text": "We would like to combine now the diffraction on individual slits with the multiple inteference from many slits. Such objects are called diffraction gratings and have large importance for spectroscopy but also for the compression of short laser pulses.\nLet’s have a look at the sketch below.\nWe consider a number of \\(N\\) slits of width \\(b\\). The slits have a distance \\(d\\) from each other. Each slit acts like the slit before giving rise to a diffraction pattern, that is oscillating with decreasing amplitude. The width of this diffraction pattern is determined by \\(\\lambda/b\\) and the pattern is given by\n\\[\nI(\\theta)=I_s\\frac{\\sin^2\\left (\\pi \\frac{b}{\\lambda}\\sin(\\theta)\\right)}{\\left( \\pi \\frac{b}{\\lambda}\\sin(\\theta)\\right)^2}\n\\]\nNow we have multiple of these “slit” sources. Each Huygens source in a slit has a corresponding Huygens source in a neighboring slit at a distance \\(d\\). So these pairs of sources interfer like in our multiple wave interference\n\\[\nI=I_{0}\\frac{\\sin^2(N\\phi/2)}{\\sin^2(\\phi/2)}\n\\]\nwhere the phase difference between neighboring waves is given by\n\\[\n    \\phi=k\\Delta s=\\frac{2\\pi}{\\lambda}d\\sin(\\theta)\n\\]\nwhich finally gives\n\\[\nI=I_{0}\\frac{\\sin^2(N\\pi\\frac{d}{\\lambda}\\sin(\\theta))}{\\sin^2(\\pi\\frac{d}{\\lambda}\\sin(\\theta))}\n\\]\nThe intensity distribution behind a diffraction grating is now given as the product of the two contributions of single slit diffraction and multiple source interference."
  },
  {
    "objectID": "wave-optics/Diffraction Grating.html#properties-of-the-diffraction-pattern",
    "href": "wave-optics/Diffraction Grating.html#properties-of-the-diffraction-pattern",
    "title": "Diffraction Grating",
    "section": "Properties of the diffraction pattern",
    "text": "Properties of the diffraction pattern\nWe may now have a look at the properties of this intensity distribution. The graph below plots the intensity distribution for a diffraction grating with \\(N=8\\) slits illuminated, a distance of slits \\(d=4\\) µm, a width of the slits of \\(b=2\\) µm and a wavelength of 532 nm. We make the following general observations:\n\nThe intensity pattern is consisting as we already calculated for the multiple wave interference. The main maxima are called diffraction orders charachetrized by an integer number. The central peak is the 0th order peak. The first main peak to the right is 1st diffraction order and so on.\nThe main peaks are seperated by \\(N-2\\) secondary peaks and \\(N-1\\) minima.\nThe intensity distribution is characterized by an envelope, which is the diffraction pattern of a single slit (dashed line). Thus in the example below the 2nd order peak is suppressed. The envelope will become wider, if the slits become narrower."
  },
  {
    "objectID": "wave-optics/Diffraction Grating.html#position-of-the-main-peaks",
    "href": "wave-optics/Diffraction Grating.html#position-of-the-main-peaks",
    "title": "Diffraction Grating",
    "section": "Position of the Main Peaks",
    "text": "Position of the Main Peaks\nThe position of the main peaks requires that the numerator and the denominator are zero. This is given whenever the denominator argument is a integer multiple of \\(\\pi\\), i.e. \\(\\pi d/\\lambda\\sin(\\theta)=m\\pi\\) or \\(\\sin(\\theta)=m\\lambda/d\\). So the first order diffraction maximum is found at \\(\\sin(\\theta)=\\lambda/d\\) independent of the slit number \\(N\\). This means that the position of the main peaks increases linearly with the wavelength \\(\\lambda\\) and decreases with increasing distance of the slits \\(d\\).\n\n\n\nFig.: Diffraction pattern of a grating wher 8 slits with a width of 2 µm and a distance of 4 micrometers are illuminated by a wavelength of 532 nm."
  },
  {
    "objectID": "wave-optics/Diffraction Grating.html#influence-of-the-slit-width",
    "href": "wave-optics/Diffraction Grating.html#influence-of-the-slit-width",
    "title": "Diffraction Grating",
    "section": "Influence of the Slit Width",
    "text": "Influence of the Slit Width\nThe two plots below show the influence of the slit width while the slit distance is the same. We have again \\(N=8\\) slits participating with \\(d=4\\) µm while the slit width is \\(b=2\\) µm on the left side and \\(b=1\\) µm on the right side. The result is clearly an increased width of the envelope. The first minimum of the slit diffraction pattern occurs at \\(\\sin(\\theta)=\\lambda/b\\).\n\n\n\nFig.: (Left) Diffraction pattern of a grating with \\(N=8\\) slits (\\(d=4\\) µm, \\(b=2\\) µm) with \\(\\lambda=532\\) nm. (Right) Diffraction pattern of a grating with \\(N=8\\) slits (\\(d=4\\) µm, \\(b=1\\) µm) with \\(\\lambda=532\\) nm."
  },
  {
    "objectID": "wave-optics/Diffraction Grating.html#influence-on-the-slit-number",
    "href": "wave-optics/Diffraction Grating.html#influence-on-the-slit-number",
    "title": "Diffraction Grating",
    "section": "Influence on the Slit Number",
    "text": "Influence on the Slit Number\nWhen using an increased slit number, we obtain the main diffraction peaks are becoming sharper. The location of the main peaks for the wavelength is unchanged, but as we have now \\(N-2\\) secondary maxima inbetween. This decreased width of the main peaks is important for the spectral resolution of the grating.\n\n\n\nFig.: (Left) Diffraction pattern of a grating with \\(N=16\\) slits (\\(d=4\\) µm, \\(b=1\\) µm) with \\(\\lambda=532\\) nm. (Right) Diffraction pattern of a grating with \\(N=100\\) slits (\\(d=4\\) µm, \\(b=1\\) µm) with \\(\\lambda=532\\) nm."
  },
  {
    "objectID": "wave-optics/Diffraction Grating.html#spectral-resolution",
    "href": "wave-optics/Diffraction Grating.html#spectral-resolution",
    "title": "Diffraction Grating",
    "section": "Spectral resolution",
    "text": "Spectral resolution\nFor the spectral resolution we have to define a criterium again, that allows us to quantify the spectral resolution. We borrow the idea we used from the optical resolution of the microscope, i.e. that two peaks are separable, if the second peak is located at the minimum of the first diffraction pattern. Here the diffraction patterns refer not to different objects on space but to different wavelength \\(\\lambda_1\\) and \\(\\lambda_2\\).\n\n\n\nFig.: Rayleigh resolution limit a grating with \\(N=100\\) slits (\\(d=4\\) µm, \\(b=1\\) µm) with \\(\\lambda_1=532\\) nm and \\(\\lambda_2=537\\) nm in the first order diffraction peak (left) and the second order peak (right).\n\n\nLet us have a look at the \\(m\\)th order diffraction peak for the wavelength \\(\\lambda_1\\). This occurs at\n\\[\n\\sin(\\theta)=m\\frac{\\lambda_1}{d}\n\\]\nThe next secondary minimum to larger angles of the diffraction pattern is then located at a position, where the numerator of the multiple wave interference\n\\[\n\\sin^2(N\\pi\\frac{d}{\\lambda}\\sin(\\theta))\n\\]\nbecomes zero or the argument\n\\[\nN\\pi\\frac{d}{\\lambda}\\sin(\\theta)=l\\pi\n\\]\nbecomes a multiple \\(l\\) of \\(\\pi\\). For the first order main peak we have had already \\(N-2\\) intermediate peaks as well as the 0th and now the first order peak. Therefore \\(m=l/N\\) and the next mimimum after the 1st order peak is at\n\\[\n\\sin(\\theta_1)=\\frac{l+1}{N}\\frac{\\lambda_1}{d}\n\\]\nThis angle has to correspond to the position of the main peak of the first order diffraction of the wavelength \\(\\lambda_2\\), so\n\\[\n\\sin(\\theta_1)=m\\frac{\\lambda_2}{d}\n\\]\nCombining both equations for the two wavelength yields\n\\[\n\\left (m+\\frac{1}{N} \\right )\\frac{\\lambda_1}{d}=m\\frac{\\lambda_2}{d}\n\\]\nand after some rearrangements (and setting _1=)\n\\[\nR=\\frac{\\lambda}{\\Delta \\lambda}=mN\n\\]\nThis is the resolving power \\(R\\) of a grating. The ability to resolve two wavelength therefore increases with the diffraction order \\(m\\) and the number of slits used for the diffraction. Yet, the intensity of higher diffraction orders rapidly decreases due to the grating envelope. Therefore, the main parameter to change is the number of illuminted slits.\nOur finding is illustrated in the Figure above. Where we achieve a resolution of about 5 nm, when using \\(N=100\\) slits at a distance of \\(d=4\\) µm.\n\n \n\nFig.: Diffraction pattern observed for a grating in the lecture with red light (left) and white light (right)."
  },
  {
    "objectID": "wave-optics/FabryPerotDummy.html",
    "href": "wave-optics/FabryPerotDummy.html",
    "title": "Experimental Physics 3 Course on Optics and Quantum Mechanics",
    "section": "",
    "text": "The contents of this Topic will only be presented in the lectures and not part of the online publications."
  },
  {
    "objectID": "wave-optics/index.html",
    "href": "wave-optics/index.html",
    "title": "EXP3 Quarto",
    "section": "",
    "text": "This is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites."
  },
  {
    "objectID": "wave-optics/Fresnel Zones.html",
    "href": "wave-optics/Fresnel Zones.html",
    "title": "Fresnel Zones",
    "section": "",
    "text": "We want to take a more general look at diffraction by exploring a concept known as Fresnel zones. Consider spherical waves of wavelength \\(\\lambda\\) emitted from a source, as indicated by the solid line in the sketch below.\nWe will examine the intensity of the wave at a point \\(P\\). To do this, we consider the amplitude contributions from all points on the wavefront, as each point on the wavefront acts as a Huygens source contributing to the intensity at point \\(P\\).\nInstead of calculating the intensity explicitly, we will analyze the distances of individual points on the wavefront from point \\(P\\). Specifically, we look at concentric circles around point \\(P\\), where the radius of each circle increases by \\(\\lambda/2\\), i.e.,\n\\[\nr_m = r_0 + m \\frac{\\lambda}{2}\n\\]\nwhere \\(m\\) is an integer. The regions between \\(r_m\\) and \\(r_{m+1}\\) are called Fresnel zones. If we consider two neighboring zones, each zone contains pairs of points that are exactly \\(\\lambda/2\\) out of phase. This means that these pairs of points would lead to destructive interference. If we remove these points, we are left with constructive interference along the optical axis only. We can construct such an aperture by calculating the ring radius\n\\[\n\\rho_{m}^2 = \\left( r_0 + m \\frac{\\lambda}{2} \\right)^2 - r_0^2\n\\]\naccording to the sketch above. This yields\n\\[\n\\rho_m^2 = r_0 m \\lambda + m^2 \\frac{\\lambda^2}{4}\n\\]\nFor \\(r_{0} \\gg \\lambda\\), we can simplify the above formula to\n\\[\n\\rho_m = \\sqrt{m r_0 \\lambda}\n\\]\nwhich gives the radius of the individual zones. The width of the zones is given by\n\\[\n\\Delta \\rho_m = \\rho_{m+1} - \\rho_m = \\sqrt{r_0 \\lambda} (\\sqrt{m+1} - \\sqrt{m})\n\\]",
    "crumbs": [
      "Wave Optics",
      "Lecture 11",
      "Fresnel Zone Plate"
    ]
  },
  {
    "objectID": "wave-optics/Fresnel Zones.html#fresnel-zone-plate",
    "href": "wave-optics/Fresnel Zones.html#fresnel-zone-plate",
    "title": "Fresnel Zones",
    "section": "Fresnel Zone Plate",
    "text": "Fresnel Zone Plate\nIf we now fill the ring from \\(\\rho_m\\) to \\(\\rho_{m+1}\\) on a glass slide but leave the ring from \\(\\rho_{m+1}\\) to \\(\\rho_{m+2}\\) transparent, we create a so-called Fresnel zone plate. Here, the radius in the first zone \\(r\\) ranges from \\(r_0\\) to \\(r_0 + \\lambda/2\\). The next zone will range from \\(r_0 + \\lambda/2\\) to \\(r_0 + \\lambda\\) but is removed from its contribution to the point.\n\n\n\nFresnel zone plate removing destructive interference to the point on the optical axis.\n\n\nThe Fresnel zone plate can be constructed by defining the inner reference zone in an arbitrary way. One may either block or transmit the direct path from the light source along the optical axis, resulting in either the odd or even zones being transparent.\n\n\n\nFresnel zone plates with odd (left) or even (right) zones transparent delivering the same result.\n\n\n \nSuch zone plates are important for applications where focusing of radiation is required but the refractive indices are not large enough to create strong enough refraction. This is especially true for X-ray radiation.\n\n\n\nFresnel zone plates for X-ray radiation. Image taken from Ion beam lithography for Fresnel zone plates in X-ray microscopy - Optics Express, Vol. 21 Issue 10, pp.11747-11756 (2013).\n\n\nBelow is an calculation of the intensity pattern at the focal distance of a zone plate from many spherical wave sources if the destructively interfering waves are not removed (left) and if they are removed.\n\n\n\n\n\nConsider with care. Need to check the result again.",
    "crumbs": [
      "Wave Optics",
      "Lecture 11",
      "Fresnel Zone Plate"
    ]
  },
  {
    "objectID": "wave-optics/Fresnel Zones.html#applications-and-importance-of-fresnel-zone-plates",
    "href": "wave-optics/Fresnel Zones.html#applications-and-importance-of-fresnel-zone-plates",
    "title": "Fresnel Zones",
    "section": "Applications and Importance of Fresnel Zone Plates",
    "text": "Applications and Importance of Fresnel Zone Plates\nFresnel zone plates are used in various applications, particularly where traditional lenses are ineffective. Some key applications include:\nX-ray Microscopy: Fresnel zone plates are used to focus X-rays, which have very short wavelengths and require special techniques for focusing. Traditional lenses are not effective for X-rays due to their low refractive indices.\nOptical Systems: In optical systems, Fresnel zone plates can be used to create focal points without the need for bulky lenses. This is particularly useful in compact optical devices.\nHolography: Fresnel zone plates are used in holography to create and reconstruct holograms. They help in manipulating the wavefronts to produce the desired holographic images.\nAstronomy: In astronomy, Fresnel zone plates can be used in telescopes to focus light from distant stars and galaxies. They offer an alternative to traditional lenses and mirrors.",
    "crumbs": [
      "Wave Optics",
      "Lecture 11",
      "Fresnel Zone Plate"
    ]
  },
  {
    "objectID": "wave-optics/Sagnac_Interferometer.html",
    "href": "wave-optics/Sagnac_Interferometer.html",
    "title": "Sagnac Interferometer",
    "section": "",
    "text": "A Sagnac interferometer operates by splitting a beam of light into two separate beams that travel in opposite directions around a closed loop. These beams are then recombined at the end of the loop, resulting in an interference pattern. If the interferometer is rotating, the path lengths of the two beams differ, leading to a phase shift.\nThe phase shift, denoted as \\(\\Delta \\phi\\), can be calculated using the formula:\n\\[\n\\Delta \\phi = \\frac{8 \\pi A \\Omega}{\\lambda c}\n\\]\nwhere \\(A\\) represents the area enclosed by the light path, \\(\\Omega\\) is the angular velocity of the rotation, \\(\\lambda\\) is the wavelength of the light, and \\(c\\) is the speed of light.\n\n\nTo derive the phase shift, we start by considering the path length difference. Assume a loop with a perimeter \\(L\\) and an area \\(A\\). In the absence of rotation, the time taken for light to travel around the loop is given by \\(T = \\frac{L}{c}\\).\nWhen the interferometer rotates with an angular velocity \\(\\Omega\\), the effective path length changes. For the beam traveling in the direction of rotation, the path length increases, while for the beam traveling opposite to the direction of rotation, the path length decreases.\nThe time difference \\(\\Delta T\\) between the two beams can be expressed as:\n\\[\n\\Delta T = \\frac{4 A \\Omega}{c^2}\n\\]\nThe phase shift \\(\\Delta \\phi\\) is related to this time difference by the equation:\n\\[\n\\Delta \\phi = \\frac{2 \\pi \\Delta T}{T} = \\frac{8 \\pi A \\Omega}{\\lambda c}\n\\]\nThis relationship shows how the rotation of the interferometer causes a measurable phase shift in the interference pattern, which can be used to determine the angular velocity of the rotation."
  },
  {
    "objectID": "wave-optics/Sagnac_Interferometer.html#sagnac-interferometer-overview",
    "href": "wave-optics/Sagnac_Interferometer.html#sagnac-interferometer-overview",
    "title": "Sagnac Interferometer",
    "section": "",
    "text": "A Sagnac interferometer operates by splitting a beam of light into two separate beams that travel in opposite directions around a closed loop. These beams are then recombined at the end of the loop, resulting in an interference pattern. If the interferometer is rotating, the path lengths of the two beams differ, leading to a phase shift.\nThe phase shift, denoted as \\(\\Delta \\phi\\), can be calculated using the formula:\n\\[\n\\Delta \\phi = \\frac{8 \\pi A \\Omega}{\\lambda c}\n\\]\nwhere \\(A\\) represents the area enclosed by the light path, \\(\\Omega\\) is the angular velocity of the rotation, \\(\\lambda\\) is the wavelength of the light, and \\(c\\) is the speed of light.\n\n\nTo derive the phase shift, we start by considering the path length difference. Assume a loop with a perimeter \\(L\\) and an area \\(A\\). In the absence of rotation, the time taken for light to travel around the loop is given by \\(T = \\frac{L}{c}\\).\nWhen the interferometer rotates with an angular velocity \\(\\Omega\\), the effective path length changes. For the beam traveling in the direction of rotation, the path length increases, while for the beam traveling opposite to the direction of rotation, the path length decreases.\nThe time difference \\(\\Delta T\\) between the two beams can be expressed as:\n\\[\n\\Delta T = \\frac{4 A \\Omega}{c^2}\n\\]\nThe phase shift \\(\\Delta \\phi\\) is related to this time difference by the equation:\n\\[\n\\Delta \\phi = \\frac{2 \\pi \\Delta T}{T} = \\frac{8 \\pi A \\Omega}{\\lambda c}\n\\]\nThis relationship shows how the rotation of the interferometer causes a measurable phase shift in the interference pattern, which can be used to determine the angular velocity of the rotation."
  },
  {
    "objectID": "wave-optics/MultiWave Interference.html",
    "href": "wave-optics/MultiWave Interference.html",
    "title": "Multiple Wave Interference",
    "section": "",
    "text": "So far we looked at the interference of two waves, which was a simplification as I mentioned already earlier. Commonly there will be a multitude of partial waves contribute to the oberved intereference. This is what we would like to have a look at now. We will do that in a quite general fashion, as the resulting formulas will appear several times again for different problems.\nNevertheless we will make a difference between\n\nmultiwave interference of waves with the constant amplitude\nmultiwave interference of waves with decreasing amplitude\n\nEspecially the latter is often occuring, if we have multiple reflections and each reflection is only a fraction of the incident amplitude.\n\nMultiple Wave Interference with Constant Amplitude\nIn the case of constant amplitude (for example realized by a grating, which we talk about later), the total wave amplitude is given according to the picture below by\n\\[\nU=U_1+U_2+U_1+U_3+\\ldots+U_M\n\\]\nwhere we sum the amplitude over \\(M\\) partial waves. Between the neighboring waves (e.g. \\(U_1\\) and \\(U_2\\)), we will assume a phase difference (because of a path length difference for example), which we denote as \\(\\Delta \\phi\\).\nThe amplitude of the p-th wave is then given by\n\\[\nU_p=\\sqrt{I_0}e^{i(p-1)\\Delta \\phi}\n\\]\nwith the index \\(p\\) being an interger \\(p=1,2,\\ldots,M\\), \\(h=e^{i\\Delta \\phi}\\) and \\(\\sqrt{I_0}\\) as the amplitude of each individual wave. The total amplitude \\(U\\) can be then expressed as\n\\[\nU=\\sqrt{I_0}\\left (1+h+h^2+\\ldots +h^{M-1}\\right)\n\\]\nwhich is a geometric sum. We can apply the sum formula for geometric sums to obtain\n\\[\nU=\\sqrt{I_0}\\frac{1-h^M}{1-h}=\\sqrt{I_0}\\frac{1-e^{iM\\Delta \\phi}}{1-e^{i\\Delta \\phi}}\n\\]\nWe now have to calculate the intensity of the total amplitude\n\\[\nI=|U|^2=I_{0}\\left | \\frac{e^{-iM\\Delta \\phi/2}-e^{iM\\Delta \\phi/2}}{e^{-i\\Delta \\phi/2}-e^{i\\Delta \\phi/2}}\\right |^2\n\\]\nwhich we can further simplify to give\n\\[\nI=I_{0}\\frac{\\sin^2(M\\Delta \\phi/2)}{\\sin^2(\\Delta \\phi/2)}\n\\]\n\nCode\n# Parameters\nM = 6  # number of phasors\nphi = np.pi/8  # example phase difference between successive phasors\n\ndef plot_angle(ax, pos, angle, length=0.95, acol=\"C0\", **kwargs):\n    vec2 = np.array([np.cos(np.deg2rad(angle)), np.sin(np.deg2rad(angle))])\n    xy = np.c_[[length, 0], [0, 0], vec2*length].T + np.array(pos)\n    ax.plot(*xy.T, color=acol)\n    return AngleAnnotation(pos, xy[0], xy[2], ax=ax, **kwargs)\n\n# Calculate phasor positions\ndef calculate_phasors(phi, M):\n    # Initialize arrays for arrow start and end points\n    x_start = np.zeros(M)\n    y_start = np.zeros(M)\n    x_end = np.zeros(M)\n    y_end = np.zeros(M)\n\n    # Running sum of phasors\n    x_sum = 0\n    y_sum = 0\n\n    for i in range(M):\n        # Current phasor\n        x = np.cos(i * phi)\n        y = np.sin(i * phi)\n\n        # Store start point (end of previous phasor)\n        x_start[i] = x_sum\n        y_start[i] = y_sum\n\n        # Add current phasor\n        x_sum += x\n        y_sum += y\n\n        # Store end point\n        x_end[i] = x_sum\n        y_end[i] = y_sum\n\n    return x_start, y_start, x_end, y_end\n\nx_start, y_start, x_end, y_end = calculate_phasors(phi, M)\n\nplt.figure(figsize=get_size(6, 6))\nax = plt.gca()\n\nfor i in range(M):\n    plt.arrow(x_start[i], y_start[i],\n             x_end[i]-x_start[i], y_end[i]-y_start[i],\n             head_width=0.15, head_length=0.2, fc='k', ec='k',\n             length_includes_head=True,\n             label=f'E{i+1}' if i == 0 else \"\")\n\nplt.arrow(0, 0, x_end[-1], y_end[-1],\n         head_width=0.15, head_length=0.2, fc='r', ec='r',\n         length_includes_head=True, label='Resultant')\n\nax.set_aspect('equal')\nxx = np.linspace(-1, 3, 100)\nax.plot(xx,(xx-1)*np.tan(phi),'k--',lw=0.5)\nax.plot([1,3],[0,0],'k--',lw=0.5)\nkw = dict(size=195, unit=\"points\", text=r\"$\\Delta \\phi$\")\nplot_angle(ax, (1.0, 0), phi*180/np.pi, textposition=\"inside\", **kw)\nplt.axis('off')\nmax_range = max(abs(x_end[-1]), abs(y_end[-1])) * 1.2\nplt.xlim(-0, max_range/1.5)\nplt.ylim(-0.1, max_range/1.)\n\nplt.show()\n# Parameters\nM = 6\nphi = np.linspace(-4*np.pi, 4*np.pi, 10000)  # increased resolution\nI0 = 1\n\ndef multiple_beam_pattern(phi, M):\n    numerator = np.sin(M * phi/2)**2\n    denominator = np.sin(phi/2)**2\n    I = np.where(denominator != 0, numerator/denominator, M**2)\n    return I\n\nI = I0 * multiple_beam_pattern(phi, M)\n\nfirst_min = 2*np.pi/M  # theoretical value\n\ndef find_nearest(array, value):\n    array = np.asarray(array)\n    idx = (np.abs(array - value)).argmin()\n    return array[idx], idx\n\nhalf_max = M**2/2\n\nphi_positive = phi[phi &gt;= 0]  # only positive values\nI_positive = I[phi &gt;= 0]\n_, idx_half = find_nearest(I_positive, half_max)\nhalf_width = phi_positive[idx_half]\n\n# Create plot\nplt.figure(figsize=get_size(10, 6))\nplt.plot(phi/np.pi, I, 'b-', label=f'M={M}')\n\n#plt.plot(first_min/np.pi, multiple_beam_pattern(first_min, M), 'ro')\n#plt.annotate(f'First minimum\\nφ = 2π/M = {first_min/np.pi:.2f}π',\n\nplt.axvline(x=first_min/np.pi, color='r', linestyle='--', label=f'φ = 2π/M = {first_min/np.pi:.2f}π')\n\n#plt.plot(half_width/np.pi, half_max, 'go')\n\nplt.xlabel(r'phase $\\Delta \\phi/\\pi$')\nplt.ylabel('intensity I/I₀')\nplt.title(f'Multiple Beam Interference Pattern (M={M})')\nplt.ylim(0, M**2 + 15)\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nMultiple wave interference of \\(M=6\\) waves with a phase difference of \\(\\phi=\\pi/8\\). The black arrows represent the individual waves, the red arrow the sum of all waves.\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 1— Multiple beam interference pattern for M=6 beams. The intensity distribution is shown as a function of the phase shift \\(\\phi\\). The first minimum is at \\(\\phi=2\\pi/M\\). The intensity distribution is symmetric around \\(\\phi=0\\).\n\n\n\n\n\n\n\nThe result is therefore an oscillating function. The numerator \\(\\sin^2(M\\Delta \\phi/2)\\) shows and oscillation frequency, which is by a factor of \\(M\\) higher than the one in the denominator \\(\\sin^2 (\\Delta \\phi/2)\\). Therefore the intensity pattern is oscillating rapidly and creating a first minimum at\n\\[\n\\Delta \\phi=\\frac{2\\pi}{M}\n\\]\nThis is an important result, since it shows that the number of sources \\(M\\) determines the position of the first minimum and the interference peak gets narrower with increasing \\(M\\). Since the phase difference \\(\\Delta \\phi\\) between neighboring sources is the same as for the double slit experiment, i.e. \\(\\Delta \\phi=2\\pi d/\\lambda \\sin(\\theta)\\), we can also determine the angular position of the first minimum. This is given by\n\\[\n\\sin(\\theta_\\textrm{min})=\\frac{1}{M}\\frac{\\lambda}{d}\n\\]\nThis again has the common feature that it scales as \\(\\lambda/d\\). A special situation occurs, whenever the numerator and the denominator become zero. This will happen whenever\n\\[\n\\Delta \\phi=m 2\\pi\n\\]\nwhere \\(m\\) is an integer and denotes the interference order, i.e. the number of wavelength that neighboring partial waves have as path length difference. In this case, the intensity distributiion will give us\n\\[\nI=I_0 \\frac{0}{0}\n\\]\nand we have to determine the limit with the help of l’Hospitals rule. The outcome of this calculation is, that\n\\[\nI(\\Delta \\phi=m2\\Delta \\pi)=M^2 I_0\n\\]\nwhich can be also realized when using the small angle approximation for the sine functions.\n\nWavevector Representation\nWe would like to introduce a different representation of the multiple wave interference of the grating, which is quite insightful. The first order (\\(m=1\\)) constructive interference condition is given by\n\\[\n\\frac{1}{\\lambda}\\sin{\\theta}= \\frac{1}{d}\n\\]\nwhich also means that\n\\[\n\\frac{2\\pi}{\\lambda}\\sin{\\theta}= \\frac{2\\pi}{d}\n\\]\nThis can be written as\n\\[\nk \\sin{\\theta}= K\n\\]\nwhere \\(k\\) is the magnitude of the wavevector of the light and \\(K\\) is the wavevector magnitude that corresponds to the grating period \\(d\\). As the magnitude of the wavevector of the light is conserved, the wavevectors of the incident light and the light traveling along the direction of the first interence peak form the sides of an equilateral triangle. This is shown in the following figure.\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\nk = 1  # Magnitude of k₁ and k₂\n\norigin = np.array([0, 0])\n\nk1 = np.array([k, 0])\n\ntheta_deg = 30  # θ = 30 degrees\ntheta_rad = np.deg2rad(theta_deg)\n\nk2 = k * np.array([np.cos(theta_rad), np.sin(theta_rad)])\n\nK = k2 - k1\n\npoint_O = origin\npoint_A = point_O + k1\npoint_B = point_O + k2\n\n\nplt.figure(figsize=get_size(10, 10))\nax = plt.gca()\n\n# Plot vector k₁\nax.arrow(point_O[0], point_O[1], k1[0], k1[1],\n         head_width=0.02, head_length=0.03, fc='k', ec='k', length_includes_head=True)\n\n\nax.arrow(point_A[0], point_A[1], K[0], K[1],\n         head_width=0.02, head_length=0.03, fc='b', ec='b', length_includes_head=True)\n\nax.arrow(point_O[0], point_O[1], k2[0], k2[1],\n         head_width=0.02, head_length=0.03, fc='k', ec='k', length_includes_head=True)\n\n# Label vectors\nax.text(k1[0]/2 - 0.05, k1[1]/2 - 0.05, r'$\\mathbf{k}$', fontsize=14, color='k')\nax.text(point_A[0] + K[0]/2 , point_A[1] + K[1]/2 + 0.05, r'$\\mathbf{K}$', fontsize=14, color='b')\nax.text(k2[0]/2 + 0.0, k2[1]/2+0.1, r'$\\mathbf{k}$', fontsize=14, color='k')\n\n# Indicate angle θ between k₁ and k₂ at the origin\narc_radius = 0.3  # Radius of the arc representing θ\nangle_range = np.linspace(0, theta_rad, 100)\narc_x = arc_radius * np.cos(angle_range)\narc_y = arc_radius * np.sin(angle_range)\nax.plot(arc_x, arc_y, color='k')\n\nax.text(arc_radius * np.cos(theta_rad / 2) + 0.02,\n        arc_radius * np.sin(theta_rad / 2) + 0.02,\n        r'$\\theta$', fontsize=14)\n\n# Set equal aspect ratio\nax.set_aspect('equal', adjustable='box')\n\nall_x = [point_O[0], point_A[0], point_B[0]]\nall_y = [point_O[1], point_A[1], point_B[1]]\nmargin = 0.2\nax.set_xlim(min(all_x) - margin, max(all_x) + margin)\nax.set_ylim(min(all_y) - margin, max(all_y) + margin)\nplt.axis('off')\n\n# Display the plot\nplt.show()\n\n\n\n\n\nWavevector summation for the diffraction grating. The wavevector of the incident light \\(k\\) and the wavevector of the light traveling along the direction of the first interference peak \\(K\\) form an equilateral triangle.\n\n\n\n\nThis means that the diffraction grating is providing a wavevector \\(K\\) to alter the direction of the incident light. This is again a common feature reappearing in many situations as for example in the X-ray diffraction of crystals.\n\n\n\nMultiple Wave Interference with Decreasing Amplitude\nWe will turn our attention now to a slight modification of the previous multiwave interference. We will introduce a decreasing amplitude of the individual waves. The first wave shall have an amplitude \\(U_1=\\sqrt{I_0}\\). The next wave, however, will not only be phase shifted but also have a smaller amplitude.\n\\[\nU_2=h U_1\n\\]\nwhere \\(h=re^{i\\phi}\\) with \\(|h|=r&lt;1\\). \\(r\\) can be regarded as a reflection coefficient, which deminishes the amplitude of the incident wave. According to that the intensity is reduced by\n\\[\nI_2=|U_2|^2=|h U_1|^2=r^2 I_1\n\\]\nThe intensity of the incident wave is multiplied by a factor \\(r^2\\), while the amplitude is multiplied by \\(r\\). Note that the phase factor \\(e^{i\\Delta\\phi}\\) is removed when taking the square of this complex number.\n\n\n\n\n\n\nIntensity at Boundaries\n\n\n\nThe amplitude of the reflected wave is diminished by a factor \\(r\\le 1\\), which is called the reflection coefficient. The intensity is diminished by a factor \\(R=|r|^2\\le1\\), which is the reflectance.\nIn the absence of absorption, reflectance \\(R\\) and transmittance \\(T\\) add to one due to energy conservation.\n\\[\nR+T=1\n\\]\n\n\nConsequently, the third wave would be now \\(U_3=hU_2=h^2U_1\\). The total amplitude is thus\n\\[\nU=U_1+U_2+U_3+\\ldots+U_M = \\sqrt{I_0}(1+h+h^2+\\ldots)\n\\]\n\nCode\nM = 18  # number of phasors\nphi = np.pi/6  # example phase difference between successive phasors\nr = 0.95  # reduction factor for each subsequent phasor\n\ndef plot_angle(ax, pos, angle, length=0.95, acol=\"C0\", **kwargs):\n    vec2 = np.array([np.cos(np.deg2rad(angle)), np.sin(np.deg2rad(angle))])\n    xy = np.c_[[length, 0], [0, 0], vec2*length].T + np.array(pos)\n    ax.plot(*xy.T, color=acol)\n    return AngleAnnotation(pos, xy[0], xy[2], ax=ax, **kwargs)\n\ndef calculate_phasors(phi, M, r):\n    x_start = np.zeros(M)\n    y_start = np.zeros(M)\n    x_end = np.zeros(M)\n    y_end = np.zeros(M)\n\n    x_sum = 0\n    y_sum = 0\n\n    for i in range(M):\n        amplitude = r**i  # exponential decrease\n        x = amplitude * np.cos(i * phi)\n        y = amplitude * np.sin(i * phi)\n\n        x_start[i] = x_sum\n        y_start[i] = y_sum\n\n        x_sum += x\n        y_sum += y\n\n        x_end[i] = x_sum\n        y_end[i] = y_sum\n\n    return x_start, y_start, x_end, y_end\n\nx_start, y_start, x_end, y_end = calculate_phasors(phi, M, r)\n\nplt.figure(figsize=get_size(6, 6),dpi=150)\nax = plt.gca()\n\nfor i in range(M):\n    plt.arrow(x_start[i], y_start[i],\n             x_end[i]-x_start[i], y_end[i]-y_start[i],\n             head_width=0.15, head_length=0.2,\n             fc='k', ec='k',\n             length_includes_head=True,\n             label=f'E{i+1}' if i == 0 else \"\")\n\nplt.arrow(0, 0, x_end[-1], y_end[-1],\n         head_width=0.15, head_length=0.2, fc='r', ec='r',\n         length_includes_head=True, label='Resultant')\n\nax.set_aspect('equal')\nxx = np.linspace(-1, 3, 100)\nax.plot(xx,(xx-1)*np.tan(phi),'k--',lw=0.5)\nax.plot([1,3],[0,0],'k--',lw=0.5)\nkw = dict(size=195, unit=\"points\", text=r\"$\\phi$\")\nplot_angle(ax, (1.0, 0), phi*180/np.pi, textposition=\"inside\", **kw)\nplt.axis('off')\nmax_range = max(abs(x_end[-1]), abs(y_end[-1])) * 1.2\nplt.xlim(-max_range/1.8, max_range/0.8)\nplt.ylim(-0.1, max_range/0.9)\n\nplt.show()\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Create phase array from -2π to 2π\nphi = np.linspace(-2*np.pi, 2*np.pi, 1000)\n\ndef calculate_intensity(phi, F):\n    return 1/(1 + 4*(F/np.pi)**2 * np.sin(phi/2)**2)\n\nplt.figure(figsize=get_size(10, 6))\n\nfinesse_values = [1, 4, 20]\nstyles = ['-', '--', ':']\n\nfor F, style in zip(finesse_values, styles):\n    I = calculate_intensity(phi, F)\n    plt.plot(phi/np.pi, I, style, label=f'$\\\\mathcal{{F}}={F}$')\n\nplt.xlabel('Phase $\\\\phi/\\\\pi$')\nplt.ylabel('$I/I_{\\\\mathrm{max}}$')\nplt.grid(True, alpha=0.3)\nplt.legend()\nplt.ylim(0, 1.1)\n\nplt.show()\n\n\n\n\n\n\n\n\nPhase construction of a multiwave intereference with M waves with decreasing amplitude due to a reflection coefficient \\(r=0.95\\).\n\n\n\n\n\n\n\n\n\nMultiple wave interference with decreasing amplitude. The graph shows the intensity distribution over the phase angle \\(\\phi\\) for different values of the Finesse \\(\\mathcal{F}\\).\n\n\n\n\n\n\nThis yields again\n\\[\nU=\\sqrt{I_0}\\frac{(1-h^M)}{1-h}=\\frac{\\sqrt{I_0}}{1-r e^{i\\Delta\\phi}}\n\\]\nCalculating the intensity of the waves is giving\n\\[\nI=|U|^2=\\frac{I_{0}}{|1-re^{i\\Delta\\phi}|^2}=\\frac{I_0}{(1-r)^2+4r\\sin^2(\\Delta\\phi/2)}\n\\]\nwhich is also known as the Airy function. This function can be further simplified by the following abbrevations\n\\[\nI_{\\rm max}=\\frac{I_0}{(1-r)^2}\n\\]\nand\n\\[\n\\mathcal{F}=\\frac{\\pi \\sqrt{r}}{1-r}\n\\]\nwhere the latter is called the Finesse. With those abbrevations, we obtain\n\\[\nI=\\frac{I_{\\rm max}}{1+4\\left(\\frac{\\mathcal{F}}{\\pi}\\right)^2\\sin^{2}(\\Delta\\phi/2)}\n\\]\nfor the interference of multiple waves with decreasing amplitude.\nThis intensity distribution has a different shape than the one we obtained for multiple waves with the same amplitude.\nWe clearly observe that with increasing Finesse the intensity maxima, which occur at multiples fo \\(\\pi\\) get much narrower. In addition the regions between the maxima show better contrast and fopr higher Finesse we get complete destructive interference.",
    "crumbs": [
      "Wave Optics",
      "Lecture 9",
      "Multi Wave Interference"
    ]
  },
  {
    "objectID": "wave-optics/Diffraction Integral.html",
    "href": "wave-optics/Diffraction Integral.html",
    "title": "Diffraction Integral",
    "section": "",
    "text": "In the last section about Fresnel zones and the zone plate, we considered how different paths contribute to the intensity at a point on the optical axis. We would like to generalize this idea to an integral formulation that allows us to calculate any kind of diffraction pattern.\nAssume we have a light source \\(S\\) as shown in the image above, which emits a spherical wave (though it does not necessarily have to be a spherical wave). The spatial amplitude of this wave at the point \\(P(x,y)\\) at a tiny aperture element \\(d\\sigma\\) is given by:\n\\[\nU_s(x,y) = U_0(x,y)e^{i\\phi(x,y)}\n\\]\nwhere\n\\[\nU_0 = \\frac{A}{R} = \\frac{A}{\\sqrt{g^2 + x^2 + y^2}}\n\\]\nand\n\\[\n\\phi(x,y) = -kR\n\\]\nThis represents the amplitude of the Huygens wave, which emanates from the point \\(P(x,y)\\) and propagates towards the screen at \\(P(x',y')\\). This Huygens wave contributes a fraction of an amplitude \\(dU_p\\) to the total amplitude at point \\(P(x',y')\\), which is given by:\n\\[\ndU_p = C \\frac{U_s d\\sigma}{r} e^{-ikr}\n\\]\nwith \\(C = \\frac{i \\cos(\\theta)}{\\lambda}\\), known as the obliquity factor, found through a more detailed calculation.\nThe total amplitude at the point \\(P(x',y')\\) is then given by the integral over all contributions:\n\\[\nU_p = \\iint C U_s \\frac{e^{-ikr}}{r} dx dy\n\\]\nwhere \\(dx dy = d\\sigma\\). The integral runs over all positions in the aperture plane \\((x,y)\\) where there is an opening. This integral is called the Fresnel-Kirchhoff diffraction integral and allows us to calculate complex scalar diffraction patterns.\nThis formulation generalizes the concept of Fresnel zones and provides a powerful tool for analyzing and predicting diffraction patterns for various aperture shapes and configurations."
  },
  {
    "objectID": "wave-optics/Diffraction Integral.html#fresnel-approximation",
    "href": "wave-optics/Diffraction Integral.html#fresnel-approximation",
    "title": "Diffraction Integral",
    "section": "Fresnel Approximation",
    "text": "Fresnel Approximation\nThe diffraction integral does not always need to be calculated in full; we can use approximations to obtain diffraction patterns in different regimes. One such approximation is the Fresnel approximation, which yields the diffraction pattern in the near field.\nThe distance \\(r\\) from the point \\(P(x,y)\\) to the point \\(P(x',y')\\) can be written as:\n\\[\nr = \\sqrt{z_0^2 + (x - x')^2 + (y - y')^2}\n\\]\nUsing a binomial expansion for small angles, we can approximate this as:\n\\[\nr \\approx z_0 \\left(1 + \\frac{(x - x')^2}{2z_0^2} + \\frac{(y - y')^2}{2z_0^2} + \\ldots \\right)\n\\]\nIn this approximation, we assume that \\(\\cos(\\theta) = z_0 / r \\approx 1\\) and \\(C = i / \\lambda\\), considering small diffraction angles. Using this approximation, we find the amplitude of the wave at a point \\(P(x',y')\\):\n\\[\nU(x', y', z_0) = i \\frac{e^{-ikz_0}}{\\lambda z_0} \\iint U_s(x, y) \\exp \\left[ -\\frac{ik}{2z_0} \\left( (x - x')^2 + (y - y')^2 \\right) \\right] dx dy\n\\]\nAs the integration is over \\(x\\) and \\(y\\), we can factor out all screen coordinate elements, yielding:\n\\[\nU(x', y', z_0) = i \\frac{e^{-ikz_0}}{\\lambda z_0} e^{-\\frac{ik}{2z_0}(x'^2 + y'^2)} \\iint U_s(x, y) e^{-\\frac{ik}{2z_0}(x^2 + y^2)} e^{\\frac{ik}{2z_0}(xx' + yy')} dx dy\n\\]\nThis is the Fresnel approximation. It simplifies the calculation of the diffraction pattern in the near field by making reasonable assumptions about the geometry and angles involved."
  },
  {
    "objectID": "wave-optics/Diffraction Integral.html#fraunhofer-approximation",
    "href": "wave-optics/Diffraction Integral.html#fraunhofer-approximation",
    "title": "Diffraction Integral",
    "section": "Fraunhofer Approximation",
    "text": "Fraunhofer Approximation\nIf we further assume that the aperture is small as compared to the distance at which we observe the diffraction pattern, we can further simplify the Fresnel approximation to yield the Fraunhofer approximation giving the diffraction patter in the far field. The condition is\n\\[\nz_0\\gg\\frac{1}{\\lambda}(x^2+y^2)\n\\]\nIn this case we can neglect the term\n\\[\ne^{ -\\frac{ik}{2z_0}(x^2+y^2)} \\approx 1\n\\]\nwhich results in\n\\[\nU(x^{\\prime},y^{\\prime},z_0)=i\\frac{e^{-ikz_0}}{\\lambda z_0} e^{-\\frac{ik}{2z_0}(x^{\\prime 2}+y^{\\prime 2})}\n\\iint U_{s}(x,y)\ne^{\\frac{ik}{2z_0}(xx^{\\prime}+yy^{\\prime})} dx dy\n\\]\n\n\n\nDiffraction pattern of a slit in the near field (Fresnel diffraction, left) and the far field (Fraunhofer diffraction, right).\n\n\nWhile these formulas provide the mathematical tools, we may obtain a more intuitive idea about the different approximation in the following way. Consider the image below, where we would like to know about the diffraction intensity of a slit of width \\(b\\) at the optical axis at a distance \\(D\\).\n\n\n\nIllustration of the importance of additional geometrical path length difference for the discrimination of Fresnel (near-field) and Fraunhofer (far-field) diffraction.\n\n\nThe waves from the center of the slit and the edge have to travel towards that point a different pathlength, whcih we may calculate to\n\\[\\begin{eqnarray}\n\\Delta s &=&  \\sqrt{\\frac{b^2}{4}+D^2}-D\\\\\n&=& D\\sqrt{\\frac{b^2}{4D^2}+1}-D\n\\end{eqnarray}\\]\nWe may develop the square root into a Taylor series and obtain\n\\[\\begin{eqnarray}\n\\Delta s &=& \\frac{b^2}{8D}-\\frac{b^4}{128 D^3}+O(4)\\\\\n&\\approx & \\frac{b^2}{8D}\n\\end{eqnarray}\\]\nThe second order correction term \\(\\frac{b^2}{8D}\\) decreases quadratic with the distance \\(D\\) of the point, which means that at large distances, we can safely assume \\(\\Delta s=0\\) on the axis, i.e. all waves arriving at that point have to travel the same distance. This corresponds to the far-field approximation. To be more specific we require\n\\[\n\\frac{b^2}{8D^2}&lt;\\frac{\\lambda}{8}\n\\]\nor\n\\[\n\\frac{b^2}{\\lambda D}&lt;1\n\\]\nto be fullfilled to be in the far field.\n\\[\nF=\\frac{b^2}{\\lambda D}\n\\begin{cases}\n\\ll 1 ,&\\textrm{Fraunhofer}\\\\\n\\approx 1,& \\textrm{Fresnel}\\\\\n\\gg 1, & \\textrm{Full vector}\n\\end{cases}\n\\]\nThis number \\(F\\) is called the Frensel number and gives us an idea by how far the dimensions of the opening contribute to the diffraction pattern rather than the direction of the wave propagation only."
  },
  {
    "objectID": "wave-optics/Diffraction Integral.html#babinets-principle",
    "href": "wave-optics/Diffraction Integral.html#babinets-principle",
    "title": "Diffraction Integral",
    "section": "Babinet’s Principle",
    "text": "Babinet’s Principle\nThe above considerations of diffraction have some intruiging consequence. Consider the two apertures in the image below.\n\n\n\nTwo complementary apertures, which have the same diffraction pattern in the far field.\n\n\nThe left aperture will create in the far field an amplitude distribution \\(U_h\\), while the inverse aperture on the right will cause an amplitude \\(U_d\\). If we combine both amplitudes in the far field, we obtain a total amplitude distribution\n\\[\nU=U_h+U_d\n\\]\nIn the case when we have two complementary apertures, that total amplitude has to be zeor, when hole and dot are placed at the same position. We therefore obtain\n\\[\nU_h=-U_d\n\\]\nand therefore\n\\[\nI_h=I_d\n\\]\nThis is the Principle of Babinet which states:\n\n\n\n\n\n\nBabinet’s Principle\n\n\n\nBabinet’s principle states that the far-field diffraction intensity distribution of complementary apertures is identical. This means that an opaque object and its complementary aperture (where the object is replaced by a transparent region and vice versa) produce the same diffraction pattern in the far field.\n\n\nThe images below show an experimental demonstration of Babinet’s principle on a slit and a wire.\n\n\n\nBabinet’s principle demonstrated experimentally on a slit (left) and a wire (right)."
  },
  {
    "objectID": "wave-optics/PC.html",
    "href": "wave-optics/PC.html",
    "title": "Calculating Band Structure for 2D Photonic Crystals",
    "section": "",
    "text": "A 2D photonic crystal consists of a periodic arrangement of dielectric materials. For a square lattice with lattice constant a, the dielectric function \\epsilon(\\mathbf{r}) is periodic:\n\\epsilon(\\mathbf{r}) = \\epsilon(\\mathbf{r} + \\mathbf{R})\nwhere \\mathbf{R} = n_1\\mathbf{a}_1 + n_2\\mathbf{a}_2 is any lattice vector.\n\n\n\nFor 2D photonic crystals, Maxwell’s equations can be separated into TE and TM modes. For TM modes (E-field parallel to rods), we solve:\n\\nabla \\times \\frac{1}{\\epsilon(\\mathbf{r})} \\nabla \\times \\mathbf{E} = \\frac{\\omega^2}{c^2}\\mathbf{E}\n\n\n\nThe dielectric function can be expanded in reciprocal lattice vectors:\n\\epsilon(\\mathbf{r}) = \\sum_\\mathbf{G} \\epsilon_\\mathbf{G} e^{i\\mathbf{G}\\cdot\\mathbf{r}}\nFor circular rods of radius R in a square lattice:\n\\epsilon_\\mathbf{G} = \\epsilon_a + (\\epsilon_b - \\epsilon_a)f\\frac{2J_1(|\\mathbf{G}|R)}{|\\mathbf{G}|R}\nwhere: - \\epsilon_a is the background dielectric constant - \\epsilon_b is the rod dielectric constant - f is the filling fraction (\\pi R^2/a^2 for circular rods) - J_1 is the Bessel function of first kind\n\n\n\nThe electric field can be expanded using Bloch’s theorem:\n\\mathbf{E}(\\mathbf{r}) = e^{i\\mathbf{k}\\cdot\\mathbf{r}}\\sum_\\mathbf{G} \\mathbf{E}_\\mathbf{G} e^{i\\mathbf{G}\\cdot\\mathbf{r}}\n\n\n\nThis leads to the eigenvalue equation:\n\\sum_{\\mathbf{G}'} |\\mathbf{k} + \\mathbf{G}|^2 \\epsilon_{\\mathbf{G}-\\mathbf{G}'} E_{\\mathbf{G}'} = \\frac{\\omega^2}{c^2}E_\\mathbf{G}\n\n\n\nFor numerical calculations, we truncate the plane wave expansion to a finite number of G vectors. The matrix elements of the eigenvalue problem are:\nH_{\\mathbf{G}\\mathbf{G}'} = |\\mathbf{k} + \\mathbf{G}|^2\\delta_{\\mathbf{G}\\mathbf{G}'} + V_{\\mathbf{G}-\\mathbf{G}'}\nwhere:\nV_{\\mathbf{G}} = (\\epsilon_b - \\epsilon_a)f\\frac{2J_1(|\\mathbf{G}|R)}{|\\mathbf{G}|R}\n\n\n\nFor a square lattice, the high symmetry points in the first Brillouin zone are:\n\n\\Gamma: (0,0)\nX: (\\pi/a,0)\nM: (\\pi/a,\\pi/a)\n\n\n\n\nA complete photonic band gap exists when there is a frequency range where:\n\\max_{\\mathbf{k}}(\\omega_n(\\mathbf{k})) &lt; \\min_{\\mathbf{k}}(\\omega_{n+1}(\\mathbf{k}))\nfor some band index n."
  },
  {
    "objectID": "wave-optics/PC.html#theory-and-formulas",
    "href": "wave-optics/PC.html#theory-and-formulas",
    "title": "Calculating Band Structure for 2D Photonic Crystals",
    "section": "",
    "text": "A 2D photonic crystal consists of a periodic arrangement of dielectric materials. For a square lattice with lattice constant a, the dielectric function \\epsilon(\\mathbf{r}) is periodic:\n\\epsilon(\\mathbf{r}) = \\epsilon(\\mathbf{r} + \\mathbf{R})\nwhere \\mathbf{R} = n_1\\mathbf{a}_1 + n_2\\mathbf{a}_2 is any lattice vector.\n\n\n\nFor 2D photonic crystals, Maxwell’s equations can be separated into TE and TM modes. For TM modes (E-field parallel to rods), we solve:\n\\nabla \\times \\frac{1}{\\epsilon(\\mathbf{r})} \\nabla \\times \\mathbf{E} = \\frac{\\omega^2}{c^2}\\mathbf{E}\n\n\n\nThe dielectric function can be expanded in reciprocal lattice vectors:\n\\epsilon(\\mathbf{r}) = \\sum_\\mathbf{G} \\epsilon_\\mathbf{G} e^{i\\mathbf{G}\\cdot\\mathbf{r}}\nFor circular rods of radius R in a square lattice:\n\\epsilon_\\mathbf{G} = \\epsilon_a + (\\epsilon_b - \\epsilon_a)f\\frac{2J_1(|\\mathbf{G}|R)}{|\\mathbf{G}|R}\nwhere: - \\epsilon_a is the background dielectric constant - \\epsilon_b is the rod dielectric constant - f is the filling fraction (\\pi R^2/a^2 for circular rods) - J_1 is the Bessel function of first kind\n\n\n\nThe electric field can be expanded using Bloch’s theorem:\n\\mathbf{E}(\\mathbf{r}) = e^{i\\mathbf{k}\\cdot\\mathbf{r}}\\sum_\\mathbf{G} \\mathbf{E}_\\mathbf{G} e^{i\\mathbf{G}\\cdot\\mathbf{r}}\n\n\n\nThis leads to the eigenvalue equation:\n\\sum_{\\mathbf{G}'} |\\mathbf{k} + \\mathbf{G}|^2 \\epsilon_{\\mathbf{G}-\\mathbf{G}'} E_{\\mathbf{G}'} = \\frac{\\omega^2}{c^2}E_\\mathbf{G}\n\n\n\nFor numerical calculations, we truncate the plane wave expansion to a finite number of G vectors. The matrix elements of the eigenvalue problem are:\nH_{\\mathbf{G}\\mathbf{G}'} = |\\mathbf{k} + \\mathbf{G}|^2\\delta_{\\mathbf{G}\\mathbf{G}'} + V_{\\mathbf{G}-\\mathbf{G}'}\nwhere:\nV_{\\mathbf{G}} = (\\epsilon_b - \\epsilon_a)f\\frac{2J_1(|\\mathbf{G}|R)}{|\\mathbf{G}|R}\n\n\n\nFor a square lattice, the high symmetry points in the first Brillouin zone are:\n\n\\Gamma: (0,0)\nX: (\\pi/a,0)\nM: (\\pi/a,\\pi/a)\n\n\n\n\nA complete photonic band gap exists when there is a frequency range where:\n\\max_{\\mathbf{k}}(\\omega_n(\\mathbf{k})) &lt; \\min_{\\mathbf{k}}(\\omega_{n+1}(\\mathbf{k}))\nfor some band index n."
  },
  {
    "objectID": "wave-optics/PC.html#implementation-in-python",
    "href": "wave-optics/PC.html#implementation-in-python",
    "title": "Calculating Band Structure for 2D Photonic Crystals",
    "section": "Implementation in Python",
    "text": "Implementation in Python\nThe numerical implementation requires:\n\nConstructing the reciprocal lattice vectors:\n\nG = 2*np.pi/a * np.array([\n    [0, 0],\n    [1, 0], [-1, 0], [0, 1], [0, -1],\n    [1, 1], [-1, -1], [1, -1], [-1, 1]\n])\n\nBuilding the Hamiltonian matrix:\n\nH[i,j] = np.sum(k_plus_G_i**2) if i == j else \\\n         (epsilon - 1) * np.pi * radius**2 / a**2 * \\\n         np.exp(-np.sum(G_diff**2) * radius**2/4)\n\nSolving the eigenvalue problem:\n\neigenvalues = linalg.eigvalsh(H)"
  },
  {
    "objectID": "wave-optics/PC.html#required-parameters",
    "href": "wave-optics/PC.html#required-parameters",
    "title": "Calculating Band Structure for 2D Photonic Crystals",
    "section": "Required Parameters",
    "text": "Required Parameters\n\n\n\nParameter\nDescription\nTypical Values\n\n\n\n\na\nLattice constant\nUnit length\n\n\n\\epsilon_b\nRod dielectric constant\n8.9 (Al₂O₃)\n\n\n\\epsilon_a\nBackground dielectric constant\n1 (air)\n\n\nR\nRod radius\n0.2a - 0.4a\n\n\nN_G\nNumber of G vectors\n9-25"
  },
  {
    "objectID": "wave-optics/PC.html#numerical-considerations",
    "href": "wave-optics/PC.html#numerical-considerations",
    "title": "Calculating Band Structure for 2D Photonic Crystals",
    "section": "Numerical Considerations",
    "text": "Numerical Considerations\n\nConvergence: Check convergence with respect to:\n\nNumber of plane waves\nk-point sampling\nSize of computational domain\n\nSymmetry: Use symmetry to reduce computational cost:\n\nConsider only irreducible Brillouin zone\nApply appropriate boundary conditions\n\nBand Gap Accuracy: For accurate band gap calculations:\n\nUse dense k-point sampling near band edges\nInclude sufficient number of plane waves\nCheck convergence of gap size"
  },
  {
    "objectID": "wave-optics/PC.html#references",
    "href": "wave-optics/PC.html#references",
    "title": "Calculating Band Structure for 2D Photonic Crystals",
    "section": "References",
    "text": "References\n\nJoannopoulos, J. D., et al. “Photonic Crystals: Molding the Flow of Light”\nSakoda, K. “Optical Properties of Photonic Crystals”"
  },
  {
    "objectID": "course-info/intructors.html",
    "href": "course-info/intructors.html",
    "title": "Instructors",
    "section": "",
    "text": "Linnéstr. 5, 04103 Leipzig\nOffice: 322\nPhone: +49 341 97 32571\nEmail: lastname@physik.uni-leipzig.de",
    "crumbs": [
      "Course Info",
      "Instructor"
    ]
  },
  {
    "objectID": "course-info/intructors.html#prof.-dr.-frank-cichos",
    "href": "course-info/intructors.html#prof.-dr.-frank-cichos",
    "title": "Instructors",
    "section": "",
    "text": "Linnéstr. 5, 04103 Leipzig\nOffice: 322\nPhone: +49 341 97 32571\nEmail: lastname@physik.uni-leipzig.de",
    "crumbs": [
      "Course Info",
      "Instructor"
    ]
  },
  {
    "objectID": "course-info/intructors.html#axel-märcker",
    "href": "course-info/intructors.html#axel-märcker",
    "title": "Instructors",
    "section": "Axel Märcker",
    "text": "Axel Märcker\n\nVorlesungsexperimente\nLinnéstr. 5, 04103 Leipzig",
    "crumbs": [
      "Course Info",
      "Instructor"
    ]
  },
  {
    "objectID": "course-info/intructors.html#dr.-diptabrata-paul",
    "href": "course-info/intructors.html#dr.-diptabrata-paul",
    "title": "Instructors",
    "section": "Dr. Diptabrata Paul",
    "text": "Dr. Diptabrata Paul\n\nLinnéstr. 5, 04103 Leipzig\nOffice: 333a\nPhone: +49 341 97 32570\nEmail: firstname.lastname@physik.uni-leipzig.de",
    "crumbs": [
      "Course Info",
      "Instructor"
    ]
  },
  {
    "objectID": "course-info/intructors.html#dr.-markus-anton",
    "href": "course-info/intructors.html#dr.-markus-anton",
    "title": "Instructors",
    "section": "Dr. Markus Anton",
    "text": "Dr. Markus Anton\n\nLinnéstr. 5, 04103 Leipzig\nOffice: 333a\nPhone: +49 341 97 32570\nEmail: lastname@physik.uni-leipzig.de",
    "crumbs": [
      "Course Info",
      "Instructor"
    ]
  },
  {
    "objectID": "course-info/resources.html",
    "href": "course-info/resources.html",
    "title": "Resources",
    "section": "",
    "text": "This website makes use of the hypothes.is annotation service. You can use it to leave comments and feedback on the content of this website. To do so, you need to create a hypothes.is account. You can then highlight text on the website and leave comments. You can also reply to comments left by others and create your own nodes. We use this service for the first time, so please let us know if you like that. The annotation sidebar can be reached with the icons depicted in the figure above, wich are located at the right side of the screen. Here is the Link to the Hypothes.is group for this course.",
    "crumbs": [
      "Course Info",
      "Ressourcen"
    ]
  },
  {
    "objectID": "course-info/resources.html#comments-and-feedback",
    "href": "course-info/resources.html#comments-and-feedback",
    "title": "Resources",
    "section": "",
    "text": "This website makes use of the hypothes.is annotation service. You can use it to leave comments and feedback on the content of this website. To do so, you need to create a hypothes.is account. You can then highlight text on the website and leave comments. You can also reply to comments left by others and create your own nodes. We use this service for the first time, so please let us know if you like that. The annotation sidebar can be reached with the icons depicted in the figure above, wich are located at the right side of the screen. Here is the Link to the Hypothes.is group for this course.",
    "crumbs": [
      "Course Info",
      "Ressourcen"
    ]
  },
  {
    "objectID": "course-info/resources.html#books",
    "href": "course-info/resources.html#books",
    "title": "Resources",
    "section": "Books",
    "text": "Books\nThe course will be mainly built on a number of excellent books on electrodynamics and optics as well as on the basics of quantum mechanics.\n\nOptics and Electrodynamics\n\nDemtröder: Electrodynamics and Optics, Springer, 2019\nSaleh/Teich: Fundamentals of Photonics, Wiley, 2007\nJackson: Classical Electrodynamics, Wiley, 1998\nHecht: Optics, Pearson, 2016\n\n\n\nQuantum Mechanics\n\nDemtröder: Atoms, Molecules and Photons, Springer, 2010\nHaken, Wolf: The Physics of Atoms and Quanta: Introduction to Experiments and Theory, Springer, 2005\nHarnwel, Livingood: Experimental Atomic Physics, McGraw-Hill Book Company, Inc, 1933",
    "crumbs": [
      "Course Info",
      "Ressourcen"
    ]
  },
  {
    "objectID": "course-info/resources.html#molecular-nanophotonics-group",
    "href": "course-info/resources.html#molecular-nanophotonics-group",
    "title": "Resources",
    "section": "Molecular Nanophotonics Group",
    "text": "Molecular Nanophotonics Group\nBesides the books, you may also want to have a look at the following websites maintained by the group:\n\nMolecular Nanophotonics Group Website\nComputer-based Physical Modeling Website @ MONA",
    "crumbs": [
      "Course Info",
      "Ressourcen"
    ]
  },
  {
    "objectID": "quantum-mechanics/Black_Body_Radiation.html",
    "href": "quantum-mechanics/Black_Body_Radiation.html",
    "title": "Black Body Radiation",
    "section": "",
    "text": "Black body radiation represents one of the pivotal problems that led to the birth of quantum mechanics. While seemingly a purely thermodynamic phenomenon - the electromagnetic radiation emitted by an idealized perfect absorber in thermal equilibrium - its explanation required a radical departure from classical physics.\nIn the late 19th century, classical physics completely failed to explain the observed spectrum of black body radiation. The classical Rayleigh-Jeans law predicted that the intensity of radiation would increase indefinitely with frequency (the ‘ultraviolet catastrophe’), which clearly contradicted experimental measurements. This crisis in physics was resolved only when Max Planck introduced the revolutionary concept that electromagnetic energy could only be emitted in discrete quantities or ‘quanta’ - an idea that would become one of the fundamental principles of quantum mechanics.\nThe study of black body radiation thus marks the historical transition point from classical to quantum physics. Planck’s solution not only explained the observed radiation spectrum but introduced the quantum of action \\(h\\) (Planck’s constant), which would become central to all of quantum mechanics. This topic demonstrates how quantum effects emerge even in seemingly classical macroscopic systems when we examine them carefully enough.\nThe figure below displays the emission of a light bulb with a tungsten filament. The filament is heated up to a specific temperature by different currents.\nWithout dispersing the spectrum we directly notice the different color of the light emitted by the filament. While the heating mechanism is different for different materials, the emitted spectrum is always similar and solely depends on the temperature of the radiator. The emitted spectrum is called the blackbody spectrum and is universal for all materials.",
    "crumbs": [
      "Quantum Mechanics",
      "Lecture 20",
      "Black Body Radiation"
    ]
  },
  {
    "objectID": "quantum-mechanics/Black_Body_Radiation.html#blackbody",
    "href": "quantum-mechanics/Black_Body_Radiation.html#blackbody",
    "title": "Black Body Radiation",
    "section": "Blackbody",
    "text": "Blackbody\n\n\n\n\n\n\nNote\n\n\n\nA blackbody is a model of a radiation source whose emission depends only on its temperature. Its emission, however, does not depend on the material the radiator is made from, nor on its surface or any other potential characteristics.\n\n\nConsider a body with a cavity as depicted below. The body is heated to a certain temperature \\(T\\) and the cavity is closed.\n\n\n\nA body with a cavity. The body is heated to a certain temperature \\(T\\) and the cavity is closed.\n\n\nThe system is in thermal equilibriums and thus each quadratic degree of freedom carries an energy of \\(0.5 k_B T\\), where \\(k_B=1.21.380649 \\times 10^{-23} \\text{ J/K}\\) is the Boltzmann constant.\nEach surface element of the cavity emits radiation at a specific frequency \\(\\nu\\). The amount of power that is radiated by a surface element \\(\\mathrm{d} A\\) into a solid angle element \\(\\mathrm{d} \\Omega\\) at a frequency interval \\(\\mathrm{d} \\nu\\) relates to the property of its surface, i.e. the emissivity \\(E^{\\ast}_{\\nu}\\)\n\\[\n\\frac{\\mathrm{d} W_{E}}{\\mathrm{d} t} = E^{\\ast}_{\\nu} \\; \\mathrm{d} A \\; \\mathrm{d} \\Omega \\; \\mathrm{d} \\nu\n\\]\nThe emissivity is thereby a number between 0 and 1. In a simular way, each surface element at the cavity absorbs a certain power under a solid angle element and frequency intervall. The absorbed power is given by\n\\[\n\\frac{\\mathrm{d} W_{A}}{\\mathrm{d} t} = A_{\\nu} \\; S^{\\ast}_{\\nu} \\; \\mathrm{d} A \\; \\mathrm{d} \\Omega \\; \\mathrm{d} \\nu\n\\]\nwhere \\(S^{\\ast}_{\\nu}\\) is the spectral radiancy, so the radiated power per unit area, per unit solid angle and per unit frequency interval. The absorption capability \\(A_{\\nu}\\) is also a number between 0 and 1.\nIn the steady state, the body emits and absorbs the same amount of power and thus\n\\[\n\\frac{\\mathrm{d} W_{E}}{\\mathrm{d} t} = \\frac{\\mathrm{d} W_{A}}{\\mathrm{d} t}\n\\]\nwhich readily yields\n\\[\nE^{\\ast}_{\\nu} = A_{\\nu} \\; S^{\\ast}_{\\nu}\n\\]\nThe spectral randiancy times the frequency dependent absorptivity is equal to the spectral emission emissivity. This is known as Kirchhoff’s law of thermal radiation.\nFrom the Kirchhoff’s law we can see that a perfectly absorbing body \\(A_{\\nu}=1\\) is also a perfect emitter. This is the case for a blackbody, which absorbs all radiation incident on it and emits the maximum amount of radiation possible at a given temperature.\nNote that in the case of a blackbody, the absorptivity does not depend anymore on the frequency \\(\\nu\\), while it will for a real body. In the case of a blackbody, the spectral radiancy \\(S^{\\ast}_{\\nu}\\) is then only a function of the temperature \\(T\\) and needs to be calculated from teh cavity structure, i.e. the modes of the cavity, which we will calculate next.\n\n\n\n\n\n\nThe Leslie Cube Experiment\n\n\n\nThe Leslie Cube, developed by John Leslie in 1804, was one of the first experimental demonstrations of how surface properties affect thermal radiation. The apparatus consists of a cubic vessel with different surface treatments on each face (e.g., polished metal, blackened surface, rough surface), filled with hot water.\n\n\n\n\n\n\nFigure 2— Leslie Cube. The cube is filled with hot water, and each face has a different surface treatment. The radiation emitted from each face is measured using a thermopile detector. The experiment demonstrated that different surfaces emit radiation differently at the same temperature, and that good absorbers are also good emitters.\n\n\n\nBy measuring the radiation emitted from each face using a thermopile detector, Leslie showed that:\n\nDifferent surfaces emit radiation differently at the same temperature\nGood absorbers are also good emitters (leading to Kirchhoff’s law)\nThe emissivity depends on the surface properties but not on the material inside\n\nThis simple but elegant experiment helped establish fundamental principles of thermal radiation and provided early experimental evidence for what would later be formalized as Kirchhoff’s law of thermal radiation:\n\\[\\frac{E^{\\ast}_{\\nu}}{A_{\\nu}} = S^{\\ast}_{\\nu}\\]",
    "crumbs": [
      "Quantum Mechanics",
      "Lecture 20",
      "Black Body Radiation"
    ]
  },
  {
    "objectID": "quantum-mechanics/Black_Body_Radiation.html#spectral-density-of-modes",
    "href": "quantum-mechanics/Black_Body_Radiation.html#spectral-density-of-modes",
    "title": "Black Body Radiation",
    "section": "Spectral density of modes",
    "text": "Spectral density of modes\nTo determine the spectral energy density in the cavity \\(S^{\\ast}_{\\nu}\\), we need to calculate two quantities: the number of modes in the cavity and the average energy per mode. While calculating the number of modes is relatively straightforward, determining the average energy per mode is more complex and ultimately leads to Planck’s law of radiation.\nThe number of modes in the cavity corresponds to the number of possible standing waves that can exist in the cavity. Let’s first consider a simple one-dimensional case where the wave propagates along the z-direction, i.e. \\(k=k_z\\). When an electric field \\(\\vec{E} \\left( z, t \\right) = E_0 \\cos \\left( \\omega t - k_z z \\right) \\; \\vec{e_x}\\) is incident on a conducting surface at \\(z = 0\\), the tangential components of the electric field must vanish. This leads to:\n\\[\n\\vec{E} \\left( z = 0, t \\right) = E_{0,\\mathrm{I}} \\; \\vec{e_x} + E_{0,\\mathrm{R}} \\; \\vec{e_x} = 0\n\\]\nand\n\\[\nE_{0,\\mathrm{I}} \\; \\vec{e_x} = -E_{0,\\mathrm{R}} \\; \\vec{e_x}\n\\]\nThe superposition of incident and reflected waves results in a standing wave:\n\\[\n\\vec{E} \\left( z, t \\right) = 2 E_0 \\sin \\left( k_z z \\right) \\sin \\left( \\omega t \\right) \\; \\vec{e_x} \\mathrm{,}\n\\]\nwhere the wavevector \\(k_z\\) is given by \\(k_z = \\omega / c_0\\) with \\(c_0\\) being the speed of light in vacuum. For a second conducting surface at \\(z = a\\), the boundary condition requires:\n\\[\n\\vec{E} \\left( z = a, t \\right) = 2 E_0 \\sin \\left( k a \\right) \\sin \\left( \\omega t \\right) \\; \\vec{e_x} = 0\n\\]\nleading to:\n\\[\nk_z  = o \\frac{\\pi}{a}\n\\]\nThese represent the modes in a one-dimensional cavity. For a three-dimensional cavity, we can analyze each direction independently, obtaining the following conditions for the wavevector components:\n\\[\n\\begin{eqnarray}\nk_x & = & n \\frac{\\pi}{a}\\\\\nk_y & = & m \\frac{\\pi}{b}\\\\\nk_z & = & o \\frac{\\pi}{c}\n\\end{eqnarray}\n\\]\nwhere \\(m,n,o\\) are natural numbers. The magnitude of the wavevector is \\(\\left| \\vec{k} \\right| = \\sqrt{k_x^2 + k_y^2 + k_z^2}\\), which determines the possible frequencies \\(\\omega\\) in the cavity\n\\[\n\\omega = c \\cdot \\pi \\; \\sqrt{\\left(\\frac{o}{a}\\right)^2 + \\left(\\frac{m}{b}\\right)^2 + \\left(\\frac{n}{c}\\right)^2}\n\\]\n\n\n\n\n\n\nResonator modes\n\n\n\n\n\nThe standing waves which follow from these frequencies in our resonator are given by:\n\\[\n\\vec{E}_{m,n,o} = \\vec{E}_{0} \\left( m,n,o \\right) \\cdot \\cos \\left( \\omega t\\right)\n\\]\nwith \\(\\vec{E}_{0} \\left( m,n,o \\right) = \\left( E_{0,x},E_{0,y},E_{0,z} \\right)^{\\mathrm{T}}\\) and\n\\[\n\\begin{eqnarray}\nE_{0,x} & = & A \\cdot \\cos \\left( n \\frac{\\pi}{a} x \\right) \\sin \\left( m \\frac{\\pi}{b} y \\right) \\sin \\left( o \\frac{\\pi}{c} z \\right)\\\\\nE_{0,y} & = & B \\cdot \\sin \\left( n \\frac{\\pi}{a} x \\right) \\cos \\left( m \\frac{\\pi}{b} y \\right) \\sin \\left( o \\frac{\\pi}{c} z \\right)\\\\\nE_{0,z} & = & C \\cdot \\sin \\left( n \\frac{\\pi}{a} x \\right) \\sin \\left( m \\frac{\\pi}{b} y \\right) \\cos \\left( o \\frac{\\pi}{c} z \\right)\\\\\n\\end{eqnarray}\n\\]\nThis system, comprising a box with ideally conducting walls, is known as a cavity resonator, and the possible standing waves are called the resonator’s principle oscillations or resonator modes.\n\n\n\nAs mentioned before, we are interested in the number of modes that fit into the cavity. For that purpose we need to count the number of modes within a certain frequency range. In order to simplify the calculation a bit, we restrict out box to a cube with edge length \\(a\\) such that\n\\[\n\\begin{eqnarray}\n\\omega & = & c \\cdot \\frac{\\pi}{a} \\; \\sqrt{ n^2 + m^2 + o^2}\\\\\n\\rightarrow n^2 + m^2 + o^2 & = & \\left( \\frac{a \\omega}{\\pi c}\\right)^2\\\\\n\\rightarrow n^2 + m^2 + o^2 & = & \\left( \\frac{a}{\\pi}\\right)^2 \\cdot k^2\\\\\n\\end{eqnarray}\n\\]\nWe can visualize the possible modes in k-space (where \\(k_x\\), \\(k_y\\), and \\(k_z\\) are our axes). The points \\((m,n,o)\\) create an evenly-spaced grid with spacing \\(\\pi/a\\) between points. Since each combination of \\((m,n,o)\\) represents one mode in the resonator, counting the grid points, or better the number of unit cell cubes with a length \\(\\pi/a\\) tells us the number of possible modes.\n\n\n\n\n\n\nFigure 3— Two-dimensional k-space with a circle representing a sphere in two-dimensional space.\n\n\n\nWhen considering large values where \\(\\sqrt{m^2 +n^2 +o^2} \\gg 1\\), the sphere radius in k-space \\(\\left| \\vec{k} \\right|\\) becomes much larger than \\(\\pi / a\\), corresponding to wavelengths \\(\\lambda\\) much smaller than the cavity size \\(a\\). In this limit, we can approximate the number of allowed modes \\(N_{\\mathrm{L}}\\) (where \\(m,n,o &gt; 0\\)) by calculating the volume occupied by unit cells within the first octant of a sphere with radius \\(\\left| \\vec{k} \\right|\\). The volume of this octant is:\n\\[\n\\begin{eqnarray}\nV_{\\mathrm{S}} & = & \\frac{1}{8} \\; \\frac{4}{3} \\pi \\left| \\vec{k} \\right|^3 \\mathrm{ or }\\\\\nV_{\\mathrm{S}} & = & \\frac{1}{6} \\pi \\left( \\frac{\\omega}{c_0} \\right)^3 \\mathrm{.}\n\\end{eqnarray}\n\\]\nThe number modes corresponds then to the volume of the octant to the volume of a unit cell (\\(V_{\\mathrm{UC}} = \\left( \\pi / a \\right)^3\\)) which is\n\\[\nN_{\\mathrm{L}} = \\frac{V_{\\mathrm{S}}}{V_{\\mathrm{UC}}} = \\frac{\\pi}{6} \\left( \\frac{a \\cdot \\omega}{\\pi \\cdot c_0} \\right)^3 \\mathrm{.}\n\\]\nSince each standing wave can have two independent polarization states, the total number of modes below frequency \\(\\omega_{\\mathrm{S}}\\) is twice the previous result and we find the total number of modes up to a limiting frequency \\(\\omega_{\\mathrm{S}}\\)\n\\[\nN \\left( \\omega \\le \\omega_{\\mathrm{S}} \\right) = 2 \\cdot \\frac{\\pi}{6} \\left( \\frac{a \\cdot \\omega_{\\mathrm{S}}}{\\pi \\cdot c_0} \\right)^3 = \\frac{8 \\pi \\nu_{\\mathrm{S}} a^3}{3 c_0^3} \\mathrm{.}\n\\]\nHere we made use of \\(\\omega_{\\mathrm{S}} = 2 \\pi v_{\\mathrm{S}}\\). The number of modes in per volume of the cavity \\(a^3\\) is thus given by\n\\[\n\\frac{N \\left( \\nu \\le \\nu_{\\mathrm{S}} \\right) }{a^3} = n = \\frac{8 \\pi \\nu_{\\mathrm{S}}^3}{3 c_0^3} \\mathrm{.}\n\\]\nWhen we now increase the limiting frequency \\(\\nu_{\\mathrm{S}}\\), the number of modes increases. This increase is best represented by the spectral density of modes, that is the number of allowed modes per unit volume of the resonator within the interval \\(\\left[ \\nu ; \\nu + \\Delta \\nu \\right]\\). A straightforward calculation of the first derivative of the density of modes with respect to the frequency \\(\\mathrm{d}n/\\mathrm{d}\\nu\\) gives us an expression for the spectral mode density\n\\[\n\\frac{\\mathrm{d} n }{\\mathrm{d} \\nu} = \\frac{8 \\pi \\nu^2}{c_0^3}\n\\]\nSo far we have calculated that only under particular conditions standing waves can be established within a cubic cavity. These eigen-oscillations are called “modes of the cavity”. Furthermore, if the wavelength is small compared to the cavity dimensions, we derived the spectral density of modes, that is the number of modes within one cubic meter of volume within the interval between \\(\\nu\\) and \\(\\nu + \\mathrm{d}\\nu\\) is\n\\[\nn \\left( \\nu \\right) \\; \\mathrm{d}\\nu = \\frac{8 \\pi \\nu^2}{c_0^3} \\mathrm{d}\\nu \\mathrm{.}\n\\]\nThis is the spectral density of optical modes per volume.\n\n\n\n\n\n\nDensity of optical modes per unit volume\n\n\n\nThis equation represents the density of optical modes per unit volume and frequency interval in free space. It has important consequences for lasing:\n\nThe density of modes increases quadratically with frequency (\\(\\nu^2\\))\nThis means there are more available modes at higher frequencies\nFor lasers, this affects:\n\nThe threshold conditions for lasing\nThe emission probability at different frequencies\nThe competition between modes\n\n\nIn practical terms, it helps explain why it’s generally easier to achieve lasing at shorter wavelengths (higher frequencies) where there are more available modes, although other factors like gain and losses also play crucial roles.\n\n\nThis spectral mode density is now the basis for any further consideration. To obtain the spectral energy density we just need to multiply the mode density with the energy stored in each mode \\(\\bar{W}_{\\nu} \\left( T \\right)\\) and obtain the spectral energy density\n\\[\n\\omega_{\\nu} \\; \\mathrm{d} \\nu = n \\left( \\nu \\right) \\cdot \\bar{W}_{\\nu} \\left( T \\right) \\cdot \\mathrm{d}\\nu = \\frac{8 \\pi \\nu^2}{c_0^3} \\cdot \\bar{W}_{\\nu} \\left( T \\right) \\cdot \\mathrm{d}\\nu\n\\]\nThis spectral energy density \\(\\omega_{\\nu}\\) relates to the spectral radiancy \\(S^*_{\\nu}\\) through:\n\\[\nS^*_{\\nu} = \\frac{c_0}{4\\pi} \\omega_{\\nu}\n\\]",
    "crumbs": [
      "Quantum Mechanics",
      "Lecture 20",
      "Black Body Radiation"
    ]
  },
  {
    "objectID": "quantum-mechanics/Black_Body_Radiation.html#rayleighjeans-law",
    "href": "quantum-mechanics/Black_Body_Radiation.html#rayleighjeans-law",
    "title": "Black Body Radiation",
    "section": "Rayleigh–Jeans law",
    "text": "Rayleigh–Jeans law\nOne way to obtain a mean energy per mode is to consider classical thermal equilbrium and equipartition. In this case, each quadratic degree of freedom contains \\(0.5 k_B T\\) energy such that\n\\[\n\\bar{W_{\\nu}} \\left( T \\right) = k_B \\cdot T \\mathrm{,}\n\\]\nwith \\(k_B\\) and \\(T\\) being the Boltzmann constant and absolute temperature, respectively. Therefore, within the limit of the classical approach the spectral energy density,\n\\[\n\\omega_{\\nu} \\; \\mathrm{d} \\nu = \\frac{8 \\pi \\nu^2}{c_0^3} \\; k \\; T \\; \\mathrm{d}\\nu \\mathrm{,}\n\\]\nrises quadratically with respect to the frequency \\(\\nu\\). This quadratic relation is known as Rayleigh-Jeans law. As a consequence a small hole in the cavity wall will then emit radiation into the solid angle of \\(\\mathrm{d} \\Omega = 1 \\mbox{ sr}\\) with the radiance of\n\\[\n\\begin{eqnarray}\nS^{\\ast}_{\\nu} \\left( \\nu \\right) \\mathrm{d} \\nu & = & \\frac{c_0}{4 \\pi} \\; \\omega_{\\nu} \\left( \\nu \\right) \\; \\mathrm{d} \\nu\\\\\n{} & = & \\frac{2 \\nu^2}{c_0^2} \\; k \\; T \\; \\mathrm{d} \\nu\n\\end{eqnarray}\n\\]\nIf we now consider a temperature of about \\(5000 \\; \\mathrm{K}\\) we achieve a wavelength bigger than \\(2 \\; \\mu\\mathrm{m}\\), being well in the infrared region. For this spectral region the measured radiance and the theoretical prediction are in agreement. However, if we reduce the wavelength, disparities between experimental findings and the prediction appear. Moreover, if the Rayleigh-Jeans law was valid, there would be the so-called ultraviolet catastrophe! In the case of decreasing frequencies, the spectral energy density and the integrated radiance will rise until they become infinitely big for vanishing frequencies.\n\n\nCode\n# Constants\nh = 6.62607015e-34  # Planck constant (J⋅s)\nc = 2.99792458e8    # Speed of light (m/s)\nk = 1.380649e-23    # Boltzmann constant (J/K)\n\n# Wavelength range (in meters)\nwavelength = np.linspace(0.1e-6, 8e-6, 1000)\n\n# Define Planck's law\ndef planck(wavelength, T):\n    return (2*h*c**2)/(wavelength**5) * 1/(np.exp((h*c)/(wavelength*k*T)) - 1)\n\n# Define Rayleigh-Jeans law\ndef rayleigh_jeans(wavelength, T):\n    return (2*c*k*T)/(wavelength**4)\n\n# Temperatures\ntemperatures = [1200, 1600, 2000, 2400, 2800]\ncolors = ['blue', 'green', 'red', 'purple', 'orange']\n\nplt.figure(figsize=get_size(12, 8))\n\n# Plot both laws for each temperature\nfor T, color in zip(temperatures, colors):\n    plt.plot(wavelength*1e6, planck(wavelength, T)*1e-12,\n             label=f'Planck {T}K', color=color)\n    plt.plot(wavelength*1e6, rayleigh_jeans(wavelength, T)*1e-12,\n             '--', label=f'Rayleigh-Jeans {T}K', color=color)\n\nplt.xlabel('Wavelength [μm]')\nplt.ylabel(r'S [$× 10^{13} W⋅sr^{-1}⋅m^{-3}$]')\nplt.legend()\nplt.ylim(0,1)\nplt.show()\n\n\n\n\n\nComparison between blackbody radiation (solid lines) and radiation as described through the Rayleigh-Jeans law (dashed lines) at different temperatures.",
    "crumbs": [
      "Quantum Mechanics",
      "Lecture 20",
      "Black Body Radiation"
    ]
  },
  {
    "objectID": "quantum-mechanics/Black_Body_Radiation.html#plancks-law",
    "href": "quantum-mechanics/Black_Body_Radiation.html#plancks-law",
    "title": "Black Body Radiation",
    "section": "Planck’s law",
    "text": "Planck’s law\nIn 1900 Max Planck tackled the problem of how to avoid the ultraviolet catastrophe and describe the blackbody radiation as a whole. He assumed that the energy of the absorbing and emitting oscillators in the wall can release or absorb small packets of energy given by \\(h \\cdot \\nu\\), where \\(h\\) was used as a helper constant. Taking the limit \\(h\\rightarrow 0\\) should then lead to the classical result, yet Planck found that the classical limit was not reached. Rather, the quantization of energy with $h=6.626 ^{-34} ; led to a new law of radiation, which was in perfect agreement with the experimental findings. The energy at a particular frequency \\(\\nu\\) is then quantized in terms of the number of energy packets \\(n\\) as\n\\[\nW_{\\nu} = n \\cdot h \\cdot \\nu\n\\]\nwhere \\(n\\) is a natural number. If we now consider thermal equilibrium, the probability \\(p \\left( W_{\\nu} \\right)\\) of finding an oscillator with energy \\(W_{\\nu} = n h \\nu\\) (meaning the eigenstate is occupied by \\(n\\) photons) is given by the Boltzmann distribution:\n\\[\np \\left( W_{\\nu} \\right) = \\frac{\n\\mathrm{e}^{- \\frac{n \\cdot h \\cdot \\nu}{k \\cdot T}}\n}{\n\\sum_{n=0}^{\\infty} \\mathrm{e}^{- \\frac{n \\cdot h \\cdot \\nu}{k \\cdot T}}\n}\n\\]\nNote that a Boltzmann distribution provides the maximum entropy for a given energy, i.e. it spreads the energy as evenly as possible over the available states (modes) of the systems. The average energy per oscillator can then be calculated as the expectation value of energy, weighting each possible energy level by its probability of occupation. The averaged energy per oscillator then reads as \\(\\bar{W}_{\\nu} = \\sum_{n=0}^{\\infty} p\\left( nh\\nu \\right) n \\, h\\, \\nu\\) and further\n\\[\n\\bar{W}_{\\nu} = \\frac{n \\cdot \\nu}{\\mathrm{e}^{+\\frac{n \\cdot h \\cdot \\nu}{k \\cdot T}} -1} \\mathrm{.}\n\\]\nThe spectral energy density in the cavity is thus given by\n\\[\n\\omega \\left( \\nu,T \\right) = n\\left(\\nu \\right) \\cdot \\bar{W_{\\nu}} \\left( \\nu,T \\right)\n\\]\nwhich leads us to the famous Planck’s formula\n\\[\n\\omega \\left( \\nu,T \\right) \\mathrm{d} \\nu = \\frac{8 \\pi h \\nu^3}{c_0^3} \\, \\frac{\\mathrm{d} \\nu}{\\mathrm{e}^{\\frac{h \\nu}{k T}} -1} \\mathrm{.}\n\\]\nHere \\(\\omega \\left( \\nu,T \\right) \\mathrm{d}\\nu\\) represents the spectral distribution of the energy density per frequency interval; its unit is \\(\\left[ \\omega \\left( \\nu,T \\right) \\right] = \\mbox{Jsm}^3\\). The radiance of the area element \\(\\mathrm{d}A\\) emitted into the solid angle \\(\\mathrm{d} \\Omega\\) then is\n\\[\n\\begin{eqnarray}\nS^{\\ast}_{\\nu} \\mathrm{d} \\nu \\mathrm{d} \\Omega & = & \\frac{c_0}{4\\pi} \\omega_{\\nu} \\left(\\nu,T\\right) \\, \\mathrm{d} \\nu \\, \\mathrm{d} \\Omega\\\\\n{} & = & \\frac{2 h \\nu^3}{c_0^2} \\, \\frac{\\mathrm{d} \\nu \\, \\mathrm{d} \\Omega}{\\mathrm{e}^{\\frac{h \\nu}{k T}} -1} \\mathrm{.}\n\\end{eqnarray}\n\\]\nPlanck’s theory posited that oscillator energy exists in discrete units or packets denoted by \\(n\\), following the relation \\(W_{\\nu} = n \\cdot h \\cdot \\nu\\). This concept was later expanded by Einstein in his explanation of the photoelectric effect, demonstrating that light itself consists of discrete energy quanta proportional to frequency \\(\\nu\\). Einstein’s interpretation, expressing the energy of the electromagnetic field as \\(E = h \\nu\\), established the foundation for understanding light as discrete particles called photons.\nWhile we’ve previously written Planck’s law in terms of frequency \\(\\nu\\), we can alternatively express it using wavelength \\(\\lambda\\) through the relationship \\(\\lambda = c/\\nu\\). Making this conversion requires noting that \\(\\mathrm{d}\\lambda = -\\left( c / \\nu^2 \\right) \\mathrm{d} \\nu\\). This allows us to express the spectral energy density\n\\[\n\\omega \\left( \\lambda,T \\right) \\mathrm{d} \\lambda = \\frac{8 \\pi h c_0}{\\lambda^5} \\, \\frac{\\mathrm{d} \\lambda}{\\mathrm{e}^{\\frac{h c_0}{\\lambda k T}} -1}\n\\]\nand the radiance\n\\[\nS^{\\ast}_{\\lambda} \\mathrm{d} \\lambda \\mathrm{d} \\Omega = \\frac{2 h c^2}{\\lambda^5} \\, \\frac{\\mathrm{d} \\lambda \\, \\mathrm{d} \\Omega}{\\mathrm{e}^{\\frac{h c}{\\lambda k T}} -1}\n\\]\nin terms of wavelength \\(\\lambda\\) and temperature \\(T\\).\n\n\nCode\n# Constants\nh = 6.626e-34  # Planck's constant (J⋅s)\nc = 2.998e8    # Speed of light (m/s)\nk = 1.381e-23  # Boltzmann constant (J/K)\n\n# Wavelength range (0.1 to 8.0 micrometers, converted to meters)\nwavelengths = np.linspace(0.1e-6, 5.0e-6, 1000)\n\n# Temperature ranges\ntemperatures_1 = np.arange(800, 2801, 200)\ntemperatures_2 = np.arange(3000, 7001, 500)\n\n# Planck function\ndef planck(wav, T):\n    a = 2.0 * h * c**2\n    b = h * c / (wav * k * T)\n    return a / ((wav**5) * (np.exp(b) - 1.0))\n\n# Create the plots\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=get_size(12, 8))\n\n# First subplot (800-2800 K)\nfor T in temperatures_1:\n    spectral_radiance = planck(wavelengths, T)\n    ax1.plot(wavelengths*1e6, spectral_radiance*1e-12, label=f'{T} K')\n\nax1.set_xlabel('wavelength [μm]')\nax1.set_ylabel(r'S [W⋅sr$^{-1}$⋅m$^{-3}$] ×10$^{12}$')\nax1.legend()\nax1.set_ylim(0, 0.8)\n\n# Second subplot (3000-7000 K)\nfor T in temperatures_2:\n    spectral_radiance = planck(wavelengths, T)\n    ax2.plot(wavelengths*1e6, spectral_radiance*1e-12, label=f'{T} K')\n\nax2.set_xlabel('wavelength [μm]')\nax2.set_ylabel(r'S [W⋅sr$^{-1}$⋅m$^{-3}$] ×10$^{12}$')\nax2.legend()\nax2.set_ylim(0, 80)  # Adjusted y-axis limit for higher temperatures\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\nPlanck’s law of blackbody radiation at different temperatures.\n\n\n\n\nThe sun is a blackbody radiator with a temperature of about \\(5778 \\; \\mathrm{K}\\). The spectral radiance of the sun is given by Planck’s law.\n\n\n\n\n\n\nFigure 4— The sun spectrum at the earth as compared to Planck’s law. Due to the presence of absorption lines of water and other components in the atmosphere, the spectrum is not a perfect blackbody spectrum.\n\n\n\nSince the spectrum is completly defined by the temperature of the blackbody, it is possible to estimate the temperature of the sun or other stars by comparing the spectrum of the sun with Planck’s law.\n\nProperties of Planck’s Radiation Formula\n\n\n\n\n\n\nPlanck’s Radiation Law\n\n\n\nThe fundamental equation describing the spectral radiance of a black body: \\[S(\\lambda,T) = \\frac{2hc^2}{\\lambda^5} \\frac{1}{e^{\\frac{hc}{\\lambda kT}} - 1}\\]\nwhere:\n\n\\(S(\\lambda,T)\\) is the spectral radiance \\([\\mathrm{W}\\cdot\\mathrm{sr}^{-1}\\cdot\\mathrm{m}^{-3}]\\)\n\\(h\\) is Planck’s constant \\([\\mathrm{J}\\cdot\\mathrm{s}]\\)\n\\(c\\) is the speed of light \\([\\mathrm{m}/\\mathrm{s}]\\)\n\\(k\\) is the Boltzmann constant \\([\\mathrm{J}/\\mathrm{K}]\\)\n\\(T\\) is absolute temperature \\([\\mathrm{K}]\\)\n\\(\\lambda\\) is wavelength \\([\\mathrm{m}]\\)\n\nNote that Plancks radiation law is only valid for propagating electromagnet modes. Evanscence modes are not included in this formula and do not follow Plancks radiation law. (see e.g. Observing of the super-Planckian near-field thermal radiation between graphene sheets)\n::: {#fig-super planck-radiation fig-align=“center”} \nA schematic of the home-made measurement setup. From top to bottom, the emitter side consists of S-magnet, heater, copper spreader, and Si/Gr and the receiver side consisting of Gr/Si, copper spreader, TEC layer, copper spreader, and H-magnet. Four photoresist posts are used to separate the emitter and the receiver. from Observing of the super-Planckian near-field thermal radiation between graphene sheets\n\n\nThis opens a number of possibilities which are used for solar energy collection beyond the Shockley limit, for example in thermophotovaltaic cells, which convert the spectrals absorbance into heat radiation, that is shaped spectrally by metametarials to match the bandgap of the solar cell. :::\n\n\n\n\n\n\nStefan-Boltzmann Law\n\n\n\nThe total power radiated per unit area across all wavelengths: \\[E = \\sigma T^4\\]\nThis can be derived by integrating Planck’s law over all wavelengths: \\[E = \\int_0^\\infty S(\\lambda,T) d\\lambda = \\sigma T^4\\]\nwhere \\(\\sigma = \\frac{2\\pi^5k^4}{15c^2h^3} \\approx 5.67 \\times 10^{-8}\\) W⋅m⁻²⋅K⁻⁴\n\n\n\n\n\n\n\n\nSolar Power at Earth’s Distance: A Stefan-Boltzmann Law Calculation\n\n\n\n\n\nWe can calculate the solar power arriving at Earth using the Stefan-Boltzmann law and basic geometric principles. The Stefan-Boltzmann law states that the total power emitted per unit area by a black body is given by:\n\\[E = \\sigma T^4\\]\nwhere \\(\\sigma = 5.67 \\times 10^{-8}\\) W⋅m⁻²⋅K⁻⁴ is the Stefan-Boltzmann constant and T is the temperature in Kelvin.\nFor our calculation, we need:\n\nTemperature of Sun’s surface: \\(T_{sun} \\approx 5778\\) K\nRadius of Sun: \\(R_{sun} \\approx 6.957 \\times 10^8\\) m\nDistance Earth-Sun: \\(d \\approx 1.496 \\times 10^{11}\\) m (1 AU)\n\nFirst, we calculate the power emitted per square meter at the Sun’s surface:\n\\[E_{sun} = 5.67 \\times 10^{-8} \\cdot (5778)^4 = 6.32 \\times 10^7 \\text{ W/m²}\\]\nThe total power output of the Sun is this value multiplied by its surface area:\n\\[P_{total} = E_{sun} \\cdot 4\\pi R_{sun}^2 = 6.32 \\times 10^7 \\cdot 4\\pi (6.957 \\times 10^8)^2 = 3.828 \\times 10^{26} \\text{ W}\\]\nTo find the power per square meter reaching Earth, we use the inverse square law. The total power is distributed over a sphere with radius equal to the Earth-Sun distance:\n\\[E_{earth} = \\frac{P_{total}}{4\\pi d^2} = \\frac{3.828 \\times 10^{26}}{4\\pi (1.496 \\times 10^{11})^2} = 1361 \\text{ W/m²}\\]\nThis value of 1361 W/m² is known as the solar constant or total solar irradiance (TSI) at the top of Earth’s atmosphere. It represents the power from the Sun reaching Earth before any atmospheric absorption. This calculated value matches well with measured values from satellites.\n\n\n\n\n\n\n\n\n\nWien’s Displacement Law\n\n\n\nThe wavelength of maximum emission: \\[\\lambda_{max} = \\frac{b}{T}\\]\nThis is derived by finding the maximum of Planck’s law: \\[\\frac{d}{d\\lambda}S(\\lambda,T) = 0\\]\nwhere \\(b = \\frac{hc}{4.965k} \\approx 2898\\) μm⋅K\n\nRayleigh-Jeans Approximation\nThe classical limit of Planck’s law for long wavelengths: \\[S(\\lambda,T) \\approx \\frac{2ckT}{\\lambda^4}\\]\nThis approximation is valid when \\(\\frac{hc}{\\lambda kT} \\ll 1\\), and historically led to the “ultraviolet catastrophe” that Planck’s law resolved.",
    "crumbs": [
      "Quantum Mechanics",
      "Lecture 20",
      "Black Body Radiation"
    ]
  },
  {
    "objectID": "quantum-mechanics/Particle_Nature_of_Light.html",
    "href": "quantum-mechanics/Particle_Nature_of_Light.html",
    "title": "Particle Nature of Light",
    "section": "",
    "text": "The nature of light has been a subject of scientific debate since the 17th century. Newton proposed a particle theory based on light’s straight propagation and refraction, while Huygens advocated a wave theory supported by interference and diffraction phenomena. The wave interpretation gained strong support when Heinrich Hertz discovered electromagnetic waves, with light being interpreted as a special spectral region governed by Maxwell’s equations.\nHowever, at the beginning of the 20th century, several experimental findings emerged that could not be explained by classical electromagnetic theory:\n\nThe photoelectric effect, where light ejects electrons from metals\nThe Compton effect, showing light scattering like particles\nThe ultraviolet catastrophe in black body radiation\n\nThese observations revealed fundamental limitations in both classical mechanics and electromagnetic wave theory for describing atomic-scale phenomena. This document examines the experimental evidence that established light’s particle nature while maintaining its wave characteristics.",
    "crumbs": [
      "Quantum Mechanics",
      "Lecture 19",
      "Particle Nature of Light"
    ]
  },
  {
    "objectID": "quantum-mechanics/Particle_Nature_of_Light.html#the-wave-particle-nature-of-light",
    "href": "quantum-mechanics/Particle_Nature_of_Light.html#the-wave-particle-nature-of-light",
    "title": "Particle Nature of Light",
    "section": "",
    "text": "The nature of light has been a subject of scientific debate since the 17th century. Newton proposed a particle theory based on light’s straight propagation and refraction, while Huygens advocated a wave theory supported by interference and diffraction phenomena. The wave interpretation gained strong support when Heinrich Hertz discovered electromagnetic waves, with light being interpreted as a special spectral region governed by Maxwell’s equations.\nHowever, at the beginning of the 20th century, several experimental findings emerged that could not be explained by classical electromagnetic theory:\n\nThe photoelectric effect, where light ejects electrons from metals\nThe Compton effect, showing light scattering like particles\nThe ultraviolet catastrophe in black body radiation\n\nThese observations revealed fundamental limitations in both classical mechanics and electromagnetic wave theory for describing atomic-scale phenomena. This document examines the experimental evidence that established light’s particle nature while maintaining its wave characteristics.",
    "crumbs": [
      "Quantum Mechanics",
      "Lecture 19",
      "Particle Nature of Light"
    ]
  },
  {
    "objectID": "quantum-mechanics/Particle_Nature_of_Light.html#the-photoelectric-effect",
    "href": "quantum-mechanics/Particle_Nature_of_Light.html#the-photoelectric-effect",
    "title": "Particle Nature of Light",
    "section": "The Photoelectric Effect",
    "text": "The Photoelectric Effect\n\nHallwachs and Lennard’s Discoveries\nIn 1888, Wilhelm Hallwachs discovered that ultraviolet light could cause negatively charged metal plates to lose their charge. Using charged foils connected to an irradiated metal plate, he observed that: - Negative charges decreased upon UV irradiation - Positive charges remained unchanged\nThis suggested that light was somehow causing electrons to leave the metal surface. ### Hallwachs and Lennard\nIn 1888 Wilhelm Hallwachs published an experiment with charged foils connected to a metal plate which was irradiated with ultraviolet light (we did this experiment in the last lecture before Christmas). If the foils and the plate are negatively charged and electrically isolated against the surrounding, the charge does decrease upon irradiation with ultraviolet light. In contrast, if the system is positively charged, the charge does not decrease. Hallwachs concluded that the light is responsible for negative charges leaving the metal plate.\n\n\n\nScheme of the apparatus used by Hallwachs (left). Scheme of the apparatus used by Lennard and the corresponding photocurrent \\(I_{\\mathrm{ph}}\\) (center). From the onset voltage \\(U_0\\) one can calculate the work function \\(W_{\\mathrm{a}}\\) as intercept and Planck’s constant \\(h\\) as part of the slope (right).\n\n\nLater in 1902 Lennard measured the photocurrent between two plates in vacuum. The current set in already at a negative voltage \\(U_0\\) between the plates, increased with rising voltage, and reached a plateau which depended only on the light’s intensity. He concluded:\n\nThe electrons must bear a minimum energy in order to overcome the oppositely directed electric field, \\(E_{\\mathrm{kin}} \\le e \\cdot U_0\\).\nThe kinetic energy \\(m v^2/2\\) of the photoelectrons depends on the frequency \\(\\nu\\) of the light, not on the light’s intensity.\nThe number of photoelectrons is proportional to the light’s intensity.\nThere is no delay between light irradiation and electron emission.\n\n\n\nClassical Wave Theory Expectations\nIf we assume a fully wave-like behavior of light, then light with a radiation power of \\(P_{\\mathrm{L}}\\) might hit a surface with an area \\(A\\) and shares its energy equally between all electrons. For a penetration depth of \\(\\Delta z \\approx \\lambda\\) and a density of the conducting electrons of \\(N\\), then every conducting electron gets on average the energy of\n\\[\n\\bar{\\Delta W} = \\frac{P_\\mathrm{L}}{N \\cdot A \\cdot \\lambda} \\; \\Delta t\n\\] within the time interval \\(\\Delta t\\). Thus, the work function can be compensated in the case of\n\\[\n\\Delta t &gt; W_{\\mathrm{a}} \\; \\frac{N \\cdot A \\cdot \\lambda}{P_\\mathrm{L}} \\mathrm{.}\n\\]\nLet us consider a zinc plate with a work function of \\(W_{\\mathrm{a}} = 4 \\, \\mathrm{eV}\\) and a light source with a spectral filter \\(\\lambda = 250 \\; \\mathrm{nm}\\) emitting a power of \\(P_\\mathrm{L} = 1 \\; \\mathrm{W}\\) at a distance of \\(R = 1 \\; \\mathrm{m}\\) away from our zinc plate, there will be an intensity of\n\\[\nI_{\\mathrm{L}} = \\frac{P_\\mathrm{L}}{4\\pi R^2} \\approx 8\\cdot 10^{-6} \\; \\frac{\\mathrm{W}}{\\mathrm{cm}^{-2}}\n\\]\nreaching the plate. For a penetration depth of \\(\\Delta z \\approx \\lambda\\) this intensity will be distributed between\n\\[\nN = 10^{23} \\cdot \\mathrm{cm}^{-3}\\cdot \\lambda = 2.5 \\cdot 10^{18} \\; \\frac{1}{{\\mathrm{cm}^{-2}}}\n\\]\nelectrons, whereas each electron acquires on average a power of\n\\[\nP_{\\mathrm{el}} = 3 \\cdot 10^{-24} \\; \\mathrm{W} = 2 \\cdot 10^{-5} \\; \\mathrm{eVs}^{-1} \\mathrm{.}\n\\]\nThus, it will take a time of \\(\\Delta t = W_{\\mathrm{a}}/P_{\\mathrm{el}} = 2 \\cdot 10^5 \\; \\mathrm{s}\\) for one electron to acquire enough energy to leave the zinc plate. This result is in clear contrast to experimental findings.\n\n\nEinstein’s Quantum Explanation\nIn 1905, Einstein proposed a revolutionary explanation based on light quanta (photons). According to this model: - Light energy is transmitted in discrete packets of energy \\(E = h\\nu\\) - Each photon interacts with a single electron - The photon’s entire energy transfers to the electron\nThis led to Einstein’s photoelectric equation:\n\\[\nE_{\\mathrm{kin}}^{\\mathrm{max}} = h \\cdot \\nu - W_{\\mathrm{a}} \\mathrm{,}\n\\]\nwith \\(W_{\\mathrm{a}} = -e \\left( \\phi_{\\mathrm{vac}} - \\phi \\right)\\) being the work function of the cathode material (often the vacuum work function is set to zero, \\(\\phi_{\\mathrm{vac}} = 0\\)). The work function is the amount of energy one has to compensate in order to bring one electron from bulk into vacuum against the forces binding the electron in bulk.\nThe work function determines at which frequency or wavelength the photoelectric effect occurs. Below are typical work functions for various metals:\n\n\n\nTable 1— Work functions and corresponding threshold wavelengths for various metals\n\n\n\n\n\n\n\n\n\n\nMetal\nWork Function (eV)\nThreshold Wavelength (nm)\n\n\n\n\nCesium\n1.95\n636\n\n\nPotassium\n2.30\n539\n\n\nSodium\n2.75\n451\n\n\nCalcium\n3.20\n388\n\n\nZinc\n4.31\n288\n\n\nCopper\n4.70\n264\n\n\nSilver\n4.73\n262\n\n\nPlatinum\n6.35\n195\n\n\n\n\n\n\nThese values show why alkali metals like cesium and potassium are particularly suitable for photoelectric devices, as they respond to visible light, while metals like platinum require ultraviolet radiation.\nSince one can determine the maximum kinetic energy \\(E_{\\mathrm{kin}}^{\\mathrm{max}} = -e\\cdot U_0\\) (\\(U_0 &lt; 0\\)) from the voltage \\(U_0\\) at which the photocurrent sets in and\n\\[\n-e\\cdot U_0 = h\\cdot\\nu -  W_{\\mathrm{a}} \\mathrm{,}\n\\]\none is able to determine the work function on the basis of the intercept of the \\(-e\\cdot U_0\\) vs. \\(h\\cdot\\nu\\) curve and Planck’s constant from the slope of the curve.\n\n\nExperimental Verification\nThe definitive test of Einstein’s photon theory came from Joffé and Dobronrawov in 1925. They used small, charged bismuth beads held within a Millikan capacitor and irradiated those beads with low-dose X-rays. Every change of the overall charge of the beads interferes with the equilibrium in the capacitor, and can be observed by means of a change of the bead position. Using a radiation power of \\(P = 10^{-12} \\; \\mathrm{W}\\) meaning an emission rate of \\(\\dot{N} = 10^3\\) photons per second with an energy of \\(h \\cdot \\nu = 10^4 \\; \\mathrm{eV}\\) on average every 30 minutes a change of the bead charge was detected. The number of photons arriving at one bead within a time interval \\(\\Delta t\\) is \\(Z = \\dot{N} \\cdot \\Delta t \\cdot \\mathrm{d} \\Omega/ \\left( 4\\pi \\right)\\), with \\(\\mathrm{d} \\Omega\\) as the solid angle covered by the bead. The calculated time constant of \\(Z\\) was in well agreement with the observed rate of the charge alteration. If we again assume a wave-like explanation of the photoeffect, the emitted power within the according solid angle will be absorbed by the bead and distributed between all its electrons. As a consequence the bead as a whole will have collected enough energy in order to release an electron within the same period of time. However it cannot be explained how all \\(10^{12}\\) atoms are supposed to combine their energy in one, single electron at the very same time.",
    "crumbs": [
      "Quantum Mechanics",
      "Lecture 19",
      "Particle Nature of Light"
    ]
  },
  {
    "objectID": "quantum-mechanics/Particle_Nature_of_Light.html#the-compton-effect",
    "href": "quantum-mechanics/Particle_Nature_of_Light.html#the-compton-effect",
    "title": "Particle Nature of Light",
    "section": "The Compton Effect",
    "text": "The Compton Effect\nThe particle nature of light received further confirmation through X-ray scattering experiments. When X-rays of wavelength \\(\\lambda_0\\) strike a material, the scattered radiation shows two components:\n\nUnshifted radiation with the original wavelength \\(\\lambda_0\\)\nShifted radiation with increased wavelength \\(\\lambda_S &gt; \\lambda_0\\)\n\nRemarkably, the wavelength shift depends primarily on the scattering angle rather than the target material, suggesting a fundamental interaction mechanism. Experiments concerning the Compoton effect were first conducted by Arthur Compton in 1923. He used X-rays with a wavelength of \\(\\lambda_0 = 0.154 \\; \\mathrm{nm}\\) and observed scattered radiation with a wavelength of \\(\\lambda_S = 0.165 \\; \\mathrm{nm}\\) at a scattering angle of \\(\\theta = 60^\\circ\\).\n\n\n\n\n\n\nFigure 1— General setup for Compton scattering experiments.\n\n\n\n\n\n\n\n\n\nFigure 2— Compton Scattering Geometry\n\n\n\n\nTheoretical Analysis\nThis phenomenon can be explained by treating light as particles (photons) colliding with electrons. Each photon carries: - Energy \\(E = h\\nu = \\hbar\\omega\\) - Momentum \\(p = h/\\lambda = \\hbar k\\)\nIf a photon impacts into a weakly bound electron with a binding energy much smaller than the photon energy (\\(E_\\mathrm{B} \\le E\\)), we can neglect the binding energy and assume the electron as free electron. In addition we simplify further and assume the electron as being at rest. During the collision event\n\\[\nh \\nu_0 + \\mathrm{e}^{-} \\longrightarrow h \\nu_{\\mathrm{S}} + \\mathrm{e}^{-} + E_{\\mathrm{kin}}\n\\]\nenergy and momentum are conserved. The law of conservation of energy then reads as\n\\[\nh \\, \\nu_0 = h \\, \\nu_\\mathrm{s} + E_{\\mathrm{kin}}^{\\mathrm{e}}\n\\]\nwith \\(E_{\\mathrm{kin}}^{\\mathrm{e}}\\) as the relativistic kinetic energy of the electron\n\\[\nE_{\\mathrm{kin}}^{\\mathrm{e}} = \\frac{m_0 c^2}{\\sqrt{1-\\beta^2}} - m_0 c^2\n\\]\nand \\(\\beta = v/c\\). If we ascribe a momentum like\n\\[\n\\vec{p} = \\hbar \\, \\vec{k}\n\\]\nwith\n\\[\n\\left| \\vec{p} \\right| = \\hbar \\, \\left| \\vec{k} \\right| = h \\frac{1}{\\lambda}\n\\]\nto the photon, we can formulate the law of momentum conservation as follows,\n\\[\n\\hbar \\, \\vec{k_0} = \\hbar \\, \\vec{k_{\\mathrm{s}}} + \\vec{p^{\\mathrm{e}}}\n\\]\nwith\n\\[\n\\vec{p^{\\mathrm{e}}} = \\frac{m_0 \\vec{v}}{\\sqrt{1-\\beta^2}} \\mathrm{.}\n\\]\nIf we isolate the square of the momentum of the electron, we obtain an equation depending on the squared difference between the wavevectors of the incident and scattered photon. Calculating this difference leads to a scalar product between these two vectors and necessitates the introduction of the angle between the propagation direction of the incident and scattered photon. We denote this angle as \\(\\phi\\),\n\\[\n\\begin{aligned}\n\\frac{m_0^2 v^2}{1-\\beta^2} &= \\hbar^2 (\\vec{k_0} - \\vec{k_{\\mathrm{s}}})^2 \\\\\n&= \\hbar^2(k_0^2 + k_{\\mathrm{s}}^2 - 2k_0k_{\\mathrm{s}}\\cos(\\varphi)) \\\\\n&= \\frac{h^2}{c^2}(\\nu_0^2 + \\nu_{\\mathrm{s}}^2 - 2\\nu_0\\nu_{\\mathrm{s}}\\cos(\\varphi))\n\\end{aligned}\n\\]\nwhere:\n\n\\(m_0\\) is the rest mass\n\\(v\\) is velocity\n\\(\\beta = v/c\\)\n\\(k_0, k_s\\) are initial and scattered wave vectors\n\\(\\nu_0, \\nu_s\\) are initial and scattered frequencies\n\\(\\varphi\\) is the scattering angle\n\nFrom the law of energy conservation we get\n\\[\n\\frac{m_0^2 v^2}{1-\\beta^2} = \\frac{h^2}{c^2} \\left( \\nu_0 - \\nu_{\\mathrm{s}} \\right)^2 + 2 h m_0 \\left( \\nu_0 - \\nu_{\\mathrm{s}}\\right) \\mathrm{,}\n\\]\nwhich we can compare with the law of momentum conservation and get\n\\[\n\\nu_0 - \\nu_{\\mathrm{s}} = \\frac{h}{m_0 c^2} \\,  \\nu_0 \\, \\nu_{\\mathrm{s}} \\, \\left(1- \\cos \\left( \\varphi \\right) \\right) \\mathrm{.}\n\\]\nNow making use of \\(1- \\cos \\left( \\varphi \\right) = 2 \\sin^2 \\left( \\varphi/2 \\right)\\) and \\(\\nu = c/\\lambda\\) we achieve the Compton formula\n\\[\n\\begin{aligned}\n\\lambda_{\\mathrm{S}} & = & \\lambda_0 + 2 \\frac{h}{m_0 c} \\sin^2 \\left( \\varphi/2 \\right)\\\\\n{} & = & \\lambda_0 + 2 \\lambda_{\\mathrm{C}} \\sin^2 \\left( \\varphi/2 \\right)\\\\\n\\end{aligned}\n\\]\nwith \\(\\lambda_{\\mathrm{C}}\\) denoting the Compton wavelength of the electron,\n\\[\n\\lambda_{\\mathrm{C}} = \\frac{h}{m_0 c} = 2.4262 \\cdot 10^{-12} \\; \\mathrm{m.}\n\\]\nThe Compton wavelength is a constant and represents the change of the wavelength \\(\\Delta \\lambda = \\lambda_{\\mathrm{S}} - \\lambda_0\\) at a scattering angle of \\(\\varphi = 90^{\\circ}\\). Results from experiments almost perfectly coincide with the Compton formula. Furthermore the ratio between the wavelengths\n\\[\n\\frac{\\lambda_{\\mathrm{S}}}{\\lambda_0} = \\frac{h \\nu_0}{m_0 c^2}\n\\]\n(replace with ?? \\[\n\\frac{\\nu_s}{\\nu_0} = \\frac{1}{1 + \\frac{h\\nu_0}{m_0c^2}(1-\\cos(\\varphi))}\n\\] ) represents the ratio between the energy of the incident photon and the energy of the electron at rest. Thus, if we know the mass of the electron, we can determine \\(\\varphi\\) and \\(\\lambda_{\\mathrm{S}}\\) (and therefore \\(\\lambda_{\\mathrm{C}}\\)) and calculate \\(h\\).\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Constants\nh = 6.626e-34  # Planck's constant in J·s\nc = 3e8        # Speed of light in m/s\nme = 9.109e-31 # Electron mass in kg\nE0 = 500e3     # Initial photon energy in eV\neV = 1.602e-19 # Conversion factor eV to Joules\n\n# Scattering angles\ntheta = np.linspace(0, 2*np.pi, 1000)\n\n# Calculate photon energy after scattering\ndef E_photon(E0, theta):\n    return E0 / (1 + (E0/(me*c**2))*(1 - np.cos(theta)))\n\n# Calculate electron kinetic energy\ndef E_electron(E0, theta):\n    E_p = E_photon(E0, theta)\n    return E0 - E_p\n\n# Convert energies to eV\nE_p = E_photon(E0*eV, theta)/eV\nE_e = E_electron(E0*eV, theta)/eV\n\n# Plotting\nplt.figure(figsize=get_size(10, 6))\nplt.plot(theta*180/np.pi, E_p/1000, label='Scattered Photon')\nplt.plot(theta*180/np.pi, E_e/1000, label='Recoil Electron')\n\nplt.xlabel(r'scattering Angle $\\theta$ [°]')\nplt.ylabel('energy [keV]')\nplt.legend()\nplt.show()\n\n\n\n\n\nPhoton and Electron Energies in Compton Scattering\n\n\n\n\n\n\nExperimental Results\nThe plots below show the observed relative scattering intensity of photons at different wavelength for different scattering angles from an experiment using XXX photons scattered on a YYY target. The plots comprise an elastic scattering peak at the wavelength of the incident photons and an inelastic scattering peak at a longer wavelength, in agreement with the Compton formula.\n\n\n\n\n\n\nFigure 3— Compton Scattering of X-rays\n\n\n\nThe Klein-Nishina formula describes the differential cross-section of the Compton effect, showing how the intensity of scattered photons depends on the scattering angle and wavelength:\n\\[\\frac{d\\sigma}{d\\Omega} = \\frac{r_e^2}{2}\\left(\\frac{E'}{E_0}\\right)^2\\left(\\frac{E'}{E_0} + \\frac{E_0}{E'} - \\sin^2\\theta\\right)\\]\nwhere:\n\n\\(r_e\\) is the classical electron radius\n\\(E'\\) is the scattered photon energy\n\\(E_0\\) is the initial photon energy\n\\(\\theta\\) is the scattering angle\n\n\n\nCode\nfrom scipy import constants\n\n# Constants\nr_e = constants.physical_constants['classical electron radius'][0]  # Classical electron radius\nE0 = 100e3  # Initial photon energy in eV\nlambda_0 = constants.h * constants.c / (E0 * constants.e)  # Initial wavelength\nlambda_c = constants.h / (constants.m_e * constants.c)  # Compton wavelength\n\ndef klein_nishina(theta, E0):\n    \"\"\"\n    Calculate Klein-Nishina differential cross-section\n    \"\"\"\n    alpha = E0 * constants.e / (constants.m_e * constants.c**2)\n    P = 1 / (1 + alpha * (1 - np.cos(theta)))\n\n    return 0.5 * r_e**2 * P**2 * (P + 1/P - np.sin(theta)**2)\n\n# Set specific scattering angles to plot\nangles = [30, 60, 90, 120]  # in degrees\nwavelengths = np.linspace(lambda_0, lambda_0 + 2*lambda_c, 1000)\n\nplt.figure(figsize=get_size(10, 6))\n\nfor theta_deg in angles:\n    theta = np.radians(theta_deg)\n    # Calculate the expected wavelength for this angle\n    lambda_expected = lambda_0 + lambda_c * (1 - np.cos(theta))\n\n    # Create a Gaussian distribution around the expected wavelength\n    sigma = lambda_expected * 0.02  # 2% resolution\n    distribution = np.exp(-(wavelengths - lambda_expected)**2 / (2*sigma**2))\n\n    # Scale by Klein-Nishina formula\n    intensity = distribution * klein_nishina(theta, E0)\n\n    # Normalize for better visualization\n    intensity = intensity / np.max(intensity)\n\n    plt.plot(wavelengths*1e12, intensity,\n             label=f'θ = {theta_deg}°')\n\nplt.xlabel('wavelength [pm]')\nplt.ylabel('relative intensity')\nplt.axvline(x=lambda_0*1e12, color='k', linestyle='--', label='Initial wavelength')\n#plt.legend()\nplt.show()\n\n\n\n\n\nKlein-Nishina Differential Cross-Section for the Compton Effect at different scattering angles of 30°, 60°, 90°, and 120°\n\n\n\n\n\n\n\n\n\n\nDetection of \\(\\gamma\\) rays\n\n\n\n\n\nHigh energy photons, i.e. \\(\\gamma\\) rays can be detected by a scintillation counter. The scintillation counter consists of a scintillator, a photomultiplier tube, and a discriminator. The scintillator is a material that emits visible light when struck by high-energy photons. The emitted light is then converted into an electrical signal by the photomultiplier tube. The photomultiplier amplifies the signal through acceleration of photoelectrons (generated by the photoelectric effect) in an electric field, creating cascades of secondary electrons upon collision with metallic dynodes. The discriminator filters the output signals to reject noise and select events within specific energy ranges of interest.\n\n\n\nSketch of a Scintillator\n\n\n\n\n\n\n\n\n\n\n\nCompton Continuum and Compton Edge\n\n\n\n\n\n\nCompton Edge\nThe Compton edge represents the maximum energy transfer possible in a single Compton scattering event, occurring at a scattering angle of \\(180°\\) (backscatter). The energy of the Compton edge \\((E_{CE})\\) can be calculated as:\n\\[E_{CE} = E_0 - E'_{min} = E_0\\left(1 - \\frac{1}{1 + \\frac{2E_0}{m_ec^2}}\\right)\\]\nwhere \\(E_0\\) is the initial photon energy and \\(E'_{min}\\) is the minimum energy of the scattered photon.\n\n\nCompton Continuum\nThe Compton continuum is the energy distribution of scattered photons between:\n\nThe photopeak (original energy \\(E_0\\))\nThe minimum energy after scattering (\\(E'_{min}\\) at \\(180°\\))\n\nThe intensity distribution across this continuum is described by the Klein-Nishina formula:\n\\[\\frac{d\\sigma}{d\\Omega} = \\frac{r_e^2}{2}\\left(\\frac{E'}{E_0}\\right)^2\\left(\\frac{E'}{E_0} + \\frac{E_0}{E'} - \\sin^2\\theta\\right)\\]\nIn gamma-ray spectroscopy, this appears as a broad feature in the energy spectrum, with:\n\nA sharp cutoff at the Compton edge\nDeclining intensity towards lower energies\nA backscatter peak at low energies corresponding to \\(180°\\) scattering",
    "crumbs": [
      "Quantum Mechanics",
      "Lecture 19",
      "Particle Nature of Light"
    ]
  },
  {
    "objectID": "quantum-mechanics/Particle_Nature_of_Light.html#properties-of-photons",
    "href": "quantum-mechanics/Particle_Nature_of_Light.html#properties-of-photons",
    "title": "Particle Nature of Light",
    "section": "Properties of Photons",
    "text": "Properties of Photons\nHaving established light’s particle nature through the photoelectric and Compton effects, we can now summarize the fundamental properties of photons. These quantum particles unite the classical wave description of light with its particle behavior.\n\nEnergy and Momentum\nEvery electromagnetic field consists of energy quanta \\(h\\nu\\), which we call photons. For a cavity resonator, the electromagnetic energy density is:\n\\[\n\\omega_{\\mathrm{em}} = n \\cdot h \\cdot \\nu \\mathrm{.}\n\\]\nWe can further comprehend the flux \\(I = \\varepsilon_0 c E^2\\) of an electromagnetic wave as a particle flux \\(\\dot{N}\\) of photons\n\\[\nI = \\dot{N} h \\nu\n\\]\nwith \\(\\dot{N} = n \\cdot c\\). Therefore, if a light wave with a flux of \\(I\\) is shining on an area is tantamount with a particle flux of photons reaching this area.\nAs demonstrated on the basis of the Compton effect, every photon bears a momentum \\(\\vec{p} = \\hbar \\cdot \\vec{k}\\) with the magnitude \\(\\left| \\vec{p} \\right| = p = h \\nu / c\\). As a consequence, if we are able to assign an energy density to the density of modes, we are also able to assign a momentum density,\n\\[\n\\pi_{\\mathrm{em}} = n \\cdot \\hbar \\cdot k \\mathrm{.}\n\\]\nThen, the relation between the energy density \\(\\omega_{\\mathrm{em}}\\) of an electromagnetic wave and the momentum density \\(\\pi_{\\mathrm{em}}\\) of the very same wave reads as\n\\[\n\\omega_{\\mathrm{em}} = c \\cdot \\pi_{\\mathrm{em}} {.}\n\\]\n\n\nAngular Momentum\nPhotons carry two distinct types of angular momentum: spin angular momentum (SAM) associated with polarization, and orbital angular momentum (OAM) associated with the spatial distribution of the wavefront.\n\nSpin Angular Momentum\nThe spin angular momentum is related to the polarization state of light. When a circularly polarized photon is absorbed by a free atom, the atom’s angular momentum changes by ±ħ. For left-handed circular polarized light (\\(\\sigma^{+}\\)) propagating along \\(z\\), the change is \\(\\Delta J_z = + \\hbar\\), while for right-handed polarization (\\(\\sigma^{-}\\)), it’s \\(\\Delta J_z = - \\hbar\\). The spin angular momentum vector is:\n\\[\n\\vec{S}_{Ph} = \\pm \\hbar \\, \\frac{\\vec{k}}{\\left| \\vec{k} \\right|}\n\\]\nLinearly polarized light, being a superposition of equal amounts of \\(\\sigma^{+}\\) and \\(\\sigma^{-}\\) light, has zero net spin angular momentum.\n\n\nOrbital Angular Momentum\nPhotons can also carry orbital angular momentum, characterized by a quantum number \\(l\\):\n\\[\n\\vec{L}_{Ph} = l\\hbar \\, \\frac{\\vec{k}}{\\left| \\vec{k} \\right|}\n\\]\nwhere \\(l\\) can be any integer. This OAM is associated with helical wavefronts and is important in applications like optical tweezers and quantum information.\nThe total angular momentum of a photon is the sum of both contributions:\n\\[\n\\vec{J}_{Ph} = \\vec{S}_{Ph} + \\vec{L}_{Ph}\n\\]\n\n\n\nEffect of Gravity on Photons\nDespite having zero rest mass, photons interact with gravitational fields due to their energy-equivalent mass. From special relativity we know that mass is affected by the relative motion of reference systems:\n\\[\nm = \\frac{1}{\\sqrt{1-\\left( \\frac{v}{c}\\right)^2}} \\, m_0\n\\]\nOnly particles with a rest mass \\(m_0 = 0\\) can travel at the speed of light, which is why photons must have zero rest mass. For the energy of a photon, we find:\n\\[\n\\begin{aligned}\nE & = & \\sqrt{p^2c^2 + m_0^2 c^4}\\\\\n{} & = & p c\\\\\n{} & = & \\frac{h}{\\lambda} c\\\\\n{} & = & h \\nu\n\\end{aligned}\n\\]\nin accordance with previous energy and momentum considerations. If we assign an effective mass \\(m\\) to the photon:\n\\[\nm = \\frac{E}{c^2} = \\frac{h \\nu}{c^2}\n\\]\nthis photon must perform work when traveling in a gravitational field. Moving from position \\(\\vec{r_1}\\) with gravitational potential \\(\\Phi(\\vec{r_1})\\) to position \\(\\vec{r_2}\\) with potential \\(\\Phi(\\vec{r_2})\\), the work is:\n\\[\nW = m \\cdot \\Delta \\Phi = \\frac{h \\nu}{c^2} \\left( \\Phi \\left( \\vec{r_2} \\right) - \\Phi \\left( \\vec{r_1} \\right) \\right)\n\\]\nBy energy conservation, the photon’s energy \\(h\\nu\\) must change by this amount, leading to a frequency shift:\n\\[\n\\nu_2 = \\nu_1 \\left(1-\\frac{\\Delta \\phi}{c^2} \\right)\n\\]\nor in relative terms:\n\\[\n\\frac{\\Delta \\nu}{\\nu} = \\frac{\\Delta \\Phi}{c^2}\n\\]\nThis remarkable prediction - that photons experience a redshift (longer wavelength, smaller frequency, lower energy) when rising in a gravitational field - was first experimentally verified by Pound and Rebka in 1959. Using the Mössbauer effect, they measured the frequency shift of gamma rays from \\(^{57}\\)Fe (14.4 keV) traveling vertically over a height of 22.5 meters at Harvard University. The expected relative frequency shift was extremely small:\n\\[\n\\frac{\\Delta \\nu}{\\nu} \\approx 2.5 \\times 10^{-15}\n\\]\n\n\n\n\n\n\n\n\nArchitectural sketch of the Jefferson Physical Laboratory tower showing the placement of the gravitational red-shift experiment running from the penthouse to the basement. Source: R. V. Pound and J. L. Snider, ‘‘Effect of Gravity’’ (ref. 23), p. B 792 and Pound & Rebka, Phys. Rev. Lett. 3, 440 (1959)\n\n\n\n\n\n\n\nSchematic of the Pound-Rebka experiment showing gamma ray source and detector separated vertically by 22.5 meters\n\n\n\n\n\n\nFigure 4— Sektch of the tower at Harvard University (left) and the Pound-Rebka experiment setup (right).\n\n\n\n\n\n\n\n\n\nThe Mößbauer Effect in the Pound-Rebka Experiment\n\n\n\n\n\nThe detection of gravitational redshift requires extremely precise frequency measurements (\\(\\Delta \\nu/\\nu \\approx 10^{-15}\\)). This was made possible by the Mößbauer effect, which allows for recoil-free emission and absorption of gamma rays in crystals.\nIn free atoms, the emission or absorption of a gamma ray causes recoil, shifting the photon energy by about \\(10^{-3}\\) eV. For a gamma ray of energy \\(E_\\gamma\\), the recoil energy is:\n\\[E_R = \\frac{E_\\gamma^2}{2Mc^2}\\]\nwhere \\(M\\) is the mass of the nucleus. However, in a crystal lattice, the nucleus is not free to recoil. Instead, the recoil momentum can be transferred to the entire crystal if:\n\nThe nucleus is tightly bound in the crystal lattice\nThe recoil energy is less than the energy of the lowest lattice vibration (phonon)\nThe entire crystal acts as a single quantum mechanical system\n\nIn this case, the effective mass \\(M\\) in the recoil energy formula becomes the mass of the entire crystal, making \\(E_R\\) negligible. For \\(^{57}\\)Fe nuclei in a crystal:\n\nGamma ray energy: 14.4 keV\nNatural linewidth: \\(\\approx 10^{-8}\\) eV\nNo recoil broadening\nExtremely sharp resonance\n\nThis allows for the detection of the tiny frequency shifts caused by gravity over the 22.5 m height difference in the Harvard tower.\n\n\n\nThe success of the Pound-Rebka experiment demonstrates how quantum mechanics and general relativity make consistent predictions about photon behavior, though a complete quantum theory of gravity remains one of physics’ greatest challenges.",
    "crumbs": [
      "Quantum Mechanics",
      "Lecture 19",
      "Particle Nature of Light"
    ]
  },
  {
    "objectID": "quantum-mechanics/Black_Body_Radiation copy.html",
    "href": "quantum-mechanics/Black_Body_Radiation copy.html",
    "title": "Black Body Radiation",
    "section": "",
    "text": "Black body radiation represents one of the pivotal problems that led to the birth of quantum mechanics. While seemingly a purely thermodynamic phenomenon - the electromagnetic radiation emitted by an idealized perfect absorber in thermal equilibrium - its explanation required a radical departure from classical physics.\nIn the late 19th century, classical physics completely failed to explain the observed spectrum of black body radiation. The classical Rayleigh-Jeans law predicted that the intensity of radiation would increase indefinitely with frequency (the ‘ultraviolet catastrophe’), which clearly contradicted experimental measurements. This crisis in physics was resolved only when Max Planck introduced the revolutionary concept that electromagnetic energy could only be emitted in discrete quantities or ‘quanta’ - an idea that would become one of the fundamental principles of quantum mechanics.\nThe study of black body radiation thus marks the historical transition point from classical to quantum physics. Planck’s solution not only explained the observed radiation spectrum but introduced the quantum of action \\(h\\) (Planck’s constant), which would become central to all of quantum mechanics. This topic demonstrates how quantum effects emerge even in seemingly classical macroscopic systems when we examine them carefully enough.\nThe figure below displays the emission of a light bulb with a tungsten filament. The filament is heated up to a specific temperature by different currents.\nWithout dispersing the spectrum we directly notice the different color of the light emitted by the filament. While the heating mechanism is different for different materials, the emitted spectrum is always similar and solely depends on the temperature of the radiator. The emitted spectrum is called the blackbody spectrum and is universal for all materials."
  },
  {
    "objectID": "quantum-mechanics/Black_Body_Radiation copy.html#black-body",
    "href": "quantum-mechanics/Black_Body_Radiation copy.html#black-body",
    "title": "Black Body Radiation",
    "section": "Black Body",
    "text": "Black Body\n\n\n\n\n\n\nNote\n\n\n\nA blackbody is a model of a radiation source whose emission depends only on its temperature. Its emission, however, does not depend on the material the radiator is made from, nor on its surface or any other potential characteristics.\n\n\nConsider a body with a cavity as depicted below. The body is heated to a certain temperature \\(T\\) and the cavity is closed.\n\n\n\nA body with a cavity. The body is heated to a certain temperature \\(T\\) and the cavity is closed.\n\n\nThe system is in thermal equilibriums and thus each quadratic degree of freedom carries an energy of \\(0.5 k_B T\\), where \\(k_B=1.21.380649 \\times 10^{-23} \\text{ J/K}\\) is the Boltzmann constant.\nEach surface element of the cavity emits radiation. The radiation is absorbed and re-emitted multiple times within the cavity. The radiation is in thermal equilibrium with the walls of the cavity. The radiation is isotropic and homogeneous. The radiation is called blackbody radiation.\nAs a consequence the absorption of an ideal blackbody is \\(A = 1\\). A realization of a blackbody radiator might be constructed on the basis of a cavity within a solid body. If one drills a hole in the cavity wall with the prerequisite that the area of this hole \\(\\Delta A\\) is small compared to the overall area of the cavity \\(A_{\\mathrm{cav}} \\gg \\Delta A\\), the radiation entering the cavity is reflected and absorbed multiple times before the radiation might reach the opening again. Practically the whole radiation is absorbed \\(A \\approx 1\\).\n\n\n\nPrinciple of a cavity resonator. Due to the geometry (the inner surface \\(A_{\\mathrm{cav}}\\) is much bigger than the area of the inlet \\(\\Delta A\\)) radiation is reflected and partially absorbed multiple times and cannot escape.\n\n\nWhen the cavity is heated while maintaining its walls at a uniform temperature, the thermal energy causes the atoms in the walls to vibrate. These vibrating atoms emit electromagnetic waves in the form of thermal radiation. Because the hole in the cavity is very small compared to the total cavity surface area (\\(\\Delta A \\ll A_{\\mathrm{cav}}\\)) and the cavity has perfect absorption (\\(A = 1\\)), the radiation that emerges from the hole represents the most intense possible thermal emission - greater than what any real material could produce at that temperature. This makes the cavity an ideal blackbody radiator.\nWe can show for cavity radiation:\n\nIf the cavity walls are in a stationary state, the absorption and emission of the walls are in equilibrium. For every frequency \\(\\nu\\) the absorption and emission of an area element is given through \\[\n\\frac{\\mathrm{d} W_{\\mathrm{A}} \\left( \\nu \\right) }{\\mathrm{d} t} = \\frac{\\mathrm{d} W_{\\mathrm{E}} \\left( \\nu \\right) }{\\mathrm{d}t}\n\\]\nCavity radiation is isotropic. The spectral radiance at any point of the cavity does not depend on the direction of observation and is independent of the kind and shape of the walls. (If this point had not been true, one might have placed a black plate into the cavity and oriented it with its normal facing the strongest radiation. Thus, one side of the plate would have become hotter than the other one, which is against the second law of thermodynamics.)\nCavity radiation is homogeneous. The energy spectral density is independent from the particular position within the cavity. (If this had not been true, you might have constructed a perpetuum mobile)\n\nIf we now place a body in the cavity the area element \\(\\mathrm{d}A\\) experiences a spectral radiancy of \\(S^{\\ast}_{\\nu} \\; \\mathrm{d} \\nu \\; \\mathrm{d} A \\; \\mathrm{d} \\Omega\\) on the interval \\(\\left[ \\nu; \\nu + \\mathrm{d} \\nu \\right]\\) from the solid angle \\(\\mathrm{d} \\Omega\\). The area \\(\\mathrm{d} A\\) then absorbs the radiant power of\n\\[\n\\frac{\\mathrm{d} W_{A}}{\\mathrm{d} t} = A_{\\nu} \\; S^{\\ast}_{\\nu} \\; \\mathrm{d} A \\; \\mathrm{d} \\Omega \\; \\mathrm{d} \\nu\n\\]\nand emits the radiancy of\n\\[\n\\frac{\\mathrm{d} W_{E}}{\\mathrm{d} t} = E^{\\ast}_{\\nu} \\; \\mathrm{d} A \\; \\mathrm{d} \\Omega \\; \\mathrm{d} \\nu\n\\]\nwith \\(A_{\\nu}\\) and \\(E^{\\ast}_{\\nu}\\) being the absorption and emission capabilities, respectively.\nIf the body is in thermal equilibrium the absorption and emitted power have to be equal. Furthermore, because the spectral radiancy within the cavity is isotropic, its value is constant for every orientation (\\(\\theta\\) and \\(\\varphi\\)). Thus, we immediately obtain Kirchhoff’s law of thermal radiation\n\\[\n\\frac{E^{\\ast}_{\\nu}}{A_{\\nu}} = S^{\\ast}_{\\nu}\n\\]\nThus, for every body being in thermal equilibrium with the cavity radiation the ratio between the emission capability and absorption capability at a given frequency \\(\\nu\\) is equal to the spectral radiancy \\(S^{\\ast}_{\\nu} \\left( T \\right)\\) of the cavity. Since the blackbody radiator absorbs perfectly \\(A = 1\\), it follows that the spectral emission capability \\(E^{\\ast}_{\\nu}\\) is identical to the spectral radiancy \\(S^{\\ast}_{\\nu}\\).\n\n\n\n\n\n\nThe Leslie Cube Experiment\n\n\n\nThe Leslie Cube, developed by John Leslie in 1804, was one of the first experimental demonstrations of how surface properties affect thermal radiation. The apparatus consists of a cubic vessel with different surface treatments on each face (e.g., polished metal, blackened surface, rough surface), filled with hot water.\n\n\n\n\n\n\nFigure 2— Leslie Cube. The cube is filled with hot water, and each face has a different surface treatment. The radiation emitted from each face is measured using a thermopile detector. The experiment demonstrated that different surfaces emit radiation differently at the same temperature, and that good absorbers are also good emitters.\n\n\n\nBy measuring the radiation emitted from each face using a thermopile detector, Leslie showed that:\n\nDifferent surfaces emit radiation differently at the same temperature\nGood absorbers are also good emitters (leading to Kirchhoff’s law)\nThe emissivity depends on the surface properties but not on the material inside\n\nThis simple but elegant experiment helped establish fundamental principles of thermal radiation and provided early experimental evidence for what would later be formalized as Kirchhoff’s law of thermal radiation:\n\\[\\frac{E^{\\ast}_{\\nu}}{A_{\\nu}} = S^{\\ast}_{\\nu}\\]"
  },
  {
    "objectID": "quantum-mechanics/Black_Body_Radiation copy.html#spectral-density-of-modes",
    "href": "quantum-mechanics/Black_Body_Radiation copy.html#spectral-density-of-modes",
    "title": "Black Body Radiation",
    "section": "Spectral density of modes",
    "text": "Spectral density of modes\nNow we would like to have a look at how electromagnetic waves behave within a cavity. First we discuss a one-dimensional problem. If we assume an electromagnetic wave with an electric field of \\(\\vec{E} \\left( z, t \\right) = E_0 \\cos \\left( \\omega t - k z \\right) \\; \\vec{e_x}\\) and being reflected at a conducting surface at \\(z = 0\\), we have to pay attention that tangential components of \\(\\vec{E}\\) cannot exist at the interface. Thus, it follows\n\\[\n\\vec{E} \\left( z = 0, t \\right) = E_{0,\\mathrm{I}} \\; \\vec{e_x} + E_{0,\\mathrm{R}} \\; \\vec{e_x} = 0\n\\] and \\[\nE_{0,\\mathrm{I}} \\; \\vec{e_x} = -E_{0,\\mathrm{R}} \\; \\vec{e_x}\n\\]\nThe superposition of incident and reflected waves then result in\n\\[\n\\vec{E} \\left( z, t \\right) = 2 E_0 \\sin \\left( k z \\right) \\sin \\left( \\omega t \\right) \\; \\vec{e_x} \\mathrm{,}\n\\] which is a standing wave.\nIf we now discuss the three-dimensional problem, we have a look at a cuboid with ideally conducting walls and the length of the edges being \\(a\\), \\(b\\), and \\(c\\). If we place one corner of the cuboid at the origin of the coordinate system and discuss the electric field for an arbitrary orientation \\(\\vec{E} = \\left( E_x, E_y, E_z \\right)^{\\mathrm{T}}\\), we obtain from the vanishing tangential components of the electric field at the interface the following boundary conditions \\[\n\\begin{eqnarray}\nE_x = 0 & \\; \\mathrm{for} \\; & z = 0,\\; z = c,\\; y = 0,\\; \\mathrm{and} \\; y = b\\\\\nE_y = 0 & \\; \\mathrm{for} \\; & z = 0,\\; z = c,\\; x = 0,\\; \\mathrm{and} \\; x = a\\\\\nE_z = 0 & \\; \\mathrm{for} \\; & x = 0,\\; x = a,\\; y = 0,\\; \\mathrm{and} \\; y = b\n\\end{eqnarray}\n\\]\n\n\n\nA cuboid as resonator.\n\n\nDue to reflections and superposition of the components of the wavevector \\(\\left( \\pm k_x, \\pm k_y, \\pm k_z \\right)\\), standing waves are generated if the boundary conditions are fulfilled\n\\[\n\\begin{eqnarray}\nk_x & = & n \\cdot \\frac{\\pi}{a}\\\\\nk_y & = & m \\cdot \\frac{\\pi}{b}\\\\\nk_z & = & o \\cdot \\frac{\\pi}{c}\n\\end{eqnarray}\n\\] with \\(m,n,o\\) being natural numbers. Furthermore, the magnitude of the wavevector is given through \\(\\left| \\vec{k} \\right| = \\sqrt{k_x^2 + k_y^2 + k_z^2}\\) which directly leads to the condition for possible frequencies\n\\[\n\\omega = c \\cdot \\pi \\; \\sqrt{\\left(\\frac{n}{a}\\right)^2 + \\left(\\frac{m}{b}\\right)^2 + \\left(\\frac{o}{c}\\right)^2}\n\\]\nConsequently, only such standing waves are allowed in our resonator that obey the conditions\n\\[\n\\vec{E}_{m,n,o} = \\vec{E}_{0} \\left( m,n,o \\right) \\cdot \\cos \\left( \\omega t\\right)\n\\]\nwith \\(\\vec{E}_{0} \\left( m,n,o \\right) = \\left( E_{0,x},E_{0,y},E_{0,z} \\right)^{\\mathrm{T}}\\) and\n\\[\n\\begin{eqnarray}\nE_{0,x} & = & A \\cdot \\cos \\left( n \\frac{\\pi}{a} x \\right) \\sin \\left( m \\frac{\\pi}{b} y \\right) \\sin \\left( o \\frac{\\pi}{c} z \\right)\\\\\nE_{0,y} & = & B \\cdot \\sin \\left( n \\frac{\\pi}{a} x \\right) \\cos \\left( m \\frac{\\pi}{b} y \\right) \\sin \\left( o \\frac{\\pi}{c} z \\right)\\\\\nE_{0,z} & = & C \\cdot \\sin \\left( n \\frac{\\pi}{a} x \\right) \\sin \\left( m \\frac{\\pi}{b} y \\right) \\cos \\left( o \\frac{\\pi}{c} z \\right)\\\\\n\\end{eqnarray}\n\\]\nSuch a box with ideally conducting walls is called a cavity resonator and the possible standing waves the resonator’s principle oscillations or resonator modes.\nIn order to simplify the calculation a bit, we discuss the case of a cube instead of a cuboid. The frequency condition then results in\n\\[\n\\begin{eqnarray}\n\\omega & = & c \\cdot \\frac{\\pi}{a} \\; \\sqrt{ n^2 + m^2 + o^2}\\\\\n\\rightarrow n^2 + m^2 + o^2 & = & \\left( \\frac{a \\omega}{\\pi c}\\right)^2\\\\\n\\rightarrow n^2 + m^2 + o^2 & = & \\left( \\frac{a}{\\pi}\\right)^2 \\cdot k^2\\\\\n\\end{eqnarray}\n\\]\nIn a coordinate system in \\(k\\)-space where \\(k_x\\), \\(k_y\\), and \\(k_z\\) define the axes, the points \\(\\left( m, n, o \\right)\\) form a lattice with the lattice constant \\(\\pi / a\\). As the combinations of the parameters \\(\\left( m, n, o \\right)\\) defines the number of modes within the resonator, as a consequence there are as many modes as lattice points in \\(k\\)-space. The very last equation, in addition, defines a sphere with the radius $| | = /a $\n\n\n\nTwo-dimensional k-space with a circle representing a sphere in two-dimensional space.\n\n\nNow we can discuss the following case. For \\(\\sqrt{m^2 +n^2 +o^2} \\gg 1\\), it follows for the radius of the sphere \\(\\left| \\vec{k} \\right| \\gg \\pi / a\\) and for the wavelength \\(\\lambda \\ll 2a\\). As a consequence the number of lattice points \\(N_{\\mathrm{L}}\\) (under the boundary condition \\(m,n,o &gt; 0\\)) can be approximated with the number of unit cells within our sphere with the radius \\(\\left| \\vec{k} \\right|\\) in the first octant. The volume of the sphere in the first octant reads as\n\\[\n\\begin{eqnarray}\nV_{\\mathrm{S}} & = & \\frac{1}{8} \\; \\frac{4}{3} \\pi \\left| \\vec{k} \\right|^3 \\mathrm{ or }\\\\\nV_{\\mathrm{S}} & = & \\frac{1}{6} \\pi \\left( \\frac{\\omega}{c_0} \\right)^3 \\mathrm{.}\n\\end{eqnarray}\n\\]\nThen, we can calculate the number of lattice points on the basis of the ratio of the volume of the sphere in the first octant to the volume of a unit cell (\\(V_{\\mathrm{UC}} = \\left( \\pi / a \\right)^3\\))\n\\[\nN_{\\mathrm{L}} = \\frac{V_{\\mathrm{S}}}{V_{\\mathrm{UC}}} = \\frac{\\pi}{6} \\left( \\frac{a \\cdot \\omega}{\\pi \\cdot c_0} \\right)^3 \\mathrm{.}\n\\]\nIf we now consider that every standing wave might have an arbitrary polarization that can be constructed as superposition of two orthogonal directions of polarization, the number of modes doubles. Thus, the number of possible modes with a frequency \\(\\omega\\) smaller than the limiting frequency \\(\\omega_{\\mathrm{S}}\\) within a cavity resonator is given through\n\\[\nN \\left( \\omega \\le \\omega_{\\mathrm{S}} \\right) = 2 \\cdot \\frac{\\pi}{6} \\left( \\frac{a \\cdot \\omega_{\\mathrm{S}}}{\\pi \\cdot c_0} \\right)^3 = \\frac{8 \\pi \\nu_{\\mathrm{S}} a^3}{3 c_0^3} \\mathrm{.}\n\\]\nHere we made use of \\(\\omega_{\\mathrm{S}} = 2 \\pi v_{\\mathrm{S}}\\). If we now go back to real space, we can calculate the number of modes per unit volume for \\(\\nu \\le \\nu_\\mathrm{S}\\) as the ratio of the number of modes up to the limiting frequency \\(\\nu_{\\mathrm{S}}\\) divided through the real-space volume \\(V = a^3\\). As a result we get the density of modes being\n\\[\n\\frac{N \\left( \\nu \\le \\nu_{\\mathrm{S}} \\right) }{V} = n = \\frac{8 \\pi \\nu_{\\mathrm{S}}^3}{3 c_0^3} \\mathrm{.}\n\\]\nOften one is interested in the spectral density of modes, that is the number of allowed modes per unit volume of the resonator within the interval \\(\\left[ \\nu ; \\nu + \\Delta \\nu \\right]\\). A straightforward calculation of the first derivative of the density of modes with respect to the frequency \\(\\mathrm{d}n/\\mathrm{d}\\nu\\) gives us an expression for the spectral mode density\n\\[\n\\frac{\\mathrm{d} n }{\\mathrm{d} \\nu} = \\frac{8 \\pi \\nu^2}{c_0^3} \\mathrm{.}\n\\]\nSo far we have calculated that only under particular conditions standing waves can be established within a cubic cavity. These eigen-oscillations are called “modes of the cavity”. Furthermore, if the wavelength is small compared to the cavity dimensions, we derived the spectral density of modes, that is the number of modes within one cubic meter of volume within the interval between \\(\\nu\\) and \\(\\nu + \\mathrm{d}\\nu\\) is\n\\[\nn \\left( \\nu \\right) \\; \\mathrm{d}\\nu = \\frac{8 \\pi \\nu^2}{c_0^3} \\mathrm{.}\n\\]\nIf we now assume \\(\\bar{W}_{\\nu} \\left( T \\right)\\) being the average energy per eigen-oscillation within the interval \\(\\mathrm{d}\\nu\\), we can calculate the spectral energy density \\(\\omega_{\\nu}\\mathrm{d} \\nu\\) as\n\\[\n\\omega_{\\nu} \\; \\mathrm{d} \\nu = n \\left( \\nu \\right) \\cdot \\bar{W}_{\\nu} \\left( T \\right) \\cdot \\mathrm{d}\\nu\n\\]\nNow the question arises how we can derive an expression for the spectral energy density \\(\\omega_{\\nu}\\mathrm{d} \\nu\\). We will discuss this expression in a moment, but before we have to have a look at historical results leading to the law of radiation as we know it nowadays."
  },
  {
    "objectID": "quantum-mechanics/Black_Body_Radiation copy.html#stefan-boltzmann-law",
    "href": "quantum-mechanics/Black_Body_Radiation copy.html#stefan-boltzmann-law",
    "title": "Black Body Radiation",
    "section": "Stefan-Boltzmann Law",
    "text": "Stefan-Boltzmann Law\nIn order to derive the expression which we know today as Stefan-Boltzmann law, Stefan discovered the empirical relation in 1879 and later in 1884 Boltzmann derived the law on the basis of thermodynamics and Maxwell relations. First we want to consider the inner energy \\(U\\) of an isolated system, which can be expressed as thermodynamic potential depending on the temperature \\(T\\), the entropy \\(S\\), pressure \\(p\\), and volume \\(V\\),\n\\[\n\\mathrm{d} U = T \\mathrm{d} S - p \\mathrm{d}V \\mathrm{.}\n\\]\nIf we now calculate the derivative of the inner energy with respect to the volume at constant temperature\n\\[\n\\left( \\frac{\\mathrm{d} U}{\\mathrm{d} V} \\right)_{T} = T \\left( \\frac{\\mathrm{d} S}{\\mathrm{d} V} \\right)_{T} - p\n\\]\nand make use of one Maxwell relation, namely\n\\[\n\\left( \\frac{\\mathrm{d} S}{\\mathrm{d} V} \\right)_{T} = \\left( \\frac{\\mathrm{d} p}{\\mathrm{d} T} \\right)_{V}\n\\]\nwe get\n\\[\n\\left( \\frac{\\mathrm{d} U}{\\mathrm{d} V} \\right)_{T} = T \\left( \\frac{\\mathrm{d} p}{\\mathrm{d} T} \\right)_{V} - p\n\\]\nPreviously Maxwell presented an expression for the radiation pressure being \\(p = \\frac{1}{3}u\\) with \\(u\\) as the energy density and the total inner energy as \\(U = u\\cdot V\\). If we use these expressions in the equation of the derivative and integrate, we obtain \\[\n\\begin{eqnarray}\nu & = & C_1 \\cdot T^4\\\\\nU & = & C_2 \\cdot V \\cdot T^4 \\mathrm{,}\n\\end{eqnarray}\n\\]\nwith \\(C_1\\) and \\(C_2\\) denoting integration constants. In the modern form we refer to the radiation power \\(P\\) as\n\\[\nP = \\sigma \\cdot A \\cdot T^4\n\\]\nbeing proportional to the Stefan-Boltzmann constant \\(\\sigma\\), the blackbody area \\(A\\), and to the fourth power of the absolute temperature. This law also describes that every body with a temperature higher than \\(0 \\mbox{ K}\\) emits electromagnetic radiation."
  },
  {
    "objectID": "quantum-mechanics/Black_Body_Radiation copy.html#wiens-displacement-law",
    "href": "quantum-mechanics/Black_Body_Radiation copy.html#wiens-displacement-law",
    "title": "Black Body Radiation",
    "section": "Wien’s Displacement Law",
    "text": "Wien’s Displacement Law\nIn 1896 Wien published how the spectrum of cavity radiation changes with altered temperature. Today this law is often not referred to the overall shape of the spectrum, but rather to the maximum of the spectrum. In 1896 the Stefan-Boltzmann law was already published stating that the emitted radiance depends on the apparent temperature to the power of 4 (\\(\\propto T^4\\)). However, the actual spectral distribution of the energy was unknown.\nOn the basis of thermodynamic concepts and the Stefan-Boltzmann law Wien derived a relation between the wavelength \\(\\lambda\\) and the spectral energy at a particular wavelength \\(\\varphi \\left(\\lambda\\right)\\)\n\\[\n\\varphi \\cdot \\mathrm{d} \\lambda = \\varphi_0 \\cdot \\mathrm{d} \\lambda_0\n\\]\nand\n\\[\n\\mathrm{d} \\lambda = \\frac{T_0}{T} \\; \\mathrm{d} \\lambda_0 \\mathrm{.}\n\\]\nThe last equation can be reformulated into the shape of\n\\[\n\\lambda_{\\mathrm{peak}} = b \\cdot \\frac{1}{T}\n\\]\nwith \\(b\\) being the proportionality or Wien’s displacement constant (\\(b = 2.898 \\cdot 10^{-3} \\, \\mathrm{m}\\cdot\\mathrm{K}\\)).\nWien further examined the integration with the result for the energy profile \\(\\varphi = \\varphi_0 \\; \\frac{\\mathrm{d} \\lambda_0}{\\mathrm{d} \\lambda} = \\varphi_0 \\; \\frac{\\mathrm{d} T}{\\mathrm{d} T_0}\\). In addition with the known relation from the Stefan-Boltzmann law \\(\\varphi \\propto \\frac{T^4}{T_0^4}\\), Wien proposed the spectral shape at a particular temperature on the basis of the spectral shape at a known temperature \\(\\varphi = \\varphi_0 \\frac{T^5}{T_0^5}\\). So far the exact spectral shape still remained unknown; however, by means of adjusting the parameter \\(\\varphi_0\\) theory was successfully brought into coincidence with experimental results and the spectrum for small wavelengths could be predicted."
  },
  {
    "objectID": "quantum-mechanics/Black_Body_Radiation copy.html#wiens-distribution-law-or-wien-approximation",
    "href": "quantum-mechanics/Black_Body_Radiation copy.html#wiens-distribution-law-or-wien-approximation",
    "title": "Black Body Radiation",
    "section": "Wien’s distribution law or Wien approximation",
    "text": "Wien’s distribution law or Wien approximation\nIn his original publication in 1896 Wien employed the wavelength dependence of the blackbody radiation and the Maxwell-Boltzmann distribution for the speed of molecules. On the basis of thermodynamic arguments he derived a formula for the radiance\n\\[\nS^{\\ast}_{\\lambda} \\left(\\lambda, T \\right) = \\frac{C_1}{\\lambda^5} \\; \\mathrm{e}^{- \\frac{C_2}{\\lambda T}} \\mathrm{.}\n\\]\nwith \\(C_1\\) and \\(C_2\\) being constants. As to be expected the curve described by this formula exhibits a maximum. In the case of short wavelength, experimental results from cavity radiation can be well described. For long wavelengths, instead, the Wien approximation underestimated the radiance.\n\n\n\nComparison between blackbody radiation (solid lines) and Wien approximation (dashed lines) at different temperatures."
  },
  {
    "objectID": "quantum-mechanics/Black_Body_Radiation copy.html#rayleighjeans-law",
    "href": "quantum-mechanics/Black_Body_Radiation copy.html#rayleighjeans-law",
    "title": "Black Body Radiation",
    "section": "Rayleigh–Jeans law",
    "text": "Rayleigh–Jeans law\nIn order to calculate the average energy per eigen-oscillation Rayleigh and Jeans used the classical approach. Similar to the harmonic oscillators every mode bears the average energy of\n\\[\n\\bar{W_{\\nu}} \\left( T \\right) = k \\cdot T \\mathrm{,}\n\\]\nwith \\(k\\) and \\(T\\) being the Boltzmann constant and absolute temperature, respectively. Therefore, within the limit of the classical approach the spectral energy density,\n\\[\n\\omega_{\\nu} \\; \\mathrm{d} \\nu = \\frac{8 \\pi \\nu^2}{c_0^3} \\; k \\; T \\; \\mathrm{d}\\nu \\mathrm{,}\n\\]\nrises quadratically with respect to the frequency \\(\\nu\\). This quadratic relation is known as Rayleigh-Jeans law. As a consequence a small hole in the cavity wall will then emit radiation into the solid angle of \\(\\mathrm{d} \\Omega = 1 \\mbox{ sr}\\) with the radiance of\n\\[\n\\begin{eqnarray}\nS^{\\ast}_{\\nu} \\left( \\nu \\right) \\mathrm{d} \\nu & = & \\frac{c_0}{4 \\pi} \\; \\omega_{\\nu} \\left( \\nu \\right) \\; \\mathrm{d} \\nu\\\\\n{} & = & \\frac{2 \\nu^2}{c_0^2} \\; k \\; T \\; \\mathrm{d} \\nu\n\\end{eqnarray}\n\\]\nIf we now consider a temperature of about \\(5000 \\; \\mathrm{K}\\) we achieve a wavelength bigger than \\(2 \\; \\mu\\mathrm{m}\\), being well in the infrared region. For this spectral region the measured radiance and the theoretical prediction are in agreement. However, if we reduce the wavelength, disparities between experimental findings and the prediction appear. Moreover, if the Rayleigh-Jeans law was valid, there would be the so-called ultraviolet catastrophe! In the case of decreasing frequencies, the spectral energy density and the integrated radiance will rise until they become infinitely big for vanishing frequencies.\n\n\n\nComparison between blackbody radiation (solid lines) and radiation as described through the Rayleigh-Jeans law (dashed lines) at different temperatures."
  },
  {
    "objectID": "quantum-mechanics/Black_Body_Radiation copy.html#plancks-law",
    "href": "quantum-mechanics/Black_Body_Radiation copy.html#plancks-law",
    "title": "Black Body Radiation",
    "section": "Planck’s law",
    "text": "Planck’s law\nIn 1900 Max Planck faced the question how to avoid the ultraviolet catastrophe and describe the blackbody radiation as a whole.\n\n\n\nComparison between blackbody radiation at 3000 K (solid line) and radiation as described through the Wien approximation (dashed line) and the Rayleigh-Jeans law (dash-dotted line).\n\n\nHe proposed a revolutionary hypothesis called Quantum Hypothesis or Planck’s Postulate. As Rayleigh and Jeans before, Planck assumed the modes within a cavity resonator as oscillations. However, in contrast to the classical approach allowing every oscillator to acquire any arbitrary small value of energy (\\(W_{\\nu} = k \\cdot T\\)), Planck postulated that these oscillators are allowed to acquire energy only in particular quanta of energy. Those quanta depend on the frequency \\(\\nu\\) of the eigen-oscillation and are multiples of a smallest quantum of energy. Thus it follows\n\\[\nE \\left( \\nu \\right) = n \\cdot E_{\\mathrm{ph}} \\left( \\nu \\right) = n \\cdot h \\cdot \\nu \\mathrm{.}\n\\]\nThe letter \\(h\\) was initially chosen as help constant, but shortly after the success of Planck’s Postulate the constant was renamed as Planck’s Constant with the value\n\\[\nh = 6.626 \\ldots \\cdot 10^{-34} \\; \\mathrm{Js}.\n\\]\nThis event of postulating a smallest quantum of energy is often referred to as the birth of quantum mechanics. Nowadays we can define the smallest quantum of the electromagnetic field bearing the energy \\(h \\cdot \\nu\\) as Photon. The energy of an eigen-oscillation with \\(n\\) photons is then\n\\[\nW_{\\nu} = n \\cdot h \\cdot \\nu\\mathrm{.}\n\\]\nIf we now consider thermal equilibrium, the likelihood \\(p \\left( W_{\\nu} \\right)\\) of this particular eigen-oscillation bearing the energy of \\(W_{\\nu}\\) (meaning that this particular eigenstate is occupied by \\(n\\) photons) is proportional to the Boltzmann factor \\(\\mathrm{e}^{-W_{\\nu}/\\left( k\\cdot T \\right)}\\)\n\\[\np \\left( W_{\\nu} \\right) = \\frac{\n\\mathrm{e}^{- \\frac{n \\cdot h \\cdot \\nu}{k \\cdot T}}\n}{\n\\sum_{n=0}^{\\infty} \\mathrm{e}^{- \\frac{n \\cdot h \\cdot \\nu}{k \\cdot T}}\n}\n\\]\nSince we did calculate a likelihood, the relation \\(\\sum_{n=0}^{\\infty} p \\left(n \\cdot h \\cdot \\nu \\right) = 1\\) holds true. Furthermore, we can calculate the average energy per eigen-oscillation as the energy of this particular oscillation weighted with the likelihood that this particular eigenstate is occupied with this particular number of photons. The averaged energy per eigen-oscillation then reads as \\(\\bar{W}_{\\nu} = \\sum_{n=0}^{\\infty} p\\left( nh\\nu \\right) n \\, h\\, \\nu\\) and further\n\\[\n\\bar{W}_{\\nu} = \\frac{n \\cdot \\nu}{\\mathrm{e}^{+\\frac{n \\cdot h \\cdot \\nu}{k \\cdot T}} -1} \\mathrm{.}\n\\]\nThe spectral energy density of a cavity radiator then is given through\n\\[\n\\omega \\left( \\nu,T \\right) = n\\left(\\nu \\right) \\cdot \\bar{W_{\\nu}} \\left( \\nu,T \\right)\n\\]\nwhich leads us to the famous Planck’s formula\n\\[\n\\omega \\left( \\nu,T \\right) \\mathrm{d} \\nu = \\frac{8 \\pi h \\nu^3}{c_0^3} \\, \\frac{\\mathrm{d} \\nu}{\\mathrm{e}^{\\frac{h \\nu}{k T}} -1} \\mathrm{.}\n\\]\nHere \\(\\omega \\left( \\nu,T \\right) \\mathrm{d}\\nu\\) represents the spectral distribution of the energy density per frequency interval; its unit is \\(\\left[ \\omega \\left( \\nu,T \\right) \\right] = \\mbox{Jsm}^3\\). The radiance of the area element \\(\\mathrm{d}A\\) emitted into the solid angle \\(\\mathrm{d} \\Omega\\) then is\n\\[\n\\begin{eqnarray}\nS^{\\ast}_{\\nu} \\mathrm{d} \\nu \\mathrm{d} \\Omega & = & \\frac{c_0}{4\\pi} \\omega_{\\nu} \\left(\\nu,T\\right) \\, \\mathrm{d} \\nu \\, \\mathrm{d} \\Omega\\\\\n{} & = & \\frac{2 h \\nu^3}{c_0^2} \\, \\frac{\\mathrm{d} \\nu \\, \\mathrm{d} \\Omega}{\\mathrm{e}^{\\frac{h \\nu}{k T}} -1} \\mathrm{.}\n\\end{eqnarray}\n\\]\nSo far we have expressed Planck’s law in dependence of the frequency \\(\\nu\\). With the aid of the relation \\(\\lambda = c/\\nu\\) we can also express Planck’s law in dependence of the wavelength. Therefore, we have to pay attention to \\(\\mathrm{d}\\lambda = -\\left( c / \\nu^2 \\right) \\mathrm{d} \\nu\\). Then, we can describe the spectral energy density\n\\[\n\\omega \\left( \\lambda,T \\right) \\mathrm{d} \\lambda = \\frac{8 \\pi h c_0}{\\lambda^5} \\, \\frac{\\mathrm{d} \\lambda}{\\mathrm{e}^{\\frac{h c_0}{\\lambda k T}} -1}\n\\]\nand the radiance \\[\nS^{\\ast}_{\\lambda} \\mathrm{d} \\lambda \\mathrm{d} \\Omega = \\frac{2 h c^2}{\\lambda^5} \\, \\frac{\\mathrm{d} \\lambda \\, \\mathrm{d} \\Omega}{\\mathrm{e}^{\\frac{h c}{\\lambda k T}} -1}\n\\]\nas functions of \\(\\lambda\\) and \\(T\\).\n\n\n\nBlackbody radiation as described through Planck’s law of radiation at different temperatures."
  },
  {
    "objectID": "quantum-mechanics/Particle_Nature_Of_Light_old.html",
    "href": "quantum-mechanics/Particle_Nature_Of_Light_old.html",
    "title": "Particle Nature of Light",
    "section": "",
    "text": "At the beginning of the 20th century, experimental findings emerged that could not be explained by the electromagnetic theory of light. Several key experiments gave rise to the development of quantum physics:\nThese findings revealed that both classical mechanics (which predicts defined particle trajectories based on initial conditions) and classical electromagnetic wave theory (based on Maxwell’s equations) needed revision for describing atomic-scale phenomena.\nDuring the 18th century, there was a fundamental dispute about the nature of light. Newton proposed a particle-like character based on straight propagation and refraction. In contrast, Huygens proposed a wave-like character based on interference and diffraction. The wave interpretation seemed confirmed when Heinrich Hertz discovered electromagnetic waves, with light being interpreted as a special spectral region governed by Maxwell’s equations. We will focus on the photoelectric effect, which demonstrates light’s particle properties."
  },
  {
    "objectID": "quantum-mechanics/Particle_Nature_Of_Light_old.html#the-hallwachs-and-photoelectric-effect",
    "href": "quantum-mechanics/Particle_Nature_Of_Light_old.html#the-hallwachs-and-photoelectric-effect",
    "title": "Particle Nature of Light",
    "section": "The Hallwachs and Photoelectric Effect",
    "text": "The Hallwachs and Photoelectric Effect\n\nHallwachs and Lennard\nIn 1888 Wilhelm Hallwachs published an experiment with charged foils connected to a metal plate which was irradiated with ultraviolet light (we did this experiment in the last lecture before Christmas). If the foils and the plate are negatively charged and electrically isolated against the surrounding, the charge does decrease upon irradiation with ultraviolet light. In contrast, if the system is positively charged, the charge does not decrease. Hallwachs concluded that the light is responsible for negative charges leaving the metal plate.\n\n\n\nScheme of the apparatus used by Hallwachs (left). Scheme of the apparatus used by Lennard and the corresponding photocurrent \\(I_{\\mathrm{ph}}\\) (center). From the onset voltage \\(U_0\\) one can calculate the work function \\(W_{\\mathrm{a}}\\) as intercept and Planck’s constant \\(h\\) as part of the slope (right).\n\n\nLater in 1902 Lennard measured the photocurrent between two plates in vacuum. The current set in already at a negative voltage \\(U_0\\) between the plates, increased with rising voltage, and reached a plateau which depended only on the light’s intensity. He concluded:\n\nThe electrons must bear a minimum energy in order to overcome the oppositely directed electric field, \\(E_{\\mathrm{kin}} \\le e \\cdot U_0\\).\nThe kinetic energy \\(m v^2/2\\) of the photoelectrons depends on the frequency \\(\\nu\\) of the light, not on the light’s intensity.\nThe number of photoelectrons is proportional to the light’s intensity.\nThere is no delay between light irradiation and electron emission.\n\n\n\nPhotoelectric Effect\n\nExpectations for Waves\nIf we assume a fully wave-like behavior of light, then light with a radiation power of \\(P_{\\mathrm{L}}\\) might hit a surface with an area \\(A\\) and shares its energy equally between all electrons. For a penetration depth of \\(\\Delta z \\approx \\lambda\\) and a density of the conducting electrons of \\(N\\), then every conducting electron gets on average the energy of\n\\[\n\\bar{\\Delta W} = \\frac{P_\\mathrm{L}}{N \\cdot A \\cdot \\lambda} \\; \\Delta t\n\\] within the time interval \\(\\Delta t\\). Thus, the work function can be compensated in the case of\n\\[\n\\Delta t &gt; W_{\\mathrm{a}} \\; \\frac{N \\cdot A \\cdot \\lambda}{P_\\mathrm{L}} \\mathrm{.}\n\\]\nLet us consider a zinc plate with a work function of \\(W_{\\mathrm{a}} = 4 \\, \\mathrm{eV}\\) and a light source with a spectral filter \\(\\lambda = 250 \\; \\mathrm{nm}\\) emitting a power of \\(P_\\mathrm{L} = 1 \\; \\mathrm{W}\\) at a distance of \\(R = 1 \\; \\mathrm{m}\\) away from our zinc plate, there will be an intensity of\n\\[\nI_{\\mathrm{L}} = \\frac{P_\\mathrm{L}}{4\\pi R^2} \\approx 8\\cdot 10^{-6} \\; \\frac{\\mathrm{W}}{\\mathrm{cm}^{-2}}\n\\]\nreaching the plate. For a penetration depth of \\(\\Delta z \\approx \\lambda\\) this intensity will be distributed between\n\\[\nN = 10^{23} \\cdot \\mathrm{cm}^{-3}\\cdot \\lambda = 2.5 \\cdot 10^{18} \\; \\frac{1}{{\\mathrm{cm}^{-2}}}\n\\]\nelectrons, whereas each electron acquires on average a power of\n\\[\nP_{\\mathrm{el}} = 3 \\cdot 10^{-24} \\; \\mathrm{W} = 2 \\cdot 10^{-5} \\; \\mathrm{eVs}^{-1} \\mathrm{.}\n\\]\nThus, it will take a time of \\(\\Delta t = W_{\\mathrm{a}}/P_{\\mathrm{el}} = 2 \\cdot 10^5 \\; \\mathrm{s}\\) for one electron to acquire enough energy to leave the zinc plate. This result is in clear contrast to experimental findings.\n\n\nExplanation by Einstein\nIn 1905 Einstein successfully explained these findings on the basis of the quantum model of light. According to this model every absorbed photon transfers its energy \\(h \\cdot \\nu\\) completely to one electron. The maximum kinetic energy of an electron is then governed by\n\\[\nE_{\\mathrm{kin}}^{\\mathrm{max}} = h \\cdot \\nu - W_{\\mathrm{a}} \\mathrm{,}\n\\]\nwith \\(W_{\\mathrm{a}} = -e \\left( \\phi_{\\mathrm{vac}} - \\phi \\right)\\) being the work function of the cathode material (often the vacuum work function is set to zero, \\(\\phi_{\\mathrm{vac}} = 0\\)). The work function is the amount of energy one has to compensate in order to bring one electron from bulk into vacuum against the forces binding the electron in bulk.\nThe work function determines at which frequency or wavelength the photoelectric effect occurs. Below are typical work functions for various metals:\n\n\n\nTable 1— Work functions and corresponding threshold wavelengths for various metals\n\n\n\n\n\n\n\n\n\n\nMetal\nWork Function (eV)\nThreshold Wavelength (nm)\n\n\n\n\nCesium\n1.95\n636\n\n\nPotassium\n2.30\n539\n\n\nSodium\n2.75\n451\n\n\nCalcium\n3.20\n388\n\n\nZinc\n4.31\n288\n\n\nCopper\n4.70\n264\n\n\nSilver\n4.73\n262\n\n\nPlatinum\n6.35\n195\n\n\n\n\n\n\nThese values show why alkali metals like cesium and potassium are particularly suitable for photoelectric devices, as they respond to visible light, while metals like platinum require ultraviolet radiation.\nSince one can determine the maximum kinetic energy \\(E_{\\mathrm{kin}}^{\\mathrm{max}} = -e\\cdot U_0\\) (\\(U_0 &lt; 0\\)) from the voltage \\(U_0\\) at which the photocurrent sets in and\n\\[\n-e\\cdot U_0 = h\\cdot\\nu -  W_{\\mathrm{a}} \\mathrm{,}\n\\]\none is able to determine the work function on the basis of the intercept of the \\(-e\\cdot U_0\\) vs. \\(h\\cdot\\nu\\) curve and Planck’s constant from the slope of the curve.\nOne example for an experiment proving Einstein’s explanation of the photoeffect was provided by von Joffé and Dobronrawov in 1925. They used small, charged bismuth beads held within a Millikan capacitor and irradiated those beads with low-dose X-rays. Every change of the overall charge of the beads interferes with the equilibrium in the capacitor, and can be observed by means of a change of the bead position. Using a radiation power of \\(P = 10^{-12} \\; \\mathrm{W}\\) meaning an emission rate of \\(\\dot{N} = 10^3\\) photons per second with an energy of \\(h \\cdot \\nu = 10^4 \\; \\mathrm{eV}\\) on average every 30 minutes a change of the bead charge was detected. The number of photons arriving at one bead within a time interval \\(\\Delta t\\) is \\(Z = \\dot{N} \\cdot \\Delta t \\cdot \\mathrm{d} \\Omega/ \\left( 4\\pi \\right)\\), with \\(\\mathrm{d} \\Omega\\) as the solid angle covered by the bead. The calculated time constant of \\(Z\\) was in well agreement with the observed rate of the charge alteration. If we again assume a wave-like explanation of the photoeffect, the emitted power within the according solid angle will be absorbed by the bead and distributed between all its electrons. As a consequence the bead as a whole will have collected enough energy in order to release an electron within the same period of time. However it cannot be explained how all \\(10^{12}\\) atoms are supposed to combine their energy in one, single electron at the very same time."
  },
  {
    "objectID": "quantum-mechanics/Particle_Nature_Of_Light_old.html#the-compton-effect",
    "href": "quantum-mechanics/Particle_Nature_Of_Light_old.html#the-compton-effect",
    "title": "Particle Nature of Light",
    "section": "The Compton Effect",
    "text": "The Compton Effect\nAnother example for demonstrating the corpuscle (particle-like) character of light is the Compton effect. If an arbitrary material is irradiated with X-rays of wavelength \\(\\lambda_0\\), one can detect scattered light with the same wavelength \\(\\lambda_0\\) but also scattered light with a greater wavelength \\(\\lambda_{\\mathrm{S}} &gt; \\lambda_0\\). Moreover, the wavelength of the scattered light seems to depend much stronger on the scattering angle than on the scattering material.\n\nThis phenomenon can be explained by means of the photon model and inelastic impact. Every photon bears an energy of \\(E = h \\cdot \\nu = \\hbar \\cdot \\omega\\) and a momentum of \\(p = h/\\lambda = \\hbar \\cdot k\\). If a photon impacts into a weakly bound electron with a binding energy much smaller than the photon energy (\\(E_\\mathrm{B} \\le E\\)), we can neglect the binding energy and assume the electron as free electron. In addition we simplify further and assume the electron as being at rest. During the collision event\n\\[\nh \\nu_0 + \\mathrm{e}^{-} \\longrightarrow h \\nu_{\\mathrm{S}} + \\mathrm{e}^{-} + E_{\\mathrm{kin}}\n\\]\nenergy and momentum are conserved. The law of conservation of energy then reads as\n\\[\nh \\, \\nu_0 = h \\, \\nu_\\mathrm{s} + E_{\\mathrm{kin}}^{\\mathrm{e}}\n\\]\nwith \\(E_{\\mathrm{kin}}^{\\mathrm{e}}\\) as the relativistic kinetic energy of the electron\n\\[\nE_{\\mathrm{kin}}^{\\mathrm{e}} = \\frac{m_0 c^2}{\\sqrt{1-\\beta^2}} - m_0 c^2\n\\]\nand \\(\\beta = v/c\\). If we ascribe a momentum like\n\\[\n\\vec{p} = \\hbar \\, \\vec{k}\n\\]\nwith\n\\[\n\\left| \\vec{p} \\right| = \\hbar \\, \\left| \\vec{k} \\right| = h \\frac{1}{\\lambda}\n\\]\nto the photon, we can formulate the law of momentum conservation as follows,\n\\[\n\\hbar \\, \\vec{k_0} = \\hbar \\, \\vec{k_{\\mathrm{s}}} + \\vec{p^{\\mathrm{e}}}\n\\]\nwith\n\\[\n\\vec{p^{\\mathrm{e}}} = \\frac{m_0 \\vec{v}}{\\sqrt{1-\\beta^2}} \\mathrm{.}\n\\]\nIf we isolate the square of the momentum of the electron, we obtain an equation depending on the squared difference between the wavevectors of the incident and scattered photon. Calculating this difference leads to a scalar product between these two vectors and necessitates the introduction of the angle between the propagation direction of the incident and scattered photon. We denote this angle as \\(\\phi\\),\n\\[\n\\begin{eqnarray}\n\\frac{m_0^2 v^2}{1-\\beta^2} & = & \\hbar^2 \\left( \\vec{k_0} - \\vec{k_{\\mathrm{s}}} \\right)^2\\\\\n{} & = & \\hbar^2 \\left( k_0^2 + k_{\\mathrm{s}}^2 + 2 k_0 k_{\\mathrm{s}} \\cos \\left( \\varphi \\right) \\right)^2\\\\\n{} & = & \\frac{h^2}{c^2} \\left( \\nu_0^2 + \\nu_{\\mathrm{s}}^2 + 2 \\nu_0 \\nu_{\\mathrm{s}} \\cos \\left( \\varphi \\right) \\right)^2\n\\end{eqnarray}\n\\]\nFrom the law of energy conservation we get\n\\[\n\\frac{m_0^2 v^2}{1-\\beta^2} = \\frac{h^2}{c^2} \\left( \\nu_0 - \\nu_{\\mathrm{s}} \\right)^2 + 2 h m_0 \\left( \\nu_0 - \\nu_{\\mathrm{s}}\\right) \\mathrm{,}\n\\]\nwhich we can compare with the law of momentum conservation and get\n\\[\n\\nu_0 - \\nu_{\\mathrm{s}} = \\frac{h}{m_0 c^2} \\,  \\nu_0 \\, \\nu_{\\mathrm{s}} \\, \\left(1- \\cos \\left( \\varphi \\right) \\right) \\mathrm{.}\n\\]\nNow making use of \\(1- \\cos \\left( \\varphi \\right) = 2 \\sin^2 \\left( \\varphi/2 \\right)\\) and \\(\\nu = c/\\lambda\\) we achieve the Compton formula\n\\[\n\\begin{eqnarray}\n\\lambda_{\\mathrm{S}} & = & \\lambda_0 + 2 \\frac{h}{m_0 c} \\sin^2 \\left( \\varphi/2 \\right)\\\\\n{} & = & \\lambda_0 + 2 \\lambda_{\\mathrm{C}} \\sin^2 \\left( \\varphi/2 \\right)\\\\\n\\end{eqnarray}\n\\]\nwith \\(\\lambda_{\\mathrm{C}}\\) denoting the Compton wavelength of the electron,\n\\[\n\\lambda_{\\mathrm{C}} = \\frac{h}{m_0 c} = 2.4262 \\cdot 10^{-12} \\; \\mathrm{m.}\n\\]\nThe Compton wavelength is a constant and represents the change of the wavelength \\(\\Delta \\lambda = \\lambda_{\\mathrm{S}} - \\lambda_0\\) at a scattering angle of \\(\\varphi = 90^{\\circ}\\). Results from experiments almost perfectly coincide with the Compton formula. Furthermore the ratio between the wavelengths\n\\[\n\\frac{\\lambda_{\\mathrm{S}}}{\\lambda_0} = \\frac{h \\nu_0}{m_0 c^2}\n\\]\nrepresents the ratio between the energy of the incident photon and the energy of the electron at rest. Thus, if we know the mass of the electron, we can determine \\(\\varphi\\) and \\(\\lambda_{\\mathrm{S}}\\) (and therefore \\(\\lambda_{\\mathrm{C}}\\)) and calculate \\(h\\).\n\n\n\n\n\n\nFigure 1— Compton Scattering of X-rays"
  },
  {
    "objectID": "quantum-mechanics/Particle_Nature_Of_Light_old.html#properties-of-photons",
    "href": "quantum-mechanics/Particle_Nature_Of_Light_old.html#properties-of-photons",
    "title": "Particle Nature of Light",
    "section": "Properties of Photons",
    "text": "Properties of Photons\nHaving established the particle nature of light through the photoelectric and Compton effects, we can now summarize the key properties of photons. These quantum particles of electromagnetic radiation exhibit remarkable characteristics that bridge the classical wave description of light with its quantum nature. Photons are massless particles that always travel at the speed of light in vacuum, carry quantized energy and momentum, and can interact with matter through absorption and emission processes. Unlike classical particles, they cannot be brought to rest and their energy is directly proportional to their frequency. Below we examine these properties in detail.\n\nEnergy and Momentum\nEvery electromagnetic field consists of quanta of energy \\(h \\cdot \\nu\\), which we call photons. If we remember back for the cavity resonator, we can now state the energy density of the electromagnetic field \\(\\omega_{\\mathrm{em}}\\) as the density of modes \\(n\\) multiplied with the quantum of energy \\(h \\cdot \\nu\\)\n\\[\n\\omega_{\\mathrm{em}} = n \\cdot h \\cdot \\nu \\mathrm{.}\n\\]\nWe can further comprehend the flux \\(I = \\varepsilon_0 c E^2\\) of an electromagnetic wave as a particle flux \\(\\dot{N}\\) of photons\n\\[\nI = \\dot{N} h \\nu\n\\]\nwith \\(\\dot{N} = n \\cdot c\\). Therefore, if a light wave with a flux of \\(I\\) is shining on an area is tantamount with a particle flux of photons reaching this area.\nAs demonstrated on the basis of the Compton effect, every photon bears a momentum \\(\\vec{p} = \\hbar \\cdot \\vec{k}\\) with the magnitude \\(\\left| \\vec{p} \\right| = p = h \\nu / c\\). As a consequence, if we are able to assign an energy density to the density of modes, we are also able to assign a momentum density,\n\\[\n\\pi_{\\mathrm{em}} = n \\cdot \\hbar \\cdot k \\mathrm{.}\n\\]\nThen, the relation between the energy density \\(\\omega_{\\mathrm{em}}\\) of an electromagnetic wave and the momentum density \\(\\pi_{\\mathrm{em}}\\) of the very same wave reads as\n\\[\n\\omega_{\\mathrm{em}} = c \\cdot \\pi_{\\mathrm{em}} {.}\n\\]\n\n\nAngular Momentum\nConcerning the angular momentum of photons, if a free atom absorbs a photon, the angular momentum of the atom is altered by \\(\\hbar\\). Thus, the law of the conservation of the angular momentum predicts that a photon does have an angular momentum of \\(\\hbar\\), independent of its energy \\(h \\cdot \\nu\\). If left-handed circular polarized light (\\(\\sigma^{+}\\)) propagating along \\(z\\) is absorbed by a free atom, its angular momentum \\(J_z\\) is changed by \\(\\Delta J_z = + \\hbar\\). In the case of right-handed circular polarized light (\\(\\sigma^{-}\\)), the change of the angular momentum of the electron is negative \\(\\Delta J_z = - \\hbar\\). We can conclude, that for \\(\\sigma^{+}\\)-polarized light the vector of the angular momentum is oriented along the direction of propagation, whereas for \\(\\sigma^{-}\\)-polarized light the vector of the angular momentum is oriented against the direction of propagation. Since the direction of propagation is determined through the wavevector, we can conclude for the photon’s angular momentum\n\\[\n\\vec{L}_{Ph} = \\pm \\hbar \\, \\frac{\\vec{k}}{\\left| \\vec{k} \\right|}\n\\]\nLinearly polarized light can be comprehended as superposition of \\(\\sigma^{+}\\)- and \\(\\sigma^{-}\\)-polarized light to equal parts. Thus the angular momentum of linearly polarized light adds up to \\(0\\).\n\n\nEffect of Gravity on Photons\nFrom special relativity we know that mass is affected by the relative motion of reference systems:\n\\[\nm = \\frac{1}{\\sqrt{1-\\left( \\frac{v}{c}\\right)^2}} \\, m_0\n\\]\nOnly particles with a rest mass \\(m_0 = 0\\) can travel at the speed of light, which is why photons must have zero rest mass. For the energy of a photon, we find:\n\\[\n\\begin{eqnarray}\nE & = & \\sqrt{p^2c^2 + m_0^2 c^4}\\\\\n{} & = & p c\\\\\n{} & = & \\frac{h}{\\lambda} c\\\\\n{} & = & h \\nu\n\\end{eqnarray}\n\\]\nin accordance with previous energy and momentum considerations. If we assign an effective mass \\(m\\) to the photon:\n\\[\nm = \\frac{E}{c^2} = \\frac{h \\nu}{c^2}\n\\]\nthis photon must perform work when traveling in a gravitational field. Moving from position \\(\\vec{r_1}\\) with gravitational potential \\(\\Phi(\\vec{r_1})\\) to position \\(\\vec{r_2}\\) with potential \\(\\Phi(\\vec{r_2})\\), the work is:\n\\[\nW = m \\cdot \\Delta \\Phi = \\frac{h \\nu}{c^2} \\left( \\Phi \\left( \\vec{r_2} \\right) - \\Phi \\left( \\vec{r_1} \\right) \\right)\n\\]\nBy energy conservation, the photon’s energy \\(h\\nu\\) must change by this amount, leading to a frequency shift:\n\\[\n\\nu_2 = \\nu_1 \\left(1-\\frac{\\Delta \\phi}{c^2} \\right)\n\\]\nor in relative terms:\n\\[\n\\frac{\\Delta \\nu}{\\nu} = \\frac{\\Delta \\Phi}{c^2}\n\\]\nThis remarkable prediction - that photons experience a redshift (longer wavelength, smaller frequency, lower energy) when rising in a gravitational field - was first experimentally verified by Pound and Rebka in 1959. Using the Mössbauer effect, they measured the frequency shift of gamma rays from \\(^{57}\\)Fe (14.4 keV) traveling vertically over a height of 22.5 meters at Harvard University. The expected relative frequency shift was extremely small:\n\\[\n\\frac{\\Delta \\nu}{\\nu} \\approx 2.5 \\times 10^{-15}\n\\]\n\n\n\n\n\n\nThe Mößbauer Effect in the Pound-Rebka Experiment\n\n\n\n\n\nThe detection of gravitational redshift requires extremely precise frequency measurements (\\(\\Delta \\nu/\\nu \\approx 10^{-15}\\)). This was made possible by the Mößbauer effect, which allows for recoil-free emission and absorption of gamma rays in crystals.\nIn free atoms, the emission or absorption of a gamma ray causes recoil, shifting the photon energy by about \\(10^{-3}\\) eV. For a gamma ray of energy \\(E_\\gamma\\), the recoil energy is:\n\\[E_R = \\frac{E_\\gamma^2}{2Mc^2}\\]\nwhere \\(M\\) is the mass of the nucleus. However, in a crystal lattice, the nucleus is not free to recoil. Instead, the recoil momentum can be transferred to the entire crystal if:\n\nThe nucleus is tightly bound in the crystal lattice\nThe recoil energy is less than the energy of the lowest lattice vibration (phonon)\nThe entire crystal acts as a single quantum mechanical system\n\nIn this case, the effective mass \\(M\\) in the recoil energy formula becomes the mass of the entire crystal, making \\(E_R\\) negligible. For \\(^{57}\\)Fe nuclei in a crystal:\n\nGamma ray energy: 14.4 keV\nNatural linewidth: \\(\\approx 10^{-8}\\) eV\nNo recoil broadening\nExtremely sharp resonance\n\nThis allows for the detection of the tiny frequency shifts caused by gravity over the 22.5 m height difference in the Harvard tower.\n\n\n\nThe experiment confirmed Einstein’s prediction to about 1% accuracy, demonstrating that even massless photons are affected by gravity, with their energy decrease exactly matching the increase in gravitational potential energy \\(m\\Delta\\Phi\\) where \\(m = h\\nu/c^2\\). This result was not only the first laboratory confirmation of gravitational redshift but also provided strong support for the equivalence principle and the gravitational time dilation predicted by general relativity.\n\n\n\nSchematic of the Pound-Rebka experiment showing gamma ray source and detector separated vertically by 22.5 meters\n\n\nThe success of this experiment shows how quantum mechanics and general relativity make consistent predictions about the behavior of photons in gravitational fields, though a complete quantum theory of gravity remains one of physics’ greatest challenges."
  },
  {
    "objectID": "geometrical-optics/refraction-total-internal-reflection.html",
    "href": "geometrical-optics/refraction-total-internal-reflection.html",
    "title": "Refraction and Total Internal Reflection",
    "section": "",
    "text": "Historical Context of Refraction\n\n\n\n\n\nThe understanding of refraction has evolved over centuries, with contributions from various cultures and scientific traditions. This timeline highlights key milestones in the discovery and formalization of refraction, showcasing how our comprehension of this fundamental optical phenomenon has deepened over time:\n\nAncient Greece (3rd century BCE): Euclid noticed that a stick partially submerged in water appears bent. Archimedes studied the refraction of light in water.\nAncient Rome (1st century CE): Ptolemy conducted experiments on refraction and compiled tables of refraction angles for different media.\nIslamic Golden Age (10th-11th centuries): Ibn Sahl (940-1000) discovered the law of refraction, describing it geometrically. Alhazen (965-1040) studied lenses and the human eye, contributing significantly to optics.\nMiddle Ages: Robert Grosseteste (1175-1253) and Roger Bacon (1214-1294) studied refraction and its application to lenses.\nRenaissance: Thomas Harriot (1560-1621) rediscovered the law of refraction but didn’t publish his findings.\n17th Century: Willebrord Snellius (1580-1626) derived the mathematical law of refraction (Snell’s law) around 1621. René Descartes (1596-1650) independently derived and published the law of refraction in 1637. Pierre de Fermat (1607-1665) derived the law of refraction using his principle of least time.\n19th Century: Augustin-Jean Fresnel (1788-1827) developed the wave theory of light, explaining refraction in terms of changes in wave speed.\n20th Century: The quantum mechanical understanding of light, which emerged in the early 20th century, significantly impacted our view of refraction. Max Planck’s work on black body radiation in 1900 and Albert Einstein’s explanation of the photoelectric effect in 1905 laid the groundwork for the quantum nature of light. This quantum perspective provided a complementary explanation to the wave theory, describing refraction in terms of photons interacting with the atoms in the medium. While this quantum view offers insights into certain aspects of refraction, it’s important to note that both the wave and particle descriptions of light are necessary for a complete understanding of optical phenomena.\n\n\n\n\nThe law of refraction is the second important law of geometrical optics. It relates the refractive index \\(n_1\\) and angle of incidence \\(\\theta_1\\) on one side of an interface to the refractive index \\(n_2\\) and angle of refraction \\(\\theta_2\\) on the other side. Both the law of reflection and the law of refraction can be derived from more fundamental principles such as Fermat’s principle of least time and are consistent with the conservation of energy. Their relation to momentum is more complex and involves considering the interaction of light with the medium at an atomic level. These laws provide a mathematical framework for predicting how light behaves when it encounters interfaces between different media, forming the basis for understanding a wide range of optical phenomena and the design of optical devices.\n\n\nThe refractive index \\(n\\) is a material constant representing the factor by which the speed of light is reduced in the medium compared to its speed in vacuum. For most natural materials and visible light, the refractive index is \\(n \\ge 1\\), as light typically travels slower in media than in vacuum. However, in certain special cases—such as for X-rays in some materials or in engineered metamaterials—the refractive index can be less than 1 or even negative. Understanding these exotic cases requires a deeper exploration of the electromagnetic properties of materials and the origin of the refractive index, which we will address later.\n\n\n\n \n\n\n\n\n\n\nLaw of Refraction (Snell’s Law)\n\n\n\nThe law of refraction (Snell’s law) is given for the above sketch by the equation:\n\\[\nn_1 \\sin(\\theta_1)=n_2 \\sin(\\theta_2)\n\\]\n\n\nYou can explore the law of refraction using the interactive visualization below. The visualization shows a light ray incident on an interface between two media with different refractive indices. You can adjust the angle of incidence and the refractive index of the first medium to see how the angle of refraction changes according to Snell’s law.\n\n\n\nIncident Angle: 45°\n\nRefractive Index n₁: 1.0\n\nRefractive Index n₂: 1.5\n\n\n\n\nSnell’s law leads to some general patterns in the behavior of light rays at interfaces, which are worth remembering. Consider these two cases:\n\nWhen light moves from a medium with lower refractive index to one with higher refractive index (\\(n_1 &lt; n_2\\)):\n\nThe refracted ray bends towards the normal (optical axis)\nThe angle of refraction is smaller than the angle of incidence (\\(\\theta_2 &lt; \\theta_1\\))\n\nWhen light moves from a medium with higher refractive index to one with lower refractive index (\\(n_1 &gt; n_2\\)):\n\nThe refracted ray bends away from the normal (optical axis)\nThe angle of refraction is larger than the angle of incidence (\\(\\theta_2 &gt; \\theta_1\\))\n\n\nFigure 1 illustrates these principles with three plots showing how the refracted angle changes with the incident angle for two common interface scenarios: glass-to-air and air-to-glass. These plots clearly demonstrate the different behaviors described above.\n\n\n\nCode\ndef snell(n1, n2, theta1):\n    sin_theta2 = n1 * np.sin(theta1) / n2\n    theta2 = np.arcsin(np.clip(sin_theta2, -1, 1))\n    theta2[sin_theta2 &gt; 1] = np.nan\n    return theta2\n\nfig, ax = plt.subplots(figsize=(4, 4))\n\ntheta1 = np.linspace(0, np.pi/2, 1000)\n\ntheta2_1_to_1_5 = snell(1.0, 1.5, theta1)\ntheta2_1_5_to_1 = snell(1.5, 1.0, theta1)\ntheta2_1_to_1 = snell(1.0, 1.0, theta1)\n\nax.plot(np.degrees(theta1), np.degrees(theta2_1_to_1_5), color='blue')\nax.plot(np.degrees(theta1), np.degrees(theta2_1_5_to_1), color='red')\nax.plot(np.degrees(theta1), np.degrees(theta2_1_to_1), color='green', linestyle='--')\n\nax.set_xlabel(r'$\\theta_1$ [°]')\nax.set_ylabel(r'$\\theta_2$ [°]')\nax.set_xlim(0, 90)\nax.set_ylim(0, 90)\n\nax.plot([0, 90], [0, 90], color='gray', linestyle=':', label='y=x')\n\nax.annotate(r'$\\frac{n_2}{n_1}=1.5$', xy=(60, 35), xytext=(50, 20),\n            arrowprops=dict(arrowstyle='-&gt;'), color='blue')\nax.annotate(r'$\\frac{n_1}{n_2}=1.5$', xy=(30, 50), xytext=(10, 70),\n            arrowprops=dict(arrowstyle='-&gt;'), color='red')\nax.annotate(r'$\\frac{n_2}{n_1}=1$', xy=(45, 45), xytext=(65, 50),\n            arrowprops=dict(arrowstyle='-&gt;'), color='green')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nFigure 1— Snell’s law for different combinations of refractive indices. The plots show the relationship between incident angle (\\(\\theta_1\\)) and refracted angle (\\(\\theta_2\\)) for three scenarios: (a) light passing from air to glass, (b) light passing from glass to air, and (c) a comparison of both cases. Note how the curves differ when light moves into a medium with higher refractive index versus a lower refractive index.\n\n\n\n\n\n\n\n\nThe above diagram reveals a special case occurring when \\(n_1 &gt; n_2\\). Under these conditions, we can increase the incident angle \\(\\theta_1\\) until the outgoing angle reaches \\(\\theta_2 = \\frac{\\pi}{2}\\). At this point, the refracted ray would be traveling along the interface between the two media. For any incident angle \\(\\theta_1\\) larger than this critical angle, there is no refracted ray at all; instead, we observe only a reflected ray. This phenomenon, known as total internal reflection, occurs despite the fact that the material with refractive index \\(n_2\\) is completely transparent.\nLet’s formalize this concept mathematically. Using Snell’s law and setting \\(\\theta_2 = \\frac{\\pi}{2}\\), we obtain the equation for the critical angle \\(\\theta_c\\):\n\\[\\theta_1 = \\theta_c = \\sin^{-1}\\left(\\frac{n_2}{n_1}\\right)\\]\nNote that the \\(\\sin^{-1}()\\) function requires an argument \\(\\le 1\\), which is why this phenomenon only occurs when \\(n_2 &lt; n_1\\).\nIt’s important to understand that during total internal reflection, all of the light energy is reflected back into the first medium, hence the term ‘total’. However, electromagnetic optics reveals an interesting subtlety: an evanescent wave penetrates a short distance into the second medium, though it doesn’t propagate energy across the boundary.\nWhen the incident angle exceeds the critical angle, Snell’s law as we’ve written it no longer applies. Instead, we observe perfect reflection, where the angle of reflection equals the angle of incidence, just as in regular reflection from a mirror. This reflection occurs without any loss of energy to the second medium, making it an extremely efficient process.\n \n\n\n\n\n\n\nTotal Internal Reflection\n\n\n\nTotal internal reflection occurs when light is passing from higher refractive index to lower refractive index materials for incidence angle larger than a critical angle\n\\[\n\\theta_c=\\sin^{-1}\\left (\\frac{n_2}{n_1}\\right )\n\\]\n\n\nWe can demonstrate total internal reflection very easily with a water basin, for example, where we couple in light from a laser from the side.\n \nBut you could try that yourself also in the bath tub diving below the water surface.\nTotal internal reflection has numerous practical applications:\n\nFiber optic communications: Light signals can travel long distances with minimal loss through optical fibers.\nOptical instruments: Prisms in binoculars and telescopes use total internal reflection to manipulate light paths.\nGemstones: The sparkle of diamonds is enhanced by total internal reflection trapping light within the stone.\nMedical endoscopes: Total internal reflection helps guide light through flexible tubes for internal imaging.\n\nOptical Fibers and Total Internal Reflection\nTotal internal reflection plays a crucial role in modern telecommunications, particularly in optical fibers, which are also part of many experimental setups. These fibers are essentially ultra-thin glass wires, ranging in diameter from a few micrometers to several hundred micrometers, designed to transport light over long distances with minimal loss.\nThe structure of an optical fiber is key to its function:\n\nCore: A central glass core with a refractive index \\(n_1\\)\nCladding: A surrounding layer with a slightly lower refractive index \\(n_2\\)\n\nThis difference in refractive indices is what allows total internal reflection to occur within the fiber.\n \nFor light to propagate effectively through the fiber, it must enter at an angle that ensures total internal reflection at the core-cladding interface. This leads to the concept of the acceptance angle, \\(\\theta_a\\), which is the maximum angle at which light can enter the fiber and still undergo total internal reflection.\nTo characterize this acceptance angle, optical engineers use a parameter called the Numerical Aperture (NA).\n\n\n\n\n\n\nNumerical Aperture\n\n\n\nThe Numerical Aperture of a fiber is defined as the sine of the maximum acceptance angle:\n\\[\\begin{equation}\nNA = \\sin(\\theta_a) = \\sqrt{n_1^2 - n_2^2}\n\\end{equation}\\]\n\n\nThis equation relates the NA directly to the refractive indices of the core and cladding. The derivation of this formula involves applying Snell’s law at the air-fiber interface and at the core-cladding interface, then using the condition for total internal reflection.\nIn practice, typical values for the refractive indices might be \\(n_1 = 1.475\\) for the core and \\(n_2 = 1.46\\) for the cladding. Plugging these into our equation:\n\\[\\begin{equation}\nNA = \\sqrt{1.475^2 - 1.46^2} \\approx 0.2\n\\end{equation}\\]\nThis means that light entering the fiber within a cone of about 11.5° (arcsin(0.2)) from the fiber’s axis will be transmitted through the fiber via total internal reflection.\nThe NA is an important parameter in fiber optic design:\n\nIt determines the light-gathering ability of the fiber.\nIt affects the fiber’s bandwidth and its susceptibility to certain types of signal distortion.\nIt influences how easily the fiber can be coupled to light sources and other fibers.\n\nOptical fibers come in various types, each optimized for different applications. Some fibers are designed to transmit light over long distances with minimal loss, while others are engineered for specific wavelengths or to guide light in unusual ways. The figure below shows a few examples of optical fiber types.\n\n\n\n\n\n\nFigure 2— Rendering of different optical fibers types (from left to right): Hollow core optical fiber, hollow core bragg fiber, photonic crystal fiber, conventional fiber\n\n\n\n\n\n\nWhile before we have considered Fermat’s principle for the special case of refraction and light propagation in a homogeneous medium, we can define a more general version of it correponding to the following situation also involving an inhomogeneous refractive index \\(n(\\vec{r})\\).\n\n\n\n\n\n\nFigure 3— Sketch for a general description of Fermat’s principle\n\n\n\nFor this general scenario of light traveling along a path, we can define an optical path length (OPL) as\n\\[\\begin{equation}\n\\text{OPL} = \\int\\limits_{A}^{C} n(\\mathbf{r}) \\mathrm ds=0,\n\\end{equation}\\]\nwith a varying refractive index \\(n(\\mathbf{r})\\). Fermat’s Principle states that the actual path taken by the light makes the OPL stationary:\n\\[\n\\delta \\left( \\int_A^B n(\\mathbf{r}) \\, ds \\right) = 0\n\\]\nUsing the calculus of variations, this leads to the Euler-Lagrange equation for the path of light. In Cartesian coordinates, if the path is parameterized by \\(\\mathbf{r}(s) = (x(s), y(s), z(s))\\), the Euler-Lagrange equations become:\n\\[\n\\frac{d}{ds} \\left( n \\frac{d\\mathbf{r}}{ds} \\right) = \\nabla n\n\\]\nwhere \\(\\nabla n\\) is the gradient of the refractive index. This equation describes how the light ray bends in response to changes in the refractive index of the medium.\nFermat’s Principle is a cornerstone of geometrical optics and has applications in designing optical systems, understanding mirages, and analyzing the behavior of light in various media.\n\n\n\n\n\n\nFermat’s Principle and Snells Law\n\n\n\n\n\nWe would like to apply Fermat’s principle to derive Snell’s law, which is a more lengthy calculation. To do this, we consider a light ray traveling from point \\(A\\) in medium 1 (with refractive index \\(n_1\\)) to point \\(C\\) in medium 2 (with refractive index \\(n_2\\)), crossing the interface at point \\(B\\). Let the coordinates of points \\(A\\), \\(B\\), and \\(C\\) be \\((x_A, y_A)\\), \\((x_B, y_B)\\), and \\((x_C, y_C)\\), respectively. Assume the interface between the two media is at \\(y = y_B\\). The optical path length (OPL) is given by:\n\\[\n\\delta \\int_{A}^{C} n(\\vec{r}) \\, ds = 0,\n\\]\nwhere \\(n(\\vec{r})\\) is the refractive index at position \\(\\vec{r}\\), and \\(ds\\) is an infinitesimal element of the path.\nConsider a light ray traveling from point \\(A\\) in medium 1 (with refractive index \\(n_1\\)) to point \\(C\\) in medium 2 (with refractive index \\(n_2\\)), crossing the interface at point \\(B\\). Let the coordinates of points \\(A\\), \\(B\\), and \\(C\\) be \\((x_A, y_A)\\), \\((x_B, y_B)\\), and \\((x_C, y_C)\\), respectively. Assume the interface between the two media is at \\(y = y_B\\).\n\n\nThe optical path length (OPL) is given by:\n\\[\n\\text{OPL} = n_1 \\int_{A}^{B} ds_1 + n_2 \\int_{B}^{C} ds_2,\n\\]\nwhere \\(ds_1\\) and \\(ds_2\\) are the infinitesimal path lengths in media 1 and 2, respectively.\n\n\n\nThe path lengths \\(ds_1\\) and \\(ds_2\\) can be expressed in terms of the coordinates:\n\\[\nds_1 = \\sqrt{(dx_1)^2 + (dy_1)^2}, \\quad ds_2 = \\sqrt{(dx_2)^2 + (dy_2)^2}.\n\\]\nSince the interface is at \\(y = y_B\\), we have \\(dy_1 = y_B - y_A\\) and \\(dy_2 = y_C - y_B\\). The total optical path length is:\n\\[\n\\text{OPL} = n_1 \\sqrt{(x_B - x_A)^2 + (y_B - y_A)^2} + n_2 \\sqrt{(x_C - x_B)^2 + (y_C - y_B)^2}.\n\\]\n\n\n\nTo find the stationary path, we take the variation of the OPL with respect to \\(x_B\\):\n\\[\n\\delta \\text{OPL} = \\delta \\left[ n_1 \\sqrt{(x_B - x_A)^2 + (y_B - y_A)^2} + n_2 \\sqrt{(x_C - x_B)^2 + (y_C - y_B)^2} \\right] = 0.\n\\]\nTaking the derivative with respect to \\(x_B\\):\n\\[\n\\frac{\\partial}{\\partial x_B} \\left[ n_1 \\sqrt{(x_B - x_A)^2 + (y_B - y_A)^2} + n_2 \\sqrt{(x_C - x_B)^2 + (y_C - y_B)^2} \\right] = 0.\n\\]\n\n\n\nDifferentiating each term separately:\n\\[\nn_1 \\frac{\\partial}{\\partial x_B} \\sqrt{(x_B - x_A)^2 + (y_B - y_A)^2} + n_2 \\frac{\\partial}{\\partial x_B} \\sqrt{(x_C - x_B)^2 + (y_C - y_B)^2} = 0.\n\\]\nUsing the chain rule:\n\\[\nn_1 \\frac{x_B - x_A}{\\sqrt{(x_B - x_A)^2 + (y_B - y_A)^2}} + n_2 \\frac{x_B - x_C}{\\sqrt{(x_C - x_B)^2 + (y_C - y_B)^2}} = 0.\n\\]\n\n\n\nLet \\(\\theta_1\\) be the angle of incidence and \\(\\theta_2\\) be the angle of refraction. Then:\n\\[\n\\sin \\theta_1 = \\frac{x_B - x_A}{\\sqrt{(x_B - x_A)^2 + (y_B - y_A)^2}}, \\quad \\sin \\theta_2 = \\frac{x_C - x_B}{\\sqrt{(x_C - x_B)^2 + (y_C - y_B)^2}}.\n\\]\nSubstituting these into the equation:\n\\[\nn_1 \\sin \\theta_1 + n_2 \\sin \\theta_2 = 0.\n\\]\nSince \\(\\sin \\theta_2\\) is in the opposite direction, we have:\n\\[\nn_1 \\sin \\theta_1 = n_2 \\sin \\theta_2.\n\\]\nThis is Snell’s law, which describes the relationship between the angles of incidence and refraction when light passes from one medium to another.\n\n\n\nBy applying Fermat’s principle and taking the variation of the optical path length, we have derived Snell’s law:\n\\[\nn_1 \\sin \\theta_1 = n_2 \\sin \\theta_2.\n\\]\nThis demonstrates how the principle of least time leads to the well-known law of refraction in optics.\n\n\n\n\n\n\n\n\n\n\nExample: Light in a Graded-Index Medium\n\n\n\n\n\nConsider a medium where the refractive index varies with height \\(y\\) as \\(n(y) = n_0 (1 - \\frac{\\alpha^2}{2 n_0} y^2)\\). The path of light in such a medium can be found by using Fermat’s principle in differential form:\n\\[\n\\frac{d}{ds}\\left (n(\\textbf{r})\\frac{d\\textbf{r}}{ds}\\right)=\\nabla n(\\textbf{r})\n\\]\nTypically, this requires to express the coordinates in terms of a parameter, such as \\(x(s)\\) and \\(y(s)\\), and then solve the differential equation. The solution will give the path of light in the medium. This is difficult and commonly done numerically. In paraxial optics, when the light is propagating roughly in the direction of \\(z\\), the differential element \\(ds\\) can be approximated as \\(dz\\) since then\n\\[\nds=dz\\sqrt{1+\\left (\\frac{dy}{dz}\\right )^2+\\left (\\frac{dx}{dz}\\right)^2}\\approx dz\n\\]\nwhich yields\n\\[\n\\frac{d}{dz}\\left (n\\frac{dx}{dz}\\right)\\approx \\frac{dn}{dx}\n\\]\nand\n\\[\n\\frac{d}{dz}\\left (n\\frac{dy}{dz}\\right )\\approx \\frac{dn}{dy}\n\\]\nThis readily yields the path of light in a homogeneous medium, where \\(n\\) is constant. In this case we have\n\\[\n\\frac{d^2 x}{dz^2}=\\frac{d^2 y}{dz^2}=0\n\\]\nwhich is true for a straight line. In a graded-index medium, the path of light can be found by solving the differential equation\n\\[\n\\frac{d^2 y}{dz^2}=-\\alpha^2 y\n\\]\nwhich is reminiscent of the equation of motion of a harmonic oscillator. The solution is therefore an oscillating function\n\\[\ny(z)=y_0\\cos(\\alpha z)+\\frac{\\theta_0}{\\alpha}\\sin(\\alpha z  )\n\\]\nwhere the angle \\(\\theta_0\\) is the initial angle of the light ray with respect to the \\(z\\) axis. This solution describes the path of light in a graded-index medium.\n\n\n\n\n\n\n\n\n\nFermats’s Principle in Integral and Differential Form\n\n\n\n\n\nWe have described Fermat’t principle in an integral form specifiying the optical path length \\(S\\) as\n\\[\nOPL=\\int n(\\textbf{r})ds\n\\]\nThe path length \\(ds\\) can be given in terms of two coordinates \\(x_1\\) and \\(x_2\\) parametrized by \\(\\lambda\\) such that\n\\[\nds=\\sqrt{\\dot{x}_1^{2}+\\dot{x}_2^{2}}d\\lambda\n\\]\nwhere \\(\\dot{x}_1=\\frac{dx_{1}}{d\\lambda}\\). We can therefore write Fermat’s principle as\n\\[\n\\delta OPL=\\int\\left[\\left(\\frac{\\partial n}{\\partial x_i} \\delta x_i\\right) \\sqrt{\\dot{x}_1^2+\\dot{x}_2^2}+n \\frac{1}{\\sqrt{\\dot{x}_1^2+\\dot{x}_2^2}} \\dot{x}_i \\delta \\dot{x}_i\\right] d \\lambda = 0\n\\]\nTo evaluate this integral we would like to integrate by parts. We can write the integrand as \\[\nu = n \\frac{1}{\\sqrt{\\dot{x}_1^2+\\dot{x}_2^2}} \\dot{x}_i\n\\]\nand\n\\[\ndv = \\delta \\dot{x}_i d\\lambda\n\\]\nWe can now calculate \\(du\\) and \\(v\\) and obtain\n\\[\ndu = \\frac{d}{d\\lambda}\\left[n \\frac{1}{\\sqrt{\\dot{x}_1^2+\\dot{x}_2^2}} \\dot{x}_i\\right] d\\lambda\n\\]\nand\n\\[\nv = \\delta x_i\n\\]\nWith these expressions we can now apply the integration by parts formula \\(\\int u dv = uv - \\int v du\\), we get:\n\\[\n\\int n \\frac{1}{\\sqrt{\\dot{x}_1^2+\\dot{x}_2^2}} \\dot{x}_i \\delta \\dot{x}_i d\\lambda = \\left[n \\frac{1}{\\sqrt{\\dot{x}_1^2+\\dot{x}_2^2}} \\dot{x}_i \\delta x_i\\right]|_{\\lambda_1}^{\\lambda_2} - \\int \\delta x_i \\frac{d}{d\\lambda}\\left[n \\frac{1}{\\sqrt{\\dot{x}_1^2+\\dot{x}_2^2}} \\dot{x}_i\\right] d\\lambda\n\\]\nThis can be substituted back into the original equation to obtain\n\\[\n\\begin{aligned}\n\\delta OPL &= \\int \\left[\\left(\\frac{\\partial n}{\\partial x_i} \\delta x_i\\right) \\sqrt{\\dot{x}_1^2+\\dot{x}_2^2}\\right] d\\lambda \\\\\n&+ \\left[n \\frac{1}{\\sqrt{\\dot{x}_1^2+\\dot{x}_2^2}} \\dot{x}_i \\delta x_i\\right]|_{\\lambda_1}^{\\lambda_2} \\\\\n&- \\int \\delta x_i \\frac{d}{d\\lambda}\\left[n \\frac{1}{\\sqrt{\\dot{x}_1^2+\\dot{x}_2^2}} \\dot{x}_i\\right] d\\lambda = 0\n\\end{aligned}\n\\]\nAfter rearranging the terms we get\n\\[\n\\begin{aligned}\n\\delta OPL &= \\int \\left\\{\\frac{\\partial n}{\\partial x_i} \\sqrt{\\dot{x}_1^2+\\dot{x}_2^2} - \\frac{d}{d\\lambda}\\left[n \\frac{1}{\\sqrt{\\dot{x}_1^2+\\dot{x}_2^2}} \\dot{x}_i\\right]\\right\\} \\delta x_i d\\lambda \\\\\n&+ \\left[n \\frac{1}{\\sqrt{\\dot{x}_1^2+\\dot{x}_2^2}} \\dot{x}_i \\delta x_i\\right]|_{\\lambda_1}^{\\lambda_2} = 0\n\\end{aligned}\n\\]\nand therefore finally\n\\[\n\\delta OPL=\\int\\left[\\left(\\frac{\\partial n}{\\partial x_i}\\right) \\sqrt{\\dot{x}_1{ }^2+\\dot{x}_2{ }^2}-\\frac{d}{d \\lambda}\\left(n \\frac{1}{\\sqrt{\\dot{x}_1^2+\\dot{x}_2^2}} \\dot{x}_i\\right)\\right] \\delta x_i d \\lambda+\\text { boundary terms }\n\\]\nfor which we choose the parameter \\(\\lambda\\) such that the boundary terms vanish.\n\\[\n\\lambda=s\n\\]\nsuch that\n\\[\n\\sqrt{\\dot{x}_1^2+\\dot{x}_2^2}=1\n\\]\nand finally leads to the Euler-Lagrange equation\n\\[\n\\left(\\frac{\\partial n}{\\partial x_i}\\right)-\\frac{d}{d s}\\left(n \\dot{x}_i\\right)=0\n\\]\nwhich is the differential form of the Fermat’s principle.",
    "crumbs": [
      "Geometrical Optics",
      "Lecture 1",
      "Refraction"
    ]
  },
  {
    "objectID": "geometrical-optics/refraction-total-internal-reflection.html#refraction",
    "href": "geometrical-optics/refraction-total-internal-reflection.html#refraction",
    "title": "Refraction and Total Internal Reflection",
    "section": "",
    "text": "Historical Context of Refraction\n\n\n\n\n\nThe understanding of refraction has evolved over centuries, with contributions from various cultures and scientific traditions. This timeline highlights key milestones in the discovery and formalization of refraction, showcasing how our comprehension of this fundamental optical phenomenon has deepened over time:\n\nAncient Greece (3rd century BCE): Euclid noticed that a stick partially submerged in water appears bent. Archimedes studied the refraction of light in water.\nAncient Rome (1st century CE): Ptolemy conducted experiments on refraction and compiled tables of refraction angles for different media.\nIslamic Golden Age (10th-11th centuries): Ibn Sahl (940-1000) discovered the law of refraction, describing it geometrically. Alhazen (965-1040) studied lenses and the human eye, contributing significantly to optics.\nMiddle Ages: Robert Grosseteste (1175-1253) and Roger Bacon (1214-1294) studied refraction and its application to lenses.\nRenaissance: Thomas Harriot (1560-1621) rediscovered the law of refraction but didn’t publish his findings.\n17th Century: Willebrord Snellius (1580-1626) derived the mathematical law of refraction (Snell’s law) around 1621. René Descartes (1596-1650) independently derived and published the law of refraction in 1637. Pierre de Fermat (1607-1665) derived the law of refraction using his principle of least time.\n19th Century: Augustin-Jean Fresnel (1788-1827) developed the wave theory of light, explaining refraction in terms of changes in wave speed.\n20th Century: The quantum mechanical understanding of light, which emerged in the early 20th century, significantly impacted our view of refraction. Max Planck’s work on black body radiation in 1900 and Albert Einstein’s explanation of the photoelectric effect in 1905 laid the groundwork for the quantum nature of light. This quantum perspective provided a complementary explanation to the wave theory, describing refraction in terms of photons interacting with the atoms in the medium. While this quantum view offers insights into certain aspects of refraction, it’s important to note that both the wave and particle descriptions of light are necessary for a complete understanding of optical phenomena.\n\n\n\n\nThe law of refraction is the second important law of geometrical optics. It relates the refractive index \\(n_1\\) and angle of incidence \\(\\theta_1\\) on one side of an interface to the refractive index \\(n_2\\) and angle of refraction \\(\\theta_2\\) on the other side. Both the law of reflection and the law of refraction can be derived from more fundamental principles such as Fermat’s principle of least time and are consistent with the conservation of energy. Their relation to momentum is more complex and involves considering the interaction of light with the medium at an atomic level. These laws provide a mathematical framework for predicting how light behaves when it encounters interfaces between different media, forming the basis for understanding a wide range of optical phenomena and the design of optical devices.\n\n\nThe refractive index \\(n\\) is a material constant representing the factor by which the speed of light is reduced in the medium compared to its speed in vacuum. For most natural materials and visible light, the refractive index is \\(n \\ge 1\\), as light typically travels slower in media than in vacuum. However, in certain special cases—such as for X-rays in some materials or in engineered metamaterials—the refractive index can be less than 1 or even negative. Understanding these exotic cases requires a deeper exploration of the electromagnetic properties of materials and the origin of the refractive index, which we will address later.\n\n\n\n \n\n\n\n\n\n\nLaw of Refraction (Snell’s Law)\n\n\n\nThe law of refraction (Snell’s law) is given for the above sketch by the equation:\n\\[\nn_1 \\sin(\\theta_1)=n_2 \\sin(\\theta_2)\n\\]\n\n\nYou can explore the law of refraction using the interactive visualization below. The visualization shows a light ray incident on an interface between two media with different refractive indices. You can adjust the angle of incidence and the refractive index of the first medium to see how the angle of refraction changes according to Snell’s law.\n\n\n\nIncident Angle: 45°\n\nRefractive Index n₁: 1.0\n\nRefractive Index n₂: 1.5\n\n\n\n\nSnell’s law leads to some general patterns in the behavior of light rays at interfaces, which are worth remembering. Consider these two cases:\n\nWhen light moves from a medium with lower refractive index to one with higher refractive index (\\(n_1 &lt; n_2\\)):\n\nThe refracted ray bends towards the normal (optical axis)\nThe angle of refraction is smaller than the angle of incidence (\\(\\theta_2 &lt; \\theta_1\\))\n\nWhen light moves from a medium with higher refractive index to one with lower refractive index (\\(n_1 &gt; n_2\\)):\n\nThe refracted ray bends away from the normal (optical axis)\nThe angle of refraction is larger than the angle of incidence (\\(\\theta_2 &gt; \\theta_1\\))\n\n\nFigure 1 illustrates these principles with three plots showing how the refracted angle changes with the incident angle for two common interface scenarios: glass-to-air and air-to-glass. These plots clearly demonstrate the different behaviors described above.\n\n\n\nCode\ndef snell(n1, n2, theta1):\n    sin_theta2 = n1 * np.sin(theta1) / n2\n    theta2 = np.arcsin(np.clip(sin_theta2, -1, 1))\n    theta2[sin_theta2 &gt; 1] = np.nan\n    return theta2\n\nfig, ax = plt.subplots(figsize=(4, 4))\n\ntheta1 = np.linspace(0, np.pi/2, 1000)\n\ntheta2_1_to_1_5 = snell(1.0, 1.5, theta1)\ntheta2_1_5_to_1 = snell(1.5, 1.0, theta1)\ntheta2_1_to_1 = snell(1.0, 1.0, theta1)\n\nax.plot(np.degrees(theta1), np.degrees(theta2_1_to_1_5), color='blue')\nax.plot(np.degrees(theta1), np.degrees(theta2_1_5_to_1), color='red')\nax.plot(np.degrees(theta1), np.degrees(theta2_1_to_1), color='green', linestyle='--')\n\nax.set_xlabel(r'$\\theta_1$ [°]')\nax.set_ylabel(r'$\\theta_2$ [°]')\nax.set_xlim(0, 90)\nax.set_ylim(0, 90)\n\nax.plot([0, 90], [0, 90], color='gray', linestyle=':', label='y=x')\n\nax.annotate(r'$\\frac{n_2}{n_1}=1.5$', xy=(60, 35), xytext=(50, 20),\n            arrowprops=dict(arrowstyle='-&gt;'), color='blue')\nax.annotate(r'$\\frac{n_1}{n_2}=1.5$', xy=(30, 50), xytext=(10, 70),\n            arrowprops=dict(arrowstyle='-&gt;'), color='red')\nax.annotate(r'$\\frac{n_2}{n_1}=1$', xy=(45, 45), xytext=(65, 50),\n            arrowprops=dict(arrowstyle='-&gt;'), color='green')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nFigure 1— Snell’s law for different combinations of refractive indices. The plots show the relationship between incident angle (\\(\\theta_1\\)) and refracted angle (\\(\\theta_2\\)) for three scenarios: (a) light passing from air to glass, (b) light passing from glass to air, and (c) a comparison of both cases. Note how the curves differ when light moves into a medium with higher refractive index versus a lower refractive index.\n\n\n\n\n\n\n\n\nThe above diagram reveals a special case occurring when \\(n_1 &gt; n_2\\). Under these conditions, we can increase the incident angle \\(\\theta_1\\) until the outgoing angle reaches \\(\\theta_2 = \\frac{\\pi}{2}\\). At this point, the refracted ray would be traveling along the interface between the two media. For any incident angle \\(\\theta_1\\) larger than this critical angle, there is no refracted ray at all; instead, we observe only a reflected ray. This phenomenon, known as total internal reflection, occurs despite the fact that the material with refractive index \\(n_2\\) is completely transparent.\nLet’s formalize this concept mathematically. Using Snell’s law and setting \\(\\theta_2 = \\frac{\\pi}{2}\\), we obtain the equation for the critical angle \\(\\theta_c\\):\n\\[\\theta_1 = \\theta_c = \\sin^{-1}\\left(\\frac{n_2}{n_1}\\right)\\]\nNote that the \\(\\sin^{-1}()\\) function requires an argument \\(\\le 1\\), which is why this phenomenon only occurs when \\(n_2 &lt; n_1\\).\nIt’s important to understand that during total internal reflection, all of the light energy is reflected back into the first medium, hence the term ‘total’. However, electromagnetic optics reveals an interesting subtlety: an evanescent wave penetrates a short distance into the second medium, though it doesn’t propagate energy across the boundary.\nWhen the incident angle exceeds the critical angle, Snell’s law as we’ve written it no longer applies. Instead, we observe perfect reflection, where the angle of reflection equals the angle of incidence, just as in regular reflection from a mirror. This reflection occurs without any loss of energy to the second medium, making it an extremely efficient process.\n \n\n\n\n\n\n\nTotal Internal Reflection\n\n\n\nTotal internal reflection occurs when light is passing from higher refractive index to lower refractive index materials for incidence angle larger than a critical angle\n\\[\n\\theta_c=\\sin^{-1}\\left (\\frac{n_2}{n_1}\\right )\n\\]\n\n\nWe can demonstrate total internal reflection very easily with a water basin, for example, where we couple in light from a laser from the side.\n \nBut you could try that yourself also in the bath tub diving below the water surface.\nTotal internal reflection has numerous practical applications:\n\nFiber optic communications: Light signals can travel long distances with minimal loss through optical fibers.\nOptical instruments: Prisms in binoculars and telescopes use total internal reflection to manipulate light paths.\nGemstones: The sparkle of diamonds is enhanced by total internal reflection trapping light within the stone.\nMedical endoscopes: Total internal reflection helps guide light through flexible tubes for internal imaging.\n\nOptical Fibers and Total Internal Reflection\nTotal internal reflection plays a crucial role in modern telecommunications, particularly in optical fibers, which are also part of many experimental setups. These fibers are essentially ultra-thin glass wires, ranging in diameter from a few micrometers to several hundred micrometers, designed to transport light over long distances with minimal loss.\nThe structure of an optical fiber is key to its function:\n\nCore: A central glass core with a refractive index \\(n_1\\)\nCladding: A surrounding layer with a slightly lower refractive index \\(n_2\\)\n\nThis difference in refractive indices is what allows total internal reflection to occur within the fiber.\n \nFor light to propagate effectively through the fiber, it must enter at an angle that ensures total internal reflection at the core-cladding interface. This leads to the concept of the acceptance angle, \\(\\theta_a\\), which is the maximum angle at which light can enter the fiber and still undergo total internal reflection.\nTo characterize this acceptance angle, optical engineers use a parameter called the Numerical Aperture (NA).\n\n\n\n\n\n\nNumerical Aperture\n\n\n\nThe Numerical Aperture of a fiber is defined as the sine of the maximum acceptance angle:\n\\[\\begin{equation}\nNA = \\sin(\\theta_a) = \\sqrt{n_1^2 - n_2^2}\n\\end{equation}\\]\n\n\nThis equation relates the NA directly to the refractive indices of the core and cladding. The derivation of this formula involves applying Snell’s law at the air-fiber interface and at the core-cladding interface, then using the condition for total internal reflection.\nIn practice, typical values for the refractive indices might be \\(n_1 = 1.475\\) for the core and \\(n_2 = 1.46\\) for the cladding. Plugging these into our equation:\n\\[\\begin{equation}\nNA = \\sqrt{1.475^2 - 1.46^2} \\approx 0.2\n\\end{equation}\\]\nThis means that light entering the fiber within a cone of about 11.5° (arcsin(0.2)) from the fiber’s axis will be transmitted through the fiber via total internal reflection.\nThe NA is an important parameter in fiber optic design:\n\nIt determines the light-gathering ability of the fiber.\nIt affects the fiber’s bandwidth and its susceptibility to certain types of signal distortion.\nIt influences how easily the fiber can be coupled to light sources and other fibers.\n\nOptical fibers come in various types, each optimized for different applications. Some fibers are designed to transmit light over long distances with minimal loss, while others are engineered for specific wavelengths or to guide light in unusual ways. The figure below shows a few examples of optical fiber types.\n\n\n\n\n\n\nFigure 2— Rendering of different optical fibers types (from left to right): Hollow core optical fiber, hollow core bragg fiber, photonic crystal fiber, conventional fiber\n\n\n\n\n\n\nWhile before we have considered Fermat’s principle for the special case of refraction and light propagation in a homogeneous medium, we can define a more general version of it correponding to the following situation also involving an inhomogeneous refractive index \\(n(\\vec{r})\\).\n\n\n\n\n\n\nFigure 3— Sketch for a general description of Fermat’s principle\n\n\n\nFor this general scenario of light traveling along a path, we can define an optical path length (OPL) as\n\\[\\begin{equation}\n\\text{OPL} = \\int\\limits_{A}^{C} n(\\mathbf{r}) \\mathrm ds=0,\n\\end{equation}\\]\nwith a varying refractive index \\(n(\\mathbf{r})\\). Fermat’s Principle states that the actual path taken by the light makes the OPL stationary:\n\\[\n\\delta \\left( \\int_A^B n(\\mathbf{r}) \\, ds \\right) = 0\n\\]\nUsing the calculus of variations, this leads to the Euler-Lagrange equation for the path of light. In Cartesian coordinates, if the path is parameterized by \\(\\mathbf{r}(s) = (x(s), y(s), z(s))\\), the Euler-Lagrange equations become:\n\\[\n\\frac{d}{ds} \\left( n \\frac{d\\mathbf{r}}{ds} \\right) = \\nabla n\n\\]\nwhere \\(\\nabla n\\) is the gradient of the refractive index. This equation describes how the light ray bends in response to changes in the refractive index of the medium.\nFermat’s Principle is a cornerstone of geometrical optics and has applications in designing optical systems, understanding mirages, and analyzing the behavior of light in various media.\n\n\n\n\n\n\nFermat’s Principle and Snells Law\n\n\n\n\n\nWe would like to apply Fermat’s principle to derive Snell’s law, which is a more lengthy calculation. To do this, we consider a light ray traveling from point \\(A\\) in medium 1 (with refractive index \\(n_1\\)) to point \\(C\\) in medium 2 (with refractive index \\(n_2\\)), crossing the interface at point \\(B\\). Let the coordinates of points \\(A\\), \\(B\\), and \\(C\\) be \\((x_A, y_A)\\), \\((x_B, y_B)\\), and \\((x_C, y_C)\\), respectively. Assume the interface between the two media is at \\(y = y_B\\). The optical path length (OPL) is given by:\n\\[\n\\delta \\int_{A}^{C} n(\\vec{r}) \\, ds = 0,\n\\]\nwhere \\(n(\\vec{r})\\) is the refractive index at position \\(\\vec{r}\\), and \\(ds\\) is an infinitesimal element of the path.\nConsider a light ray traveling from point \\(A\\) in medium 1 (with refractive index \\(n_1\\)) to point \\(C\\) in medium 2 (with refractive index \\(n_2\\)), crossing the interface at point \\(B\\). Let the coordinates of points \\(A\\), \\(B\\), and \\(C\\) be \\((x_A, y_A)\\), \\((x_B, y_B)\\), and \\((x_C, y_C)\\), respectively. Assume the interface between the two media is at \\(y = y_B\\).\n\n\nThe optical path length (OPL) is given by:\n\\[\n\\text{OPL} = n_1 \\int_{A}^{B} ds_1 + n_2 \\int_{B}^{C} ds_2,\n\\]\nwhere \\(ds_1\\) and \\(ds_2\\) are the infinitesimal path lengths in media 1 and 2, respectively.\n\n\n\nThe path lengths \\(ds_1\\) and \\(ds_2\\) can be expressed in terms of the coordinates:\n\\[\nds_1 = \\sqrt{(dx_1)^2 + (dy_1)^2}, \\quad ds_2 = \\sqrt{(dx_2)^2 + (dy_2)^2}.\n\\]\nSince the interface is at \\(y = y_B\\), we have \\(dy_1 = y_B - y_A\\) and \\(dy_2 = y_C - y_B\\). The total optical path length is:\n\\[\n\\text{OPL} = n_1 \\sqrt{(x_B - x_A)^2 + (y_B - y_A)^2} + n_2 \\sqrt{(x_C - x_B)^2 + (y_C - y_B)^2}.\n\\]\n\n\n\nTo find the stationary path, we take the variation of the OPL with respect to \\(x_B\\):\n\\[\n\\delta \\text{OPL} = \\delta \\left[ n_1 \\sqrt{(x_B - x_A)^2 + (y_B - y_A)^2} + n_2 \\sqrt{(x_C - x_B)^2 + (y_C - y_B)^2} \\right] = 0.\n\\]\nTaking the derivative with respect to \\(x_B\\):\n\\[\n\\frac{\\partial}{\\partial x_B} \\left[ n_1 \\sqrt{(x_B - x_A)^2 + (y_B - y_A)^2} + n_2 \\sqrt{(x_C - x_B)^2 + (y_C - y_B)^2} \\right] = 0.\n\\]\n\n\n\nDifferentiating each term separately:\n\\[\nn_1 \\frac{\\partial}{\\partial x_B} \\sqrt{(x_B - x_A)^2 + (y_B - y_A)^2} + n_2 \\frac{\\partial}{\\partial x_B} \\sqrt{(x_C - x_B)^2 + (y_C - y_B)^2} = 0.\n\\]\nUsing the chain rule:\n\\[\nn_1 \\frac{x_B - x_A}{\\sqrt{(x_B - x_A)^2 + (y_B - y_A)^2}} + n_2 \\frac{x_B - x_C}{\\sqrt{(x_C - x_B)^2 + (y_C - y_B)^2}} = 0.\n\\]\n\n\n\nLet \\(\\theta_1\\) be the angle of incidence and \\(\\theta_2\\) be the angle of refraction. Then:\n\\[\n\\sin \\theta_1 = \\frac{x_B - x_A}{\\sqrt{(x_B - x_A)^2 + (y_B - y_A)^2}}, \\quad \\sin \\theta_2 = \\frac{x_C - x_B}{\\sqrt{(x_C - x_B)^2 + (y_C - y_B)^2}}.\n\\]\nSubstituting these into the equation:\n\\[\nn_1 \\sin \\theta_1 + n_2 \\sin \\theta_2 = 0.\n\\]\nSince \\(\\sin \\theta_2\\) is in the opposite direction, we have:\n\\[\nn_1 \\sin \\theta_1 = n_2 \\sin \\theta_2.\n\\]\nThis is Snell’s law, which describes the relationship between the angles of incidence and refraction when light passes from one medium to another.\n\n\n\nBy applying Fermat’s principle and taking the variation of the optical path length, we have derived Snell’s law:\n\\[\nn_1 \\sin \\theta_1 = n_2 \\sin \\theta_2.\n\\]\nThis demonstrates how the principle of least time leads to the well-known law of refraction in optics.\n\n\n\n\n\n\n\n\n\n\nExample: Light in a Graded-Index Medium\n\n\n\n\n\nConsider a medium where the refractive index varies with height \\(y\\) as \\(n(y) = n_0 (1 - \\frac{\\alpha^2}{2 n_0} y^2)\\). The path of light in such a medium can be found by using Fermat’s principle in differential form:\n\\[\n\\frac{d}{ds}\\left (n(\\textbf{r})\\frac{d\\textbf{r}}{ds}\\right)=\\nabla n(\\textbf{r})\n\\]\nTypically, this requires to express the coordinates in terms of a parameter, such as \\(x(s)\\) and \\(y(s)\\), and then solve the differential equation. The solution will give the path of light in the medium. This is difficult and commonly done numerically. In paraxial optics, when the light is propagating roughly in the direction of \\(z\\), the differential element \\(ds\\) can be approximated as \\(dz\\) since then\n\\[\nds=dz\\sqrt{1+\\left (\\frac{dy}{dz}\\right )^2+\\left (\\frac{dx}{dz}\\right)^2}\\approx dz\n\\]\nwhich yields\n\\[\n\\frac{d}{dz}\\left (n\\frac{dx}{dz}\\right)\\approx \\frac{dn}{dx}\n\\]\nand\n\\[\n\\frac{d}{dz}\\left (n\\frac{dy}{dz}\\right )\\approx \\frac{dn}{dy}\n\\]\nThis readily yields the path of light in a homogeneous medium, where \\(n\\) is constant. In this case we have\n\\[\n\\frac{d^2 x}{dz^2}=\\frac{d^2 y}{dz^2}=0\n\\]\nwhich is true for a straight line. In a graded-index medium, the path of light can be found by solving the differential equation\n\\[\n\\frac{d^2 y}{dz^2}=-\\alpha^2 y\n\\]\nwhich is reminiscent of the equation of motion of a harmonic oscillator. The solution is therefore an oscillating function\n\\[\ny(z)=y_0\\cos(\\alpha z)+\\frac{\\theta_0}{\\alpha}\\sin(\\alpha z  )\n\\]\nwhere the angle \\(\\theta_0\\) is the initial angle of the light ray with respect to the \\(z\\) axis. This solution describes the path of light in a graded-index medium.\n\n\n\n\n\n\n\n\n\nFermats’s Principle in Integral and Differential Form\n\n\n\n\n\nWe have described Fermat’t principle in an integral form specifiying the optical path length \\(S\\) as\n\\[\nOPL=\\int n(\\textbf{r})ds\n\\]\nThe path length \\(ds\\) can be given in terms of two coordinates \\(x_1\\) and \\(x_2\\) parametrized by \\(\\lambda\\) such that\n\\[\nds=\\sqrt{\\dot{x}_1^{2}+\\dot{x}_2^{2}}d\\lambda\n\\]\nwhere \\(\\dot{x}_1=\\frac{dx_{1}}{d\\lambda}\\). We can therefore write Fermat’s principle as\n\\[\n\\delta OPL=\\int\\left[\\left(\\frac{\\partial n}{\\partial x_i} \\delta x_i\\right) \\sqrt{\\dot{x}_1^2+\\dot{x}_2^2}+n \\frac{1}{\\sqrt{\\dot{x}_1^2+\\dot{x}_2^2}} \\dot{x}_i \\delta \\dot{x}_i\\right] d \\lambda = 0\n\\]\nTo evaluate this integral we would like to integrate by parts. We can write the integrand as \\[\nu = n \\frac{1}{\\sqrt{\\dot{x}_1^2+\\dot{x}_2^2}} \\dot{x}_i\n\\]\nand\n\\[\ndv = \\delta \\dot{x}_i d\\lambda\n\\]\nWe can now calculate \\(du\\) and \\(v\\) and obtain\n\\[\ndu = \\frac{d}{d\\lambda}\\left[n \\frac{1}{\\sqrt{\\dot{x}_1^2+\\dot{x}_2^2}} \\dot{x}_i\\right] d\\lambda\n\\]\nand\n\\[\nv = \\delta x_i\n\\]\nWith these expressions we can now apply the integration by parts formula \\(\\int u dv = uv - \\int v du\\), we get:\n\\[\n\\int n \\frac{1}{\\sqrt{\\dot{x}_1^2+\\dot{x}_2^2}} \\dot{x}_i \\delta \\dot{x}_i d\\lambda = \\left[n \\frac{1}{\\sqrt{\\dot{x}_1^2+\\dot{x}_2^2}} \\dot{x}_i \\delta x_i\\right]|_{\\lambda_1}^{\\lambda_2} - \\int \\delta x_i \\frac{d}{d\\lambda}\\left[n \\frac{1}{\\sqrt{\\dot{x}_1^2+\\dot{x}_2^2}} \\dot{x}_i\\right] d\\lambda\n\\]\nThis can be substituted back into the original equation to obtain\n\\[\n\\begin{aligned}\n\\delta OPL &= \\int \\left[\\left(\\frac{\\partial n}{\\partial x_i} \\delta x_i\\right) \\sqrt{\\dot{x}_1^2+\\dot{x}_2^2}\\right] d\\lambda \\\\\n&+ \\left[n \\frac{1}{\\sqrt{\\dot{x}_1^2+\\dot{x}_2^2}} \\dot{x}_i \\delta x_i\\right]|_{\\lambda_1}^{\\lambda_2} \\\\\n&- \\int \\delta x_i \\frac{d}{d\\lambda}\\left[n \\frac{1}{\\sqrt{\\dot{x}_1^2+\\dot{x}_2^2}} \\dot{x}_i\\right] d\\lambda = 0\n\\end{aligned}\n\\]\nAfter rearranging the terms we get\n\\[\n\\begin{aligned}\n\\delta OPL &= \\int \\left\\{\\frac{\\partial n}{\\partial x_i} \\sqrt{\\dot{x}_1^2+\\dot{x}_2^2} - \\frac{d}{d\\lambda}\\left[n \\frac{1}{\\sqrt{\\dot{x}_1^2+\\dot{x}_2^2}} \\dot{x}_i\\right]\\right\\} \\delta x_i d\\lambda \\\\\n&+ \\left[n \\frac{1}{\\sqrt{\\dot{x}_1^2+\\dot{x}_2^2}} \\dot{x}_i \\delta x_i\\right]|_{\\lambda_1}^{\\lambda_2} = 0\n\\end{aligned}\n\\]\nand therefore finally\n\\[\n\\delta OPL=\\int\\left[\\left(\\frac{\\partial n}{\\partial x_i}\\right) \\sqrt{\\dot{x}_1{ }^2+\\dot{x}_2{ }^2}-\\frac{d}{d \\lambda}\\left(n \\frac{1}{\\sqrt{\\dot{x}_1^2+\\dot{x}_2^2}} \\dot{x}_i\\right)\\right] \\delta x_i d \\lambda+\\text { boundary terms }\n\\]\nfor which we choose the parameter \\(\\lambda\\) such that the boundary terms vanish.\n\\[\n\\lambda=s\n\\]\nsuch that\n\\[\n\\sqrt{\\dot{x}_1^2+\\dot{x}_2^2}=1\n\\]\nand finally leads to the Euler-Lagrange equation\n\\[\n\\left(\\frac{\\partial n}{\\partial x_i}\\right)-\\frac{d}{d s}\\left(n \\dot{x}_i\\right)=0\n\\]\nwhich is the differential form of the Fermat’s principle.",
    "crumbs": [
      "Geometrical Optics",
      "Lecture 1",
      "Refraction"
    ]
  },
  {
    "objectID": "geometrical-optics/reflection.html",
    "href": "geometrical-optics/reflection.html",
    "title": "Reflection",
    "section": "",
    "text": "Historical Context of Reflection Laws\n\n\n\n\n\nThe study of reflection has a rich history dating back to ancient times:\n\nAncient Greece (300 BCE): Euclid, in his work “Catoptrics,” was among the first to formally describe the law of reflection. He stated that the angle of incidence equals the angle of reflection.\nAncient Rome (50 CE): Hero of Alexandria expanded on Euclid’s work, applying the principle that light travels along the path of least distance.\nIslamic Golden Age (1000 CE): Ibn al-Haytham (Alhazen) made significant contributions to optics in his “Book of Optics.” He conducted experiments to verify the law of reflection and explored the properties of spherical and parabolic mirrors.\n17th Century: Fermat’s Principle, formulated by Pierre de Fermat, provided a more general framework for understanding reflection (and refraction) based on the principle of least time.\nModern Era: The understanding of reflection has been further refined with the development of electromagnetic theory by James Clerk Maxwell in the 19th century and quantum optics in the 20th century.\n\n\n\n\nThe law of reflection is probably the most simple one. Yet the simplicity gives us the chance to define some basic objects which we will further use for the description of light rays and their propagation.\n\nLaw of Reflection\nThe sketch below shows the reflection of an incoming light ray (red) on an interface. This incoming light ray has an angle \\(\\theta_{1}\\) with the axis (dashed line), which is perpendicular to the reflecting surface. As compared to X-ray diffraction, we measure the angle to the normal of the surface and not to the surface itself.\n\n\n\n\n\n\n\n\n\n\n\n(a) Law of reflection\n\n\n\n\n\n\n\n\n\n\n\n(b) Experimental Demonstration\n\n\n\n\n\n\n\nFigure 1— Figure 1 (a) illustrates the law of reflection, while Figure Figure 1 (b) shows an experimental demonstration.\n\n\n\nFigure 1 (a) shows the reflection of an incoming light ray (red) on an interface. This incoming light ray has an angle \\(\\theta_{1}\\) with the axis (dashed line), which is perpendicular to the reflecting surface. As compared to X-ray diffraction, we measure the angle to the normal of the surface and not to the surface itself.\nThe law of reflection tells us now, that the outgoing reflected ray is now leaving the surface under an angle \\(\\theta_2=\\theta_1\\). So both angles are the same for the reflection.\n\n\n\n\n\n\nLaw of Reflection\n\n\n\nIf a ray is incident to a reflecting surface under an angle \\(\\theta_1\\) it will be reflected towards under an angle \\(\\theta_2=\\theta_1\\) to the same side of the surface.\n\n\n\n\nFermat’s Principle\nThe law of reflection can be actually obtained from a variational principle saying the light rays propagate along those path on which the propagation time is an extremum. This variational principle is called Fermat’s principle.\n\n\n\n\n\n\nFigure 2— Sketch for deriving the law of reflection from Fermat’s principle\n\n\n\nConsider now a light ray that should travel from point \\(A\\) to point \\(C\\) via a point \\(B\\) on the mirror surface. In general multiple paths are possible such as the one indicated in the above picture. Clearly this path is not satisfying our reflection law formulated above. Fermat’s principle now restricts the path length from \\(A\\) to \\(C\\) to be the one, which takes the least amount of time.\n\n\n\n\n\n\nFermat’s principle\n\n\n\nThe path taken by a ray between two given points A, B is the path that can be traversed in the least time.\nMore precise alternative: A ray going in a certain particular path has the property that if we make a small change in the ray in any manner whatever, say in the location at which it comes to the mirror, or the shape of the curve, or anything, there will be no first-order change in the time; there will be only a second-order change in the time.\n\n\nSo let us consider that contraints to the path length. The total length the light hast to travel via the three points is\n\\[\nl=l_{1}+l_{2}=\\sqrt{(x-x_1)^2+y_1^2}+\\sqrt{(x_2-x)^2+y_2^2}\n\\]\nThe time that is required by the light to travel that distance \\(l\\) is then given by\n\\[\nt=\\frac{l}{c},\n\\]\nwhere \\(c\\) is the speed of light in the medium above the mirror. If this time should now be a minimum, we have to take the derivative of the time \\(t\\) with respect to the position \\(x\\) on the mirror and set that to zero, i.e.,\n\\[\\frac{\\mathrm dt}{\\mathrm dx}=0. \\tag{1}\\]\nThis results in Eq. 1\n\\[\n\\frac{x-x_1}{\\sqrt{(x-x_1)^2+y_{1}^2}}=\\frac{x_2-x}{\\sqrt{(x_2-x)^2+y_{2}^2}},\n\\]\nwhich is actually\n\\[\n\\frac{x-x_1}{l_1}=\\frac{x_2-x}{l_2}\n\\]\nor\n\\[\n\\sin(\\theta_1)=\\sin(\\theta_2)\n\\]\nwhich finally requires\n\\[\n\\theta_1=\\theta_2\n\\]\nand is our law of reflection. Thus, reflection satisfies Fermat’s principle, i.e. the light rays propagate along those path on which the propagation time is an extremum.\n\n\n\n\n\n\nPrinciple of Least Action (Hamilton’s Principle)\n\n\n\n\n\nThe Principle of Least Action, also known as Hamilton’s Principle, is a fundamental concept in classical mechanics. It states that the path taken by a physical system between two states is the one for which the action integral is stationary (usually a minimum).\n\nAction Integral\nThe action \\(S\\) is defined as the integral of the Lagrangian \\(L\\) over time:\n\\[\nS = \\int_{t_1}^{t_2} L \\, dt\n\\]\n\n\nLagrangian\nThe Lagrangian \\(L\\) is a function that summarizes the dynamics of the system. For a system with generalized coordinates \\(q_i\\) and velocities \\(\\dot{q}_i\\), the Lagrangian is typically given by:\n\\[\nL = T - V\n\\]\nwhere:\n\n\\(T\\) is the kinetic energy of the system.\n\\(V\\) is the potential energy of the system.\n\n\n\nEuler-Lagrange Equations\nHamilton’s Principle leads to the Euler-Lagrange equations, which are the equations of motion for the system. These equations are derived by requiring that the action \\(S\\) be stationary with respect to variations in the path \\(q_i(t)\\):\n\\[\n\\delta S = 0\n\\]\nThis condition leads to the following differential equations:\n\\[\n\\frac{d}{dt} \\left( \\frac{\\partial L}{\\partial \\dot{q}_i} \\right) - \\frac{\\partial L}{\\partial q_i} = 0\n\\]\nThese are the Euler-Lagrange equations, and they provide a powerful method for deriving the equations of motion for a wide variety of physical systems.\n\n\nExample: Simple Harmonic Oscillator\nFor a simple harmonic oscillator with mass \\(m\\) and spring constant \\(k\\), the Lagrangian is:\n\\[\nL = \\frac{1}{2} m \\dot{x}^2 - \\frac{1}{2} k x^2\n\\]\nApplying the Euler-Lagrange equation:\n\\[\n\\frac{d}{dt} \\left( \\frac{\\partial L}{\\partial \\dot{x}} \\right) - \\frac{\\partial L}{\\partial x} = 0\n\\]\nwe get:\n\\[\nm \\ddot{x} + k x = 0\n\\]\nwhich is the familiar equation of motion for a simple harmonic oscillator.\nHamilton’s Principle and the associated Euler-Lagrange equations are foundational in classical mechanics and have far-reaching implications in other areas of physics, including quantum mechanics and field theory.",
    "crumbs": [
      "Geometrical Optics",
      "Lecture 1",
      "Reflection"
    ]
  },
  {
    "objectID": "geometrical-optics/Optical Elements I.html",
    "href": "geometrical-optics/Optical Elements I.html",
    "title": "Optical Elements Part I",
    "section": "",
    "text": "When light radiates from a point \\(P\\) and reflects off a mirror, as shown in the image, the reflected rays diverge but appear to originate from a point \\(P'\\) located behind the mirror. According to the law of reflection, this image point is positioned at the same distance behind the mirror as the original object point is in front of it. As a result, an observer receiving these reflected rays, such as on their retina, perceives the point as if it were situated behind the mirror, even though no light actually travels behind the mirror surface.\n\n\n\n\n\n\n\n\n\n\n\n(a)\n\n\n\n\n\n\n\n\n\n\n\n(b)\n\n\n\n\n\n\n\nFigure 1: Image formation on a plane mirror.\n\n\n\nWhen multiple points of an object emit light towards the mirror, this principle applies to each point. As a result, the entire object appears as an image behind the mirror. Since each point of the image is equidistant from the mirror as its corresponding object point, the image has the same size as the object. This leads to the definition of magnification as:\n\\[\nM=\\frac{h_{\\text{image}}}{h_{\\text{object}}}\n\\]\n\n\n\n\n\n\nFigure 2: Image formation on a plane mirror.\n\n\n\n\n\n\n\n\n\nVirtual Images\n\n\n\nA virtual image is an optical illusion where light rays appear to come from a point, but don’t actually converge there. Unlike real images, virtual images can’t be projected onto a screen. They’re commonly seen in plane mirrors, convex mirrors, and when objects are closer to a lens than its focal point. Remember: for virtual images, light rays only seem to originate from the image when traced backwards.\n\n\n\n\n\n\n\n\nReal Images\n\n\n\nA real image forms when light rays actually meet at a point after reflection or refraction. These images can be projected onto a screen because light physically passes through the image location. Real images are often inverted and occur with concave mirrors and lenses when objects are beyond the focal point. Key point: real images involve actual convergence of light rays.\n\n\n\n\n\nFor a concave mirror (where the reflecting surface is on the inside of the spherical curve), applying the law of reflection yields interesting results. Light rays parallel to the optical axis, at a distance \\(h\\) from it, are reflected towards the axis and intersect it at a specific point \\(F\\). Due to the mirror’s symmetry, a parallel ray on the opposite side of the axis will also converge to this same point \\(F\\).\n\n\n\n\n\n\nFigure 3: Reflection of a parallel ray incident at a height \\(h\\) from the optical axis on a concave mirror.\n\n\n\nWe may calculate the position of the point \\(F\\), e.g. the distance from the mirror surface point \\(O\\), by applying the law of reflection. If the spherical mirror surface has a radius \\(R\\), then the distance between the center of the sphere \\(M\\) and the point \\(F\\) is given by\n\\[FM=\\frac{R}{2\\cos(\\alpha)}\\]\nTherefore, we can also calculate the distance of the mirror surface from the point \\(F\\), which results in\n\\[\\begin{equation}\nOF=R\\left (1-\\frac{1}{2\\cos(\\alpha)}\\right)=f\n\\end{equation}\\]\nThis distance is the so-called focal length of the concave mirror \\(f\\). For small angle \\(\\alpha\\), the above equation yields the so called paraxial limit (all angles are small and the rays are close to the optical axis). In this limit we find \\(\\cos(\\alpha)\\approx 1\\) and the focal length becomes \\(f=R/2\\). If we replace the cosine function by \\(\\cos(\\alpha)=\\sqrt{1-\\sin^2(\\alpha)}\\) with \\(\\sin(\\alpha)=h/R\\), we find\n\\[\\begin{equation}\nf=R\\left [ 1-\\frac{R}{2\\sqrt{R^2-h^2}}\\right ]\n\\end{equation}\\]\nThis equation is telling us, that the focal distance is not a single value for a concave mirror. The focal distance rather changes with the distance \\(h\\) from the optical axis. If \\(h\\) approaches \\(R\\) the focal length become shorter.\n\n\n\n\n\n\nFocal Length of a Concave Spherical Mirror\n\n\n\n\n\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Set up the plot\nfig,(ax1,ax2)=plt.subplots(1,2,figsize=(7, 3))\n\n\nax1.axhline(y=0, color='k', linestyle='--', linewidth=0.5)\nax1.axvline(x=0, color='k', linestyle='--', linewidth=0.5)\n\n# Define the spherical mirror\nradius = 4\n\ntheta = np.linspace(-np.pi/3, np.pi/3, 100)\nx = radius * np.sin(theta)\ny = radius * (1 - np.cos(theta))\n\n# Plot the spherical mirror\nax1.plot(x, y, 'b-', linewidth=2, label='Spherical Mirror')\n\n# Calculate and plot the paraxial focal point\nparaxial_focal_length = radius / 2\nax1.plot([0], [paraxial_focal_length], 'ro', markersize=5, label='Paraxial Focal Point')\n\ndef reflect_ray(x0, y0):\n    xc, yc = 0, radius\n\n    # Normal vector\n    nx, ny = x0 - xc, y0 - yc\n    norm = np.sqrt(nx**2 + ny**2)\n    nx, ny = nx/norm, ny/norm\n\n    ix, iy = 0, -1\n\n    # Reflected ray direction\n    dot_product = 2 * (ix*nx + iy*ny)\n    rx, ry = ix - dot_product*nx, iy - dot_product*ny\n\n    return rx, ry\n\n# Plot several reflected rays\nnum_rays = 10\nfor x0 in np.linspace(-3, 3, num_rays):\n    y0 = radius - np.sqrt(radius**2 - x0**2)\n\n    # Incident ray\n    ax1.plot([x0, x0], [5, y0], 'k-', linewidth=1)\n\n    # Reflected ray\n    rx, ry = reflect_ray(x0, y0)\n    t = (0 - x0) / rx  # parameter to reach x=0\n    x1, y1 = x0 + t*rx, y0 + t*ry\n    ax1.plot([x0, x1], [y0, y1], 'k-', linewidth=1)\n\nax1.set_xlabel('h')\nax1.set_ylabel('y')\nax1.grid(True, linestyle=':', alpha=0.7)\nax1.axis('equal')\n\n\ndef focal_length(h, R):\n    return R * (1 - R / (2 * np.sqrt(R**2 - h**2)))\n\nR = 4  # Radius of curvature\nh = np.linspace(0, R*0.99, 1000)  # Range of h values (avoiding h=R which would cause division by zero)\n\nf = focal_length(h, R)\n\nax2.plot(h, f, 'b-', linewidth=2)\n\nax2.axhline(y=R/2, color='r', linestyle='--', label='Paraxial focal length (R/2)')\n\nax2.set_xlabel('h')\nax2.set_ylabel('f')\nax2.grid(True, linestyle=':', alpha=0.7)\n\nax2.set_ylim(0, R/2 * 1.1)\n\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nFigure 4: Spherical mirror of radius \\(R=4\\) reflecting parallel rays, showing spherical aberration and focal distance as a function of the distance from the optical axis \\(h\\).\n\n\n\n\n\n\n\n\nTo obtain now an equation which predicts the point at which the reflected ray intersects the optical axis if it emerged at a point \\(A\\), we just consider the following sketch.\n\n\n\n\n\n\nFigure 5: Image formation on a concave mirror.\n\n\n\nFor this situation, we can write down immediately the following relations\n\\[\\delta=\\alpha+\\gamma\\]\n\\[\\gamma+\\beta=2\\delta\\]\nFurther under the assumption of small angles (paraxial approximation) we can write down\n\\[\\tan(\\gamma) \\approx \\gamma = \\frac{h}{g}\\] \\[\\tan(\\beta) \\approx \\beta = \\frac{h}{b}\\] \\[\\sin(\\delta) \\approx \\delta = \\frac{h}{R}\\]\nfrom which we obtain\n\\[\\frac{h}{g}+\\frac{h}{b}=2\\frac{h}{R}\\]\nand by divding by \\(h\\) finally the imaging equation:\n\\[\\frac{1}{g}+\\frac{1}{b}= \\frac{2}{R}= \\frac{1}{f}\\]\nwhere we have used the focal length \\(f=R/2\\). This equation has some surprising property. It is completely independent of \\(h\\) and \\(\\gamma\\). That means all points in a plane at a distance \\(g\\) are images into a plane at a distance \\(b\\). Both planes are therefore called conjugated planes.\n\n\n\n\n\n\nImaging Equation Concave Mirror\n\n\n\nThe sum of the inverse object and image distances equals the inverse focal length of the cocave mirror.\n\\[\\frac{1}{g}+\\frac{1}{b}\\approx\\frac{1}{f}\\]\n\n\nThis equation now helps to construct the image of an object in front of a concave mirror and we may define 3 different rays to identify the size of an image \\(h_{\\text{image}}\\) from the size of an object \\(h_{\\text{object}}\\).\n\n\n\n\n\n\nFigure 6: Image formation on a concave mirror.\n\n\n\nIn the diagram above, three key rays are used to construct the image:\n\nRed ray: Parallel to optical axis → reflects through focal point\nGreen ray: Through focal point → reflects parallel to optical axis\nCentral ray: Through center of curvature → reflects back along same path\n\nThe behavior of these reflected rays determines the nature of the image:\n\nIf the rays intersect on the same side of the mirror as the object, a real image forms. This image is inverted, as shown in the sketch.\nIf the rays diverge after reflection, they appear to intersect behind the mirror, creating a virtual image. This image is upright and located behind the mirror, though no actual ray intersection occurs.\n\nThe point where these rays meet (or appear to meet) determines the image size. By drawing a ray from the object’s tip through the mirror’s center (point O), we can easily determine the image height h_image. As an exercise, consider how this construction demonstrates that the magnification of a concave mirror is given by\n\\[ \\frac{h_{\\text{image}}}{h_{\\text{object}}}=-\\frac{b}{g}=M\\]\nThis ratio indeed represents the magnification \\(M\\). The negative sign in the expression reflects an important optical property: for real images formed by concave mirrors, the image is inverted relative to the object. This inversion is mathematically represented by the negative magnification value. Conversely, a positive magnification would indicate an upright image, which occurs with virtual images.\nWith the help of the imaging equation and the magnification we may in general differentiate between the following general situations:\n\n\n\n\n\n\n\n\n\nObject Distance\nImage Characteristics\nImage Position\nMagnification\n\n\n\n\n\\(g &gt; 2f\\)\nReal, inverted, smaller\nBetween f and 2f\n\\(|m|\\) &lt; 1\n\n\n\\(g = 2f\\)\nReal, inverted, same size\nAt 2f\n\\(|m|\\) = 1\n\n\n\\(f &lt; g &lt; 2f\\)\nReal, inverted, larger\nBeyond 2f\n\\(|m|\\) &gt; 1\n\n\n\\(g = f\\)\nImage at infinity\nAt infinity\nN/A\n\n\n\\(g &lt; f\\)\nVirtual, upright, larger\nBehind mirror\n\\(|m|\\) &gt; 1\n\n\n\n\n\n\n\n\n\nParabolic Mirrors Focus Parallel Rays\n\n\n\n\n\nWe would like to show in the following, that a parabolic mirror is a shape which reflects all light rays parallel to the principal axis to a single point, the focus. This is a fundamental property of parabolic mirrors and is used in many optical systems, such as telescopes, satellite dishes, and car headlights.\nFor this purpose, we would like to use Fermat’s principle. We examine a light ray originating from a point \\(x,y_0\\) and travelling parallel to the principal axis. The light ray is reflected at a point \\((x,y)\\) on the mirror and travels to the focus at \\((0,p)\\). The light path is therefore consisting out of two linear segments \\(A\\) and \\(B\\) for which we have to calculate the time of travel. The total duration of the light’s journey is then: \\[\nt = t_A + t_B\n\\]\nwhere:\n\n\\(t_A\\) is the time taken to travel from \\(x,y_0\\) to the mirror.\n\\(t_B\\) is the time taken to travel from \\((x,y)\\) to \\((0,p)\\).\n\n\n\nThe distance covered in path A is equal to \\(y_0 - y\\), where \\(y\\) represents the y-coordinate of the point where the ray meets the mirror. Consequently, the time taken for the light to traverse path A can be expressed as:\n\\[\nt_A = \\frac{y_0 - y}{c}\n\\]\nIn this equation, \\(c\\) represents the speed of light in the medium.\n\n\n\nAfter reflection, the light ray travels from the point \\((x, y)\\) on the mirror’s surface to the focal point located at \\((0, p)\\). The length of this segment of the path can be calculated using the distance formula:\n\\[\n\\sqrt{x^2 + (y - p)^2}\n\\]\nConsequently, the time required for the light to traverse path B is expressed as:\n\\[\nt_B = \\frac{\\sqrt{x^2 + (y - p)^2}}{c}\n\\]\n\n\n\nThe total time for the light ray’s journey is the sum of times for paths A and B:\n\\[\nt = \\frac{y_0 - y}{v} + \\frac{\\sqrt{x^2 + (y - p)^2}}{c}\n\\]\nAccording to Fermat’s principle, all light rays should take the same time. We can express this by setting the total time equal to a constant \\(t_c\\):\n\\[\n\\frac{y_0 - y}{v} + \\frac{\\sqrt{x^2 + (y - p)^2}}{v} = t_c\n\\]\nFor a ray traveling along the y-axis, reflecting at \\((0, 0)\\), the total distance is \\(y_0 + p\\). The time for this ray is:\n\\[\n\\frac{y_0 + p}{c}\n\\]\nThis gives us \\(t_c = \\frac{y_0 + p}{c}\\). Substituting into our general equation:\n\\[\n\\frac{y_0 - y}{v} + \\frac{\\sqrt{x^2 + (y - p)^2}}{c} = \\frac{y_0 + p}{c}\n\\]\nMultiplying by \\(c\\) and rearranging:\n\\[\ny_0 - y + \\sqrt{x^2 + (y - p)^2} = y_0 + p\n\\]\n\\[\n\\sqrt{x^2 + (y - p)^2} = y + p\n\\]\nSquaring both sides and simplifying:\n\\[\nx^2 + (y - p)^2 = (y + p)^2\n\\]\n\\[\nx^2 + y^2 - 2py + p^2 = y^2 + 2py + p^2\n\\]\n\\[\nx^2 = 4py\n\\]\nor\n\\[\ny=\\frac{1}{4p}x^2\n\\]\nThis final equation describes a parabola with its focus at \\((0, p)\\). The code below plots a parabolic mirror reflecting parallel rays to the focal point. Yet, I’m cheating a bit here. I’m not calculating the reflected rays, but just plotting them.\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(4, 4))\nplt.axhline(y=0, color='k', linestyle='--', linewidth=0.5)\nplt.axvline(x=0, color='k', linestyle='--', linewidth=0.5)\n\nfocal_length = 2\nx = np.linspace(-4, 4, 100)\ny = x**2 / (4 * focal_length)\n\n\nplt.plot([0], [focal_length], 'ro', markersize=5, label='Focal Point')\n\ndef plot_reflected_ray(x0, y0):\n    plt.plot([x0, x0], [5, y0], 'k-', linewidth=1)\n\n    m = 2 * (y0/x0)  # Slope of reflected ray\n    x1 = 0\n    y1 = focal_length\n    plt.plot([x0, x1], [y0, y1], 'k-', linewidth=1)\n\nfor x0 in np.linspace(-3.5, 3.5, 8):\n    y0 = x0**2 / (4 * focal_length)\n    plot_reflected_ray(x0, y0)\n\nplt.plot(x, y, 'b-', linewidth=3, label='Parabolic Mirror')\n\nplt.xlabel('x')\nplt.ylabel('y')\nplt.grid(True, linestyle=':', alpha=0.7)\nplt.axis('equal')\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nFigure 7: Parabolic mirror reflecting parallel rays to focal point\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nElliptical Mirrors and Fermat’s Principle\n\n\n\n\n\nThere is one interesting feature about elliptical mirrors: they can focus light from one focal point to the other. This is because the sum of the distances from any point on the ellipse to the two focal points is constant. This property is known as the ellipse’s geometric definition and you can try that at home with a piece of string and two pins.\nWe can now apply Fermat’s principle to proof that the light reflected from the ellipse travels a path length that is a saddle point. This means that the path length is stationary with respect to small perturbations in the path. Assuming for example that light travels from one focal point by a different path that is reflected from a line which is tangent to the ellipse at the point of reflection, the path length would be longer at any other point than the initial reflection point.\nOn the other side, if we reflect the ray on a surface that is a circle, which is intersecting the ellipse at the point of reflection, the path length would be shorter at any other point than the initial reflection point. This is a proof that the ellipse is a saddle point.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConsider an ellipse with semi-major axis \\(a\\) and semi-minor axis \\(b\\), defined by:\n\\[\\frac{x^2}{a^2} + \\frac{y^2}{b^2} = 1\\]\n\n\nThe focal points are located at \\(F_1(-c, 0)\\) and \\(F_2(c, 0)\\), where:\n\\[c^2 = a^2 - b^2\\]\n\n\n\nLet \\(P(x_0, y_0)\\) be a point on the ellipse. The total path length \\(L\\) from \\(F_1\\) to \\(F_2\\) via \\(P\\) is:\n\\[L = |F_1P| + |PF_2| = \\sqrt{(x_0+c)^2 + y_0^2} + \\sqrt{(x_0-c)^2 + y_0^2}\\]\n\n\n\nThe path length \\(L\\) is stationary with respect to small perturbations in \\(P\\):\n\\[\\frac{\\partial L}{\\partial x_0} = 0 \\quad \\text{and} \\quad \\frac{\\partial L}{\\partial y_0} = 0 \\quad \\text{at the reflection point}\\]\n\n\n\nThe tangent line to the ellipse at \\(P(x_0, y_0)\\) is given by:\n\\[\\frac{x_0x}{a^2} + \\frac{y_0y}{b^2} = 1\\]\nLet \\(Q\\) be any point on this tangent line different from \\(P\\). The path \\(F_1 \\to Q \\to F_2\\) is longer than \\(F_1 \\to P \\to F_2\\):\n\\[|F_1Q| + |QF_2| &gt; |F_1P| + |PF_2|\\]\n\n\n\nThe radius of curvature \\(R\\) at \\(P\\) is:\n\\[R = \\frac{(a^2b^2)^{3/2}}{(b^2x_0^2 + a^2y_0^2)^{3/2}}\\]\nThe center of curvature \\(C\\) is located at:\n\\[C = P + R\\cdot\\mathbf{n}\\]\nwhere \\(\\mathbf{n}\\) is the unit normal vector at \\(P\\).\nLet \\(Q\\) be any point on this circle different from \\(P\\). The path \\(F_1 \\to Q \\to F_2\\) is shorter than \\(F_1 \\to P \\to F_2\\):\n\\[|F_1Q| + |QF_2| &lt; |F_1P| + |PF_2|\\]\nAs a consequence, the path length for the reflection on and ellipse between the two focal points must be a saddle point.",
    "crumbs": [
      "Geometrical Optics",
      "Lecture 2",
      "Optical Elements I - Mirrors"
    ]
  },
  {
    "objectID": "geometrical-optics/Optical Elements I.html#mirrors",
    "href": "geometrical-optics/Optical Elements I.html#mirrors",
    "title": "Optical Elements Part I",
    "section": "",
    "text": "When light radiates from a point \\(P\\) and reflects off a mirror, as shown in the image, the reflected rays diverge but appear to originate from a point \\(P'\\) located behind the mirror. According to the law of reflection, this image point is positioned at the same distance behind the mirror as the original object point is in front of it. As a result, an observer receiving these reflected rays, such as on their retina, perceives the point as if it were situated behind the mirror, even though no light actually travels behind the mirror surface.\n\n\n\n\n\n\n\n\n\n\n\n(a)\n\n\n\n\n\n\n\n\n\n\n\n(b)\n\n\n\n\n\n\n\nFigure 1: Image formation on a plane mirror.\n\n\n\nWhen multiple points of an object emit light towards the mirror, this principle applies to each point. As a result, the entire object appears as an image behind the mirror. Since each point of the image is equidistant from the mirror as its corresponding object point, the image has the same size as the object. This leads to the definition of magnification as:\n\\[\nM=\\frac{h_{\\text{image}}}{h_{\\text{object}}}\n\\]\n\n\n\n\n\n\nFigure 2: Image formation on a plane mirror.\n\n\n\n\n\n\n\n\n\nVirtual Images\n\n\n\nA virtual image is an optical illusion where light rays appear to come from a point, but don’t actually converge there. Unlike real images, virtual images can’t be projected onto a screen. They’re commonly seen in plane mirrors, convex mirrors, and when objects are closer to a lens than its focal point. Remember: for virtual images, light rays only seem to originate from the image when traced backwards.\n\n\n\n\n\n\n\n\nReal Images\n\n\n\nA real image forms when light rays actually meet at a point after reflection or refraction. These images can be projected onto a screen because light physically passes through the image location. Real images are often inverted and occur with concave mirrors and lenses when objects are beyond the focal point. Key point: real images involve actual convergence of light rays.\n\n\n\n\n\nFor a concave mirror (where the reflecting surface is on the inside of the spherical curve), applying the law of reflection yields interesting results. Light rays parallel to the optical axis, at a distance \\(h\\) from it, are reflected towards the axis and intersect it at a specific point \\(F\\). Due to the mirror’s symmetry, a parallel ray on the opposite side of the axis will also converge to this same point \\(F\\).\n\n\n\n\n\n\nFigure 3: Reflection of a parallel ray incident at a height \\(h\\) from the optical axis on a concave mirror.\n\n\n\nWe may calculate the position of the point \\(F\\), e.g. the distance from the mirror surface point \\(O\\), by applying the law of reflection. If the spherical mirror surface has a radius \\(R\\), then the distance between the center of the sphere \\(M\\) and the point \\(F\\) is given by\n\\[FM=\\frac{R}{2\\cos(\\alpha)}\\]\nTherefore, we can also calculate the distance of the mirror surface from the point \\(F\\), which results in\n\\[\\begin{equation}\nOF=R\\left (1-\\frac{1}{2\\cos(\\alpha)}\\right)=f\n\\end{equation}\\]\nThis distance is the so-called focal length of the concave mirror \\(f\\). For small angle \\(\\alpha\\), the above equation yields the so called paraxial limit (all angles are small and the rays are close to the optical axis). In this limit we find \\(\\cos(\\alpha)\\approx 1\\) and the focal length becomes \\(f=R/2\\). If we replace the cosine function by \\(\\cos(\\alpha)=\\sqrt{1-\\sin^2(\\alpha)}\\) with \\(\\sin(\\alpha)=h/R\\), we find\n\\[\\begin{equation}\nf=R\\left [ 1-\\frac{R}{2\\sqrt{R^2-h^2}}\\right ]\n\\end{equation}\\]\nThis equation is telling us, that the focal distance is not a single value for a concave mirror. The focal distance rather changes with the distance \\(h\\) from the optical axis. If \\(h\\) approaches \\(R\\) the focal length become shorter.\n\n\n\n\n\n\nFocal Length of a Concave Spherical Mirror\n\n\n\n\n\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Set up the plot\nfig,(ax1,ax2)=plt.subplots(1,2,figsize=(7, 3))\n\n\nax1.axhline(y=0, color='k', linestyle='--', linewidth=0.5)\nax1.axvline(x=0, color='k', linestyle='--', linewidth=0.5)\n\n# Define the spherical mirror\nradius = 4\n\ntheta = np.linspace(-np.pi/3, np.pi/3, 100)\nx = radius * np.sin(theta)\ny = radius * (1 - np.cos(theta))\n\n# Plot the spherical mirror\nax1.plot(x, y, 'b-', linewidth=2, label='Spherical Mirror')\n\n# Calculate and plot the paraxial focal point\nparaxial_focal_length = radius / 2\nax1.plot([0], [paraxial_focal_length], 'ro', markersize=5, label='Paraxial Focal Point')\n\ndef reflect_ray(x0, y0):\n    xc, yc = 0, radius\n\n    # Normal vector\n    nx, ny = x0 - xc, y0 - yc\n    norm = np.sqrt(nx**2 + ny**2)\n    nx, ny = nx/norm, ny/norm\n\n    ix, iy = 0, -1\n\n    # Reflected ray direction\n    dot_product = 2 * (ix*nx + iy*ny)\n    rx, ry = ix - dot_product*nx, iy - dot_product*ny\n\n    return rx, ry\n\n# Plot several reflected rays\nnum_rays = 10\nfor x0 in np.linspace(-3, 3, num_rays):\n    y0 = radius - np.sqrt(radius**2 - x0**2)\n\n    # Incident ray\n    ax1.plot([x0, x0], [5, y0], 'k-', linewidth=1)\n\n    # Reflected ray\n    rx, ry = reflect_ray(x0, y0)\n    t = (0 - x0) / rx  # parameter to reach x=0\n    x1, y1 = x0 + t*rx, y0 + t*ry\n    ax1.plot([x0, x1], [y0, y1], 'k-', linewidth=1)\n\nax1.set_xlabel('h')\nax1.set_ylabel('y')\nax1.grid(True, linestyle=':', alpha=0.7)\nax1.axis('equal')\n\n\ndef focal_length(h, R):\n    return R * (1 - R / (2 * np.sqrt(R**2 - h**2)))\n\nR = 4  # Radius of curvature\nh = np.linspace(0, R*0.99, 1000)  # Range of h values (avoiding h=R which would cause division by zero)\n\nf = focal_length(h, R)\n\nax2.plot(h, f, 'b-', linewidth=2)\n\nax2.axhline(y=R/2, color='r', linestyle='--', label='Paraxial focal length (R/2)')\n\nax2.set_xlabel('h')\nax2.set_ylabel('f')\nax2.grid(True, linestyle=':', alpha=0.7)\n\nax2.set_ylim(0, R/2 * 1.1)\n\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nFigure 4: Spherical mirror of radius \\(R=4\\) reflecting parallel rays, showing spherical aberration and focal distance as a function of the distance from the optical axis \\(h\\).\n\n\n\n\n\n\n\n\nTo obtain now an equation which predicts the point at which the reflected ray intersects the optical axis if it emerged at a point \\(A\\), we just consider the following sketch.\n\n\n\n\n\n\nFigure 5: Image formation on a concave mirror.\n\n\n\nFor this situation, we can write down immediately the following relations\n\\[\\delta=\\alpha+\\gamma\\]\n\\[\\gamma+\\beta=2\\delta\\]\nFurther under the assumption of small angles (paraxial approximation) we can write down\n\\[\\tan(\\gamma) \\approx \\gamma = \\frac{h}{g}\\] \\[\\tan(\\beta) \\approx \\beta = \\frac{h}{b}\\] \\[\\sin(\\delta) \\approx \\delta = \\frac{h}{R}\\]\nfrom which we obtain\n\\[\\frac{h}{g}+\\frac{h}{b}=2\\frac{h}{R}\\]\nand by divding by \\(h\\) finally the imaging equation:\n\\[\\frac{1}{g}+\\frac{1}{b}= \\frac{2}{R}= \\frac{1}{f}\\]\nwhere we have used the focal length \\(f=R/2\\). This equation has some surprising property. It is completely independent of \\(h\\) and \\(\\gamma\\). That means all points in a plane at a distance \\(g\\) are images into a plane at a distance \\(b\\). Both planes are therefore called conjugated planes.\n\n\n\n\n\n\nImaging Equation Concave Mirror\n\n\n\nThe sum of the inverse object and image distances equals the inverse focal length of the cocave mirror.\n\\[\\frac{1}{g}+\\frac{1}{b}\\approx\\frac{1}{f}\\]\n\n\nThis equation now helps to construct the image of an object in front of a concave mirror and we may define 3 different rays to identify the size of an image \\(h_{\\text{image}}\\) from the size of an object \\(h_{\\text{object}}\\).\n\n\n\n\n\n\nFigure 6: Image formation on a concave mirror.\n\n\n\nIn the diagram above, three key rays are used to construct the image:\n\nRed ray: Parallel to optical axis → reflects through focal point\nGreen ray: Through focal point → reflects parallel to optical axis\nCentral ray: Through center of curvature → reflects back along same path\n\nThe behavior of these reflected rays determines the nature of the image:\n\nIf the rays intersect on the same side of the mirror as the object, a real image forms. This image is inverted, as shown in the sketch.\nIf the rays diverge after reflection, they appear to intersect behind the mirror, creating a virtual image. This image is upright and located behind the mirror, though no actual ray intersection occurs.\n\nThe point where these rays meet (or appear to meet) determines the image size. By drawing a ray from the object’s tip through the mirror’s center (point O), we can easily determine the image height h_image. As an exercise, consider how this construction demonstrates that the magnification of a concave mirror is given by\n\\[ \\frac{h_{\\text{image}}}{h_{\\text{object}}}=-\\frac{b}{g}=M\\]\nThis ratio indeed represents the magnification \\(M\\). The negative sign in the expression reflects an important optical property: for real images formed by concave mirrors, the image is inverted relative to the object. This inversion is mathematically represented by the negative magnification value. Conversely, a positive magnification would indicate an upright image, which occurs with virtual images.\nWith the help of the imaging equation and the magnification we may in general differentiate between the following general situations:\n\n\n\n\n\n\n\n\n\nObject Distance\nImage Characteristics\nImage Position\nMagnification\n\n\n\n\n\\(g &gt; 2f\\)\nReal, inverted, smaller\nBetween f and 2f\n\\(|m|\\) &lt; 1\n\n\n\\(g = 2f\\)\nReal, inverted, same size\nAt 2f\n\\(|m|\\) = 1\n\n\n\\(f &lt; g &lt; 2f\\)\nReal, inverted, larger\nBeyond 2f\n\\(|m|\\) &gt; 1\n\n\n\\(g = f\\)\nImage at infinity\nAt infinity\nN/A\n\n\n\\(g &lt; f\\)\nVirtual, upright, larger\nBehind mirror\n\\(|m|\\) &gt; 1\n\n\n\n\n\n\n\n\n\nParabolic Mirrors Focus Parallel Rays\n\n\n\n\n\nWe would like to show in the following, that a parabolic mirror is a shape which reflects all light rays parallel to the principal axis to a single point, the focus. This is a fundamental property of parabolic mirrors and is used in many optical systems, such as telescopes, satellite dishes, and car headlights.\nFor this purpose, we would like to use Fermat’s principle. We examine a light ray originating from a point \\(x,y_0\\) and travelling parallel to the principal axis. The light ray is reflected at a point \\((x,y)\\) on the mirror and travels to the focus at \\((0,p)\\). The light path is therefore consisting out of two linear segments \\(A\\) and \\(B\\) for which we have to calculate the time of travel. The total duration of the light’s journey is then: \\[\nt = t_A + t_B\n\\]\nwhere:\n\n\\(t_A\\) is the time taken to travel from \\(x,y_0\\) to the mirror.\n\\(t_B\\) is the time taken to travel from \\((x,y)\\) to \\((0,p)\\).\n\n\n\nThe distance covered in path A is equal to \\(y_0 - y\\), where \\(y\\) represents the y-coordinate of the point where the ray meets the mirror. Consequently, the time taken for the light to traverse path A can be expressed as:\n\\[\nt_A = \\frac{y_0 - y}{c}\n\\]\nIn this equation, \\(c\\) represents the speed of light in the medium.\n\n\n\nAfter reflection, the light ray travels from the point \\((x, y)\\) on the mirror’s surface to the focal point located at \\((0, p)\\). The length of this segment of the path can be calculated using the distance formula:\n\\[\n\\sqrt{x^2 + (y - p)^2}\n\\]\nConsequently, the time required for the light to traverse path B is expressed as:\n\\[\nt_B = \\frac{\\sqrt{x^2 + (y - p)^2}}{c}\n\\]\n\n\n\nThe total time for the light ray’s journey is the sum of times for paths A and B:\n\\[\nt = \\frac{y_0 - y}{v} + \\frac{\\sqrt{x^2 + (y - p)^2}}{c}\n\\]\nAccording to Fermat’s principle, all light rays should take the same time. We can express this by setting the total time equal to a constant \\(t_c\\):\n\\[\n\\frac{y_0 - y}{v} + \\frac{\\sqrt{x^2 + (y - p)^2}}{v} = t_c\n\\]\nFor a ray traveling along the y-axis, reflecting at \\((0, 0)\\), the total distance is \\(y_0 + p\\). The time for this ray is:\n\\[\n\\frac{y_0 + p}{c}\n\\]\nThis gives us \\(t_c = \\frac{y_0 + p}{c}\\). Substituting into our general equation:\n\\[\n\\frac{y_0 - y}{v} + \\frac{\\sqrt{x^2 + (y - p)^2}}{c} = \\frac{y_0 + p}{c}\n\\]\nMultiplying by \\(c\\) and rearranging:\n\\[\ny_0 - y + \\sqrt{x^2 + (y - p)^2} = y_0 + p\n\\]\n\\[\n\\sqrt{x^2 + (y - p)^2} = y + p\n\\]\nSquaring both sides and simplifying:\n\\[\nx^2 + (y - p)^2 = (y + p)^2\n\\]\n\\[\nx^2 + y^2 - 2py + p^2 = y^2 + 2py + p^2\n\\]\n\\[\nx^2 = 4py\n\\]\nor\n\\[\ny=\\frac{1}{4p}x^2\n\\]\nThis final equation describes a parabola with its focus at \\((0, p)\\). The code below plots a parabolic mirror reflecting parallel rays to the focal point. Yet, I’m cheating a bit here. I’m not calculating the reflected rays, but just plotting them.\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(4, 4))\nplt.axhline(y=0, color='k', linestyle='--', linewidth=0.5)\nplt.axvline(x=0, color='k', linestyle='--', linewidth=0.5)\n\nfocal_length = 2\nx = np.linspace(-4, 4, 100)\ny = x**2 / (4 * focal_length)\n\n\nplt.plot([0], [focal_length], 'ro', markersize=5, label='Focal Point')\n\ndef plot_reflected_ray(x0, y0):\n    plt.plot([x0, x0], [5, y0], 'k-', linewidth=1)\n\n    m = 2 * (y0/x0)  # Slope of reflected ray\n    x1 = 0\n    y1 = focal_length\n    plt.plot([x0, x1], [y0, y1], 'k-', linewidth=1)\n\nfor x0 in np.linspace(-3.5, 3.5, 8):\n    y0 = x0**2 / (4 * focal_length)\n    plot_reflected_ray(x0, y0)\n\nplt.plot(x, y, 'b-', linewidth=3, label='Parabolic Mirror')\n\nplt.xlabel('x')\nplt.ylabel('y')\nplt.grid(True, linestyle=':', alpha=0.7)\nplt.axis('equal')\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nFigure 7: Parabolic mirror reflecting parallel rays to focal point\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nElliptical Mirrors and Fermat’s Principle\n\n\n\n\n\nThere is one interesting feature about elliptical mirrors: they can focus light from one focal point to the other. This is because the sum of the distances from any point on the ellipse to the two focal points is constant. This property is known as the ellipse’s geometric definition and you can try that at home with a piece of string and two pins.\nWe can now apply Fermat’s principle to proof that the light reflected from the ellipse travels a path length that is a saddle point. This means that the path length is stationary with respect to small perturbations in the path. Assuming for example that light travels from one focal point by a different path that is reflected from a line which is tangent to the ellipse at the point of reflection, the path length would be longer at any other point than the initial reflection point.\nOn the other side, if we reflect the ray on a surface that is a circle, which is intersecting the ellipse at the point of reflection, the path length would be shorter at any other point than the initial reflection point. This is a proof that the ellipse is a saddle point.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConsider an ellipse with semi-major axis \\(a\\) and semi-minor axis \\(b\\), defined by:\n\\[\\frac{x^2}{a^2} + \\frac{y^2}{b^2} = 1\\]\n\n\nThe focal points are located at \\(F_1(-c, 0)\\) and \\(F_2(c, 0)\\), where:\n\\[c^2 = a^2 - b^2\\]\n\n\n\nLet \\(P(x_0, y_0)\\) be a point on the ellipse. The total path length \\(L\\) from \\(F_1\\) to \\(F_2\\) via \\(P\\) is:\n\\[L = |F_1P| + |PF_2| = \\sqrt{(x_0+c)^2 + y_0^2} + \\sqrt{(x_0-c)^2 + y_0^2}\\]\n\n\n\nThe path length \\(L\\) is stationary with respect to small perturbations in \\(P\\):\n\\[\\frac{\\partial L}{\\partial x_0} = 0 \\quad \\text{and} \\quad \\frac{\\partial L}{\\partial y_0} = 0 \\quad \\text{at the reflection point}\\]\n\n\n\nThe tangent line to the ellipse at \\(P(x_0, y_0)\\) is given by:\n\\[\\frac{x_0x}{a^2} + \\frac{y_0y}{b^2} = 1\\]\nLet \\(Q\\) be any point on this tangent line different from \\(P\\). The path \\(F_1 \\to Q \\to F_2\\) is longer than \\(F_1 \\to P \\to F_2\\):\n\\[|F_1Q| + |QF_2| &gt; |F_1P| + |PF_2|\\]\n\n\n\nThe radius of curvature \\(R\\) at \\(P\\) is:\n\\[R = \\frac{(a^2b^2)^{3/2}}{(b^2x_0^2 + a^2y_0^2)^{3/2}}\\]\nThe center of curvature \\(C\\) is located at:\n\\[C = P + R\\cdot\\mathbf{n}\\]\nwhere \\(\\mathbf{n}\\) is the unit normal vector at \\(P\\).\nLet \\(Q\\) be any point on this circle different from \\(P\\). The path \\(F_1 \\to Q \\to F_2\\) is shorter than \\(F_1 \\to P \\to F_2\\):\n\\[|F_1Q| + |QF_2| &lt; |F_1P| + |PF_2|\\]\nAs a consequence, the path length for the reflection on and ellipse between the two focal points must be a saddle point.",
    "crumbs": [
      "Geometrical Optics",
      "Lecture 2",
      "Optical Elements I - Mirrors"
    ]
  },
  {
    "objectID": "geometrical-optics/Imaging Errors.html",
    "href": "geometrical-optics/Imaging Errors.html",
    "title": "Imaging Errors",
    "section": "",
    "text": "During our derivation of the imaging equation for lenses and the lens-maker equation we have been working under the paraxial approximation. This approximation stated, that all rays are close to the optical axis and therefore make only small angles with the surface normals of the curved surfaces of lenses (but also mirrors). If we violate this approximation, i.e. if we use rays, which are incident for from the optical axis or strongly inclined, then we end up with reflections and refraction which do not obey the imaging equation. In addition we have seen that light propagation for different colors is subject to different refractive indices (remember the prism). Thus we will induce aberrations, related to color. According to Seidel, aberration are classified the following way"
  },
  {
    "objectID": "geometrical-optics/Imaging Errors.html#chromatic-aberration",
    "href": "geometrical-optics/Imaging Errors.html#chromatic-aberration",
    "title": "Imaging Errors",
    "section": "Chromatic Aberration",
    "text": "Chromatic Aberration\nChromatic Aberration are based on the fact that light of different color has a different speed of propgation and thus also a different refractive index. We experienced that also for the prism, where it was useful to create a spectrograph. Here it is causing colored edges in you image, which you do not want.\nAs the refractive index for shorter wavelength is typically higher, we expect that the blue color has a shorter focal distance than the red color.\n\n\n\n\n\n\n\n\n\n\n\n(a) Sketch\n\n\n\n\n\n\n\n\n\n\n\n\n\n(b) Lecture\n\n\n\n\n\n\n\n\n\n\n\n(c) Rendered\n\n\n\n\n\n\n\nFigure 1— Chromatic aberration. Left: Sketch of the chromatic aberration, focusing red light less strong than blue. Middle: Image from the lecture. Right: Rendered image using the refractive index for BK7 glass.\n\n\n\nHere is a plot for the variation of the focal distance of a lens with a radius of curvature of 100 mm as a function of the wavelength for three different glasses.\n\n\nCode\nbk7=pd.read_csv(\"data/BK7.csv\",delimiter=\",\")\nsf10=pd.read_csv(\"data/SF10.csv\",delimiter=\",\")\nfk51a=pd.read_csv(\"data/FK51A.csv\",delimiter=\",\")\n\nwavelengths = bk7.wl*1000\nn_bk7 = bk7.n\n\nR = 100  # radius of curvature in mm\ny_max = 50  # max height of lens\n\ndef f(n,R):\n    return 1/(n-1)*R/2\n\nplt.figure(figsize=get_size(8,8))\nplt.plot(bk7.wl*1000, f(bk7.n,R),label=\"BK7\")\nplt.plot(sf10.wl*1000, f(sf10.n,R),label=\"SF10\")\nplt.plot(fk51a.wl*1000, f(fk51a.n,R),label=\"FK51a\")\nplt.grid(True)\nplt.xlabel(r'wavelength $\\lambda$ [nm]')\nplt.ylabel('focal distance f [mm]')\nplt.xlim(400,700)\nplt.legend()\n#plt.ylim(94,98)\nplt.show()\n\n\n\n\n\nFocal distance of a Bk7, SF10 and FK51a lens with a radius of curvature of 100 mm as a function of the wavelength.\n\n\n\n\nSuch a chromatic aberrations may be corrected by using a system of two lenses as shown below.\n\n\n\n\n\n\nFigure 2— Correction of chromatic aberration by a lens doublet with a convex and a a concave lens.\n\n\n\nChromatic aberration can be corrected by using an achromatic lens. Achromatic lenses are typically constructed by combining two lenses with different optical properties: a biconvex lens made of crown glass (lower dispersion) bonded to a biconcave lens made of flint glass (higher dispersion). This combination allows for the correction of chromatic aberration. Each lens \\(i\\) has a focal length according to the lensmaker equation:\n\\[\n\\frac{1}{f_i}=(n_i-1)\\rho_i\n\\]\nwhere \\(\\rho_i\\) is given by:\n\\[\n\\rho_i=\\frac{(R_{i2}-R_{i1})}{R_{i1}R_{i2}}\n\\]\nFor a system of two lenses in contact, the total refractive power is:\n\\[\n\\frac{1}{f}=(n_1-1)\\rho_1+(n_2-1)\\rho_2\n\\]\nFor color correction, we require equal focusing of red and blue light:\n\\[\n(n_{1r}-1)\\rho_1+(n_{2r}-1)\\rho_2=(n_{1b}-1)\\rho_1+(n_{2b}-1)\\rho_2\n\\]\nThis transforms to:\n\\[\n\\frac{\\rho_1}{\\rho_2}=-\\frac{n_{2b}-n_{2r}}{n_{1b}-n_{1r}}\n\\]\nFor the specific geometry shown in the achromat figure where:\n\n\\(R_{12}=R_{21}\\) (common radius at contact surface)\n\\(R_{11}=R_1=-R_{12}=-R_{21}\\)\n\\(R_{22}=R_2\\)\n\nwe can express \\(\\rho_1\\) and \\(\\rho_2\\) as:\n\\[\n\\rho_1=\\frac{2}{R_1} \\quad \\text{and} \\quad \\rho_2=\\frac{-1}{R_1}+\\frac{1}{R_2}\n\\]\nSubstituting these into the color correction condition gives us the relationship between \\(R_1\\) and \\(R_2\\) needed for an achromatic doublet. Substituting the expressions for \\(\\rho_1\\) and \\(\\rho_2\\) into:\n\\[\n\\frac{\\rho_1}{\\rho_2}=-\\frac{n_{2b}-n_{2r}}{n_{1b}-n_{1r}}\n\\]\nwe get:\n\\[\n\\frac{2/R_1}{-1/R_1+1/R_2}=-\\frac{n_{2b}-n_{2r}}{n_{1b}-n_{1r}}\n\\]\nLet’s define the dispersion ratios (typically called V-numbers or Abbe numbers): \\[\nV_1=\\frac{n_{1r}-1}{n_{1b}-n_{1r}} \\quad \\text{and} \\quad V_2=\\frac{n_{2r}-1}{n_{2b}-n_{2r}}\n\\]\nThen, after some algebra, the relationship between \\(R_1\\) and \\(R_2\\) becomes:\n\\[\n\\frac{R_2}{R_1}=1+2\\frac{V_2(n_{1r}-1)}{V_1(n_{2r}-1)}\n\\]\nThis equation determines the ratio of radii needed to achieve an achromatic doublet for the chosen glass materials.\n\n\n\n\n\n\nChromatic Aberration\n\n\n\nAn optical aberration caused by the wavelength-dependent refractive index of materials, resulting in different colors focusing at different distances from the lens, typically with blue light focusing closer to the lens than red light."
  },
  {
    "objectID": "geometrical-optics/Imaging Errors.html#spherical-aberration",
    "href": "geometrical-optics/Imaging Errors.html#spherical-aberration",
    "title": "Imaging Errors",
    "section": "Spherical Aberration",
    "text": "Spherical Aberration\nThe spherical abberation arises due to the fact that we have always considered a simplification of the angluar functions to their first order Taylor series expansion. If the angles of incidence on the spherical surfaces get to large, we cannot do that anymore and need to consider higher order corrections.\nThe result is that parallel rays which are far from the optical axis are not imaged into the same focal point as the paraxial rays, but to points closer to the lens. You might have all seen such effect also in the case of your empty coffee cup, when the sunlight enters and causes a so-called caustics. This pattern, you observe there is also the result of a soherical aberration. The image below shows the spherical aberration of a lens.\n\n\n\n\n\n\n\n\n\n\n\n(a) Sketch\n\n\n\n\n\n\n\n\n\n\n\n(b) Experimental\n\n\n\n\n\n\n\nFigure 3— Spherical aberration. Left: Schematic illustration showing how parallel rays at different distances from the optical axis focus at different points. Right: Experimental demonstration from the lecture.\n\n\n\nTo be a bit more qauntitative, we would like to reconsider the refraction at a single spherical surface as depicted in the image below.\n\n\n\n\n\n\nFigure 4— Spherical aberration: Theoretical ray tracing showing the focal point variation with incident ray height.\n\n\n\nFor spherical surfaces, we can derive a more accurate expression for the focal length using the following relations: \\[\\sin(\\beta)=\\frac{\\sin(\\alpha)}{n}, \\quad \\sin(\\alpha)=\\frac{h}{R}, \\quad \\alpha=\\beta+\\gamma\\]\nUsing these relations, we obtain \\(f=R+b\\) and \\(b=R\\sin(\\beta)/\\sin(\\gamma)\\), which can be transformed into:\n\\[\nf=R\\left [ 1+ \\frac{1}{n\\cos(\\beta)-\\cos(\\alpha)}\\right ]\n\\]\nBy replacing the cosines with their corresponding expressions, we get:\n\\[\nf=R\\left [ 1+ \\frac{1}{n\\sqrt{1-\\frac{h^2}{n^2 R^2}}-\\sqrt{1-\\frac{h^2}{R^2}}}\\right ]\n\\]\nExpanding the square roots leads to:\n\\[\nf=R\\left [ \\frac{n}{n-1}- \\frac{h^2}{2n(n-1)R^2} \\right]\n\\]\nThis result reveals that the focal length depends on the height \\(h\\) at which the ray is incident on the spherical surface, similar to the case of concave mirrors. The second term in the square brackets represents this height-dependent contribution, which reduces the focal length when \\(h\\neq 0\\).\nFrom these relations, we can derive an imaging equation for a single spherical surface:\n\\[\n\\frac{1}{a}+\\frac{n}{b}=\\frac{n-1}{R}+h^2\\left [ \\frac{1}{2a}\\left ( \\frac{1}{a}+\\frac{1}{R}\\right )^2 +\\frac{n}{2b}\\left ( \\frac{1}{R}-\\frac{1}{b}\\right )^2\\right]\n\\]\nThis complex equation for a single surface demonstrates that the image is no longer formed on a plane; instead, its location depends on both \\(R\\) and \\(h\\). This height dependence for a single surface manifests in various image distortions, including field curvature.\n\n\n\n\n\n\nSpherical Aberration\n\n\n\nAn optical aberration where rays passing through a lens at different distances from the optical axis focus at different points along the axis, with rays through the outer regions of the lens focusing closer to the lens than rays passing near the center."
  },
  {
    "objectID": "geometrical-optics/Imaging Errors.html#field-curvature",
    "href": "geometrical-optics/Imaging Errors.html#field-curvature",
    "title": "Imaging Errors",
    "section": "Field Curvature",
    "text": "Field Curvature\nThe field curvature is related to our calculations of the spherical abberation. We have seen there, that the focal distance depends on the height \\(h\\) of the rays over the optical axis. This means also means that the image plane is actually not anymore a plane but a curved surface as shown below. The rays incident from point \\(A_0\\) and \\(A_1\\) do not meet in the same plane. This plane is even different for meridional and saggital rays. This typically results in the fact, that you may have the center of the image in focus, but not the edges or vice versa.\n\n\n\n\n\n\n\n\n\n\n\n(a) Sketch\n\n\n\n\n\n\n\n\n\n\n\n(b) Experimental\n\n\n\n\n\n\n\nFigure 5— Field curvature in optical systems. Left: Schematic diagram showing how a flat object plane is imaged onto a curved image surface (Petzval surface) rather than a flat image plane. This causes different regions of the image to focus at different distances from the lens. Right: Experimental demonstration showing how either the center or the edges of the image can be in focus, but not simultaneously, when using a flat detector. This aberration is particularly noticeable in wide-field imaging systems with simple lenses.\n\n\n\n\n\n\n\n\n\nField Curvature\n\n\n\nAn optical aberration where the image of a flat object is formed on a curved surface rather than a plane, causing the center and edges of the image field to not be simultaneously in focus on a flat detector or screen."
  },
  {
    "objectID": "geometrical-optics/Imaging Errors.html#coma",
    "href": "geometrical-optics/Imaging Errors.html#coma",
    "title": "Imaging Errors",
    "section": "Coma",
    "text": "Coma\nWhile our previous discussion focused on rays parallel to the optical axis at varying distances, significant aberrations also occur for rays emanating from off-axis object points (both at finite and infinite distances). One important example of such an aberration is “coma.”\nIn the case of coma, rays entering the lens at different heights with an angle to the optical axis do not converge to a single point in the image plane. Instead, they create a characteristic comet-shaped intensity distribution, where the light is asymmetrically distributed with a bright head and a diffuse tail pointing radially outward from the optical axis. This asymmetric distribution occurs because rays passing through different zones of the lens experience different effective magnifications, leading to the distinctive comet-like shape that gives this aberration its name.\nThe severity of coma typically increases with the distance from the optical axis and with larger apertures, making it particularly problematic in wide-field imaging systems or when using large-aperture optics.\n\n\n\n\n\n\n\n\n\n\n\n(a) Sketch\n\n\n\n\n\n\n\n\n\n\n\n(b) Experimental\n\n\n\n\n\n\n\nFigure 6— Coma aberration in optical systems. Left: Schematic illustration showing how oblique rays entering the lens at different heights focus at different positions in the image plane, creating a characteristic comet-shaped blur (coma). The rays passing through different zones of the lens have different effective focal lengths and magnifications, resulting in the asymmetric image formation. Right: Experimental demonstration from the lecture showing the characteristic comet-like shape of the aberration, where the intensity distribution is asymmetric around the central image point.\n\n\n\n\n\n\n\n\n\nComa\n\n\n\nAn optical aberration where rays from an off-axis point source passing through different zones of a lens focus at different positions in the image plane, creating a characteristic comet-shaped intensity distribution with a bright head and a diffuse tail pointing radially outward."
  },
  {
    "objectID": "geometrical-optics/Imaging Errors.html#astigmatism",
    "href": "geometrical-optics/Imaging Errors.html#astigmatism",
    "title": "Imaging Errors",
    "section": "Astigmatism",
    "text": "Astigmatism\nAstigmatism also occurs when imaging point sources located away from the optical axis. To understand this effect, we can analyze the rays from such a source by separating them into two categories:\n\nRays in the vertical (meridional) plane\nRays in the perpendicular (sagittal) plane\n\nAnalysis shows that meridional rays focus at a point closer to the lens compared to sagittal rays. This difference in focal positions creates a characteristic pattern in the image: when moving a screen through the focal region, the image of a point source transforms from a horizontal ellipse, through a circular point (at the circle of least confusion), to a vertical ellipse. This variation in image shape occurs because the focal surfaces for the meridional and sagittal rays are curved differently and intersect only at points along the optical axis.\nThe distance between these two focal surfaces increases with the distance from the optical axis, making astigmatism particularly noticeable for off-axis object points. This aberration is especially significant in systems where the object plane is not perpendicular to the optical axis or when using simple spherical lenses for wide-field imaging.\nFor an extended image as shown below, this results in the sperate focusing of vertical (left) and horizontal lines (right) in the image.\n\n\n\n\n\n\n\n\n\n\n\n(a) Sketch\n\n\n\n\n\n\n\n\n\n\n\n\n\n(b) Vertical Focus\n\n\n\n\n\n\n\n\n\n\n\n(c) Horizontal Focus\n\n\n\n\n\n\n\nFigure 7— Astigmatism in optical systems. Left: Schematic diagram illustrating how a tilted lens creates different focal planes for rays in different meridional planes. The tangential (vertical) and sagittal (horizontal) rays focus at different distances from the lens. Middle: Experimental image showing the focusing of vertical lines of a test object (letter “F”) at one focal position. Right: The same object at a different focal position where horizontal lines are in focus. This demonstrates how astigmatism causes different focal planes for vertical and horizontal features when a lens is tilted relative to the optical axis. The inability to focus both orientations simultaneously is a characteristic feature of astigmatic aberration.\n\n\n\nThis distortion, i.e. the elliptical shape of the focus has been used advatageously in single molecule microscopy to locate their position alsong the optical axis, which is typically a challenge for optical microscopy.\n\n\n\n\n\n\nAstigmatism\n\n\n\nAn optical aberration where rays from an off-axis point source focusing in two perpendicular planes (meridional and sagittal) have different focal lengths, resulting in image points that appear as ellipses oriented either horizontally or vertically, depending on the observation plane.\n\n\n\nDistortions\nBarrel or cushion shaped distortions in the image are found when inserting apertures in the optical path. This results in the removal of certain ray path ending up in field distortions.\n\n\n\n\n\n\n\n\n\n\n\n(a) Cushion Distortion\n\n\n\n\n\n\n\n\n\n\n\n(b) Barrel Distortion\n\n\n\n\n\n\n\nFigure 8— Geometric distortions in optical systems. Left: Cushion (or pincushion) distortion, where the magnification increases with distance from the optical axis, causing straight lines to bow inward and creating a cushion-like appearance. Right: Barrel distortion, where the magnification decreases with distance from the optical axis, causing straight lines to bow outward, resembling the shape of a barrel. These distortions maintain image sharpness but alter the geometric shape of the image, particularly noticeable in architectural photography or when imaging regular grid patterns.\n\n\n\nGeometric distortions arise from the position of the aperture relative to the lens and its effect on ray paths. This mechanism can be understood by analyzing how different rays contribute to image formation:\nWhen an aperture is placed behind the lens, rays that pass through create an image point \\(M_1\\) that is farther from the optical axis than the ideal image point \\(M\\) (where \\(M\\) is determined by the central ray from object point \\(A_0\\)). As the object point moves farther from the optical axis, the displacement between \\(M_1\\) and \\(M\\) increases proportionally. This progressive displacement transforms a regular grid pattern into a cushion (or pincushion) shape.\nConversely, when the aperture is placed in front of the lens, the opposite effect occurs. The rays that pass through the aperture create an image point closer to the optical axis than the ideal image point, resulting in barrel distortion. The magnitude of this displacement also increases with distance from the optical axis.\nThese theoretical predictions are confirmed by experimental observations, where:\n\nA rear aperture produces cushion distortion, causing straight lines to bow inward\nA front aperture produces barrel distortion, causing straight lines to bow outward\n\nThe severity of these distortions depends on both the aperture position and the distance of object points from the optical axis.\n\n\n\n\n\n\nFigure 9— Cushion (left) and barrel (right) type of distortions.\n\n\n\n\n\n\n\n\n\nCushion Distortion\n\n\n\nCushion Distortion (also called Pincushion Distortion) - An optical aberration where straight lines appear to bow inward toward the center of the image, like the sides of a cushion or pincushion. This type of distortion is typically seen in telephoto lenses and makes the center of the image appear to be pinched inward.\n\n\n\n\n\n\n\n\nBarrel Distortion\n\n\n\nBarrel Distortion - An optical aberration where straight lines appear to bow outward from the center of the image, like a barrel shape. This type of distortion is common in wide-angle lenses and makes the center of the image appear to bulge outward.\n\n\n\n\n\n\n\n\nAberration Characterization and Zernike Polynomials\n\n\n\n\n\nThe Zernike polynomials are a set of orthonormal polynomials that are widely used in optics to describe wavefronts and to characterize optical aberrations. As we did not discuss wavefronts and waves yet, this is a more advanced topic here and only for information. Zernike polynomials are defined over the unit disk and are particularly useful because they are orthogonal under the inner product, which involves integration over the unit circle. This makes them suitable for decomposing a wavefront into a sum of orthogonal modes, each representing a different type of aberration.\nThe general form of the Zernike polynomials can be expressed in polar coordinates \\((\\rho, \\phi)\\), where \\(\\rho\\) is the radial distance from the origin (normalized to the unit circle) and \\(\\phi\\) is the azimuthal angle. The Zernike polynomials are defined as:\n\\[\nZ_n^m(\\rho, \\phi) =\n\\begin{cases}\nR_n^m(\\rho) \\cos(m\\phi) & \\text{for } m \\geq 0 \\\\\nR_n^{|m|}(\\rho) \\sin(|m|\\phi) & \\text{for } m &lt; 0\n\\end{cases}\n\\]\nwhere \\(n\\) is a non-negative integer, \\(m\\) is an integer such that \\(n - |m|\\) is even and \\(0 \\leq |m| \\leq n\\), and \\(R_n^m(\\rho)\\) is the radial polynomial given by:\n\\[\nR_n^m(\\rho) = \\sum_{k=0}^{\\frac{n-m}{2}} \\frac{(-1)^k (n-k)!}{k! \\left(\\frac{n+m}{2} - k\\right)! \\left(\\frac{n-m}{2} - k\\right)!} \\rho^{n-2k}\n\\]\nThe radial polynomials \\(R_n^m(\\rho)\\) are only dependent on the radial distance \\(\\rho\\), and they modulate the angular functions \\(\\cos(m\\phi)\\) and \\(\\sin(|m|\\phi)\\) that describe the azimuthal variation of the wavefront.\nThe Zernike polynomials are indexed in several ways, with one common method being the Noll index, which provides a single index \\(j\\) to each polynomial. Another method uses the pair \\((n, m)\\) to index the polynomials, where \\(n\\) indicates the order of the polynomial and \\(m\\) its azimuthal frequency.\nThese polynomials are particularly useful in optics and ophthalmology for describing the shape of optical wavefronts and the aberrations of optical systems, including the human eye. They allow for the decomposition of a complex wavefront into simpler, orthogonal components, each corresponding to a specific type of aberration, such as defocus, astigmatism, coma, etc.\nThe plots below visualize the Zernike Polynomials up to a certain order.\n\n\nCode\ndef radial_polynomial(n, m, rho):\n    \"\"\"\n    Compute the radial component of the Zernike polynomial.\n    \"\"\"\n    R = np.zeros_like(rho)\n    for k in range((n - abs(m)) // 2 + 1):\n        R += ((-1)**k * sp.factorial(n - k) /\n              (sp.factorial(k) * sp.factorial((n + abs(m)) // 2 - k) *\n              sp.factorial((n - abs(m)) // 2 - k))) * rho**(n - 2*k)\n    return R\n\ndef zernike_polynomial(n, m, rho, phi):\n    \"\"\"\n    Compute the Zernike polynomial.\n    \"\"\"\n    if m &gt;= 0:\n        return radial_polynomial(n, m, rho) * np.cos(m * phi)\n    else:\n        return radial_polynomial(n, -m, rho) * np.sin(-m * phi)\n\nx = np.linspace(-1, 1, 400)\ny = np.linspace(-1, 1, 400)\nxx, yy = np.meshgrid(x, y)\nrho = np.sqrt(xx**2 + yy**2)\nphi = np.arctan2(yy, xx)\n\nmask = rho &gt; 1\nrho[mask] = np.nan\n\nfig, axs = plt.subplots(3, 6, figsize=(8, 4))\naxs = axs.flatten()\n\nindex = 0\nfor n in range(6):\n    for m in range(-n, n+1, 2):\n        if index &gt;= len(axs):\n            break\n        Z = zernike_polynomial(n, m, rho, phi)\n        Z[mask] = np.nan  # Apply mask\n        ax = axs[index]\n        c = ax.imshow(Z, extent=(-1, 1, -1, 1), origin='lower')\n        ax.set_title(f'n={n}, m={m}')\n        ax.axis('off')\n        index += 1\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "geometrical-optics/Optical Elements III.html",
    "href": "geometrical-optics/Optical Elements III.html",
    "title": "Optical Elements Part III",
    "section": "",
    "text": "The most important optical elements are lenses, which come in many different flavors. They consist of curved surfaces, which most commonly have the shape of a part of a spherical cap. It is, therefore, useful to have a look at the refraction at spherical surfaces.\n\n\nFor our calculations of the refraction at spherical surfaces, we consider the sketch below.\n\n\n\n\n\n\nFigure 1: Refraction at a curved surface.\n\n\n\nTo derive an imaging equation for a lens, we aim to calculate the distance \\(b\\) and angle \\(\\theta_2\\) at which a ray crosses the optical axis, given its origin at distance \\(a\\) and angle \\(\\theta_1\\). We begin with Snell’s law for the geometry:\n\\[n_{1}\\sin(\\alpha+\\theta_1)=n_{2}\\sin(\\alpha-\\theta_2)\\]\nWe define key relationships:\n\\[\\sin(\\alpha)=\\frac{y}{R}, \\quad \\tan(\\theta_1)=\\frac{y}{a}, \\quad \\tan(\\theta_2)=\\frac{y}{b}\\]\nTo simplify this, we employ the paraxial approximation, which assumes all angles are small. This allows us to use first-order approximations of trigonometric functions, effectively linearizing them:\n\\[\\sin(\\theta) \\approx \\theta+ O(\\theta^{3}), \\quad \\tan(\\theta) \\approx \\theta + O(\\theta^{3}),\\quad \\cos(\\theta)\\approx 1 + O(\\theta^{2})\\]\nThis approach, common in optics, significantly simplifies our calculations while maintaining accuracy for most practical scenarios involving lenses.\nWith the help of these approximations we can write Snell’s law for the curved surface as\n\\[n_1(\\alpha+\\theta_1)=n_2(\\alpha-\\theta_2).\\]\nWith some slight transformation which you will find in the video of the online lecture we obtain, therefore,\n\\[\\theta_2=\\frac{n_2-n_1}{n_2 R}y -\\frac{n_1}{n_2}\\theta_1,\\]\nwhich is a purely linear equation in \\(y\\) and \\(\\theta_1\\).\n\n\n\n\n\n\nParaxial Approximation\n\n\n\n\n\nThe paraxial approximation is a fundamental simplification in optics that assumes all angles are small. This allows us to use linear approximations for trigonometric functions, significantly simplifying calculations while maintaining accuracy for most practical scenarios involving lenses.\nTo visualize the validity of this approximation, let’s examine two plots:\n\nThe first plot compares sin(θ) (blue line) with its linear approximation θ (red dashed line) for angles ranging from 0 to π/2 radians.\nThe second plot shows the absolute error between sin(θ) and θ.\n\nThese plots demonstrate that:\n\nFor small angles (roughly up to 0.5 radians or about 30 degrees), the approximation is very close to the actual sine function.\nThe error increases rapidly for larger angles, indicating the limitations of the paraxial approximation.\n\nIn most optical systems, especially those involving lenses, the angles of incident and refracted rays are typically small enough for this approximation to be valid. However, it’s important to be aware of its limitations when dealing with wide-angle optical systems or scenarios where precision is critical.\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n# Define the range of angles (in radians)\ntheta = np.linspace(0, np.pi/2, 1000)\n\n# Calculate sin(theta) and theta (linear approximation)\nsin_theta = np.sin(theta)\nlinear_approx = theta\n\n# Calculate the absolute error\nerror = np.abs(sin_theta - linear_approx)\n\n# Create the plot with two subplots side by side\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(7.5, 4))\n\n# Plot sin(theta) and theta on the first subplot\nax1.plot(theta, sin_theta, label='sin(θ)', color='blue')\nax1.plot(theta, linear_approx, label='θ', color='red', linestyle='--')\nax1.set_xlabel(r'$\\theta$ [rad]')\nax1.set_ylabel(r'$\\sin(x),x$')\nax1.legend()\n\n# Plot the error on the second subplot\nax2.plot(theta, error, label='Absolute Error', color='green')\nax2.set_xlabel(r'$\\theta$ [rad]')\nax2.set_ylabel('|sin(θ) - θ|')\nax2.legend()\n\n# Adjust the layout and display the plot\nplt.tight_layout()\nplt.show()\n\n\n\n\n\nVisualization of the paraxial approximation plotting the \\(\\sin(\\theta)\\) and the linear approximation \\(\\theta\\) (dashed line) for angles ranging from 0 to \\(\\pi/2\\) radians.\n\n\n\n\n\n\n\nConsider light originating from a point at distance \\(y\\) from the optical axis. We’ll analyze two rays: one traveling parallel to the optical axis and hitting the spherical surface at height \\(y\\), and another incident at \\(y=0\\).\n\n\n\n\n\n\nFigure 2: Image formation at a curved surface.\n\n\n\nApplying our derived formula to these two cases:\nFor the parallel ray (\\(\\theta_1=0\\)):\n\\[\\theta_2=\\frac{n_2-n_1}{n_2}\\frac{y}{R}\\] \\[\\theta_2=\\frac{y+\\Delta y}{b}\\]\nEquating these expressions:\n\\[\\frac{y+\\Delta y}{b}=\\frac{n_2-n_1}{n_2}\\frac{y}{R}\\]\nFor the ray through the center (\\(y=0\\)):\n\\[n_2\\frac{\\Delta y}{b}=n_1\\frac{y}{a}\\]\nCombining these equations yields the imaging equation for a curved surface:\n\\[\\frac{n_1}{a}+\\frac{n_2}{b}=\\frac{n_2-n_1}{R}\\]\nWe can define a new quantity, the focal length, which depends only on the properties of the curved surface:\n\\[f=\\frac{n_2}{n_2-n_1}R\\]\n\n\n\n\n\n\nImaging Equation for Spherical Refracting Surface\n\n\n\nThe sum of the inverse object and image distances equals the inverse focal length of the spherical refracting surface:\n\\[\\frac{n_1}{a}+\\frac{n_2}{b}\\approx\\frac{n_2}{f}\\]\nwhere the focal length of the refracting surface is given by:\n\\[f=\\frac{n_2}{n_2-n_1}R\\]\nin the paraxial approximation.",
    "crumbs": [
      "Geometrical Optics",
      "Lecture 3",
      "Optical Elements III - Lenses"
    ]
  },
  {
    "objectID": "geometrical-optics/Optical Elements III.html#derivation",
    "href": "geometrical-optics/Optical Elements III.html#derivation",
    "title": "Optical Elements Part III",
    "section": "Derivation",
    "text": "Derivation\nFor a lens with refractive index \\(n\\) in air, the focal lengths of the surfaces are:\n\\[\\frac{1}{f_1} = \\frac{1-n}{nR_1}, \\quad \\frac{1}{f_2} = \\frac{n-1}{R_2}\\]\nWhere \\(R_1\\) and \\(R_2\\) are the radii of curvature of the front and back surfaces.\nThe total system matrix is then\n\\[M_{total} = M_3 \\cdot M_2 \\cdot M_1\\]\nAfter multiplication the total matrix is\n\\[\nM=\\begin{bmatrix}\n  1 - \\frac{d \\left(1 - n\\right)}{R_{1}} & d\\\\\n  - \\frac{n-1}{R_{2} } - \\frac{\\left(1 - n\\right) \\left(n - \\frac{d n \\left( n-1\\right)}{R_{2}}\\right)}{R_{1} n} & \\frac{\\left(n - \\frac{d n \\left( n-1\\right)}{R_{2}}\\right)}{n}\n\\end{bmatrix}\n\\]\nwhere the element in the lower left corner is the inverse of the focal length of the thick lens. This can be simplified to the following expression:\n\\[-\\frac{1}{f} = -\\frac{1}{f_2} - \\frac{n}{f_1} -\\frac{d n}{f_1f_2}\\]\nSubstituting the expressions for \\(1/f_1\\) and \\(1/f_2\\):\n\\[\\frac{1}{f} = \\frac{n-1}{R_1} - \\frac{n-1}{R_2} + \\frac{d(n-1)^2}{nR_1R_2}\\]\nFactoring out \\((n-1)\\) gives the final expression for the focal length of a thick lens:\n\\[\\frac{1}{f} = (n-1)\\left[\\frac{1}{R_1} - \\frac{1}{R_2} + \\frac{(n-1)d}{R_1R_2}\\right]\\]\nThis is the Lensmaker’s equation for a thick lens.\nThe construction of ray diagrams for thick lenses is similar to that for thin lenses, but the object and image distances are measured from the principal planes. The magnification is also calculated using the distances from the principal planes. Principal planes are where a thick lens can be treated as an equivalent thin lens. At these planes, the magnification is unity.\nThe derivation of the local of the principle planes will be part of the seminar.\n\n\nCode\n# %% Importing libraries and defining symbols\nfrom sympy import *\nfrom IPython.display import display, Math\n\nn1, n2 , d, R1, R2, f1, f2, f    = symbols('n1 n2 d R1 R2 f1 f2 f')\ninit_session(quiet=True)\ninit_printing()\n\n# %% Definition of matrices\n#\nf1=1/((n2-n1)/R1/n2) ## First spherical refracting surface\nf2=1/((n1-n2)/R2/n1) ## Second spherical refracting surface\n\nM1=Matrix([[1,0],[-1/f1,n1/n2]]) # first refracting surface\nM2=Matrix([[1,n2*d],[0,1]]) # free space\nM3=Matrix([[1,0],[-1/f2,n2/n1]]) # second refracting surface\n\n# %% Thin lens calculation\nM_thin=M3*M1  # first and second refracting surfaces\n#display(Math('1/f ='+ latex(factor(collect(expand(simplify(-M_thin)[1,0]),[1/R1,1/R2],factor)))))\n\n# The result of the matrix multiplication for a thick lens with SymPy\n# %% Thick lens calculation\nM_thick=M3*M2*M1\n\ndisplay(Math('1/f ='+ latex(collect(expand(simplify(-M_thick)[1,0]),[1/R1,1/R2,1/(R1*R2)],factor))))\n\n\n\n\n\n\\(\\displaystyle 1/f =\\frac{n_{1} - n_{2}}{R_{2} n_{1}} - \\frac{n_{1} - n_{2}}{R_{1} n_{1}} + \\frac{d \\left(n_{1} - n_{2}\\right)^{2}}{R_{1} R_{2} n_{1}}\\)",
    "crumbs": [
      "Geometrical Optics",
      "Lecture 3",
      "Optical Elements III - Lenses"
    ]
  },
  {
    "objectID": "geometrical-optics/Optical Elements II.html",
    "href": "geometrical-optics/Optical Elements II.html",
    "title": "Optical Elements Part II",
    "section": "",
    "text": "Prisms are wedge-shaped optical elements made of a transparent material, such as glass. A special form of such a prism is an isosceles prism with two sides of equal length. The two equal sides enclose an angle \\(\\gamma\\), known as the apex angle of the prism. When light passes through this prism, it undergoes refraction twice.\nFirst, the incident angle \\(\\alpha_1\\) is changed into a refracted angle \\(\\beta_1\\) as the light enters the prism. This refracted ray then hits the second interface at an angle \\(\\beta_2\\), leading to a second refraction as it exits the prism at an angle \\(\\alpha_2\\).\nOf particular interest is the total deflection of the incident ray, which is measured by the angle \\(\\delta\\). This deflection angle represents the difference between the final outgoing angle \\(\\alpha_2\\) and the initial incident angle \\(\\alpha_1\\).\nUnderstanding how this deflection angle changes based on the prism’s properties and the incident angle is crucial in various optical applications. In the following sections, we will explore how to calculate this deflection angle and examine its dependence on different parameters.\n\n\n\n\n\n\nFigure 1— Refraction of rays on a prism.\n\n\n\n\n\n\nWe can calculate the deflection angle \\(\\delta\\) from a number of considerations. First consider the following relations between the angles in the prism and Snell’s law\n\\[\\beta_1=\\sin^{-1}\\left (\\frac{n_0}{n_1}\\sin(\\alpha_1) \\right)\\] \\[\\beta_2=\\gamma-\\beta_1\\] \\[\\alpha_2=\\sin^{-1}\\left (\\frac{n_1}{n_0}\\sin(\\beta_2)\\right )\\] \\[\\theta_2=\\alpha_2-\\gamma\\]\nwhere \\(\\theta_2\\) is the angle between the incident surface normal and the outgoing ray. The total deflection angle \\(\\delta\\) is then\n\\[\\delta =\\alpha_1-\\beta_1+\\alpha_2-\\beta_2\\]\nor\n\\[\\delta =\\alpha_1+\\alpha_2-\\gamma\\]\nfrom which we obtain\n\\[\\delta=\\alpha_1+\\sin^{-1}\\left (\\frac{n_1}{n_0}\\sin\\left [\\gamma-\\sin^{-1}\\left (\\frac{n_0}{n_1}\\sin(\\alpha_1) \\right)\\right]\\right )-\\gamma\\]\nas the deflection angle.\n\n\nCode\ndef deflection(alpha_1,gamma,n0,n1):\n    g=gamma*np.pi/180\n    return(alpha_1+np.arcsin(n1*np.sin(g-np.arcsin(n0*np.sin(alpha_1)/n1))))-g\n\na_1=np.linspace(0.1,np.pi/2,100)\nplt.figure(figsize=(4,4))\nplt.plot(a_1*180/np.pi,deflection(a_1,45,1,1.5)*180/np.pi,label=r\"$\\gamma=45$ °\")\nplt.plot(a_1*180/np.pi,deflection(a_1,30,1,1.5)*180/np.pi,label=r\"$\\gamma=30$ °\")\nplt.plot(a_1*180/np.pi,deflection(a_1,10,1,1.5)*180/np.pi,label=r\"$\\gamma=10$ °\")\nplt.xlabel(r\"incindence angle $\\alpha_1$ [°]\")\nplt.ylabel(r\"deflection angle $\\delta$ [°]\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nFigure 2— Deflection angle as a function of the incidence angle for different prism angles.\n\n\n\n\n\n\n\n\nIf we now would like to know how the deflection angle changes with the incident angle \\(\\alpha_1\\), we calculate the derivative of the deflection angle \\(\\delta\\) with respect to \\(\\alpha_1\\), i.e.,\n\\[\\frac{\\mathrm d\\delta}{\\mathrm d\\alpha_1}=1+\\frac{\\mathrm d\\alpha_2}{\\mathrm d \\alpha_1}.\\]\nWe are here especially interested in the case, where this change in deflection is reaching a minimum, i.e., \\(\\mathrm d\\delta/\\mathrm d\\alpha_1 =0\\). This readily yields\n\\[\\mathrm d \\alpha_2=-\\mathrm d\\alpha_1.\\]\nThis means a change in the incidence angle \\(\\mathrm d\\alpha_1\\) yields an opposite change in the outgoing angle \\(-\\mathrm d\\alpha_2\\). We may later observe that in the experiment.\nAs both, the incident and the outgoing angle are related to each other by Snells’s law, we may introduce the derivatives of Snell’s law for both interfaces, e.g.,\n\n\\(\\cos(\\alpha_1)\\mathrm d\\alpha_1=n\\cos(\\beta_1)\\mathrm d\\beta_1\\)\n\\(\\cos(\\alpha_2)\\mathrm d\\alpha_2=n\\cos(\\beta_2)\\mathrm d\\beta_2\\)\n\nwhere \\(n\\) is the refractive index of the prism material and the material outside is air (\\(n_{\\rm air}=1\\)). Replacing \\(\\cos(\\alpha)=\\sqrt{1-\\sin^2(\\alpha)}\\) and dividing the two previous equations by each other readily yields\n\\[\\frac{1-\\sin^2(\\alpha_1)}{1-\\sin^2(\\alpha_2)}=\\frac{n^2-\\sin^2(\\alpha_1)}{n^2-\\sin^2(\\alpha_2)}.\\]\nThe latter equation is for \\(n\\neq 1\\) only satisfied if \\(\\alpha_1=\\alpha_2=\\alpha\\). In this case, the light path through the prism must be symmetric and we may write down the minimum deflection angle \\(\\delta_{\\rm min}\\):\n\n\n\n\n\n\nMinimum prism deflection\n\n\n\nThe minimum deflection angle of an isosceles prism with a prism angle \\(\\gamma\\) is given by\n\\[\\delta_{\\rm min}=2\\alpha-\\gamma.\\]\n\n\nGiven this minimum deflection angle \\(\\delta_{\\rm min}\\) and the properties of the prism, we may also write down Snell’s law using \\(\\sin(\\alpha)=n\\sin(\\beta)\\), which results in\n\\[\\sin \\left ( \\frac{\\delta_{\\rm min}+\\gamma}{2}\\right )=n\\sin\\left (\\frac{\\gamma}{2}\\right).\\]\nwhich indicates the dependence of the deflection in the refractive index \\(n\\) of the prism material.\n\n\n\nVery important applications now arise from the fact, that the refractive index is a material property, which depends on the color (frequency or wavelength) of light. We do not yet understand the origin of this dependence. The plots below show the wavelength dependence of three different glasses. You may find much more data on the refractive index of different materials in an online database.\n\n\nCode\nbk7=pd.read_csv(\"data/BK7.csv\",delimiter=\",\")\nsf10=pd.read_csv(\"data/SF10.csv\",delimiter=\",\")\nfk51a=pd.read_csv(\"data/FK51A.csv\",delimiter=\",\")\nplt.figure(figsize=(4,4))\nplt.plot(bk7.wl*1000,bk7.n,label=\"BK7\")\nplt.plot(sf10.wl*1000,sf10.n,label=\"SF10\")\nplt.plot(fk51a.wl*1000,fk51a.n,label=\"FK51A\")\nplt.xlim(300,900)\nplt.xlabel(\"wavelength [nm]\")\nplt.ylabel(\"refractive index n\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nFigure 3— Refractive index of different glasses as a function of the wavelength.\n\n\n\n\n\n\n\nCode\nbk7=pd.read_csv(\"data/BK7.csv\",delimiter=\",\")\na_1=np.linspace(0.15,np.pi/2,100)\nplt.figure(figsize=(7.5,4))\nplt.subplot(1,2,1)\nfor wl in np.linspace(0.400,0.700,100):\n    n1=np.interp(wl,bk7.wl,bk7.n)\n    c=wavelength_to_rgb(wl*1000, gamma=0.8)\n    plt.plot(a_1*180/np.pi,deflection(a_1,45,1,n1)*180/np.pi,color=c)\n\nplt.xlabel(r\"incindence angle $\\alpha_1$ [°]\")\nplt.ylabel(r\"deflection angle $\\delta$ [°]\")\n\n\nplt.subplot(1,2,2)\nfor wl in np.linspace(0.400,0.700,100):\n    n1=np.interp(wl,bk7.wl,bk7.n)\n    c=wavelength_to_rgb(wl*1000, gamma=0.8)\n    plt.plot(a_1*180/np.pi,deflection(a_1,45,1,n1)*180/np.pi,color=c)\n\nplt.xlabel(r\"incindence angle $\\alpha_1$ [°]\")\nplt.ylabel(r\"deflection angle $\\delta$ [°]\")\nplt.xlim(30,45)\nplt.ylim(25,30)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nFigure 4— Deflection angle as a function of the incidence angle for different wavelengths.\n\n\n\n\n\nThe plots have a general feature, which is that the refractive index is largest at small wavelength (blue colors), while it drops continuously with increasing wavelength towards the red (800 nm). If you would characterize the dependence by the slope, i.e., \\(\\mathrm dn/\\mathrm d\\lambda\\) then all displayed curves show in the visible range\n\n\\(\\frac{\\mathrm dn}{\\mathrm d\\lambda}&lt;0\\), is called normal dispersion\n\nwhile\n\n\\(\\frac{\\mathrm dn}{\\mathrm d\\lambda}&gt;0\\), is called anomalous dispersion\n\nThis wavelength dependence of the refractive index will yield a dependence of the deflection angle on the color of light as well. The change of the deflection angle with the refractive index can be calculated to be\n\\[\\frac{\\mathrm d\\delta}{\\mathrm d n}=\\frac{2\\sin(\\gamma/2)}{\\sqrt{1-n^2\\sin^2(\\gamma/2)}}\\]\ntogether with the relation\n\\[\\frac{\\mathrm d \\delta}{\\mathrm d \\lambda}=\\frac{\\mathrm d\\delta}{\\mathrm d n}\\frac{\\mathrm d n}{\\mathrm d\\lambda}\\]\nwe obtain\n\\[\\frac{\\mathrm d\\delta}{\\mathrm d\\lambda}=\\frac{2\\sin(\\gamma/2)}{\\sqrt{1-n^2\\sin^2(\\gamma/2)}}\\frac{\\mathrm d n}{\\mathrm d \\lambda}.\\]\nThe refraction of white light through a prism splits the different colors composing white light spatially into a colored spectrum. In this process, light with the longest wavelength (red) is deflected the least, while light with the shortest wavelength (violet) is deflected the most. This occurs because the refractive index of the prism material varies with wavelength, a phenomenon known as dispersion.\n\n\n\n\n\n\nFigure 5— Spectrum as created by a prism in the lecture.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Spectrum\n\n\n\n\n\n\n\n\n\n\n\n(b) Prism\n\n\n\n\n\n\n\nFigure 6— Deflection of different wavelengths of light in a prism with normal dispersion.\n\n\n\n\n\n\nThis wavelength-dependent refraction is crucial as it forms the basis for spectroscopy, a powerful analytical technique that measures and records the intensity of light as a function of wavelength. Spectroscopy allows scientists to analyze the composition and properties of matter by examining its interaction with light across different wavelengths.\n\n\n\n\n\n\n\n\n\n\n\n(a) Principle of a prism spectrometer\n\n\n\n\n\n\n\n\n\n\n\n(b) Technical realization of a prism spectrometer\n\n\n\n\n\n\n\nFigure 7— Principle and technical realization of a prism spectrometer.\n\n\n\nDIY prism\nIf you don’t have a prism at home (which most people don’t), you can create a simple substitute using a mirror and a basin of water. Here’s how:\n\nPlace a mirror in a basin of water, partially submerged.\nShine white light from a flashlight onto the mirror.\nObserve the reflected and refracted light, paying special attention to the edges.\n\nFor better results, you can create a small aperture by making a tiny hole in a piece of black paper and placing it in front of the flashlight.\n\n\n\n\n\n\nFigure 8— Home made water prism.\n\n\n\nWhile the dependence of water’s refractive index on wavelength is relatively weak, it’s still sufficient to demonstrate the familiar colors of the rainbow. This phenomenon will be referenced later in our discussion.\n\n\nCode\n#\nh2o=pd.read_csv(\"data/H2O.csv\",delimiter=\",\")\nplt.figure(figsize=(6,4))\nplt.plot(h2o.wl*1000,h2o.n,label=r\"$H_2O$\")\nplt.xlim(300,900)\nplt.ylim(1.3,1.36)\nplt.xlabel(\"wavelength [nm]\")\nplt.ylabel(\"refractive index n\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nFigure 9— Refractive index of water as a function of the wavelength.\n\n\n\n\n\n\n\n\n\n\n\nApplications of prims\n\n\n\n\n\nPrisms are versatile optical components with a wide range of applications across various fields. Here are some common uses of prisms:\n\n\nPorro prisms in traditional binoculars and roof prisms in modern designs serve to correct image inversion and provide a compact form. These prisms enable a longer optical path within a shorter physical length, enhancing magnification while maintaining portability. This design is crucial for both binoculars and some telescopes, offering users powerful magnification in a handheld device.\n\n\n\nRight-angle prisms are the key component in periscopes, redirecting light at 90-degree angles. This simple yet effective design allows viewers to see over obstacles or around corners, making periscopes invaluable in submarines and various military applications where direct line of sight is obstructed.\n\n\n\nCube beamsplitters play a vital role in dividing a single beam of light into two separate beams. This capability is essential in various scientific and medical applications, including interferometry, holography, and optical coherence tomography (OCT). The ability to split light beams precisely opens up numerous possibilities in research and diagnostics.\n\n\n\nRisley prisms, consisting of a pair of rotating wedge prisms, offer precise control over laser beam direction. This technology finds applications in laser scanning, target tracking, and adaptive optics. The ability to steer beams accurately is crucial in fields ranging from military applications to advanced scientific research.\n\n\n\nTotal Internal Reflection (TIR) prisms are a crucial component in Digital Light Processing (DLP) projectors. They direct light from the lamp to the Digital Micromirror Device (DMD) and then to the projection lens, enabling the high-quality image projection that DLP technology is known for.\n\n\n\nIn Single-Lens Reflex (SLR) cameras, pentaprisms play a critical role in the viewfinder system. They flip the image from the lens to appear upright and correctly oriented in the viewfinder, allowing photographers to accurately compose their shots.\n\n\n\nBrewster prisms find use in laser systems for polarization and wavelength separation. Additionally, dispersing prisms can be employed for wavelength tuning in certain laser setups, providing precise control over the laser’s output characteristics.\n\n\n\nIn the realm of telecommunications, prisms are utilized in some fiber optic connectors and switches. They help redirect light between fibers, playing a crucial role in maintaining signal integrity and enabling complex network architectures.\n\n\n\nFresnel lenses, a specialized type of prism, are employed in concentrated solar power systems. These lenses focus sunlight efficiently, contributing to the development of more effective solar energy collection technologies.\n\n\n\nPrisms are an integral part of HUD systems in both automotive and aviation contexts. They project crucial information onto the windshield or a combiner glass, allowing drivers or pilots to access important data without taking their eyes off their primary viewpoint.\n\n\n\nNomarski prisms enhance the capabilities of differential interference contrast microscopy. They increase contrast in transparent specimens, enabling scientists to observe details that would be difficult or impossible to see with conventional microscopy techniques.\n\n\n\nIn some OCT systems, prisms are employed for sample arm scanning and reference arm delay. This application of prisms contributes to the high-resolution imaging capabilities of OCT, which is particularly valuable in medical diagnostics, especially in ophthalmology.",
    "crumbs": [
      "Geometrical Optics",
      "Lecture 3",
      "Optical Elements II - Prims"
    ]
  },
  {
    "objectID": "geometrical-optics/Optical Elements II.html#prism",
    "href": "geometrical-optics/Optical Elements II.html#prism",
    "title": "Optical Elements Part II",
    "section": "",
    "text": "Prisms are wedge-shaped optical elements made of a transparent material, such as glass. A special form of such a prism is an isosceles prism with two sides of equal length. The two equal sides enclose an angle \\(\\gamma\\), known as the apex angle of the prism. When light passes through this prism, it undergoes refraction twice.\nFirst, the incident angle \\(\\alpha_1\\) is changed into a refracted angle \\(\\beta_1\\) as the light enters the prism. This refracted ray then hits the second interface at an angle \\(\\beta_2\\), leading to a second refraction as it exits the prism at an angle \\(\\alpha_2\\).\nOf particular interest is the total deflection of the incident ray, which is measured by the angle \\(\\delta\\). This deflection angle represents the difference between the final outgoing angle \\(\\alpha_2\\) and the initial incident angle \\(\\alpha_1\\).\nUnderstanding how this deflection angle changes based on the prism’s properties and the incident angle is crucial in various optical applications. In the following sections, we will explore how to calculate this deflection angle and examine its dependence on different parameters.\n\n\n\n\n\n\nFigure 1— Refraction of rays on a prism.\n\n\n\n\n\n\nWe can calculate the deflection angle \\(\\delta\\) from a number of considerations. First consider the following relations between the angles in the prism and Snell’s law\n\\[\\beta_1=\\sin^{-1}\\left (\\frac{n_0}{n_1}\\sin(\\alpha_1) \\right)\\] \\[\\beta_2=\\gamma-\\beta_1\\] \\[\\alpha_2=\\sin^{-1}\\left (\\frac{n_1}{n_0}\\sin(\\beta_2)\\right )\\] \\[\\theta_2=\\alpha_2-\\gamma\\]\nwhere \\(\\theta_2\\) is the angle between the incident surface normal and the outgoing ray. The total deflection angle \\(\\delta\\) is then\n\\[\\delta =\\alpha_1-\\beta_1+\\alpha_2-\\beta_2\\]\nor\n\\[\\delta =\\alpha_1+\\alpha_2-\\gamma\\]\nfrom which we obtain\n\\[\\delta=\\alpha_1+\\sin^{-1}\\left (\\frac{n_1}{n_0}\\sin\\left [\\gamma-\\sin^{-1}\\left (\\frac{n_0}{n_1}\\sin(\\alpha_1) \\right)\\right]\\right )-\\gamma\\]\nas the deflection angle.\n\n\nCode\ndef deflection(alpha_1,gamma,n0,n1):\n    g=gamma*np.pi/180\n    return(alpha_1+np.arcsin(n1*np.sin(g-np.arcsin(n0*np.sin(alpha_1)/n1))))-g\n\na_1=np.linspace(0.1,np.pi/2,100)\nplt.figure(figsize=(4,4))\nplt.plot(a_1*180/np.pi,deflection(a_1,45,1,1.5)*180/np.pi,label=r\"$\\gamma=45$ °\")\nplt.plot(a_1*180/np.pi,deflection(a_1,30,1,1.5)*180/np.pi,label=r\"$\\gamma=30$ °\")\nplt.plot(a_1*180/np.pi,deflection(a_1,10,1,1.5)*180/np.pi,label=r\"$\\gamma=10$ °\")\nplt.xlabel(r\"incindence angle $\\alpha_1$ [°]\")\nplt.ylabel(r\"deflection angle $\\delta$ [°]\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nFigure 2— Deflection angle as a function of the incidence angle for different prism angles.\n\n\n\n\n\n\n\n\nIf we now would like to know how the deflection angle changes with the incident angle \\(\\alpha_1\\), we calculate the derivative of the deflection angle \\(\\delta\\) with respect to \\(\\alpha_1\\), i.e.,\n\\[\\frac{\\mathrm d\\delta}{\\mathrm d\\alpha_1}=1+\\frac{\\mathrm d\\alpha_2}{\\mathrm d \\alpha_1}.\\]\nWe are here especially interested in the case, where this change in deflection is reaching a minimum, i.e., \\(\\mathrm d\\delta/\\mathrm d\\alpha_1 =0\\). This readily yields\n\\[\\mathrm d \\alpha_2=-\\mathrm d\\alpha_1.\\]\nThis means a change in the incidence angle \\(\\mathrm d\\alpha_1\\) yields an opposite change in the outgoing angle \\(-\\mathrm d\\alpha_2\\). We may later observe that in the experiment.\nAs both, the incident and the outgoing angle are related to each other by Snells’s law, we may introduce the derivatives of Snell’s law for both interfaces, e.g.,\n\n\\(\\cos(\\alpha_1)\\mathrm d\\alpha_1=n\\cos(\\beta_1)\\mathrm d\\beta_1\\)\n\\(\\cos(\\alpha_2)\\mathrm d\\alpha_2=n\\cos(\\beta_2)\\mathrm d\\beta_2\\)\n\nwhere \\(n\\) is the refractive index of the prism material and the material outside is air (\\(n_{\\rm air}=1\\)). Replacing \\(\\cos(\\alpha)=\\sqrt{1-\\sin^2(\\alpha)}\\) and dividing the two previous equations by each other readily yields\n\\[\\frac{1-\\sin^2(\\alpha_1)}{1-\\sin^2(\\alpha_2)}=\\frac{n^2-\\sin^2(\\alpha_1)}{n^2-\\sin^2(\\alpha_2)}.\\]\nThe latter equation is for \\(n\\neq 1\\) only satisfied if \\(\\alpha_1=\\alpha_2=\\alpha\\). In this case, the light path through the prism must be symmetric and we may write down the minimum deflection angle \\(\\delta_{\\rm min}\\):\n\n\n\n\n\n\nMinimum prism deflection\n\n\n\nThe minimum deflection angle of an isosceles prism with a prism angle \\(\\gamma\\) is given by\n\\[\\delta_{\\rm min}=2\\alpha-\\gamma.\\]\n\n\nGiven this minimum deflection angle \\(\\delta_{\\rm min}\\) and the properties of the prism, we may also write down Snell’s law using \\(\\sin(\\alpha)=n\\sin(\\beta)\\), which results in\n\\[\\sin \\left ( \\frac{\\delta_{\\rm min}+\\gamma}{2}\\right )=n\\sin\\left (\\frac{\\gamma}{2}\\right).\\]\nwhich indicates the dependence of the deflection in the refractive index \\(n\\) of the prism material.\n\n\n\nVery important applications now arise from the fact, that the refractive index is a material property, which depends on the color (frequency or wavelength) of light. We do not yet understand the origin of this dependence. The plots below show the wavelength dependence of three different glasses. You may find much more data on the refractive index of different materials in an online database.\n\n\nCode\nbk7=pd.read_csv(\"data/BK7.csv\",delimiter=\",\")\nsf10=pd.read_csv(\"data/SF10.csv\",delimiter=\",\")\nfk51a=pd.read_csv(\"data/FK51A.csv\",delimiter=\",\")\nplt.figure(figsize=(4,4))\nplt.plot(bk7.wl*1000,bk7.n,label=\"BK7\")\nplt.plot(sf10.wl*1000,sf10.n,label=\"SF10\")\nplt.plot(fk51a.wl*1000,fk51a.n,label=\"FK51A\")\nplt.xlim(300,900)\nplt.xlabel(\"wavelength [nm]\")\nplt.ylabel(\"refractive index n\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nFigure 3— Refractive index of different glasses as a function of the wavelength.\n\n\n\n\n\n\n\nCode\nbk7=pd.read_csv(\"data/BK7.csv\",delimiter=\",\")\na_1=np.linspace(0.15,np.pi/2,100)\nplt.figure(figsize=(7.5,4))\nplt.subplot(1,2,1)\nfor wl in np.linspace(0.400,0.700,100):\n    n1=np.interp(wl,bk7.wl,bk7.n)\n    c=wavelength_to_rgb(wl*1000, gamma=0.8)\n    plt.plot(a_1*180/np.pi,deflection(a_1,45,1,n1)*180/np.pi,color=c)\n\nplt.xlabel(r\"incindence angle $\\alpha_1$ [°]\")\nplt.ylabel(r\"deflection angle $\\delta$ [°]\")\n\n\nplt.subplot(1,2,2)\nfor wl in np.linspace(0.400,0.700,100):\n    n1=np.interp(wl,bk7.wl,bk7.n)\n    c=wavelength_to_rgb(wl*1000, gamma=0.8)\n    plt.plot(a_1*180/np.pi,deflection(a_1,45,1,n1)*180/np.pi,color=c)\n\nplt.xlabel(r\"incindence angle $\\alpha_1$ [°]\")\nplt.ylabel(r\"deflection angle $\\delta$ [°]\")\nplt.xlim(30,45)\nplt.ylim(25,30)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nFigure 4— Deflection angle as a function of the incidence angle for different wavelengths.\n\n\n\n\n\nThe plots have a general feature, which is that the refractive index is largest at small wavelength (blue colors), while it drops continuously with increasing wavelength towards the red (800 nm). If you would characterize the dependence by the slope, i.e., \\(\\mathrm dn/\\mathrm d\\lambda\\) then all displayed curves show in the visible range\n\n\\(\\frac{\\mathrm dn}{\\mathrm d\\lambda}&lt;0\\), is called normal dispersion\n\nwhile\n\n\\(\\frac{\\mathrm dn}{\\mathrm d\\lambda}&gt;0\\), is called anomalous dispersion\n\nThis wavelength dependence of the refractive index will yield a dependence of the deflection angle on the color of light as well. The change of the deflection angle with the refractive index can be calculated to be\n\\[\\frac{\\mathrm d\\delta}{\\mathrm d n}=\\frac{2\\sin(\\gamma/2)}{\\sqrt{1-n^2\\sin^2(\\gamma/2)}}\\]\ntogether with the relation\n\\[\\frac{\\mathrm d \\delta}{\\mathrm d \\lambda}=\\frac{\\mathrm d\\delta}{\\mathrm d n}\\frac{\\mathrm d n}{\\mathrm d\\lambda}\\]\nwe obtain\n\\[\\frac{\\mathrm d\\delta}{\\mathrm d\\lambda}=\\frac{2\\sin(\\gamma/2)}{\\sqrt{1-n^2\\sin^2(\\gamma/2)}}\\frac{\\mathrm d n}{\\mathrm d \\lambda}.\\]\nThe refraction of white light through a prism splits the different colors composing white light spatially into a colored spectrum. In this process, light with the longest wavelength (red) is deflected the least, while light with the shortest wavelength (violet) is deflected the most. This occurs because the refractive index of the prism material varies with wavelength, a phenomenon known as dispersion.\n\n\n\n\n\n\nFigure 5— Spectrum as created by a prism in the lecture.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Spectrum\n\n\n\n\n\n\n\n\n\n\n\n(b) Prism\n\n\n\n\n\n\n\nFigure 6— Deflection of different wavelengths of light in a prism with normal dispersion.\n\n\n\n\n\n\nThis wavelength-dependent refraction is crucial as it forms the basis for spectroscopy, a powerful analytical technique that measures and records the intensity of light as a function of wavelength. Spectroscopy allows scientists to analyze the composition and properties of matter by examining its interaction with light across different wavelengths.\n\n\n\n\n\n\n\n\n\n\n\n(a) Principle of a prism spectrometer\n\n\n\n\n\n\n\n\n\n\n\n(b) Technical realization of a prism spectrometer\n\n\n\n\n\n\n\nFigure 7— Principle and technical realization of a prism spectrometer.\n\n\n\nDIY prism\nIf you don’t have a prism at home (which most people don’t), you can create a simple substitute using a mirror and a basin of water. Here’s how:\n\nPlace a mirror in a basin of water, partially submerged.\nShine white light from a flashlight onto the mirror.\nObserve the reflected and refracted light, paying special attention to the edges.\n\nFor better results, you can create a small aperture by making a tiny hole in a piece of black paper and placing it in front of the flashlight.\n\n\n\n\n\n\nFigure 8— Home made water prism.\n\n\n\nWhile the dependence of water’s refractive index on wavelength is relatively weak, it’s still sufficient to demonstrate the familiar colors of the rainbow. This phenomenon will be referenced later in our discussion.\n\n\nCode\n#\nh2o=pd.read_csv(\"data/H2O.csv\",delimiter=\",\")\nplt.figure(figsize=(6,4))\nplt.plot(h2o.wl*1000,h2o.n,label=r\"$H_2O$\")\nplt.xlim(300,900)\nplt.ylim(1.3,1.36)\nplt.xlabel(\"wavelength [nm]\")\nplt.ylabel(\"refractive index n\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nFigure 9— Refractive index of water as a function of the wavelength.\n\n\n\n\n\n\n\n\n\n\n\nApplications of prims\n\n\n\n\n\nPrisms are versatile optical components with a wide range of applications across various fields. Here are some common uses of prisms:\n\n\nPorro prisms in traditional binoculars and roof prisms in modern designs serve to correct image inversion and provide a compact form. These prisms enable a longer optical path within a shorter physical length, enhancing magnification while maintaining portability. This design is crucial for both binoculars and some telescopes, offering users powerful magnification in a handheld device.\n\n\n\nRight-angle prisms are the key component in periscopes, redirecting light at 90-degree angles. This simple yet effective design allows viewers to see over obstacles or around corners, making periscopes invaluable in submarines and various military applications where direct line of sight is obstructed.\n\n\n\nCube beamsplitters play a vital role in dividing a single beam of light into two separate beams. This capability is essential in various scientific and medical applications, including interferometry, holography, and optical coherence tomography (OCT). The ability to split light beams precisely opens up numerous possibilities in research and diagnostics.\n\n\n\nRisley prisms, consisting of a pair of rotating wedge prisms, offer precise control over laser beam direction. This technology finds applications in laser scanning, target tracking, and adaptive optics. The ability to steer beams accurately is crucial in fields ranging from military applications to advanced scientific research.\n\n\n\nTotal Internal Reflection (TIR) prisms are a crucial component in Digital Light Processing (DLP) projectors. They direct light from the lamp to the Digital Micromirror Device (DMD) and then to the projection lens, enabling the high-quality image projection that DLP technology is known for.\n\n\n\nIn Single-Lens Reflex (SLR) cameras, pentaprisms play a critical role in the viewfinder system. They flip the image from the lens to appear upright and correctly oriented in the viewfinder, allowing photographers to accurately compose their shots.\n\n\n\nBrewster prisms find use in laser systems for polarization and wavelength separation. Additionally, dispersing prisms can be employed for wavelength tuning in certain laser setups, providing precise control over the laser’s output characteristics.\n\n\n\nIn the realm of telecommunications, prisms are utilized in some fiber optic connectors and switches. They help redirect light between fibers, playing a crucial role in maintaining signal integrity and enabling complex network architectures.\n\n\n\nFresnel lenses, a specialized type of prism, are employed in concentrated solar power systems. These lenses focus sunlight efficiently, contributing to the development of more effective solar energy collection technologies.\n\n\n\nPrisms are an integral part of HUD systems in both automotive and aviation contexts. They project crucial information onto the windshield or a combiner glass, allowing drivers or pilots to access important data without taking their eyes off their primary viewpoint.\n\n\n\nNomarski prisms enhance the capabilities of differential interference contrast microscopy. They increase contrast in transparent specimens, enabling scientists to observe details that would be difficult or impossible to see with conventional microscopy techniques.\n\n\n\nIn some OCT systems, prisms are employed for sample arm scanning and reference arm delay. This application of prisms contributes to the high-resolution imaging capabilities of OCT, which is particularly valuable in medical diagnostics, especially in ophthalmology.",
    "crumbs": [
      "Geometrical Optics",
      "Lecture 3",
      "Optical Elements II - Prims"
    ]
  },
  {
    "objectID": "geometrical-optics/Eye.html",
    "href": "geometrical-optics/Eye.html",
    "title": "Optical Instruments",
    "section": "",
    "text": "The human eye stands is one of the most remarkable sensory systems. This sophisticated organ combines an array of precisely crafted components—including an adjustable aperture, an adaptive lens, and a highly sensitive photodetector—all interconnected with a neural network capable of rapid and accurate pattern recognition. What’s truly astounding is that this entire system operates on mere watts of power.\n\n\n\n\n\n\n\n\n\n\n\n(a) Anatomy of the human eye\n\n\n\n\n\n\n\n\n\n\n\n(b) Retinal structure detail\n\n\n\n\n\n\n\nFigure 1: Left: Key components of the human eye, including the lens, vitreous body, and retina with its light-sensitive cells. Right: Detailed view of the retina, showing the arrangement and neural connections of rods and cones.\n\n\n\n\n\n\nPupil and Iris: The pupil, surrounded by the iris, acts as an adjustable aperture. It regulates the amount of light entering the eye and influences the depth of field. In bright conditions, a constricted pupil increases the depth of field, allowing a wider range of distances to be in focus simultaneously.\nLens: Connected to the ciliary muscles, the lens can change its curvature to adjust focal length, a process known as accommodation. This allows the eye to focus on objects at varying distances.\nVitreous Humor: This gel-like substance fills the eye cavity, maintaining its shape and contributing to the eye’s optical properties.\nRetina: The light-sensitive layer at the back of the eye, containing photoreceptor cells (rods and cones) that convert light into neural signals.\n\n\n\n\nThe retina contains two types of photoreceptor cells:\n\nCones: Responsible for color vision and high acuity in bright light. They are concentrated around the fovea, the area of highest visual acuity. There are about 6 Million cones in the human eye.\nRods: More sensitive to light but do not distinguish colors, providing vision in low light conditions. There are around 12 Million rods in the human eye.\n\nRods and cones obtain their function from a chromophore molecule called retina, which undergoes a conformational change when exposed to light. This change triggers a cascade of chemical reactions that ultimately lead to the generation of neural signals. The color vision is achieved with the same chromophore molecule that is embedded in slightly different protein structures in cones. This allows cones to be sensitive to different wavelengths of light.\n\n\n\n\n\n\nFigure 2: Distribution of cones and rods around the fovea, their microscopic structure, and spectral sensitivity.\n\n\n\nCones contain light-sensitive pigments based on retinal molecules, which undergo conformational changes when excited by light, triggering a cascade of chemical processes. There are three types of cones, each sensitive to different wavelengths of light, enabling color vision.\n\n\n\nVisual acuity, often measured using an eye chart, quantifies the eye’s ability to resolve fine details. It’s typically expressed as a fraction (e.g., 20/20 vision), where the numerator is the test distance and the denominator is the distance at which a person with normal acuity can read the same line.\nThe human eye’s remarkable performance in pattern recognition, depth perception, and adaptability to varying light conditions is achieved through the complex interplay of its optical components and neural processing. This sophisticated system continues to inspire developments in artificial vision systems and optical technologies.\n\n\n\nThe eye’s optical system is asymmetrical due to the different media it interfaces with (air on one side, vitreous humor on the other). This results in different focal lengths:\n\nFront focal length: \\(f_1 = 17\\) mm\nBack focal length: \\(f_2 = 22\\) mm\n\nThese values can change during accommodation for near vision:\n\nClose object front focal length: \\(f_1 = 14\\) mm\nClose object back focal length: \\(f_2 = 19\\) mm\n\nThe eye’s refractive power, measured in diopters (D), is the reciprocal of the focal length in meters. For a relaxed eye:\n\\[P = \\frac{1}{f} = \\frac{1}{0.022 \\text{ m}} \\approx 45.45 \\text{ D}\\]\nDuring accommodation, this can increase to about 52 D.\n\n\n\n\n\n\nFigure 3: Illustration of the eye’s focal distances.\n\n\n\n\n\n\nThe resolution of the eye is limited by diffraction and the spacing of photoreceptors. The minimum angle of resolution θ_min can be approximated by:\n\\[\\theta_{\\text{min}} \\approx \\frac{1.22\\lambda}{D}\\]\nwhere λ is the wavelength of light and D is the diameter of the pupil. For a 3 mm pupil and 555 nm light (peak sensitivity), this gives a theoretical resolution of about 1 arc minute.\n\n\n\nThe human eye, under normal conditions, focuses images of distant objects onto the retina at the back focal distance of approximately 22 mm. However, various refractive errors can occur due to imperfections in the eye’s optical system, primarily the cornea and lens. These errors affect the eye’s ability to focus light accurately on the retina, leading to vision problems.\nCommon refractive errors include:\n\nMyopia (Short-sightedness): Light from distant objects focuses in front of the retina, causing distant objects to appear blurry while near objects remain clear.\nHyperopia (Far-sightedness): Light focuses behind the retina, making nearby objects appear blurry while distant objects may remain clear.\nAstigmatism: The cornea or lens isn’t perfectly spherical, causing light to focus at multiple points rather than a single sharp point on the retina.\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Correction of Myopia\n\n\n\n\n\n\n\n\n\n\n\n(b) Correction of Hyperopia\n\n\n\n\n\n\n\nFigure 4: Left: Myopia correction using a concave lens. Right: Hyperopia correction using a convex lens.\n\n\n\nThe severity of refractive errors can be quantified using the concept of refractive power. The refractive error R of the eye, measured in diopters (D), is calculated as:\n\\[R = \\frac{1}{f_{\\text{required}}} - \\frac{1}{f_{\\text{actual}}}\\]\nwhere f_required is the focal length needed for perfect focus, and f_actual is the eye’s actual focal length. This formula helps determine the degree of correction needed for various eye defects.\nIn a normal, relaxed state, the human eye can observe objects clearly up to a distance of approximately \\(s_0=25\\) cm without additional accommodation of the lens. This distance, known as the range of clear visual sight, varies among individuals and is used as a standard in optical calculations. Objects within this range can be observed under a visual angle \\(\\epsilon_0\\). For small angles, which is typically the case in vision, the angular size \\(\\epsilon_0\\) of an object of height h at a distance \\(s_0\\) is approximated by:\n\\[\n\\epsilon_0 \\approx \\tan(\\epsilon_0) = \\frac{h}{s_0}\n\\]\nThis relationship is fundamental in understanding how objects are perceived and in designing corrective lenses and optical instruments.\n\n\n\n\n\n\nFigure 5: Diagram of a relaxed eye focusing on a distant object.\n\n\n\nhistory |grep git\nUnderstanding these concepts is crucial for diagnosing vision problems and designing appropriate corrective measures, whether through eyeglasses, contact lenses, or surgical interventions.\n\n\n\nHaving discussed the basic structure and function of the human eye, we now turn to how optical instruments can enhance our vision. Instead of calculating the magnification of optical instruments from object and image distances, we introduce a more relevant measure: the angular magnification.\nThe angular magnification, V, is defined as the ratio of the angle subtended by the image when viewed through the instrument to the angle subtended by the object when viewed with the naked eye at the near point. It is given by:\n\\[\nV=\\frac{\\tan(\\epsilon)}{\\tan(\\epsilon_0)}\\approx \\frac{\\epsilon}{\\epsilon_0}\n\\]\nwhere: - ε is the angle subtended by the image at the eye when viewed through the instrument - ε₀ is the angle subtended by the object when viewed with the naked eye at the near point\nThis concept is crucial in understanding how optical instruments like telescopes and microscopes enhance our vision. Angular magnification effectively increases the apparent size of objects by increasing the angle at which they are viewed. This measure is particularly useful as the actual image size is often not directly accessible or relevant to the viewer’s experience.",
    "crumbs": [
      "Geometrical Optics",
      "Lecture 4",
      "Optical Instruments- Eye"
    ]
  },
  {
    "objectID": "geometrical-optics/Eye.html#the-human-eye",
    "href": "geometrical-optics/Eye.html#the-human-eye",
    "title": "Optical Instruments",
    "section": "",
    "text": "The human eye stands is one of the most remarkable sensory systems. This sophisticated organ combines an array of precisely crafted components—including an adjustable aperture, an adaptive lens, and a highly sensitive photodetector—all interconnected with a neural network capable of rapid and accurate pattern recognition. What’s truly astounding is that this entire system operates on mere watts of power.\n\n\n\n\n\n\n\n\n\n\n\n(a) Anatomy of the human eye\n\n\n\n\n\n\n\n\n\n\n\n(b) Retinal structure detail\n\n\n\n\n\n\n\nFigure 1: Left: Key components of the human eye, including the lens, vitreous body, and retina with its light-sensitive cells. Right: Detailed view of the retina, showing the arrangement and neural connections of rods and cones.\n\n\n\n\n\n\nPupil and Iris: The pupil, surrounded by the iris, acts as an adjustable aperture. It regulates the amount of light entering the eye and influences the depth of field. In bright conditions, a constricted pupil increases the depth of field, allowing a wider range of distances to be in focus simultaneously.\nLens: Connected to the ciliary muscles, the lens can change its curvature to adjust focal length, a process known as accommodation. This allows the eye to focus on objects at varying distances.\nVitreous Humor: This gel-like substance fills the eye cavity, maintaining its shape and contributing to the eye’s optical properties.\nRetina: The light-sensitive layer at the back of the eye, containing photoreceptor cells (rods and cones) that convert light into neural signals.\n\n\n\n\nThe retina contains two types of photoreceptor cells:\n\nCones: Responsible for color vision and high acuity in bright light. They are concentrated around the fovea, the area of highest visual acuity. There are about 6 Million cones in the human eye.\nRods: More sensitive to light but do not distinguish colors, providing vision in low light conditions. There are around 12 Million rods in the human eye.\n\nRods and cones obtain their function from a chromophore molecule called retina, which undergoes a conformational change when exposed to light. This change triggers a cascade of chemical reactions that ultimately lead to the generation of neural signals. The color vision is achieved with the same chromophore molecule that is embedded in slightly different protein structures in cones. This allows cones to be sensitive to different wavelengths of light.\n\n\n\n\n\n\nFigure 2: Distribution of cones and rods around the fovea, their microscopic structure, and spectral sensitivity.\n\n\n\nCones contain light-sensitive pigments based on retinal molecules, which undergo conformational changes when excited by light, triggering a cascade of chemical processes. There are three types of cones, each sensitive to different wavelengths of light, enabling color vision.\n\n\n\nVisual acuity, often measured using an eye chart, quantifies the eye’s ability to resolve fine details. It’s typically expressed as a fraction (e.g., 20/20 vision), where the numerator is the test distance and the denominator is the distance at which a person with normal acuity can read the same line.\nThe human eye’s remarkable performance in pattern recognition, depth perception, and adaptability to varying light conditions is achieved through the complex interplay of its optical components and neural processing. This sophisticated system continues to inspire developments in artificial vision systems and optical technologies.\n\n\n\nThe eye’s optical system is asymmetrical due to the different media it interfaces with (air on one side, vitreous humor on the other). This results in different focal lengths:\n\nFront focal length: \\(f_1 = 17\\) mm\nBack focal length: \\(f_2 = 22\\) mm\n\nThese values can change during accommodation for near vision:\n\nClose object front focal length: \\(f_1 = 14\\) mm\nClose object back focal length: \\(f_2 = 19\\) mm\n\nThe eye’s refractive power, measured in diopters (D), is the reciprocal of the focal length in meters. For a relaxed eye:\n\\[P = \\frac{1}{f} = \\frac{1}{0.022 \\text{ m}} \\approx 45.45 \\text{ D}\\]\nDuring accommodation, this can increase to about 52 D.\n\n\n\n\n\n\nFigure 3: Illustration of the eye’s focal distances.\n\n\n\n\n\n\nThe resolution of the eye is limited by diffraction and the spacing of photoreceptors. The minimum angle of resolution θ_min can be approximated by:\n\\[\\theta_{\\text{min}} \\approx \\frac{1.22\\lambda}{D}\\]\nwhere λ is the wavelength of light and D is the diameter of the pupil. For a 3 mm pupil and 555 nm light (peak sensitivity), this gives a theoretical resolution of about 1 arc minute.\n\n\n\nThe human eye, under normal conditions, focuses images of distant objects onto the retina at the back focal distance of approximately 22 mm. However, various refractive errors can occur due to imperfections in the eye’s optical system, primarily the cornea and lens. These errors affect the eye’s ability to focus light accurately on the retina, leading to vision problems.\nCommon refractive errors include:\n\nMyopia (Short-sightedness): Light from distant objects focuses in front of the retina, causing distant objects to appear blurry while near objects remain clear.\nHyperopia (Far-sightedness): Light focuses behind the retina, making nearby objects appear blurry while distant objects may remain clear.\nAstigmatism: The cornea or lens isn’t perfectly spherical, causing light to focus at multiple points rather than a single sharp point on the retina.\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Correction of Myopia\n\n\n\n\n\n\n\n\n\n\n\n(b) Correction of Hyperopia\n\n\n\n\n\n\n\nFigure 4: Left: Myopia correction using a concave lens. Right: Hyperopia correction using a convex lens.\n\n\n\nThe severity of refractive errors can be quantified using the concept of refractive power. The refractive error R of the eye, measured in diopters (D), is calculated as:\n\\[R = \\frac{1}{f_{\\text{required}}} - \\frac{1}{f_{\\text{actual}}}\\]\nwhere f_required is the focal length needed for perfect focus, and f_actual is the eye’s actual focal length. This formula helps determine the degree of correction needed for various eye defects.\nIn a normal, relaxed state, the human eye can observe objects clearly up to a distance of approximately \\(s_0=25\\) cm without additional accommodation of the lens. This distance, known as the range of clear visual sight, varies among individuals and is used as a standard in optical calculations. Objects within this range can be observed under a visual angle \\(\\epsilon_0\\). For small angles, which is typically the case in vision, the angular size \\(\\epsilon_0\\) of an object of height h at a distance \\(s_0\\) is approximated by:\n\\[\n\\epsilon_0 \\approx \\tan(\\epsilon_0) = \\frac{h}{s_0}\n\\]\nThis relationship is fundamental in understanding how objects are perceived and in designing corrective lenses and optical instruments.\n\n\n\n\n\n\nFigure 5: Diagram of a relaxed eye focusing on a distant object.\n\n\n\nhistory |grep git\nUnderstanding these concepts is crucial for diagnosing vision problems and designing appropriate corrective measures, whether through eyeglasses, contact lenses, or surgical interventions.\n\n\n\nHaving discussed the basic structure and function of the human eye, we now turn to how optical instruments can enhance our vision. Instead of calculating the magnification of optical instruments from object and image distances, we introduce a more relevant measure: the angular magnification.\nThe angular magnification, V, is defined as the ratio of the angle subtended by the image when viewed through the instrument to the angle subtended by the object when viewed with the naked eye at the near point. It is given by:\n\\[\nV=\\frac{\\tan(\\epsilon)}{\\tan(\\epsilon_0)}\\approx \\frac{\\epsilon}{\\epsilon_0}\n\\]\nwhere: - ε is the angle subtended by the image at the eye when viewed through the instrument - ε₀ is the angle subtended by the object when viewed with the naked eye at the near point\nThis concept is crucial in understanding how optical instruments like telescopes and microscopes enhance our vision. Angular magnification effectively increases the apparent size of objects by increasing the angle at which they are viewed. This measure is particularly useful as the actual image size is often not directly accessible or relevant to the viewer’s experience.",
    "crumbs": [
      "Geometrical Optics",
      "Lecture 4",
      "Optical Instruments- Eye"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Experimental Physics 3",
    "section": "",
    "text": "Welcome to the Experimental Physics 3 Course!\nIn this Experimental Physics 3 course, we will explore fundamental experiments and mathematical descriptions related to light propagation, electromagnetic waves, and their material counterpart, matter waves. Specifically, we will focus on:\n\nGeometrical Optics\nWave Optics\nElectromagnetic Waves\nMatter Waves and Quantum Mechanics\n\nThe fields of optics and quantum mechanics are currently vibrant areas of research, with rapidly evolving optical technologies, high-resolution microscopy, and quantum information science. All of these advancements build upon the foundations that we will address in this course.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "single_slit_kirchhoff.html",
    "href": "single_slit_kirchhoff.html",
    "title": "Experimental Physics 3 Course on Optics and Quantum Mechanics",
    "section": "",
    "text": "Derivation of Single Slit Diffraction Pattern Using Kirchhoff Diffraction Integral\n\nSetup\nConsider a monochromatic plane wave of wavelength \\(\\lambda\\) incident on a single slit of width \\(b\\). We want to find the diffraction pattern at a point \\(P\\) on a screen located at a distance \\(z\\) from the slit.\n\n\nKirchhoff Diffraction Integral\nThe Kirchhoff diffraction integral for the wave amplitude \\(U(P)\\) at point \\(P\\) is given by:\n\\[\nU(P) = \\frac{1}{i\\lambda} \\int_{\\text{aperture}} \\left( \\frac{\\partial U(Q)}{\\partial n} \\frac{e^{ikr}}{r} - U(Q) \\frac{\\partial}{\\partial n} \\left( \\frac{e^{ikr}}{r} \\right) \\right) dS\n\\]\nFor simplicity, we assume the incident wave is a plane wave \\(U_0\\) and the observation point \\(P\\) is in the far field (Fraunhofer approximation).\n\n\nSimplifications\n\nFar-Field Approximation: In the far field, the distance \\(r\\) from any point \\(Q\\) on the slit to the point \\(P\\) can be approximated as:\n\\[\nr \\approx z \\left( 1 + \\frac{x^2}{2z^2} \\right) \\approx z \\left( 1 + \\frac{x \\sin \\theta}{z} \\right) = z + x \\sin \\theta\n\\]\nwhere \\(x\\) is the coordinate along the slit width, and \\(\\theta\\) is the angle of diffraction.\nPlane Wave Approximation: The incident plane wave \\(U(Q)\\) can be taken as a constant \\(U_0\\).\nNeglecting Edge Effects: For simplicity, we neglect the edge effects and focus on the main term.\n\n\n\nIntegral Simplification\nThe Kirchhoff integral simplifies to:\n\\[\nU(P) \\approx \\frac{U_0}{i\\lambda z} \\int_{-b/2}^{b/2} e^{ikr} dx\n\\]\nSubstituting \\(r \\approx z + x \\sin \\theta\\):\n\\[\nU(P) \\approx \\frac{U_0 e^{ikz}}{i\\lambda z} \\int_{-b/2}^{b/2} e^{ik(x \\sin \\theta)} dx\n\\]\nSince \\(k = \\frac{2\\pi}{\\lambda}\\):\n\\[\nU(P) \\approx \\frac{U_0 e^{ikz}}{i\\lambda z} \\int_{-b/2}^{b/2} e^{i\\left(\\frac{2\\pi}{\\lambda}\\right)x \\sin \\theta} dx\n\\]\n\n\nEvaluating the Integral\nThe integral is:\n\\[\n\\int_{-b/2}^{b/2} e^{ikx \\sin \\theta} dx\n\\]\nThis is a standard integral of the form:\n\\[\n\\int_{-a}^{a} e^{iux} dx = \\frac{2 \\sin(ua)}{u}\n\\]\nHere, \\(a = \\frac{b}{2}\\) and \\(u = k \\sin \\theta\\):\n\\[\n\\int_{-b/2}^{b/2} e^{ikx \\sin \\theta} dx = \\frac{2 \\sin\\left( \\frac{kb \\sin \\theta}{2} \\right)}{k \\sin \\theta / 2}\n\\]\nSimplifying:\n\\[\n\\int_{-b/2}^{b/2} e^{ikx \\sin \\theta} dx = \\frac{2 \\sin\\left( \\frac{\\pi b \\sin \\theta}{\\lambda} \\right)}{2 \\pi \\sin \\theta / \\lambda} = \\frac{\\lambda \\sin\\left( \\frac{\\pi b \\sin \\theta}{\\lambda} \\right)}{\\pi \\sin \\theta}\n\\]\n\n\nFinal Expression\nSubstituting back into the expression for \\(U(P)\\):\n\\[\nU(P) \\approx \\frac{U_0 e^{ikz}}{i\\lambda z} \\cdot \\frac{\\sin\\left( \\frac{\\pi b \\sin \\theta}{\\lambda} \\right)}{\\pi \\sin \\theta}\n\\]\nSimplifying:\n\\[\nU(P) \\approx \\frac{U_0 e^{ikz}}{i z} \\cdot \\frac{\\sin\\left( \\frac{\\pi b \\sin \\theta}{\\lambda} \\right)}{\\pi \\sin \\theta}\n\\]\nThe intensity \\(I(\\theta)\\) is proportional to the square of the amplitude \\(U(P)\\):\n\\[\nI(\\theta) \\propto \\left| U(P) \\right|^2 \\propto \\left( \\frac{\\sin\\left( \\frac{\\pi b \\sin \\theta}{\\lambda} \\right)}{\\pi \\sin \\theta} \\right)^2\n\\]\nThus, the intensity distribution for single slit diffraction is:\n\\[\nI(\\theta) = I_0 \\left( \\frac{\\sin\\left( \\frac{\\pi b \\sin \\theta}{\\lambda} \\right)}{\\pi \\sin \\theta} \\right)^2\n\\]\nwhere \\(I_0\\) is the maximum intensity at \\(\\theta = 0\\)."
  },
  {
    "objectID": "electromagnetic-waves/Fresnel Equations.html",
    "href": "electromagnetic-waves/Fresnel Equations.html",
    "title": "Fresnel Equations",
    "section": "",
    "text": "In the last lecture, we have discussed the matching of the frequency and the wavevector at an interface between two materials. We now also need to have a look at the matching of the electric field amplitudes at the boundaries.\nIn the last lecture, we have discussed the mathcing of the frequency and the wavevector at an interface between the two materials. We no also need to have a look at the matching of the electric field amplitudes at the boundaries.",
    "crumbs": [
      "Electromagnetic Optics",
      "Lecture 15",
      "Fresnel Equations"
    ]
  },
  {
    "objectID": "electromagnetic-waves/Fresnel Equations.html#reflection",
    "href": "electromagnetic-waves/Fresnel Equations.html#reflection",
    "title": "Fresnel Equations",
    "section": "Reflection",
    "text": "Reflection\ns-polarized light\nWe would first like to have a look at light that is polarized perpendicular to the incident plane - so-called s-polarized light. According to our previous definition, s-polarized light is directed along the y-axis of our coordinate system. The incident light amplitude is therefore written as\n\\[\n\\vec{E}_I=E_I\\hat{e}_y\n\\]\nThis electric field vector is perpendicular to the plane of incidence. With this polarization the reflected and the refracted electric field also have to have this polarizations and thus\n\\[\n\\vec{E}_R=E_{R}\\hat{e}_y\n\\]\nand\n\\[\n\\vec{E}_T=E_{T}\\hat{e}_y\n\\]\nFrom this it also follows that at the boundary, the incident and the reflected field must be the same as the transmitted field in our matching condition. This is due to the fact that s-polarized light it always parallel to the interface.\n\\[\nE_I+E_R=E_T\n\\tag{matching}\n\\]\nThe magnetic field lies then in the plane of incidence as it is perpendicular to \\(\\vec{k}_I\\) and \\(\\vec{E}_I\\). It has components parallel \\(||\\) and perpendicular \\(\\perp\\) to the interface. The tangential components as well as the perpendicular ones are conserved so we can write for the tangential ones\n\\[\nB_I\\cos(\\theta_I)-B_R\\cos(\\theta_R)=B_T\\cos(\\theta_T)\n\\]\nGiven the fact that\n\\[\n\\vec{B}=\\frac{1}{v}(\\hat{v}\\times \\vec{E})\n\\]\nand that all three vectors are orthogonal we can use the relation \\(B=E/v\\) for the magnetic and electric field amplitudes and \\(\\theta_I=\\theta_R\\) to obtain\n\\[\n\\frac{E_I-E_R}{v_1}\\cos(\\theta_I)=\\frac{E_T}{v_2}\\cos(\\theta_T)\n\\]\nWith the help of the condition matching above we can replace the transmitted electric field \\(E_T\\) and using \\(v_1=c/n_1\\) and \\(v_2=c/n_2\\) we finally find\n\\[\n\\frac{E_R}{E_I}=\\frac{n_1\\cos(\\theta_I)-n_2\\cos(\\theta_T)}{n_1\\cos(\\theta_I)+n_2\\cos(\\theta_T)}=r_s\n\\]\nThis is the Fresnel coefficient for the reflection of s-polarized light \\(r_s\\). If we replace not the transmitted but the reflected electric field in the formula above, we may obtain the Fresnel coefficient for the transmission of s-polarized light \\(t_s\\)\n\\[\n\\frac{E_T}{E_I}=\\frac{2n_1\\cos(\\theta_I)}{n_1\\cos(\\theta_I)+n_2\\cos(\\theta_T)}=t_s\n\\]\np-polarized light\nIf the electric field is parallel to the plane of incidence, the we need to split it into parallel \\(||\\) and perpendicular \\(\\perp\\) components. The incident field may be written as\n\\[\n\\vec{E}_I=E_I\\sin(\\theta_I)\\hat{e}_x+E_I\\cos(\\theta_I)\\hat{e}_z\n\\]\nwhere \\(\\hat{e}_z\\) and \\(\\hat{e}_x\\) are the unit vectors in the z- and x-direction, respectively. The first term is the normal component to the boundary and the second the parallel component. We may pick our the parallel part, for which we know that the electric field is just continuous across the interface.\n\\[\nE_I\\cos(\\theta_I)+E_R\\cos(\\theta_R)=E_T\\cos(\\theta_T)\n\\]\nNow the magnetic field is perpendicular to the plane of incidence and we may write\n\\[\nB_I-B_R=B_T\n\\]\nfor the matching condition of the magnetic field. From this follows that\n\\[\n\\frac{E_I-E_R}{v_1}=\\frac{E_T}{v_2}\n\\]\nWe may now replace again the transmitted field, which results finally in the Fresnel coefficient for the reflection of p-polarized light \\(r_p\\)\n\\[\n\\frac{E_R}{E_I}=\\frac{n_2\\cos(\\theta_I)-n_1\\cos(\\theta_T)}{n_1\\cos(\\theta_T)+n_2\\cos(\\theta_I)}=r_p\n\\]\nFinally, we may also do the same for the Fresnel coefficient of the transmission of p-polarized light \\(t_p\\)\n\\[\n\\frac{E_T}{E_I}=\\frac{2n_1\\cos(\\theta_I)}{n_1\\cos(\\theta_T)+n_2\\cos(\\theta_I)}=t_p\n\\]\n\n\n\n\n\n\nNote\n\n\n\nFresnel Equations\nThe Fresnel equations give the relations for the amplitude of the transmitted and reflected electric fields to the incident electric field amplitude as a function of the angle of incident and the light polarization.\ns-polarization\n\\[\n\\frac{E_R}{E_I}=\\frac{n_1\\cos(\\theta_I)-n_2\\cos(\\theta_T)}{n_1\\cos(\\theta_I)+n_2\\cos(\\theta_T)}=r_s\n\\tag{Fresnel Coefficient $r_s$}\n\\]\n\\[\n\\frac{E_T}{E_I}=\\frac{2n_1\\cos(\\theta_I)}{n_1\\cos(\\theta_I)+n_2\\cos(\\theta_T)}=t_s\n\\tag{Fresnel Coefficient $t_s$}\n\\]\np-polarization\n\\[\n\\frac{E_R}{E_I}=\\frac{n_2\\cos(\\theta_I)-n_1\\cos(\\theta_T)}{n_1\\cos(\\theta_T)+n_2\\cos(\\theta_I)}=r_p\n\\tag{Fresnel Coefficient $r_p$}\n\\]\n\\[\n\\frac{E_T}{E_I}=\\frac{2n_1\\cos(\\theta_I)}{n_1\\cos(\\theta_T)+n_2\\cos(\\theta_I)}=t_p\n\\tag{Fresnel Coefficient $t_p$}\n\\]\n\n\n\nAir to Glass\nLets discuss the results we obtained with the help of specifc examples. We will consider the interface between air (\\(n_1=1\\)) and glass (\\(n_2=1.5\\)) and vary the angle of incidence. The transmission angle can the be obtained from Snell’s law \\(n_1\\sin(\\theta_I)=n_2\\sin(\\theta_T)\\). Besides the Frensel coefficients, we plot also the phase. This phase gives us an idea about possible phase changes upon reflection and refraction. We have previously assume for example, that under normal incidence we obtain a phase jump of \\(\\pi\\) upon reflection when coming from air to glass. This is something we may check now.\nTo do so, we just represent the complex Fresnel coefficients as \\(r_s=|r_s|e^{i\\phi}\\)\n\n\nCode\ndef fresnel_r(theta_i, n1, n2):\n    theta_i = np.deg2rad(theta_i)\n\n    theta_t = np.arcsin(n1*np.sin(theta_i)/n2)\n\n    r_s = (n1*np.cos(theta_i) - n2*np.cos(theta_t))/(n1*np.cos(theta_i) + n2*np.cos(theta_t))\n    r_p = (n2*np.cos(theta_i) - n1*np.cos(theta_t))/(n2*np.cos(theta_i) + n1*np.cos(theta_t))\n\n    return r_s, r_p\n\nn1 = 1.0    # Air\nn2 = 1.5    # Glass\ntheta = np.linspace(0, 89, 1000)  # Angle of incidence in degrees\n\nr_s, r_p = fresnel_r(theta, n1, n2)\n\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=get_size(12, 6))\n\n# Plot signed coefficients\nax1.plot(theta, r_s, 'b-', label='$r_s$')\nax1.plot(theta, r_p, 'r-', label='$r_p$')\nax1.set_xlabel(r'$\\theta_{I}$')\nax1.set_ylabel(r'$r_s,r_p$')\nax1.set_ylim(-1, 1)\nax1.legend()\n\n# Plot phase\nax2.plot(theta, np.angle(r_s, deg=True), 'b-', label='$\\\\phi_s$')\nax2.plot(theta, np.angle(r_p, deg=True), 'r-', label='$\\\\phi_p$')\nax2.set_xlabel(r'$\\theta_{I}$')\nax2.set_ylabel(r'phase $\\phi$')\nax2.set_ylim(-10, 190)\nax2.legend()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nFigure 1— Fresnel coefficients (left) and phase (right) of the reflected light observed for the reflection at an air(\\(n_1=1\\))/glass(\\(n_2=1.5\\)) interface.\n\n\n\n\n\nThe above graph displays the reflection coefficients \\(r_s,r_p\\) as a function of the angle of incidence. The value of \\(r_s\\) is negative for the whole range indicating the there is a phase jump by an angle of \\(\\pi\\) as we assumed already in the thin film interference section. This phase jump is also confirmed in the second plot on the right. Note that that reflection coefficient for the parallel polarization \\(r_p\\) is positive up to an angle of about \\(56^{\\circ}\\). This also means that there is no phase jump for this component up to this angle. Beyond this angle we find also a phase jump of \\(\\phi\\). Note that normal incidence \\(\\theta_I=0\\) is a special point, where all incident electric field are tangential to the interface. So also \\(r_p\\) will be negative at that point and for this incident angle there is no plane of incidence definition.\nThe special angle where the \\(r_p=0\\) is called the Brewster Angle. It is special since at this angle of incidence unpolarized light will be turned into completely s-polarized light in reflection. This also means that you can get rid of a reflection from an air/glass interface, when observing this interface with a linear polarizer.\n\n\n\nReflections observed with linear polarizer.\n\n\nFollowing the Fresnel formula for \\(r_p\\), the reflection coefficient becomes zero when \\(n_2\\cos(\\theta_I)=n_1\\cos(\\theta_T)\\). Using Snells law as well, we find that\n\\[\n\\theta_I+\\theta_T=\\frac{\\pi}{2}\n\\]\nand thus the following definition for the Brewster angle (\\(\\theta_B\\))\n\\[\n\\tan(\\theta_B)=\\frac{n_2}{n_1}\n\\]\nThe Brewster angle arises from the fact that the dipoles which are induced by the incident light in the material oscillate along the direction of the reflected light. We will see later that dipoles do not emit light along its oscillation direction and hence, there is no reflection for the in plane polarization.\n\n\n\n\n\n\nNote\n\n\n\nBrewster Angle\nThe Brewster angle is the angle under which the reflection of light with a polarization in the plane of incidence vanishes.\n\\[\n\\tan(\\theta_B)=\\frac{n_2}{n_1}\n\\]\n\n\nBrewsters Pyramid\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 2— Reflections from a pyramid observed with linear polarizer. The pyramid sides are arranged at an angle, which corresponds to the Brewster angle. If polarized light in a certain direction is falling on the pyramid faces, the reflection disappears.\n\n\n\n\n\n\n\n\n\nBrewster Angle Microscopy\n\n\n\n\n\nBrewster angle microscopy (BAM) is a powerful surface-sensitive technique that takes advantage of the Brewster angle phenomenon. At the Brewster angle, p-polarized light is completely transmitted through an interface, resulting in zero reflection. However, if there are molecules or thin films present at the interface, they will disturb this condition and create a reflection that can be detected.\n\n\n\n\n\n\n\n\n\n\n\n(a)\n\n\n\n\n\n\n\n\n\n\n\n(b)\n\n\n\n\n\n\n\nFigure 3— MODEL SKIN LIPIDS a) without and b) with 40 % addition of oleic acid at 10 mN/m imaged with KSV NIMA BAM. The size of the images is ~720 μm (W) × 400 μm (H). With permission from Langmuir 2013, 29 (15), pp 4857–4865. Copyright 2013 American Chemical Society.\n\n\n\n\n\n\nReflection Removal\n\n\n\n\n\n\nFigure 4— Reflections from surfaces which are observed under an angle are often partially polarized such that the observation with the help of a polarizer (e.g. in photography), can greatly reduce the highlights from reflections and make objects behind windows visible.\n\n\n\n\n\nGlass to Air\nIf we invert the order of the materials and have light incindent to a glass/air interface we observe a new effect in the total internal reflection of light. First of all the p-polarization obtains now a phase shift by \\(pi\\) up to the Brewster angle, which is now at \\(33^{\\circ}\\), when it gets back in phase with the incident light. The s-polarized light has no phase jump at the interface, yet both components reach a magnitude of \\(1\\) at the critical angle of total internal reflection \\(\\theta_C\\). Starting from this incident angle, all light is reflected by the glass/air interface. As we know from the geometrical optics, the angle of total internal reflection is obtained when the transmission angle becomes \\(90^{\\circ}\\).\n\\[\n\\sin(\\theta_C)=\\frac{n_2}{n_1}\n\\tag{$n_2&lt;n_1$}\n\\]\nFor the glass/air interface as shown below, this total internal reflection occurs for an angle \\(\\theta_C=41.8^{\\circ}\\). While the magnitude of the reflections coefficient is then \\(1\\), the phase of the reflected light changes continuously from \\(0^{\\circ}\\) to \\(90^{\\circ}\\).\n\n\nCode\ndef fresnel_r(theta_i, n1, n2):\n    theta_i = np.deg2rad(theta_i)\n\n    theta_t = np.arcsin(n1*np.sin(theta_i)/n2 +0j)\n\n    r_s = (n1*np.cos(theta_i) - n2*np.cos(theta_t))/(n1*np.cos(theta_i) + n2*np.cos(theta_t))\n    r_p = (n2*np.cos(theta_i) - n1*np.cos(theta_t))/(n2*np.cos(theta_i) + n1*np.cos(theta_t))\n\n    return r_s, r_p\n\nn1 = 1.5    # Glass\nn2 = 1.0    # Air\ntheta = np.linspace(0, 41.8, 1000)  # Angle of incidence in degrees\n\nr_s, r_p = fresnel_r(theta, n1, n2)\n\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=get_size(12, 6))\n\n# Plot signed coefficients\nax1.plot(theta, np.real(r_s)+np.imag(r_s), 'b-', label='$r_s$')\nax1.plot(theta, np.real(r_p)+np.imag(r_s), 'r-', label='$r_p$')\nax1.set_xlabel(r'$\\theta_{I}$')\nax1.set_ylabel(r'$r_s,r_p$')\nax1.set_xlim(0,90)\nax1.set_ylim(-1, 1)\nax1.legend()\n\n# Plot phase\nax2.plot(theta, np.angle(r_s, deg=True), 'b-', label='$\\\\phi_s$')\nax2.plot(theta, np.angle(r_p, deg=True), 'r-', label='$\\\\phi_p$')\nax2.set_xlabel(r'$\\theta_{I}$')\nax2.set_ylabel(r'phase $\\phi$')\nax2.set_xlim(0,90)\nax2.set_ylim(-10, 190)\nax2.legend()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nFigure 5— Fresnel coefficients (left) and phase (right) of the reflected light observed for the reflection at an air(\\(n_1=1\\))/glass(\\(n_2=1.5\\)) interface.\n\n\n\n\n\nWe will investigate the transmitted light in the case of total internal reflection below in the transmission section. You will see in the images below also, that the on the reflection side a standing interference pattern is observed, due to the superposition of incident and reflected wave.\n\n\n\nTotal internal reflection of microwaves by a prism.",
    "crumbs": [
      "Electromagnetic Optics",
      "Lecture 15",
      "Fresnel Equations"
    ]
  },
  {
    "objectID": "electromagnetic-waves/Fresnel Equations.html#transmission",
    "href": "electromagnetic-waves/Fresnel Equations.html#transmission",
    "title": "Fresnel Equations",
    "section": "Transmission",
    "text": "Transmission\nAs compared to the reflection, the transmission of light is more or less boring.\n\nAir to Glass\nThe transmission of light from air to glass only changes weakly the intensity, except for large angles of incidence. Also the phase angle is not changed at all upon transmission.\n\n\nCode\ndef fresnel_t(theta_i, n1, n2):\n    theta_i = np.deg2rad(theta_i)\n\n    theta_t = np.arcsin(n1*np.sin(theta_i)/n2)\n\n    t_s = 2*n1*np.cos(theta_i)/(n1*np.cos(theta_i) + n2*np.cos(theta_t))\n    t_p = 2*n1*np.cos(theta_i)/(n2*np.cos(theta_i) + n1*np.cos(theta_t))\n\n    return t_s, t_p\n\nn1 = 1.0    # Air\nn2 = 1.5    # Glass\ntheta = np.linspace(0, 89, 1000)  # Angle of incidence in degrees\n\nt_s, t_p = fresnel_t(theta, n1, n2)\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=get_size(12, 6))\n\n# Plot signed coefficients\nax1.plot(theta, t_s, 'b-', label='$t_s$')\nax1.plot(theta, t_p, 'r-', label='$t_p$')\nax1.set_xlabel(r'$\\theta_{I}$')\nax1.set_ylabel(r'$t_s,t_p$')\nax1.set_ylim(0, 2)\nax1.legend()\n\n# Plot phase\nax2.plot(theta, np.angle(t_s, deg=True), 'b-', label='$\\\\phi_s$')\nax2.plot(theta, np.angle(t_p, deg=True), 'r-', label='$\\\\phi_p$')\nax2.set_xlabel(r'$\\theta_{I}$')\nax2.set_ylabel(r'phase $\\phi$')\nax2.set_ylim(-10, 10)\nax2.legend()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nFigure 6— Fresnel coefficients (left) and phase (right) of the transmitted light observed for the transmission at an air(\\(n_1=1\\))/glass(\\(n_2=1.5\\)) interface.\n\n\n\n\n\n\n\nGlass to Air\nThe situation, however, becomes a bit more interesting the the case of the transmission of light from glass to air. The first thing we notice here is that the Fresnel coefficients for transmission \\(t_s,t_p\\) are both bigger than one and even grow to larger values at the edge of total internal reflection. This seems to say that the amplitude of the electric field that is transmitted is bigger than the one incident. This is in fact true, but does not violate energy conservation, but is rather resulting from the changed speed of light in the glass. We will have a closer look at the intensities down below.\n\n\nCode\ndef fresnel_t(theta_i, n1, n2):\n    theta_i = np.deg2rad(theta_i)\n\n    theta_t = np.arcsin(n1*np.sin(theta_i)/n2 + 0j)\n\n    t_s = 2*n1*np.cos(theta_i)/(n1*np.cos(theta_i) + n2*np.cos(theta_t))\n    t_p = 2*n1*np.cos(theta_i)/(n2*np.cos(theta_i) + n1*np.cos(theta_t))\n\n    return t_s, t_p\n\nn1 = 1.5    # Glass\nn2 = 1.0    # Air\ntheta = np.linspace(0, 41.8, 1000)  # Angle of incidence in degrees\n\nt_s, t_p = fresnel_t(theta, n1, n2)\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=get_size(12, 6))\n\n# Plot signed coefficients\nax1.plot(theta, np.real(t_s)+np.imag(t_s), 'b-', label='$t_s$')\nax1.plot(theta, np.real(t_p)+np.imag(t_p), 'r-', label='$t_p$')\nax1.set_xlabel(r'$\\theta_{I}$')\nax1.set_ylabel(r'$t_s,t_p$')\nax1.set_xlim(0,90)\nax1.set_ylim(0, 2)\nax1.legend()\n\n# Plot phase\nax2.plot(theta, np.angle(t_s, deg=True), 'b-', label='$\\\\phi_s$')\nax2.plot(theta, np.angle(t_p, deg=True), 'r-', label='$\\\\phi_p$')\nax2.set_xlabel(r'$\\theta_{I}$')\nax2.set_ylabel(r'phase $\\phi$')\nax2.set_xlim(0,90)\nax2.set_ylim(-10, 10)\nax2.legend()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nFigure 7— Fresnel coefficients (left) and phase (right) of the transmitted light observed for the transmission at a glass(\\(n_1=1.5\\))/air(\\(n_2=1.0\\)) interface.\n\n\n\n\n\nAnother thing that is occuring but not directly visible is the electric field amplitude in the region directly behind the glass interface in air. Even though all of the light is reflected, this does not mean that no electric field may exist on the transmission side. In fact, an electric field is present and will decay in amplitude exponentially. To see what is happing directly behind the interface we\nWhat is interesting for the total internal reflection is now the electric field that exists on the side, where usually the transmission would go. Here is our coordinate system again such that we can have a look at the wavevectors in the different regions.\n\n\n\nCoordinate system for wave at interfaces.\n\n\nThe wavevector in the transmission region is given by\n\\[\n\\vec{k}_T=k_{Tx} \\hat{e}_x+k_{Tz} \\hat{e}_z\n\\] Accordining to the condition that the tangential component of the wavevector is conserved we can write down\n\\[\nk_{Iz}=\\vec{k}_I\\cdot \\hat{e}_z=\\vec{k}_T\\cdot \\hat{e}_z=k_{Tz}=\\frac{\\omega}{v_1}\\sin(\\theta_I)\\hat{e}_z\n\\]\nwhere \\(\\omega\\) is the frequency of light and \\(v_1\\) the phase velocity in medium 1, which is in this case glass. Besides the tangential component of the wavevector we can also calculate the magnitude square of the wavevector that is transmitted, which is\n\\[\n|\\vec{k}_T|^2=\\frac{\\omega^2}{v_2^2}\n\\]\nSince the wavevector is in the x-z plane we may calculate the x-component from\n\\[\\begin{eqnarray}\n\\vec{k}_T\\cdot \\hat{e}_x&=&\\pm \\sqrt{|\\vec{k}_T|^2-(\\vec{k}_T\\cdot \\hat{e}_z)^2}\\\\\n&=&\\pm \\frac{\\omega}{v_2}\\sqrt{1-\\frac{v_2^2\\sin^2(\\theta_I)}{v_1^2}}\\\\\n&=&\\pm \\frac{\\omega}{v_2}\\sqrt{1-\\frac{n_1^2\\sin^2(\\theta_I)}{n_2^2}}\n\\end{eqnarray}\\]\nThe last equation will yield a negative value under the square root\n\\[\n\\frac{n_1}{n_2}\\sin(\\theta_I)&gt;1\n\\]\nwhich is in fact the region, where total internal reflection occurs. If this is the case, the transmitted wavevector along the x-direction will be imaginary and we may write\n\\[\nk_{Tx}=\\vec{k}_T\\cdot \\hat{e}_x=\\pm i \\frac{\\omega}{v_2}\\alpha\n\\]\nwhere \\(\\alpha\\) is the given by\n\\[\n\\alpha=\\sqrt{\\frac{n_1^2\\sin^2(\\theta_I)}{n_2^2}-1}\n\\]\nand is a positive number due to a little trick taking the negative value of the previous square root term. We may now use this wavevector with the x- and the z-component and insert that in our plane wave, which would be propagating in the transmission region (here air).\n\\[\n\\vec{E}_{\\rm trans}=\\vec{E}_T e^{i(\\omega t -k_{Tx}x-k_{Tz}z)}\n\\]\nInserting the results for the components of the wavevector obtained above yields\n\\[\n\\vec{E}_{\\rm trans}=\\vec{E}_T e^{i(\\omega t -n_1 k_0\\sin(\\theta_I) z)}e^{-n_2k_0 \\alpha x}\n\\]\nThe imaginary -xcomponent of the wavevector is creating a real valued factor for the amplitude of the electric field in the transmission region. The electric field in this region is decaying exponentially with the distance \\(x\\) from the interface. Yet, the field is only osciallting along the interface but not in the x-direction. Such an exponentially decaying field without oscillation is called evanescent wave. Equivalent exponential decays do also exist in quantum mechanics, however, they concern in this case the decay of the probability to find a particle inside a region.\nThe image below shows the electric field (left) and the intensity (right) for the total internal reflection at a boundary between glass and air, which the exponential decay is nicely visible for the electric field. To calculate the intensity, we would have to calculate the Poynting vector. As it turns our, the Pyonting vector is zero in the transmission region and hence there is no energy flow in the transmission region. Nevertheless, there is a time oscillating electric field and we may calculate the magnitude square of the electric field decay, which is shown in the right figure.\n\n\nCode\ndef plane_wave(k,omega,r,t):\n    return(np.exp(1j*(np.dot(k,r)-omega*t)))\n\n## snells law\ndef snell(n1,n2,alpha):\n    tmp=n1*np.sin(alpha)/n2\n    return(np.arcsin(tmp,dtype=complex))\n\n## reflection coefficient\ndef rs(n1,n2,alpha,beta):\n    return((n1*np.cos(alpha)-n2*np.cos(beta))/((n1*np.cos(alpha)+n2*np.cos(beta))))\n\n## transmission coefficient\ndef ts(n1,n2,alpha,beta):\n    return(2*n1*np.cos(alpha)/((n1*np.cos(alpha)+n2*np.cos(beta))))\n\nwavelength=532e-9\nk0=2*np.pi/wavelength\nc=299792458\nomega0=k0*c\nn1=1.5\nn2=1.0\nvec=np.array([0.0,0.,1.])\nvec=vec/np.sqrt(np.dot(vec,vec))\n\nk=k0*vec\n\n\nx=np.linspace(-5e-6,5e-6,500)\nz1,z2=np.linspace(-5e-6,0,250),np.linspace(0,5e-6,250)\nX,Z1=np.meshgrid(x,z1)\n\n\nX,Z2=np.meshgrid(x,z2)\nr1=np.array([X,0,Z1],dtype=object)\nr2=np.array([X,0,Z2],dtype=object)\n\nalpha=45*np.pi/180\n\nvec=np.array([np.sin(alpha),0.,np.cos(alpha)])\nk1=n1*k0*vec\nk2=n1*k0*vec\nk2[2]=k2[2]*-1\nk3=np.zeros([3],dtype=complex)\nk3[0]=k1[0]\nk3[2]=np.sqrt(n2**2*k1[2]**2+(n2**2-n1**2)*k1[0]**2,dtype=complex)/n1\n\nfield=np.zeros([500,500],dtype=complex)\nfield1=plane_wave(k1,omega0,r1,0)\nfield2=plane_wave(k2,omega0,r1,0)\nfield3=plane_wave(k3,omega0,r2,0)\n\nbeta=snell(n1,n2,alpha)\nr=rs(n1,n2,alpha,beta)\nt=ts(n1,n2,alpha,beta)\n\nfield[:250,:]=field1+r*field2\nfield[250:,:]=t*field3\n\nplt.figure(figsize=get_size(12,6))\nextent = np.min(z1)*1e6, np.max(z2)*1e6,np.max(x)*1e6, np.min(x)*1e6\nplt.subplot(1,2,1)\nplt.imshow(np.real(field.transpose()),extent=extent,cmap='seismic')\nplt.title('electric field')\nplt.xlabel('z [µm]')\nplt.ylabel('x [µm]')\n\nplt.subplot(1,2,2)\nplt.imshow(np.abs(field.transpose())**2,extent=extent,cmap='gray')\nplt.title('intensity')\nplt.xlabel('z [µm]')\nplt.ylabel('x [µm]')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nFigure 8— Electric field amplitude (left) and intensity (right) at a glass(\\(n_1=1.5\\))/air(\\(n_2=1.0\\)) interface.\n\n\n\n\n\nTo gain a bit more insight into the lengthscale on which the electric field in Figure Figure 9 is decaying, we may have a look at the prefactor in the above exponential term.\n\n\nCode\nfig,(ax1,ax2)=plt.subplots(1,2,figsize=get_size(12,6))\nax1.plot(x*1e6,np.abs(field.transpose()[250,:])**2)\nax1.set_xlabel('z [µm]')\nax1.set_ylabel('intensity')\n\n\nax2.semilogy(x*1e6,np.abs(field.transpose()[250,:])**2)\nax2.set_xlabel('z [µm]')\nax2.set_ylabel('intensity')\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nFigure 9— Electric field amplitude (left) and intensity (right) along the propagation direction at a glass(\\(n_1=1.5\\))/air(\\(n_2=1.0\\)) interface.\n\n\n\n\n\nThis prefactor denotes an inverse length scale, i.e.\n\\[\n\\delta=\\frac{1}{n_2k_0 \\alpha}\n\\]\nand measures the distance on which the electric field decayed to \\(1/e\\). The plot below shows that the decay length for the electric field amplitude quickly drops with increasing incident angle\n\n\nCode\n# Parameters\nwavelength = 532e-9  # green light\nn1 = 1.5  # glass\nn2 = 1.0  # air\nk0 = 2*np.pi/wavelength\n\n# Critical angle\ntheta_c = np.arcsin(n2/n1)\n#print(f\"Critical angle: {np.rad2deg(theta_c):.1f}°\")\n\n# Angles from critical angle to 89 degrees\ntheta_i = np.linspace(np.rad2deg(theta_c)+0.1, 89, 1000)\nalpha = np.sqrt((n1*np.sin(np.deg2rad(theta_i)))**2/n2**2 - 1)\n\n# Calculate decay length\ndecay_length = 1/(n2*k0*alpha)\n\n# Plot\nplt.figure(figsize=get_size(8, 6))\nplt.plot(theta_i, decay_length*1e9)  # convert to nm\nplt.axvline(np.rad2deg(theta_c), color='r', linestyle='--', label='Critical angle')\nplt.xlabel(r'incident angle $\\theta_I$ [°]')\nplt.ylabel(r'decay length $\\delta$ [nm]')\nplt.legend()\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nFigure 10— Decay length of the evanescent wave in air for total internal reflection at a glass/air interface (wavelength = 532nm).\n\n\n\n\n\nThe evanescent field in the transmission region can be converted back into a propagating wave if a second interface is brought in the range of the evanescent wave. This can be demonstrated easily with microwaves, since their wavelength is long.\n\n\n\nTotal internal reflection of microwaves by a prism (left).\n\n\nIn the visible region, this decay length is on the order of a few 100 nanometers. Evanescent field play an important role for optical microscopy for example, where they are either used in total internal reflection fluorescence microscopy (TIRF), exciting only a tiny sheet above an interface and thus reducing fluorescence background. Other techniques use the evanescent field on tiny tips as sources for excitation of fluorescence or scattering (NSOM). Evanescent waves are also used for coupling light into small mechanical resonators to cool them to extremely low temperatures (opto-mechanics).",
    "crumbs": [
      "Electromagnetic Optics",
      "Lecture 15",
      "Fresnel Equations"
    ]
  },
  {
    "objectID": "electromagnetic-waves/Fresnel Equations.html#intensities-of-reflected-and-transmitted-waves",
    "href": "electromagnetic-waves/Fresnel Equations.html#intensities-of-reflected-and-transmitted-waves",
    "title": "Fresnel Equations",
    "section": "Intensities of Reflected and Transmitted Waves",
    "text": "Intensities of Reflected and Transmitted Waves\nSo far we calculated the Fresnel coefficients, from which we may obtain the electric and magnetic field amplitudes of the reflected and transmitted waves. We now want to calculate the intensities. The Poynting vector of a wave is given by\n\\[\n\\vec{S}=\\vec{E}\\times \\vec{H}=\\frac{1}{\\mu_r \\mu_0}(\\vec{E}\\times \\vec{B})=\\epsilon_r \\epsilon_0 v^2(\\vec{E}\\times \\vec{B})\n\\]\nThe magnitude of the Pyonting vector is therefore given by\n\\[\nS=\\epsilon_r\\epsilon_0 v|\\vec{E}|^2=n^2\\epsilon_0 c|\\vec{E}|^2\n\\]\nThe intensity is then obtained from the integration over one cycle of oscialltion, which finally results in\n\\[\nI=\\frac{1}{2}n\\epsilon_0 c|\\vec{E}|^2\n\\]\nWith the help of this equation it can be seen that the reflected intensity and the incident intensity contain the same refractive index. thus only the magnitude square of the Fresnel coefficients for the reflection is importnat giving\n\\[\nR=|r|^2\n\\]\nwhich is valid for either s- or p-polarization.\nFor the transmission we have to be a bit more careful as first of all the light propagates with different phase velocities (refractive index \\(n\\)) and the cross section of a beam changes due to the refraction at the interface as shown in the image below.\n\n\n\nRelevant areas for the calculation of the intensities from the transmission Fresnel coefficients.\n\n\nThe two cross-section behave as\n\\[\n\\frac{A''}{A}=\\frac{\\cos(\\theta_T)}{\\cos(\\theta_I)}\n\\]\nThe intensities directly contain the refractive index and this\n\\[\nT=\\frac{n_2\\cos(\\theta_T)}{n_1\\cos(\\theta_I)}|t|^2\n\\]\nAs energy conservation is valid, the reflected energy and the transmitted energy have to sum up to the incident energy in nonabsorbing media, which states that\n\\[\nR+T=1\n\\tag{nonabsorbing media}\n\\]\n\n\nCode\ndef fresnel_intensities(theta_i, n1, n2):\n    theta_i = np.deg2rad(theta_i)\n\n    # Calculate transmitted angle (complex for TIR)\n    theta_t = np.arcsin(n1*np.sin(theta_i)/n2 + 0j)\n\n    # Reflection coefficients\n    r_s = (n1*np.cos(theta_i) - n2*np.cos(theta_t))/(n1*np.cos(theta_i) + n2*np.cos(theta_t))\n    r_p = (n2*np.cos(theta_i) - n1*np.cos(theta_t))/(n2*np.cos(theta_i) + n1*np.cos(theta_t))\n\n    # Transmission coefficients\n    t_s = 2*n1*np.cos(theta_i)/(n1*np.cos(theta_i) + n2*np.cos(theta_t))\n    t_p = 2*n1*np.cos(theta_i)/(n2*np.cos(theta_i) + n1*np.cos(theta_t))\n\n    # Intensity reflection coefficients\n    R_s = np.abs(r_s)**2\n    R_p = np.abs(r_p)**2\n\n    # Intensity transmission coefficients\n    T_s = np.real(n2*np.cos(theta_t)/(n1*np.cos(theta_i))) * np.abs(t_s)**2\n    T_p = np.real(n2*np.cos(theta_t)/(n1*np.cos(theta_i))) * np.abs(t_p)**2\n\n    return R_s, R_p, T_s, T_p\n\n# Create figure\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=get_size(12, 6))\n\n# Air to glass\ntheta1 = np.linspace(0, 89, 1000)\nn1, n2 = 1.0, 1.5  # Air to glass\nR_s1, R_p1, T_s1, T_p1 = fresnel_intensities(theta1, n1, n2)\n\nax1.plot(theta1, R_s1, 'b-', label='$R_s$')\nax1.plot(theta1, R_p1, 'r-', label='$R_p$')\nax1.plot(theta1, T_s1, 'b--', label='$T_s$')\nax1.plot(theta1, T_p1, 'r--', label='$T_p$')\nax1.set_xlabel(r'$\\theta_{I}$')\nax1.set_ylabel('R,T')\nax1.set_ylim(0, 1)\nax1.legend()\n\n# Glass to air\ntheta2 = np.linspace(0, 90, 1000)\nn1, n2 = 1.5, 1.0  # Glass to air\nR_s2, R_p2, T_s2, T_p2 = fresnel_intensities(theta2, n1, n2)\n\nax2.plot(theta2, R_s2, 'b-', label='$R_s$')\nax2.plot(theta2, R_p2, 'r-', label='$R_p$')\nax2.plot(theta2, T_s2, 'b--', label='$T_s$')\nax2.plot(theta2, T_p2, 'r--', label='$T_p$')\nax2.set_xlabel(r'$\\theta_{I}$')\nax2.set_ylabel('R,T')\nax2.set_xlim(0, 90)\nax2.set_ylim(0, 1)\nax2.legend()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nFigure 11— Reflected and transmitted intensities for air to glass (left) and glass to air (right) interfaces.\n\n\n\n\n\nThe displayed reflection and transmission coefficients will reappear in quantum mechanics for the tunneling effect on a potential energy barrier.\n\n\n\n\n\n\nTotal Internal Reflection Fluorescence (TIRF) Microscopy\n\n\n\n\n\nTIRF microscopy is a powerful imaging technique that exploits the properties of evanescent waves to achieve exceptional signal-to-noise ratio in fluorescence imaging. When light undergoes total internal reflection at a glass-water interface (typically a microscope coverslip-sample interface), the resulting evanescent field only penetrates about 100-200 nm into the sample. This shallow excitation depth provides an excellent optical sectioning capability, as only fluorophores within this thin layer are excited. This makes TIRF microscopy particularly well-suited for studying processes at or near the cell membrane, such as:\n\nMembrane protein dynamics\nEndocytosis and exocytosis\nCell adhesion\nSingle-molecule tracking\n\nThe signal-to-background ratio in TIRF microscopy can be 100-1000 times better than conventional fluorescence microscopy because out-of-focus fluorescence is virtually eliminated. The technique has become indispensable in cell biology, especially for studying membrane-associated processes in living cells. The exponential decay of the evanescent field intensity with distance from the interface provides an additional advantage: the fluorescence intensity can be used to estimate the distance of fluorescent molecules from the surface with nanometer precision.",
    "crumbs": [
      "Electromagnetic Optics",
      "Lecture 15",
      "Fresnel Equations"
    ]
  },
  {
    "objectID": "electromagnetic-waves/Dispersion and Absorption.html",
    "href": "electromagnetic-waves/Dispersion and Absorption.html",
    "title": "Dispersion & Absorption",
    "section": "",
    "text": "When light interacts with matter, its electric field \\(\\vec{E}(\\vec{r},t)\\) influences the charged particles within atoms. For visible light (\\(\\lambda \\approx 500\\, \\text{nm}\\)) interacting with atoms (size \\(\\approx 0.1\\, \\text{nm}\\)), we can make two important approximations:\nFor a linearly polarized wave along the x-direction: \\[\\vec{E}(t)=E_0\\hat{x} e^{-i\\omega t}\\]\nFor isotropic media, the dipole moment \\(\\vec{p}\\) of an atom is proportional to the local electric field:\n\\[\\vec{p}=\\alpha\\vec{E}\\]\nThe equation of motion for the electron displacement vector follows: \\[\n\\ddot{\\vec{r}}+\\sigma\\dot{\\vec{r}}+\\omega_0\\vec{r}=\\frac{q}{m}\\vec{E}(t)\n\\]\nFor the x-component, we can write: \\[\n\\ddot{x}+\\sigma\\dot{x}+\\omega_0x=\\frac{q}{m}E_x(t)\n\\]\nThe solution has the form: \\[\nx(t)=x_0 e^{i\\omega t}\n\\]\nThis leads to: \\[\n\\vec{r}(t)=\\frac{1}{\\omega_0^2+i\\omega\\sigma-\\omega^2}\\frac{q}{m}\\vec{E}(t)\n\\]\nThe oscillating dipole moment becomes \\(\\vec{p}=q\\vec{r}(t)=\\alpha\\vec{E}(t)\\), and the polarization density: \\[\n\\vec{P}=Nq\\frac{1}{\\omega_0^2+i\\omega\\sigma-\\omega^2}\\frac{q}{m}\\vec{E}(t)=\\epsilon_0\\chi\\vec{E}(t)\n\\]\nFrom this, we obtain the electronic susceptibility:\n\\[\n\\chi=\\chi_0\\frac{1}{\\omega_0^2+i\\omega\\sigma-\\omega^2}\n\\]\nwith\n\\[\n\\chi_0=\\frac{q^2N}{m\\epsilon_0}\n\\]\nThe susceptibility is complex, written as \\(\\chi=\\chi^{'}+i\\chi^{\"}\\), making both the dielectric function \\(\\epsilon_r=1+\\chi\\) and refractive index complex quantities.\nThe complex refractive index takes the form:\n\\[\nn=n_r-i\\kappa=\\sqrt{\\epsilon_r}=\\sqrt{1+\\chi}\n\\]\nwhere the negative sign convention for the imaginary part is standard but not universal. Explicitly:\n\\[\nn=1+\\frac{Nq^2}{2\\epsilon_0 m}\\frac{(\\omega_0^2-\\omega^2)-i\\sigma\\omega}{(\\omega_0^2-\\omega^2)^2+\\omega^2\\sigma^2}=n_r-i\\kappa\n\\]\nThese real and imaginary components, \\(n_r\\) and \\(\\kappa\\), significantly affect light propagation. The two components can be written as\n\\[n_r = 1 + A\\frac{(\\omega_0^2-\\omega^2)}{(\\omega_0^2-\\omega^2)^2+\\omega^2\\sigma^2}\\]\nand\n\\[\\kappa = A\\frac{\\sigma\\omega}{(\\omega_0^2-\\omega^2)^2+\\omega^2\\sigma^2}\\]\nwith \\(A=\\frac{Nq^2}{2\\epsilon_0 m}\\).\nCode\nN = 1  # Number density\nq = 1  # Charge\nm = 1  # Mass\nepsilon_0 = 1  # Vacuum permittivity\nomega_0 = 1  # Resonance frequency\nsigma = 0.1  # Damping parameter\n\nomega = np.linspace(0, 2, 1000)\n\nprefactor = N * q**2 / (2 * epsilon_0 * m)\n\ndenominator = (omega_0**2 - omega**2)**2 + omega**2 * sigma**2\nn_real = 1 + prefactor * (omega_0**2 - omega**2) / denominator\nn_imag = prefactor * sigma * omega / denominator\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=get_size(12,7))\n\n# Real part\nax1.plot(omega/omega_0, n_real, 'b-')\nax1.axhline(y=0, color='k', linestyle=':')\nax1.axvline(x=1, color='k', linestyle=':')\nax1.set_xlabel('ω/ω₀')\nax1.set_ylabel('Re(n)')\n\n# Imaginary part\nax2.plot(omega/omega_0, n_imag, 'r-')\nax2.axhline(y=0, color='k', linestyle=':')\nax2.axvline(x=1, color='k', linestyle=':')\nax2.set_xlabel('ω/ω₀')\nax2.set_ylabel('Im(n)')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\nReal and imaginary part of the refractive index.\nThe plots show how both components vary with frequency due to the atomic resonance. Near resonance, the real part exhibits strong dispersion, transitioning from values above 1 to below 1. The imaginary part shows a Lorentzian peak with width determined by the damping coefficient \\(\\sigma\\).",
    "crumbs": [
      "Electromagnetic Optics",
      "Lecture 14",
      "Origin of Refractive Index"
    ]
  },
  {
    "objectID": "electromagnetic-waves/Dispersion and Absorption.html#absorption",
    "href": "electromagnetic-waves/Dispersion and Absorption.html#absorption",
    "title": "Dispersion & Absorption",
    "section": "Absorption",
    "text": "Absorption\n\n\n\n\n\n\nImportant\n\n\n\nThe imaginary component of the refractive index leads to the Lambert-Beer Law, a fundamental principle in optics and spectroscopy.\n\n\nThe imaginary component \\(\\kappa\\) determines wave attenuation. For a plane wave propagating in the z-direction, the electric field is:\n\\[\n\\vec{E}(z,t) = E_0\\hat{x}e^{i(kz-\\omega t)}\n\\]\nThe spatial part follows:\n\\[\n\\vec{E}(z)=E_0\\hat{x}e^{-ik z}=E_0\\hat{x}e^{-in k_0 z}\n\\]\nIncluding the complex refractive index:\n\\[\n\\vec{E}(z)=E_0\\hat{x}e^{-i(n-i\\kappa) k_0 z} =E_0\\hat{x} e^{-i n_r k_0 z}e^{-\\kappa k_0 z}\n\\]\nThe exponential decay factor modifies the wave amplitude with distance.\nThe intensity, which is proportional to the time-averaged Poynting vector magnitude, follows:\n\\[\\begin{align}\nI &= \\frac{1}{2}\\epsilon_0 c|\\vec{E}|^2 \\\\\n  &= \\frac{1}{2}\\epsilon_0 c |E_0|^2 \\left | e^{-in_r k_0 z }e^{-\\kappa k_0 z} \\right |^2\\\\\n  &= I_0 e^{-2\\kappa k_0 z} \\\\\n  &= I_0 e^{-\\alpha z}\n\\end{align}\\]\nwhere \\(\\alpha=2k_0\\kappa = \\frac{4\\pi\\kappa}{\\lambda}\\) represents the absorption coefficient. This exponential decay of intensity with distance is known as the Lambert-Beer Law:\n\\[\n\\frac{I}{I_0}= e^{-\\alpha z}\n\\tag{Lambert Beer Law}\n\\]\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 2— Measurement of the absorption coefficient.\n\n\n\nThe frequency-dependent absorption reflects resonant behavior, with strong absorption near resonance and weak absorption elsewhere. Real materials typically have multiple resonances, creating complex absorption spectra that serve as unique chemical fingerprints.\n\n\n\n\n\n\nAbsorption Measurements\n\n\n\nThe measurement of absorption is fundamental to many fields including chemistry, materials science, and biological studies. The basic principle relies on the Lambert-Beer Law:\n\\[\\ln\\left(\\frac{I}{I_0}\\right) = -\\alpha(\\lambda)L = -\\epsilon(\\lambda)cL\\]\nwhere:\n\n\\(I/I_0\\) is the transmittance\n\\(\\alpha(\\lambda)\\) is the absorption coefficient\n\\(\\epsilon(\\lambda)\\) is the molar extinction coefficient\n\\(c\\) is the molar concentration\n\\(L\\) is the path length\n\nThe above logarithm can be used to define the absorbance \\(A\\) as\n\\[A = -\\ln\\left(\\frac{I}{I_0}\\right)/\\ln(10)\\]\nwhich is the typical quantity that is plotted against concentration in absorption measurements and linearly depends on the concentration. According to Lambert Beers law, the absorbance is calculated from \\[A = \\epsilon c L\\] and provides the molar extinction coefficient \\(\\epsilon\\) for the material at a given wavelength.\n\n\n\n\n\nBasic setup for absorption measurements\n\n\n\n\n\nConcentration Measurements\nThe linear relationship between absorbance and concentration enables quantitative analysis:\n\n\nCode\nconcentrations = np.linspace(0, 1, 10)\nabsorbance = 2*concentrations + np.random.normal(0, 0.02, 10)\n\nplt.figure(figsize=get_size(8,6))\nplt.plot(concentrations, absorbance, 'bo', label='Data')\nplt.plot(concentrations, 2*concentrations, 'r-', label='Linear fit')\nplt.xlabel('concentration')\nplt.ylabel('absorbance')\nplt.legend()\nplt.show()\n\n\n\n\n\nBeer-Lambert law verification plot\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe linear range typically extends up to absorbance values of ~1.0 Beyond this, deviation from linearity may occur\n\n\n\n\nApplications\n\n1. Chemical Analysis\nChemical analysis provides quantitative information about composition and concentration in solutions. Absorption measurements enable precise determination of concentration levels across many compounds. Reaction kinetics can be monitored in real-time by tracking absorption changes. Quality control in industrial processes relies on rapid and accurate absorption measurements to ensure product consistency.\n\n\n2. Materials Characterization\nOptical properties of materials reveal crucial information about their electronic structure and physical properties. Band gap determination helps classify semiconductors and predict their behavior in devices. Film thickness measurements using absorption techniques provide non-destructive ways to characterize thin films and coatings. Understanding these properties is essential for developing new materials and optimizing their performance in applications.\n\n\n3. Biological Studies\nProtein quantification through absorption measurements forms a cornerstone of biochemical analysis. DNA and RNA analysis relies on characteristic absorption peaks to determine concentration and purity. Enzyme assays monitor reaction progress through changes in absorption, providing insight into biological processes. These techniques are fundamental to modern biological research and medical diagnostics.",
    "crumbs": [
      "Electromagnetic Optics",
      "Lecture 14",
      "Origin of Refractive Index"
    ]
  },
  {
    "objectID": "electromagnetic-waves/Dispersion and Absorption.html#dispersion",
    "href": "electromagnetic-waves/Dispersion and Absorption.html#dispersion",
    "title": "Dispersion & Absorption",
    "section": "Dispersion",
    "text": "Dispersion\n\n\n\n\n\n\nNote\n\n\n\nDispersion manifests through two key velocities:\n\nPhase velocity: speed of wave fronts\nGroup velocity: speed of wave packets\n\n\n\nThe frequency dependence of the real refractive index affects wave propagation speeds in two important ways: through the phase velocity and group velocity.\n\nPhase Velocity\nThe phase velocity represents the speed of wave phase fronts: \\[\nv=\\frac{\\omega}{k}=\\frac{c}{n_r}\n\\tag{phase velocity}\n\\]\n\n\nGroup Velocity\nThe group velocity represents the speed of wave packets \\[\nv_g=\\frac{d\\omega}{dk}\n\\tag{group velocity}\n\\]\n\n\nCode\n# Set up the spatial grid\nx = np.linspace(-10, 10, 1000)\nt = 0  # Time snapshot\n\n# Wave packet parameters\nk0 = 2.0  # Central wavenumber\nsigma = 1.0  # Width of gaussian envelope\nomega = 2.0  # Angular frequency\n\n# Create gaussian envelope\nenvelope = np.exp(-x**2/(4*sigma**2))\n\n# Create carrier wave\ncarrier = np.cos(k0*x - omega*t)\n\n# Combine to create wave packet\nwave_packet = envelope * carrier\n\n# Plotting\nplt.figure(figsize=get_size(10, 8))\n\n# Plot envelope\nplt.plot(x, envelope, 'r--', label='Envelope', alpha=0.5)\nplt.plot(x, -envelope, 'r--', alpha=0.5)\n\n# Plot carrier wave\nplt.plot(x, carrier, 'g:', label='Carrier wave', alpha=0.5)\n\n# Plot wave packet\nplt.plot(x, wave_packet, 'b-', label='Wave packet')\n\nplt.xlabel('position x')\nplt.ylabel('amplitude')\nplt.legend()\nplt.ylim(-1.2, 1.2)\n\nplt.show()\n\n\n\n\n\n\n\n\n\nTo relate group velocity to the refractive index, we can derive:\n\\[\nv_g=\\frac{d}{dk}(v k)=v+k\\frac{dv}{dk}\n\\]\nUsing \\(k=k_0 n_r\\) and \\(v=c/n_r\\), and after some algebra, we obtain:\n\\[\nv_g=\\frac{c}{n_r+\\omega \\frac{dn_r}{d\\omega}}\n\\tag{group velocity dispersion}\n\\]\nThe group velocity is distinct from the phase velocity and represents how fast the envelope of a wave packet propagates through space. In a dispersive medium, where the refractive index depends on frequency, the group velocity can differ significantly from the phase velocity. This is particularly important in optical communications where information is carried by wave packets rather than single-frequency waves.\n\n\nCode\n# Constants (working in scaled units)\nc = 1.0          # Speed of light (scaled)\nA = 0.1          # Amplitude parameter\nomega_0 = 1.0    # Resonant frequency (scaled to 1)\nsigma = 0.2    # Damping parameter (~10% of omega_0)\n\n# Frequency range\nomega = np.linspace(0.5*omega_0, 1.5*omega_0, 1000)\n\n# Calculate refractive index\ndef n_r(omega):\n    return 1 + A * (omega_0**2 - omega**2) / ((omega_0**2 - omega**2)**2 + omega**2 * sigma**2)\n\n# Calculate dn_r/dω\ndef dn_r_domega(omega):\n    numerator = -2*A*omega*((omega_0**2 - omega**2)**2 + omega**2*sigma**2) \\\n                + A*(omega_0**2 - omega**2)*(-4*omega*(omega_0**2 - omega**2) + 2*omega*sigma**2)\n    denominator = ((omega_0**2 - omega**2)**2 + omega**2*sigma**2)**2\n    return numerator/denominator\n\nv_g = c / (n_r(omega) + omega * dn_r_domega(omega))\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=get_size(12, 7))\n\nax1.plot(omega/omega_0, n_r(omega), 'b-', label='Refractive index')\nax1.set_xlabel('ω/ω₀')\nax1.set_ylabel(r'$n_r$')\nax1.legend()\nax1.axhline(y=1, color='k', linestyle=':')\nax1.axvline(x=1, color='k', linestyle=':')\n\nax2.plot(omega/omega_0, v_g/c, 'r-', label='Group velocity')\nax2.set_xlabel('ω/ω₀')\nax2.set_ylabel(r'$v_g/c$')\nax2.legend()\nax2.axhline(y=1, color='k', linestyle=':')\nax2.axvline(x=1, color='k', linestyle=':')\nax2.set_ylim(-10,10)\n\n# Adjust layout\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nFor optical pulses in fibers or other waveguides, group velocity dispersion leads to pulse spreading because different frequency components travel at different speeds. This effect becomes critical in long-distance optical communication systems where pulse broadening can lead to signal distortion and intersymbol interference.\nIn vacuum or non-dispersive media where the refractive index is constant (\\(\\frac{dn_r}{d\\omega}=0\\)), the group velocity equals the phase velocity. However, in most practical situations involving light propagation through materials, dispersion causes these velocities to differ, necessitating careful consideration in optical system design.\n\n\nTypes of Dispersion\nThe frequency dependence of the refractive index leads to two distinct regimes of dispersion:\n\nNormal Dispersion: \\[\n\\frac{dn_r}{d\\omega}&gt;0\n\\] In the normal dispersion regime, the refractive index increases with frequency, meaning that higher frequency (blue) light travels more slowly through the medium than lower frequency (red) light. This behavior is commonly observed in transparent materials at frequencies far from their resonances. The effects of normal dispersion are ubiquitous in optics: when white light passes through a prism, it separates into its spectral components creating a rainbow pattern; in optical systems, it causes chromatic aberration where different colors focus at different points; and in optical fibers, it leads to temporal spreading of pulses as different frequency components travel at different speeds through the medium.\n\n\n\n\n\n\n\nNote\n\n\n\nNormal dispersion dominates in transparent materials at frequencies well below their resonances. This is why prisms separate white light into its spectral components with blue light bending more than red light.\n\n\n\nAnomalous Dispersion: \\[\n\\frac{dn_r}{d\\omega}&lt;0\n\\] Anomalous dispersion occurs in the vicinity of absorption resonances, where the conventional relationship between frequency and refractive index is reversed. In this regime, higher frequencies propagate faster than lower frequencies, leading to unique optical phenomena. The behavior is characterized by strong frequency-dependent absorption accompanied by rapid variations in the refractive index. This unusual dispersion can even result in negative group velocities under certain conditions. The practical applications of anomalous dispersion are particularly important in modern optics, where it is used for pulse compression in ultrafast laser systems, dispersion compensation in optical communications, and various applications in ultrafast optics.\n\n\n\n\n\n\n\nImportant\n\n\n\nThe transition between normal and anomalous dispersion typically occurs near absorption resonances, where the refractive index varies rapidly with frequency. This behavior is described by the Kramers-Kronig relations, which connect the real and imaginary parts of the refractive index.\n\n\nReal materials often exhibit both types of dispersion across different frequency ranges, resulting in complex optical behavior. Understanding and controlling these dispersion effects is crucial for the development of optical communication systems, the generation and manipulation of ultrashort pulses, the design of optical components, and the implementation of nonlinear optical processes. The interplay between normal and anomalous dispersion enables sophisticated control over light propagation, essential for modern optical technologies.\n\n\nSuperluminal Group Velocity\nThe concept of superluminal group velocity emerges in regions of anomalous dispersion, where the group velocity can mathematically exceed the speed of light c. This occurs when: \\[\nn_r+\\omega \\frac{dn_r}{d\\omega}&lt;1\n\\]\nIn our classical oscillator model, this condition is met near the resonance frequency when: \\[\n|\\omega_0-\\omega|&lt;\\frac{\\sigma}{2}\n\\]\nThis seemingly paradoxical result warrants careful interpretation. The group velocity, while traditionally associated with the speed of energy or information transport, becomes problematic near resonances. Several key points help clarify this phenomenon:\n\nPhysical Interpretation: The superluminal effect is associated with pulse reshaping rather than actual faster-than-light signal propagation. The pulse peak appears to emerge from the medium before it would in vacuum due to preferential absorption and dispersion of different frequency components.\nPulse Distortion: Near resonances, pulses undergo severe distortion, making the group velocity less meaningful as a measure of signal propagation. The pulse envelope no longer maintains its shape, and different parts of the pulse travel at different velocities.\nCausality and Energy Transport: While \\(v_g\\) may exceed c, the energy transport velocity: \\[\nv_{E}=\\frac{\\vec{S}}{w_{em}}=\\frac{I}{w_{em}}\\le c\n\\] where \\(\\vec{S}\\) is the Poynting vector and \\(w_{em}\\) is the electromagnetic energy density, always remains subluminal, preserving causality.\n\n\n\n\n\n\n\nNote\n\n\n\nThe apparent superluminal propagation has been observed experimentally in various systems, including:\n\nGain media\nPhotonic crystals\nAtomic gases near absorption lines (see Wang, Kuzmich, and Dogariu (2000))\nOptical fibers with specially engineered dispersion\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nDespite superluminal group velocity, no information can be transmitted faster than c. This is ensured by:\n\nThe severe pulse distortion in regions of anomalous dispersion\nThe Kramers-Kronig relations linking absorption and dispersion\nThe principle of causality in electromagnetic theory\n\n\n\nThe study of superluminal group velocity has practical applications in: - Understanding fundamental limits of signal propagation - Designing fast-light and slow-light devices - Developing optical delay lines and buffers - Quantum information processing\nThis phenomenon illustrates the subtle interplay between classical electromagnetic theory, special relativity, and the practical limitations of optical pulse propagation.\n\n\n\n\n\n\nKramers-Kronig Relations\n\n\n\n\n\nThe Kramers-Kronig relations express a fundamental connection between the real and imaginary parts of the complex refractive index (or susceptibility). These relations arise from causality - the principle that effects cannot precede their causes - and the analytical properties of response functions in the complex frequency plane.\n\nPhysical Origin\nConsider a general response function \\(\\chi(\\omega)\\) describing how a system responds to electromagnetic perturbations. For this response to be causal, \\(\\chi(\\omega)\\) must be analytic in the upper half of the complex frequency plane. This analyticity requirement, combined with the reality condition \\(\\chi(-\\omega)=\\chi^*(\\omega)\\), leads to the Kramers-Kronig relations.\n\n\nPrincipal Relations\nFor the complex susceptibility \\(\\chi(\\omega)=\\chi'(\\omega)+i\\chi''(\\omega)\\), the Kramers-Kronig relations take the form:\n\\[\n\\chi'(\\omega) = \\frac{1}{\\pi}\\mathcal{P}\\int_{-\\infty}^{\\infty}\\frac{\\chi''(\\omega')}{\\omega'-\\omega}d\\omega'\n\\]\n\\[\n\\chi''(\\omega) = -\\frac{1}{\\pi}\\mathcal{P}\\int_{-\\infty}^{\\infty}\\frac{\\chi'(\\omega')}{\\omega'-\\omega}d\\omega'\n\\]\nwhere \\(\\mathcal{P}\\) denotes the Cauchy principal value of the integral.\n\n\n\n\n\n\nNote\n\n\n\nSimilar relations hold for the complex refractive index \\(n(\\omega)=n_r(\\omega)+i\\kappa(\\omega)\\):\n\\[\nn_r(\\omega)-1 = \\frac{2}{\\pi}\\mathcal{P}\\int_{0}^{\\infty}\\frac{\\omega'\\kappa(\\omega')}{\\omega'^2-\\omega^2}d\\omega'\n\\]\n\\[\n\\kappa(\\omega) = -\\frac{2\\omega}{\\pi}\\mathcal{P}\\int_{0}^{\\infty}\\frac{n_r(\\omega')-1}{\\omega'^2-\\omega^2}d\\omega'\n\\]\n\n\n\n\nImplications\nThe Kramers-Kronig relations reveal profound connections in optical physics. Most significantly, they demonstrate that absorption and dispersion are intrinsically linked phenomena. It is impossible to have a perfectly transparent medium that exhibits dispersion, as the presence of dispersion necessarily implies some absorption at certain frequencies. This connection is mathematically expressed through sum rules, such as the integral relation \\(\\int_0^\\infty \\omega'\\chi''(\\omega')d\\omega' = 0\\), which places constraints on physically possible optical responses.\nThe relations enforce causality in light-matter interactions, ensuring that optical responses cannot precede their stimuli. This causality principle manifests in the observed behavior of optical materials, particularly near resonances where anomalous dispersion invariably accompanies absorption peaks.\n\n\n\n\n\n\nImportant\n\n\n\nThe Kramers-Kronig relations demonstrate that dispersion and absorption are not independent phenomena but are fundamentally linked through causality. This connection explains why anomalous dispersion always occurs near absorption resonances.\n\n\n\n\nApplications\nThe practical significance of the Kramers-Kronig relations extends throughout optical physics and engineering. Scientists and engineers use these relations to determine complete optical responses from partial measurements, as measuring either the real or imaginary part allows reconstruction of the other. This capability proves invaluable in materials characterization and optical device design. The relations also serve as a theoretical framework for validating experimental optical data and understanding the fundamental limits of optical materials.\nIn optical device design, these relations guide the development of components with specific dispersion properties, though they also highlight the inherent trade-offs between dispersion and absorption that must be considered. The understanding provided by the Kramers-Kronig relations has become essential in fields ranging from spectroscopy to telecommunications, where precise control of optical properties is crucial.\nThe Kramers-Kronig relations stand as one of the most elegant examples of how fundamental physical principles - in this case, causality - manifest in measurable optical properties, providing both practical tools for optical engineering and deep insights into the nature of light-matter interactions.",
    "crumbs": [
      "Electromagnetic Optics",
      "Lecture 14",
      "Origin of Refractive Index"
    ]
  },
  {
    "objectID": "electromagnetic-waves/EM Waves in Matter_old.html#single-atom-in-an-electric-field",
    "href": "electromagnetic-waves/EM Waves in Matter_old.html#single-atom-in-an-electric-field",
    "title": "Experimental Physics 3 Course on Optics and Quantum Mechanics",
    "section": "Single Atom in an electric Field",
    "text": "Single Atom in an electric Field\nThe behavior of electromagnetic waves changes significantly when they propagate through materials rather than vacuum. This interaction is fundamentally governed by how the electric and magnetic fields of the wave affect the charged particles within the material. Before exploring these wave phenomena, let’s first understand how materials respond to electric fields through the process of polarization - the separation of positive and negative charge centers in atoms.\nTo understand how materials respond to electromagnetic waves, let’s first examine how individual atoms become polarized in an electric field. We’ll use a simple but instructive model where:\n\nAn electron charge \\(-q\\) is uniformly distributed in a spherical cloud of radius \\(a\\)\nA positive nucleus sits at the center of this negative charge distribution\n\nThe charge density of the electron cloud is a scalar quantity:\n\\[\n\\rho=\\frac{-q}{\\frac{4}{3}\\pi a^{3}}=-\\frac{3q}{4\\pi a^3}\n\\]\nThis configuration creates a radial electric field inside the cloud:\n\\[\n\\vec{E}(\\vec{r})=-\\frac{1}{4\\pi\\epsilon_0}\\frac{q}{a^3}\\vec{r}\n\\]\nwhere \\(\\vec{r}\\) is the position vector from the center. The linear dependence on \\(\\vec{r}\\) creates a restoring force similar to a spring.\n\n\n\n\n\n\nFigure 1: Polarization of an electric cloud of an atom: An external electric field displaces the positive nucleus relative to the negative electron cloud, creating an induced dipole moment.\n\n\n\nWhen we apply an external electric field \\(\\vec{E}_{\\rm ex}\\), the nucleus is displaced by a vector \\(\\vec{d}\\) until forces balance:\n\\[\nq\\vec{E}_{\\rm ex}-\\frac{1}{4\\pi\\epsilon_0}\\frac{q^2\\vec{d}}{a^3}=\\vec{0}\n\\]\nThis force balance between the external field (pushing the nucleus) and the internal field (trying to restore the nucleus to the center) determines the atomic polarization, from which we find the displacement:\n\\[\n\\vec{d}=4\\pi \\epsilon_0 a^3 \\frac{\\vec{E}_{\\rm ex}}{q}\n\\]\nThis displacement creates a dipole moment:\n\\[\n\\vec{p}=q\\vec{d}=4\\pi\\epsilon_0 a^3 \\vec{E}_{\\rm ex}\n\\]\nThe dipole moment increases linearly with the external field, with the proportionality constant:\n\\[\n\\alpha=4\\pi \\epsilon_0 a^3\n\\]\nknown as the electronic polarizability. Note that while α is a scalar for this spherically symmetric case, in general it can be a tensor. The polarizability scales with atomic volume.\nWhen many atoms in a material are exposed to an electric field, their individual dipole moments combine to create a macroscopic polarization. The collective behavior can be characterized by the polarization density:\n\\[\n\\vec{P}=N\\vec{p}\n\\]\nwhere \\(N\\) is the number of dipoles per unit volume and \\(p\\) is the individual atomic dipole moment.\n\n\n\n\n\n\nFigure 2: Polarization in a dielectric material showing aligned atomic dipoles and resulting surface charges.\n\n\n\nThen finally for a cylindrical sample with cross-sectional area \\(A\\) and height \\(s\\), this microscopic picture leads to:\n\nTotal dipole moment: \\(p_{\\rm cyl}=A s P\\)\nEnd charges: \\(q_{\\rm end}=\\frac{p_{\\rm cyl}}{s}=A P\\)\nSurface charge density: \\(\\sigma=\\frac{q_{\\rm end}}{A}=P\\)\n\nMore generally, the surface charge density at any boundary is:\n\\[\n\\sigma=\\vec{P}\\cdot\\hat{n}\n\\]\nwhere \\(\\hat{n}\\) is the surface normal. These surface charges are “bound” to atoms, distinct from free charges, and denoted as \\(\\sigma_b\\).\n\nVolume Charge Density\nWhen polarization isn’t uniform throughout a material, we need to consider both surface and volume charges. All bound charges in the material must sum to zero since the material was initially neutral. This charge conservation requirement leads to:\n\\[\\int \\sigma_b dA +\\int \\rho_b dv=0\\]\nWe know that surface charge density is related to polarization through \\(\\sigma_b=\\vec{P}\\cdot\\hat{n}\\). Therefore, the surface integral can be written as:\n\\[\\int \\sigma_b dA = \\int \\vec{P}\\cdot\\hat{n}dA = \\int \\vec{P}\\cdot d\\vec{A}\\]\nNow we can apply Gauss’s theorem, which states that \\(\\int \\vec{P}\\cdot d\\vec{A} = \\int (\\nabla\\cdot\\vec{P})dv\\). Applying this to our charge conservation equation gives:\n\\[\\int \\rho_b dv + \\int (\\nabla\\cdot\\vec{P})dv = 0\\]\nSince this relationship must hold for any arbitrary volume within the material, we can conclude that the integrands must be equal and opposite, leading to the local relationship:\n\\[\\rho_b = -\\nabla\\cdot\\vec{P}\\]\nThis fundamental equation reveals that bound volume charges appear wherever the polarization has a divergence - that is, wherever it changes spatially in a way that creates an imbalance of positive and negative charges.\n\n\nElectric Displacement Field\nIn materials, the electric field’s divergence must account for both free charges and the bound charges that arise from polarization. Starting with Gauss’s law, we can write:\n\\[\n\\nabla \\cdot \\vec{E}=\\frac{\\rho_{\\rm f}+\\rho_{\\rm b}}{\\epsilon_0}\n\\]\nWe previously found that bound charges are related to the polarization through \\(\\rho_b=-\\nabla\\cdot \\vec{P}\\). Inserting this relationship into Gauss’s law yields:\n\\[\n\\nabla \\cdot \\vec{E}=\\frac{\\rho_{\\rm f}-\\nabla\\cdot \\vec{P}}{\\epsilon_0}\n\\]\nMultiplying both sides by \\(\\epsilon_0\\) and rearranging terms leads to a more compact form:\n\\[\n\\nabla \\cdot(\\epsilon_0\\vec{E}+\\vec{P})=\\rho_f\n\\]\nThis naturally suggests defining a new field quantity, the electric displacement field:\n\\[\n\\vec{D}=\\epsilon_0 \\vec{E}+\\vec{P}\n\\]\nThe displacement field \\(\\vec{D}\\) elegantly simplifies Gauss’s law to:\n\\[\n\\nabla \\cdot \\vec{D} =\\rho_f\n\\]\nThis form resembles the original Gauss’s law in vacuum, but now the displacement field \\(\\vec{D}\\) accounts for both the electric field and the material’s polarization response, while only relating to free charges.\n\n\nDielectric Polarization in Materials\nFor many materials, the polarization density is proportional to the applied electric field:\n\\[\n\\vec{P}=\\epsilon_0\\chi\\vec{E}\n\\]\nwhere \\(\\chi\\) is the electric susceptibility, characterizing the material’s response to electric fields. This linear relationship between \\(\\vec{P}\\) and \\(\\vec{E}\\) defines what we call linear dielectric materials. While this linear response follows from our simple atomic model, real materials often exhibit nonlinear responses to strong electric fields - effects studied in the field of nonlinear optics.\nWithin this linear approximation, we can express the displacement field in terms of the susceptibility:\n\\[\n\\vec{D}=\\epsilon_0 \\vec{E}+\\vec{P}=\\epsilon_0 (1+\\chi)\\vec{E}=\\epsilon \\vec{E}\n\\]\nwhere we define the electric permittivity as:\n\\[\n\\epsilon=\\epsilon_0 (1+\\chi)\n\\tag{electric permittivity}\n\\]\nThe dimensionless ratio\n\\[\n\\epsilon_r=\\frac{\\epsilon}{\\epsilon_0}=1+\\chi\n\\]\nis called the relative permittivity or dielectric constant. However, this term can be misleading as \\(\\epsilon_r\\) typically depends on the frequency of the electromagnetic field - making it a dielectric function rather than a constant.\n\n\nClausius-Mossotti Relation\nWhile this model provides useful intuition, it requires modification for dense materials where atoms are closely packed. Consider a dielectric material composed of polarizable atoms or molecules. The local electric field \\(\\vec{E}_{loc}\\) experienced by an atom differs from the average (macroscopic) field \\(\\vec{E}\\) due to the contributions from surrounding dipoles. The local field inside a small spherical cavity in the dielectric consists of three contributions:\n\\[\\vec{E}_{loc} = \\vec{E} + \\vec{E}_{dep}\\]\nwhere \\(\\vec{E}\\) is the applied field, \\(\\vec{E}_{dep}\\) is the depolarization field from charges on the cavity surface, and \\(\\vec{E}_{near}\\) is the near-field contribution from neighboring dipoles.\nFor a spherical cavity, the depolarization field is given by \\(\\vec{E}_{dep} = -\\frac{\\vec{P}}{3\\epsilon_0}\\), where \\(\\vec{P}\\) is the polarization density. The near-field contribution from a cubic lattice arrangement averages to zero (\\(\\vec{E}_{near} = \\vec{0}\\)). Therefore, the local field becomes:\n\\[\\vec{E}_{loc} = \\vec{E} - \\frac{\\vec{P}}{3\\epsilon_0}\\]\nThe polarization density is related to the local field through \\(\\vec{P} = N\\alpha \\vec{E}_{loc}\\), where N is the number density of dipoles and α is the polarizability. We also know that \\(\\vec{P} = \\epsilon_0\\chi \\vec{E} = \\epsilon_0(\\epsilon_r-1)\\vec{E}\\).\nSubstituting these equations and solving for \\(\\vec{P}\\):\n\\[\\vec{P} = N\\alpha(\\vec{E} - \\frac{\\vec{P}}{3\\epsilon_0})\\]\n\\[\\vec{P} + \\frac{N\\alpha \\vec{P}}{3\\epsilon_0} = N\\alpha \\vec{E}\\]\n\\[\\vec{P}(1 + \\frac{N\\alpha}{3\\epsilon_0}) = N\\alpha \\vec{E}\\]\nEquating the two expressions for \\(\\vec{P}\\):\n\\[\\epsilon_0(\\epsilon_r-1)\\vec{E} = \\frac{N\\alpha \\vec{E}}{1 + \\frac{N\\alpha}{3\\epsilon_0}}\\]\nSince this equation holds for any direction of \\(\\vec{E}\\), and assuming an isotropic medium, we obtain the scalar Clausius-Mossotti relation:\n\\[\\frac{\\epsilon_r-1}{\\epsilon_r+2} = \\frac{N\\alpha}{3\\epsilon_0}\\]\nThis relation provides a powerful link between microscopic polarizability and macroscopic dielectric properties, though it assumes the material is isotropic and the local field corrections are adequately described by the spherical cavity model.\n\n\nMagnetic Response of Materials\nSimilar principles apply to magnetic materials, though the physics differs due to the absence of magnetic monopoles. The magnetic flux density \\(\\vec{B}\\) relates to the magnetic field \\(\\vec{H}\\) through:\n\\[\n\\vec{B}=\\mu_0(1+\\chi_m)\\vec{H}\n\\]\nwhere \\(\\chi_m\\) is the magnetic susceptibility. Analogous to electric polarization, we define the magnetization \\(\\vec{M}\\) as the density of magnetic dipole moments:\n\\[\n\\vec{B}=\\mu_0(\\vec{H}+\\vec{M})\n\\]"
  },
  {
    "objectID": "electromagnetic-waves/EM Waves in Matter_old.html#maxwells-equations-in-matter",
    "href": "electromagnetic-waves/EM Waves in Matter_old.html#maxwells-equations-in-matter",
    "title": "Experimental Physics 3 Course on Optics and Quantum Mechanics",
    "section": "Maxwell’s Equations in Matter",
    "text": "Maxwell’s Equations in Matter\nMaxwell’s equations in materials take a modified form to account for the material’s response to electromagnetic fields. The four fundamental equations become:\n\\[\n\\nabla \\times \\vec{E}=-\\frac{\\partial \\vec{B}}{\\partial t}\n\\tag{ME.1}\n\\]\nFaraday’s law of induction remains unchanged from its vacuum form.\n\\[\n\\nabla\\cdot\\vec{D}=\\rho_f\n\\tag{ME.2}\n\\]\nGauss’s law now involves the displacement field \\(\\vec{D}\\) and only free charges \\(\\rho_f\\).\n\\[\n\\nabla\\times \\vec{H}=\\frac{\\partial \\vec{D}}{\\partial t}+\\vec{j}_f\n\\tag{ME.3}\n\\]\nAmpère’s law includes both the displacement current \\(\\frac{\\partial \\vec{D}}{\\partial t}\\) and free current density \\(\\vec{j}_f\\).\n\\[\n\\nabla\\cdot \\vec{B}=0\n\\tag{ME.4}\n\\]\nThe absence of magnetic monopoles remains a fundamental principle.\nThe material properties enter through the constitutive relations:\n\\[\\begin{eqnarray}\n\\vec{D}&=&\\epsilon \\vec{E}=\\epsilon_0 \\epsilon_r\\vec{E}\\\\\n\\vec{B}&=&\\mu \\vec{H}=\\mu_0 \\mu_r\\vec{H}\n\\end{eqnarray}\\]\n\nWave Propagation in Matter\nFor media without free charges (\\(\\rho_f=0\\)) and currents (\\(\\vec{j}_f=0\\)), these equations lead to the wave equation:\n\\[\n\\frac{\\partial^2 \\vec{E}}{\\partial \\vec{r}^2}-\\frac{1}{v^2} \\frac{\\partial^2\\vec{E}}{\\partial t^2}=0\n\\]\nwhere the phase velocity \\(v\\) is:\n\\[\nv=\\frac{c}{\\sqrt{\\epsilon_r\\mu_r}}\n\\]\nThis shows that electromagnetic waves travel more slowly in matter than in vacuum. For non-magnetic materials (\\(\\mu_r=1\\)), we define the refractive index:\n\\[\nn=\\frac{c}{v}=\\sqrt{\\epsilon_r}\n\\tag{refractive index}\n\\]\nThis connects our microscopic understanding of atomic polarization to the macroscopic phenomenon of light propagation in matter.\n\n\nSpecial Case: Negative Refraction\nWhile most materials have \\(n&gt;1\\), materials with both \\(\\epsilon_r&lt;0\\) and \\(\\mu_r&lt;0\\) exhibit the unusual property of negative refraction, where:\n\\[\nv=-\\frac{c}{\\sqrt{\\epsilon_r\\mu_r}}\n\\tag{negative refraction}\n\\]\nSuch metamaterials, engineered with specific substructures, enable novel optical phenomena and applications.\n\n\n\n\n\n\nFigure 3: Refraction: Diagrams of (a) positive refraction and (b) negative refraction; and calculated images of a metal rod (c) in a glass filled with regular water (\\(n = 1.3\\)), and (d) in a glass filled with “negative-index water” (\\(n = -1.3\\)). In parts a and b, solid lines with arrows indicate the direction of the energy flows, broken lines with arrows show the direction of the wave vectors. (Parts c and d from G. Dolling et al., Photorealistic images of objects in effective negative-index materials, Opt. Express, 14:1842–1849, 2006).\n\n\n\nThe Poynting vector describes the energy flow in electromagnetic waves, representing power per unit area. For any electromagnetic wave, we can calculate this energy flow as the cross product of the electric and magnetic fields:\n\\[ \\mathbf{S} = \\mathbf{E} \\times \\mathbf{H} \\]\nwhere \\(\\mathbf{H}\\) relates to the magnetic field \\(\\mathbf{B}\\) through the material’s permeability: \\(\\mathbf{B} = \\mu \\mathbf{H}\\). In negative refractive index materials, both the permittivity and permeability are negative, leading to \\(\\mathbf{H}\\) pointing opposite to \\(\\mathbf{B}\\).\nFor a plane wave, the magnetic field relates to the electric field through \\(\\mathbf{B} = \\frac{1}{\\omega} \\mathbf{k} \\times \\mathbf{E}\\), allowing us to express \\(\\mathbf{H}\\) as:\n\\[ \\mathbf{H} = \\frac{1}{\\mu \\omega} \\mathbf{k} \\times \\mathbf{E} \\]\nInserting this into our expression for the Poynting vector and using the vector triple product identity, we find:\n\\[ \\mathbf{S} = \\frac{1}{\\mu \\omega} \\left[ \\mathbf{k} (\\mathbf{E} \\cdot \\mathbf{E}) - \\mathbf{E} (\\mathbf{E} \\cdot \\mathbf{k}) \\right] \\]\nSince the electric field is perpendicular to the wave vector in a plane wave (\\(\\mathbf{E} \\cdot \\mathbf{k} = 0\\)), this simplifies to:\n\\[ \\mathbf{S} = \\frac{1}{\\mu \\omega} \\mathbf{k} E_0^2 \\]\nIn negative index materials, where \\(\\mathbf{k} = -k \\hat{\\mathbf{k}}\\), the Poynting vector becomes:\n\\[ \\mathbf{S} = -\\frac{k E_0^2}{\\mu \\omega} \\hat{\\mathbf{k}} \\]\nThis remarkable result shows that energy flows in the direction opposite to the wave propagation, a unique characteristic of negative index materials that leads to their unusual optical properties.\n\n\n\n\n\n\nFigure 4: Metamaterial with negative refraction. Smith, D. R., et al. (2004). Metamaterials and Negative Refractive Index. Science, 305(5685), 788-792.\n\n\n\nThe concept of negative refractive index was first theorized by Victor Veselago in 1968. He predicted that materials with simultaneous negative permittivity and permeability would exhibit unique optical properties such as reversed Snell’s law, reversed Doppler effect, and reversed Cherenkov radiation.\nVeselago, V. G. (1968). The Electrodynamics of Substances with Simultaneously Negative Values of $\\epsilon$ and $\\mu$. *Soviet Physics Uspekhi*, 10(4), 509-514.\nPendry, J. B. (2000). Negative Refraction Makes a Perfect Lens. *Physical Review Letters*, 85(18), 3966-3969.\n\n\nWave Properties\nFor monochromatic waves of the form:\n\\[\n\\vec{E}=\\vec{E}_0e^{i(\\omega t- \\vec{k}\\cdot \\vec{r})}\n\\]\nthe wavevector \\(\\vec{k}\\) relates to the vacuum wavevector \\(\\vec{k}_0\\) through:\n\\[\n\\vec{k}=n\\vec{k}_0\n\\]\nThis relationship determines how waves propagate and refract at material interfaces."
  },
  {
    "objectID": "electromagnetic-waves/EM Waves in Matter.html",
    "href": "electromagnetic-waves/EM Waves in Matter.html",
    "title": "Electromagnetic Waves in Matter",
    "section": "",
    "text": "The behavior of electromagnetic waves changes dramatically when they propagate through materials rather than vacuum. This interaction between light and matter underlies numerous phenomena in our daily lives, from the colors we see to modern optical technologies. Understanding these interactions requires bridging two perspectives: the microscopic view of how individual atoms respond to electromagnetic fields, and the macroscopic description of wave propagation through bulk materials.",
    "crumbs": [
      "Electromagnetic Optics",
      "Lecture 14",
      "Waves in Matter"
    ]
  },
  {
    "objectID": "electromagnetic-waves/EM Waves in Matter.html#microscopic-picture-of-dielectric-response",
    "href": "electromagnetic-waves/EM Waves in Matter.html#microscopic-picture-of-dielectric-response",
    "title": "Electromagnetic Waves in Matter",
    "section": "Microscopic Picture of Dielectric Response",
    "text": "Microscopic Picture of Dielectric Response\n\nSingle Atom Response\nTo understand how materials respond to electromagnetic waves, let’s first examine how individual atoms become polarized in an electric field. Our model atom consists of:\n\nAn electron charge \\(-q\\) uniformly distributed in a spherical cloud of radius \\(a\\)\nA positive nucleus at the center of this negative charge distribution\n\nThe charge density of the electron cloud is:\n\\[\n\\rho=\\frac{-q}{\\frac{4}{3}\\pi a^{3}}=-\\frac{3q}{4\\pi a^3}\n\\]\nThis configuration creates a radial electric field inside the cloud:\n\\[\n\\vec{E}(r)=-\\frac{1}{4\\pi\\epsilon_0}\\frac{q}{a^3}\\vec{r}\n\\]\nwhere \\(\\vec{r}\\) is the position vector from the center. The linear dependence on \\(\\vec{r}\\) creates a restoring force similar to a spring.\n\n\n\n\n\n\nFigure 1— Polarization of an electric cloud of an atom: An external electric field displaces the positive nucleus relative to the negative electron cloud, creating an induced dipole moment.\n\n\n\n\n\nAtomic Polarizability\nWhen we apply an external electric field \\(\\vec{E}_{\\rm ex}\\), the nucleus is displaced by a distance \\(\\vec{d}\\) until forces balance:\n\\[\nq\\vec{E}_{\\rm ex}-\\frac{1}{4\\pi\\epsilon_0}\\frac{q^2\\vec{d}}{a^3}=\\vec{0}\n\\]\nThis force balance between the external field (pushing the nucleus) and the internal field (trying to restore the nucleus to the center) determines the atomic polarization, leading to the displacement:\n\\[\n\\vec{d}=4\\pi \\epsilon_0 a^3 \\frac{\\vec{E}_{\\rm ex}}{q}\n\\]\nThis displacement creates a dipole moment:\n\\[\n\\vec{p}=q\\vec{d}=4\\pi\\epsilon_0 a^3 \\vec{E}_{\\rm ex}\n\\]\nThe dipole moment increases linearly with the external field, with the proportionality constant:\n\\[\n\\alpha=4\\pi \\epsilon_0 a^3\n\\]\nknown as the electronic polarizability. Note that this polarizability scales with atomic volume.\n\n\nFrom Single Atoms to Collective Response\nWhen many atoms in a material are exposed to an electric field, their individual dipole moments combine to create a macroscopic polarization. The collective behavior can be characterized by the polarization density:\n\\[\n\\vec{P}=N\\vec{p}\n\\]\nwhere \\(N\\) is the number of dipoles per unit volume and \\(\\vec{p}\\) is the individual atomic dipole moment. However, this simple picture of independent atoms needs modification for dense materials where atoms are closely packed and interact with each other.\nIn real materials, each atom experiences not only the external field but also the fields from neighboring dipoles. This leads us to consider the local field effects and the transition from microscopic to macroscopic descriptions, which we’ll explore in the next section.",
    "crumbs": [
      "Electromagnetic Optics",
      "Lecture 14",
      "Waves in Matter"
    ]
  },
  {
    "objectID": "electromagnetic-waves/EM Waves in Matter.html#macroscopic-description-of-dielectric-materials",
    "href": "electromagnetic-waves/EM Waves in Matter.html#macroscopic-description-of-dielectric-materials",
    "title": "Electromagnetic Waves in Matter",
    "section": "Macroscopic Description of Dielectric Materials",
    "text": "Macroscopic Description of Dielectric Materials\n\nPolarization Density and Surface Charges\nThe transition from microscopic to macroscopic behavior becomes apparent when we examine a sample of polarized material. For a cylindrical sample with cross-sectional area \\(A\\) and height \\(s\\), the microscopic dipoles create observable macroscopic effects:\n\n\n\n\n\n\nFigure 2— Polarization in a dielectric material showing aligned atomic dipoles and resulting surface charges.\n\n\n\nThis alignment leads to:\n\nTotal dipole moment: \\(\\vec{p}_{\\rm cyl}=A s \\vec{P}\\)\nEnd charges: \\(q_{\\rm end}=\\frac{p_{\\rm cyl}}{s}=A P\\)\nSurface charge density: \\(\\sigma=\\frac{q_{\\rm end}}{A}=P\\)\n\nMore generally, the surface charge density at any boundary is:\n\\[\n\\sigma_b=\\vec{P}\\cdot\\hat{n}\n\\]\nwhere \\(\\hat{n}\\) is the surface normal. These surface charges are “bound” to atoms, distinct from free charges.\n\n\nVolume Charge Density\nWhen polarization isn’t uniform throughout a material, we need to consider both surface and volume charges. All bound charges in the material must sum to zero since the material was initially neutral:\n\\[\\int \\sigma_b dA +\\int \\rho_b dv=0\\]\nUsing the surface charge relation \\(\\sigma_b=\\vec{P}\\cdot\\hat{n}\\), we can write:\n\\[\\int \\sigma_b dA = \\int \\vec{P}\\cdot\\hat{n}dA = \\int \\vec{P}\\cdot d\\vec{A}\\]\nApplying Gauss’s theorem:\n\\[\\int \\vec{P}\\cdot d\\vec{A} = \\int (\\nabla\\cdot\\vec{P})dv\\]\nThis leads to the local relationship:\n\\[\\rho_b = -\\nabla\\cdot\\vec{P}\\]\nThis fundamental equation reveals that bound volume charges appear wherever the polarization has a divergence - that is, wherever it changes spatially in a way that creates an imbalance of positive and negative charges.\n\n\nElectric Displacement Field\nIn materials, the electric field’s divergence must account for both free charges and bound charges:\n\\[\n\\nabla \\cdot \\vec{E}=\\frac{\\rho_{\\rm f}+\\rho_{\\rm b}}{\\epsilon_0}\n\\]\nUsing \\(\\rho_b=-\\nabla\\cdot \\vec{P}\\):\n\\[\n\\nabla \\cdot \\vec{E}=\\frac{\\rho_{\\rm f}-\\nabla\\cdot \\vec{P}}{\\epsilon_0}\n\\]\nThis suggests defining the electric displacement field:\n\\[\n\\vec{D}=\\epsilon_0 \\vec{E}+\\vec{P}\n\\]\nwhich simplifies Gauss’s law to:\n\\[\n\\nabla \\cdot \\vec{D} =\\rho_f\n\\]\nThis is beautiful, since it brings back the same dependence on free charges as in vacuum, but now with the displacement field \\(\\vec{D}\\) instead of the electric field \\(\\vec{E}\\).\n\n\nLinear Dielectric Response\nFor many materials, the polarization density is proportional to the applied electric field:\n\\[\n\\vec{P}=\\epsilon_0\\chi\\vec{E}\n\\]\nwhere \\(\\chi\\) is the electric susceptibility. This linear relationship defines linear dielectric materials, though real materials can exhibit nonlinear responses under strong fields.\nThe displacement field becomes:\n\\[\n\\vec{D}=\\epsilon_0 \\vec{E}+\\vec{P}=\\epsilon_0 (1+\\chi)\\vec{E}=\\epsilon \\vec{E}\n\\]\nwith electric permittivity:\n\\[\n\\epsilon=\\epsilon_0 (1+\\chi)\n\\tag{electric permittivity}\n\\]\nThe dimensionless ratio:\n\\[\n\\epsilon_r=\\frac{\\epsilon}{\\epsilon_0}=1+\\chi\n\\]\nis the relative permittivity or dielectric constant, though it typically depends on frequency.\n\n\nClausius-Mossotti Relation\nIn dense materials, the local electric field \\(\\vec{E}_{loc}\\) experienced by an atom differs from the average field \\(\\vec{E}\\):\n\\[\\vec{E}_{loc} = \\vec{E} + \\vec{E}_{dep}\\]\nwhere \\(\\vec{E}_{dep} = -\\frac{\\vec{P}}{3\\epsilon_0}\\) is the depolarization field from the cavity surface charges.\nThe polarization density relates to the local field through:\n\\[\\vec{P} = N\\alpha \\vec{E}_{loc} = N\\alpha(\\vec{E} - \\frac{\\vec{P}}{3\\epsilon_0})\\]\nSolving this equation and comparing with \\(\\vec{P} = \\epsilon_0(\\epsilon_r-1)\\vec{E}\\) yields the Clausius-Mossotti relation:\n\\[\\frac{\\epsilon_r-1}{\\epsilon_r+2} = \\frac{N\\alpha}{3\\epsilon_0}\\]\nThis fundamental relation connects microscopic polarizability to macroscopic permittivity, accounting for local field effects in dense media.",
    "crumbs": [
      "Electromagnetic Optics",
      "Lecture 14",
      "Waves in Matter"
    ]
  },
  {
    "objectID": "electromagnetic-waves/EM Waves in Matter.html#maxwells-equations-in-matter",
    "href": "electromagnetic-waves/EM Waves in Matter.html#maxwells-equations-in-matter",
    "title": "Electromagnetic Waves in Matter",
    "section": "Maxwell’s Equations in Matter",
    "text": "Maxwell’s Equations in Matter\nThe presence of bound charges and currents in materials requires a modified form of Maxwell’s equations. The four fundamental equations become:\n\\[\n\\nabla \\times \\vec{E}=-\\frac{\\partial \\vec{B}}{\\partial t}\n\\tag{ME.1}\n\\]\nFaraday’s law remains unchanged, describing electromagnetic induction regardless of medium.\n\\[\n\\nabla\\cdot\\vec{D}=\\rho_f\n\\tag{ME.2}\n\\]\nGauss’s law now involves the displacement field \\(\\vec{D}\\) and only free charges \\(\\rho_f\\).\n\\[\n\\nabla\\times \\vec{H}=\\frac{\\partial \\vec{D}}{\\partial t}+\\vec{j}_f\n\\tag{ME.3}\n\\]\nAmpère’s law includes both the displacement current \\(\\frac{\\partial \\vec{D}}{\\partial t}\\) and free current density \\(\\vec{j}_f\\).\n\\[\n\\nabla\\cdot \\vec{B}=0\n\\tag{ME.4}\n\\]\nThe absence of magnetic monopoles remains fundamental. The material properties enter through the constitutive relations:\n\\[\\begin{eqnarray}\n\\vec{D}&=&\\epsilon \\vec{E}=\\epsilon_0 \\epsilon_r\\vec{E}\\\\\n\\vec{B}&=&\\mu \\vec{H}=\\mu_0 \\mu_r\\vec{H}\n\\end{eqnarray}\\]\nSimilar to electric polarization, materials respond to magnetic fields through magnetization \\(\\vec{M}\\):\n\\[\n\\vec{B}=\\mu_0(\\vec{H}+\\vec{M})\n\\]\nFor linear magnetic materials:\n\\[\n\\vec{B}=\\mu_0(1+\\chi_m)\\vec{H}\n\\]\nwhere \\(\\chi_m\\) is the magnetic susceptibility.",
    "crumbs": [
      "Electromagnetic Optics",
      "Lecture 14",
      "Waves in Matter"
    ]
  },
  {
    "objectID": "electromagnetic-waves/EM Waves in Matter.html#wave-propagation-in-non-conducting-matter",
    "href": "electromagnetic-waves/EM Waves in Matter.html#wave-propagation-in-non-conducting-matter",
    "title": "Electromagnetic Waves in Matter",
    "section": "Wave Propagation in Non-conducting Matter",
    "text": "Wave Propagation in Non-conducting Matter\nFor isotropic media without free charges (\\(\\rho_f=0\\)) and currents (\\(\\vec{j}_f=0\\)), Maxwell’s equations lead to the wave equation:\n\\[\n\\nabla^2\\vec{E}-\\frac{1}{v^2} \\frac{\\partial^2\\vec{E}}{\\partial t^2}=0\n\\]\nwhere the phase velocity is:\n\\[\nv=\\frac{c}{\\sqrt{\\epsilon_r\\mu_r}}\n\\]\nFor non-magnetic materials (\\(\\mu_r=1\\)), we define the refractive index:\n\\[\nn=\\frac{c}{v}=\\sqrt{\\epsilon_r}\n\\tag{refractive index}\n\\]\nThis fundamental relation connects our microscopic understanding of atomic polarization to the macroscopic phenomenon of light propagation. In a later section we will provide a more detailed discussion of the microscopic origins of the refractive index. Monochromatic waves in matter take the form:\n\\[\n\\vec{E}=\\vec{E}_0e^{i(\\omega t- \\vec{k}\\cdot \\vec{r})}\n\\]\nThe wavevector \\(\\vec{k}\\) relates to the vacuum wavevector \\(\\vec{k}_0\\) through:\n\\[\n\\vec{k}=n\\vec{k}_0\n\\]\nWhen electromagnetic waves enter a material, their wavelength changes while the frequency remains constant. This is because:\n\\[\n\\lambda = \\frac{\\lambda_0}{n}\n\\]\nwhere \\(\\lambda_0\\) is the vacuum wavelength. The wave frequency \\(\\omega\\) remains unchanged:\n\\[\n\\omega = \\frac{2\\pi c}{\\lambda_0} = \\frac{2\\pi v}{\\lambda}\n\\]",
    "crumbs": [
      "Electromagnetic Optics",
      "Lecture 14",
      "Waves in Matter"
    ]
  },
  {
    "objectID": "electromagnetic-waves/EM Waves in Matter.html#special-cases",
    "href": "electromagnetic-waves/EM Waves in Matter.html#special-cases",
    "title": "Electromagnetic Waves in Matter",
    "section": "Special Cases",
    "text": "Special Cases\n\nNegative Refraction\nWhile most materials have \\(n&gt;1\\), a remarkable class of engineered materials called metamaterials can exhibit negative refraction when both \\(\\epsilon_r&lt;0\\) and \\(\\mu_r&lt;0\\). In these materials:\n\\[\nv=-\\frac{c}{\\sqrt{\\epsilon_r\\mu_r}}\n\\tag{negative refraction}\n\\]\n\n\n\n\n\n\nFigure 3— Refraction: Diagrams of (a) positive refraction and (b) negative refraction; and calculated images of a metal rod (c) in a glass filled with regular water (\\(n = 1.3\\)), and (d) in a glass filled with “negative-index water” (\\(n = -1.3\\)). In parts a and b, solid lines with arrows indicate the direction of the energy flows, broken lines with arrows show the direction of the wave vectors. (Parts c and d from G. Dolling et al., Opt. Express, 14:1842–1849, 2006).\n\n\n\n\n\nEnergy Flow in Negative Index Materials\nThe Poynting vector describes energy flow in electromagnetic waves:\n\\[ \\vec{S} = \\vec{E} \\times \\vec{H} \\]\nwhere \\(\\vec{H}\\) relates to \\(\\vec{B}\\) through \\(\\vec{B} = \\mu \\vec{H}\\). In negative index materials, both permittivity and permeability are negative, leading to unusual behavior.\nFor a plane wave, \\(\\vec{B} = \\frac{1}{\\omega} \\vec{k} \\times \\vec{E}\\), giving:\n\\[ \\vec{H} = \\frac{1}{\\mu \\omega} \\vec{k} \\times \\vec{E} \\]\nUsing the vector triple product identity:\n\\[ \\vec{S} = \\frac{1}{\\mu \\omega} \\left[ \\vec{k} (\\vec{E} \\cdot \\vec{E}) - \\vec{E} (\\vec{E} \\cdot \\vec{k}) \\right] \\]\nSince \\(\\vec{E} \\cdot \\vec{k} = 0\\) in a plane wave:\n\\[ \\vec{S} = \\frac{1}{\\mu \\omega} \\vec{k} E_0^2 \\]\nIn negative index materials (\\(\\vec{k} = -k \\hat{\\vec{k}}\\)):\n\\[ \\vec{S} = -\\frac{k E_0^2}{\\mu \\omega} \\hat{\\vec{k}} \\]\nThis remarkable result shows that energy flows opposite to wave propagation, a unique characteristic of negative index materials.\n\n\nMetamaterial Realization\n\n\n\n\n\n\nFigure 4— Metamaterial with negative refraction. Split-ring resonators provide negative permeability while metallic wires provide negative permittivity. Smith, D. R., et al. (2004). Science, 305(5685), 788-792.\n\n\n\n\n\n\n\n\n\nSplit-Ring Resonators (SRRs)\n\n\n\n\n\nA split-ring resonator typically consists of a pair of concentric metallic rings, each with a gap. These rings can be thought of as forming an LC circuit, where the rings themselves provide the inductance (\\(L\\)) and the gaps provide the capacitance (\\(C\\)).\n\nResonant Frequency of the SRR\nThe SRR behaves as an LC resonator with a specific resonant frequency (\\(\\omega_0\\)). The resonant frequency can be expressed as:\n\\[ \\omega_0 = \\frac{1}{\\sqrt{LC}} \\]\nwhere: - \\(L\\) is the inductance of the rings. - \\(C\\) is the capacitance of the gaps.\n\n\nMagnetic Response of the SRR\nWhen an external alternating magnetic field is applied perpendicular to the plane of the SRR, it induces a circulating current around the rings. This induced current creates a magnetic dipole moment that opposes the change in the external magnetic field (Lenz’s Law).\n\n\nMagnetic Susceptibility\nThe magnetic susceptibility (\\(\\chi_m\\)) of the SRR can be related to the magnetic moment (\\(m\\)) induced in response to the external magnetic field (\\(H\\)):\n\\[ m = \\alpha H \\]\nwhere \\(\\alpha\\) is the polarizability of the SRR. The susceptibility is given by:\n\\[ \\chi_m = \\frac{m}{H} = \\alpha \\]\n\n\nPolarizability of the SRR\nThe polarizability \\(\\alpha\\) can be modeled using the Lorentz oscillator model for the resonant behavior of the SRR. This gives:\n\\[ \\alpha(\\omega) = \\frac{F\\omega^2}{\\omega_0^2 - \\omega^2 - i\\gamma\\omega} \\]\nwhere: - \\(F\\) is a geometric factor related to the SRR. - \\(\\omega_0\\) is the resonant frequency. - \\(\\gamma\\) is the damping factor (related to losses). - \\(\\omega\\) is the angular frequency of the applied magnetic field.\n\n\nEffective Permeability\nThe effective permeability \\(\\mu(\\omega)\\) of the metamaterial containing SRRs can be expressed in terms of the magnetic susceptibility \\(\\chi_m(\\omega)\\):\n\\[ \\mu(\\omega) = 1 + \\chi_m(\\omega) \\]\nSubstituting \\(\\chi_m(\\omega)\\) with \\(\\alpha(\\omega)\\):\n\\[ \\mu(\\omega) = 1 + \\frac{F\\omega^2}{\\omega_0^2 - \\omega^2 - i\\gamma\\omega} \\]\nThis equation describes the frequency-dependent effective permeability of a metamaterial containing split-ring resonators.\n\n\nNegative Permeability\nFor negative permeability to occur, the term in the denominator \\((\\omega_0^2 - \\omega^2 - i\\gamma\\omega)\\) must be such that the real part of the permeability becomes negative. This generally happens in the frequency range around the resonant frequency \\(\\omega_0\\). Specifically, when \\(\\omega\\) is slightly below \\(\\omega_0\\), the real part of \\(\\mu(\\omega)\\) can become negative due to the resonance.\nThe final equation for the effective permeability of a metamaterial with split-ring resonators is:\n\\[ \\mu(\\omega) = 1 + \\frac{F\\omega^2}{\\omega_0^2 - \\omega^2 - i\\gamma\\omega} \\]\n\n\nInterpretation\n\nWhen \\(\\omega\\) is near \\(\\omega_0\\), the permeability \\(\\mu(\\omega)\\) can exhibit negative values.\nThe parameters \\(F\\), \\(\\omega_0\\), and \\(\\gamma\\) are determined by the geometry and material properties of the SRRs.\n\nThis equation highlights how the resonant properties of the SRRs lead to a negative permeability in the metamaterial, enabling unique electromagnetic properties such as a negative refractive index.\n\n\n\n\nThe concept of negative refractive index, first theorized by Victor Veselago in 1968, predicted materials with simultaneous negative permittivity and permeability would exhibit:\n\nReversed Snell’s law\nReversed Doppler effect\nReversed Cherenkov radiation\n\nModern realizations use carefully designed structures with:\n\nSplit-ring resonators for negative μ\nWire arrays for negative ε\nPrecise geometric arrangements to maintain wave propagation\n\nThese materials enable novel applications including:\n\nSuperlenses breaking the diffraction limit\nElectromagnetic cloaking\nNovel waveguiding devices\n\nThe concept of negative refractive index was first theorized by Veselago (Veselago 1968). Later, Pendry showed how these materials could be used to create perfect lenses (Pendry 2000).",
    "crumbs": [
      "Electromagnetic Optics",
      "Lecture 14",
      "Waves in Matter"
    ]
  },
  {
    "objectID": "electromagnetic-waves/Reflection and Refraction.html",
    "href": "electromagnetic-waves/Reflection and Refraction.html",
    "title": "Reflection and Refraction of Electromagnetic Waves",
    "section": "",
    "text": "The effect of the material on the wave propagation can be understood when considering a plane wave \\(E_s\\) incident on a thin material slab of thickness \\(\\Delta z\\).\n\\[\n\\begin{aligned}\nE & =E_0 \\cdot e^{-i(\\omega t-k z-(n-1) k \\cdot \\Delta z)} \\\\\n& =E_0 e^{-i(n-1) k \\Delta z} e^{i(\\omega t-k z)} \\\\\n& =e^{-i \\theta} E_s \\quad \\text { with } \\theta=k(n-1) \\Delta z\n\\end{aligned}\n\\tag{1}\\]\nFor small values of \\(\\theta\\) the exponential function can be approximated by\n\\[e^x \\sim 1+x+\\frac{x^2}{2} \\tag{2}\\]\nsuch that we obtain\n\\[e^{-i k(n-1) \\Delta z} \\approx 1-i k(n-1) \\Delta z-\\frac{k^2(n-1)^2 \\Delta z^2}{2} \\tag{3}\\]\nThe total field behind the thin slab therefore is\n\\[E(z)=\\underbrace{E_0 e^{i(\\omega t-k z)}}_{E_e}-\\underbrace{i k(n-1) \\Delta z E_0 e^{i(\\omega t-k z)}}_{E_{\\text {medium}}} \\tag{4}\\]\nAs shown in Figure 1, the resulting wave is delayed by a phase factor \\(k(n-1) \\Delta z\\) (see Equation 1) and the amplitude is reduced by a factor \\(k(n-1) \\Delta z\\).\n\n\nCode\n# Parameters\nE0 = 1.0  # Initial amplitude\nk = 2*np.pi  # Wave number\nn = 1.5  # Refractive index\ndz = 0.1  # Thickness of slab\nomega = 2*np.pi  # Angular frequency\nt = 0  # Fixed time point\n\n# Spatial grid\nz = np.linspace(0, 2, 1000)\n\n# Calculate components\nE_vacuum = E0 * np.exp(1j*(omega*t - k*z))\nE_medium = -1j * k * (n-1) * dz * E0 * np.exp(1j*(omega*t - k*z))\nE_total = E_vacuum + E_medium\n\n# Create figure\nfig, ax1 = plt.subplots(1, 1, figsize=get_size(12, 8))\n\n# Plot real parts\nax1.plot(z, E_vacuum.real, 'b-', label='Incident', alpha=0.7)\nax1.plot(z, E_medium.real, 'r-', label='Medium', alpha=0.7)\nax1.plot(z, E_total.real, 'g-.', label='Total', alpha=0.7)\nax1.set_xlabel('position (z)')\nax1.set_ylabel('Re[E(z)]')\nax1.legend()\n\nplt.show()\n\n\n\n\n\n\n\n\nFigure 1— Components of the electric field in medium",
    "crumbs": [
      "Electromagnetic Optics",
      "Lecture 15",
      "Reflection and Refraction"
    ]
  },
  {
    "objectID": "electromagnetic-waves/Reflection and Refraction.html#effect-of-the-refractive-index",
    "href": "electromagnetic-waves/Reflection and Refraction.html#effect-of-the-refractive-index",
    "title": "Reflection and Refraction of Electromagnetic Waves",
    "section": "",
    "text": "The effect of the material on the wave propagation can be understood when considering a plane wave \\(E_s\\) incident on a thin material slab of thickness \\(\\Delta z\\).\n\\[\n\\begin{aligned}\nE & =E_0 \\cdot e^{-i(\\omega t-k z-(n-1) k \\cdot \\Delta z)} \\\\\n& =E_0 e^{-i(n-1) k \\Delta z} e^{i(\\omega t-k z)} \\\\\n& =e^{-i \\theta} E_s \\quad \\text { with } \\theta=k(n-1) \\Delta z\n\\end{aligned}\n\\tag{1}\\]\nFor small values of \\(\\theta\\) the exponential function can be approximated by\n\\[e^x \\sim 1+x+\\frac{x^2}{2} \\tag{2}\\]\nsuch that we obtain\n\\[e^{-i k(n-1) \\Delta z} \\approx 1-i k(n-1) \\Delta z-\\frac{k^2(n-1)^2 \\Delta z^2}{2} \\tag{3}\\]\nThe total field behind the thin slab therefore is\n\\[E(z)=\\underbrace{E_0 e^{i(\\omega t-k z)}}_{E_e}-\\underbrace{i k(n-1) \\Delta z E_0 e^{i(\\omega t-k z)}}_{E_{\\text {medium}}} \\tag{4}\\]\nAs shown in Figure 1, the resulting wave is delayed by a phase factor \\(k(n-1) \\Delta z\\) (see Equation 1) and the amplitude is reduced by a factor \\(k(n-1) \\Delta z\\).\n\n\nCode\n# Parameters\nE0 = 1.0  # Initial amplitude\nk = 2*np.pi  # Wave number\nn = 1.5  # Refractive index\ndz = 0.1  # Thickness of slab\nomega = 2*np.pi  # Angular frequency\nt = 0  # Fixed time point\n\n# Spatial grid\nz = np.linspace(0, 2, 1000)\n\n# Calculate components\nE_vacuum = E0 * np.exp(1j*(omega*t - k*z))\nE_medium = -1j * k * (n-1) * dz * E0 * np.exp(1j*(omega*t - k*z))\nE_total = E_vacuum + E_medium\n\n# Create figure\nfig, ax1 = plt.subplots(1, 1, figsize=get_size(12, 8))\n\n# Plot real parts\nax1.plot(z, E_vacuum.real, 'b-', label='Incident', alpha=0.7)\nax1.plot(z, E_medium.real, 'r-', label='Medium', alpha=0.7)\nax1.plot(z, E_total.real, 'g-.', label='Total', alpha=0.7)\nax1.set_xlabel('position (z)')\nax1.set_ylabel('Re[E(z)]')\nax1.legend()\n\nplt.show()\n\n\n\n\n\n\n\n\nFigure 1— Components of the electric field in medium",
    "crumbs": [
      "Electromagnetic Optics",
      "Lecture 15",
      "Reflection and Refraction"
    ]
  },
  {
    "objectID": "electromagnetic-waves/Reflection and Refraction.html#general-description-of-reflection-and-refraction",
    "href": "electromagnetic-waves/Reflection and Refraction.html#general-description-of-reflection-and-refraction",
    "title": "Reflection and Refraction of Electromagnetic Waves",
    "section": "General Description of Reflection and Refraction",
    "text": "General Description of Reflection and Refraction\nBefore we examine the behavior of electromagnetic waves at boundaries, we need to define the geometry and examine the electric and magnetic fields present. Figure 2 shows the wavevectors of the incident \\(\\vec{k}_I\\), reflected \\(\\vec{k}_R\\) and transmitted \\(\\vec{k}_T\\) waves in the two materials with the refractive indices \\(n_1\\) and \\(n_2\\).\n\n\n\n\n\n\nFigure 2— Reflection and refraction of an electromagnetic wave at a boundary.\n\n\n\nThese wavevectors are connected to the following plane waves:\n\\[\n\\vec{E}_{ inc}=\\vec{E}_I e^{i(\\omega_I t -\\vec{k}_I\\cdot \\vec{r})}\n\\tag{5}\\]\n\\[\n\\vec{E}_{ ref}=\\vec{E}_R e^{i(\\omega_R t -\\vec{k}_R\\cdot \\vec{r})}\n\\tag{6}\\]\n\\[\n\\vec{E}_{ tra}=\\vec{E}_T e^{i(\\omega_T t -\\vec{k}_T\\cdot \\vec{r})}\n\\tag{7}\\]\nAs discussed in Equation 5 through Equation 7, we must consider the direction of polarization of their electric or magnetic fields. We differentiate between:\n\np-polarized light: electric field is in the plane of incidence (given by the \\(k\\)-vector and the surface normal), also called transverse magnetic (TM)\ns-polarized light: electric field is perpendicular to the plane of incidence, also called transverse electric (TE)\n\n\n\n\n\n\n\nFigure 3— Decomposition of the incident electric field into components normal and tangential to the dielectric boundary.\n\n\n\nAs shown in Figure 3 , we need to split these polarisation vectors into components that are parallel (\\(||\\)) or perpendicular (\\(\\perp\\)) to the interface. This is required for applying boundary conditions for the electric and magnetic fields.\n\nBoundary Conditions\nThe boundary conditions for the electric or magnetic field passing an interface are derived from the Maxwell equations.\n\n\n\n\n\n\nFigure 4— Integration over a closed surface (left) and close path (right) to obtain the boundary conditions for the electric field components.\n\n\n\nLet us take the divergence of the displacement field \\(\\nabla \\cdot \\vec{D}=\\rho_f\\) which is equal to the density of free charges. When integrating both sides over the volume:\n\\[\n\\int\\nabla \\vec{D} dV=\\int \\rho_f dV\n\\tag{8}\\]\nwe can apply Gauss’ theorem and replace the volume integral over the divergence with an integral over closed surface of that volume:\n\\[\n\\oint \\vec{D} d\\vec{A}= q_f\n\\tag{9}\\]\nwhere \\(d\\vec{A}\\) is a vector standing perpendicular on the surface element \\(dA\\) and \\(q_f\\) are the free charges in the volume. When we consider a pillbox-shaped volume straddling the interface between two materials, the surface integral can be broken down into three parts:\n\nTop surface (in material 1)\nBottom surface (in material 2)\nSide surface (cylindrical part)\n\nThe total surface integral becomes:\n\\[\n\\oint \\vec{D} \\cdot d\\vec{A} = \\int_{\\text{top}} \\vec{D}_1 \\cdot d\\vec{A} + \\int_{\\text{bottom}} \\vec{D}_2 \\cdot d\\vec{A} + \\int_{\\text{side}} \\vec{D} \\cdot d\\vec{A}\n\\]\nFor a pillbox of height \\(h\\) and radius \\(r\\):\n\nThe top surface contributes: \\(\\vec{D}_1 \\cdot \\hat{n}A\\) (negative because \\(d\\vec{A}\\) points along \\(\\hat{n}\\))\nThe bottom surface contributes: \\(-\\vec{D}_2 \\cdot \\hat{n}A\\)\nThe side surface contribution goes to zero as \\(h \\to 0\\) (as area \\(\\sim 2\\pi rh\\))\n\nTherefore:\n\\[\n\\oint \\vec{D} \\cdot d\\vec{A} = A(\\vec{D}_1 - \\vec{D}_2) \\cdot \\hat{n} = q_f\n\\]\nKey Points\n\nThe side surface contribution vanishes as \\(h \\to 0\\) because:\n\nIts area scales with \\(h\\) (\\(2\\pi rh\\))\nThe field components remain finite\n\nOnly the normal components of \\(\\vec{D}\\) contribute because:\n\n\\(d\\vec{A}\\) is parallel to \\(\\hat{n}\\) for top and bottom surfaces\nThe tangential components don’t contribute to the dot product\n\nThe ratio \\(q_f/A\\) becomes the surface charge density \\(\\sigma_f\\) as \\(h \\to 0\\)\n\nFollowing that, we obtain the boundary condition for the normal component of the displacement field:\n\\[\nD_{1\\perp}=D_{1\\perp}\n\\tag{10}\\]\nThis implies a jump in the normal electric field component:\n\\[\n\\frac{E_{1\\perp}}{E_{2\\perp}}=\\frac{\\epsilon_2}{\\epsilon_1}\n\\tag{11}\\]\nas \\(D=\\epsilon E\\). Another boundary condition arises from the curl of the electric field. Using the Maxwell equation:\n\\[\n\\nabla \\times \\vec{E}=-\\frac{\\partial \\vec{B}}{\\partial t}\n\\tag{12}\\]\nIntegrating both sides over an area and applying Stokes theorem:\n\\[\n\\oint \\vec{E} d\\vec{l}=-\\frac{\\partial}{\\partial t}\\int \\vec{B}d\\vec{A}\n\\tag{13}\\]\nConsider a rectangular loop straddling the interface between two media, with a height \\(h\\) a width \\(w\\) and a normal to the interface \\(\\hat{n}\\) the line integral can be broken down into four parts:\n\nTop segment (in medium 1)\nBottom segment (in medium 2)\nTwo vertical segments connecting them\n\nThe line integral becomes:\n\\[\n\\oint \\vec{E} \\cdot d\\vec{l} = w\\vec{E}_1 \\cdot \\hat{t} - w\\vec{E}_2 \\cdot \\hat{t} + \\text{(vertical segments)}\n\\]\nwhere \\(\\hat{t}\\) is the unit vector tangent to the interface.\nAs \\(h \\to 0\\):\n\nThe contribution from vertical segments vanishes (as \\(h \\to 0\\))\nThe area of the loop approaches zero, making the right-hand side zero: \\[-\\frac{\\partial}{\\partial t}\\int \\vec{B}\\cdot d\\vec{A} \\to 0\\]\n\nTherefore:\n\\[\nw(\\vec{E}_1 - \\vec{E}_2) \\cdot \\hat{t} = 0\n\\]\nSince \\(w \\neq 0\\), this implies:\n\\[\n(\\vec{E}_1 - \\vec{E}_2) \\cdot \\hat{t} = 0\n\\]\nThis can be rewritten in terms of the cross product with the normal vector:\n\\[\n\\hat{n} \\times (\\vec{E}_2-\\vec{E}_1)=0\n\\tag{14}\\]\nTherefore:\n\\[\nE_{2||}=E_{1||}\n\\tag{15}\\]\nindicating that the tangential component of the electric field is conserved.\n\n\n\n\n\n\nBoundary Conditions for the Magnetic Field\n\n\n\n\n\nFor the magnetic field, we can derive boundary conditions using similar approaches. Starting with Ampère’s law:\n\\[\n\\nabla \\times \\vec{H}=\\vec{J}+\\frac{\\partial \\vec{D}}{\\partial t}\n\\]\nIntegrating over an area and applying Stokes’ theorem:\n\\[\n\\oint \\vec{H} \\cdot d\\vec{l}=\\int \\vec{J} \\cdot d\\vec{A}+\\frac{\\partial}{\\partial t}\\int \\vec{D} \\cdot d\\vec{A}\n\\]\nUsing the same rectangular loop approach as with the electric field, but now in the limit as \\(h \\to 0\\):\n\nThe area integral of the displacement current (\\(\\partial \\vec{D}/\\partial t\\)) vanishes\nThe surface current density \\(\\vec{K}=\\vec{J}dA\\) remains finite\n\nThis yields:\n\\[\n\\hat{n} \\times (\\vec{H}_2-\\vec{H}_1)=\\vec{K}\n\\]\nIn the absence of surface currents (\\(\\vec{K}=0\\)), we have:\n\\[\nH_{2||}=H_{1||}\n\\tag{16}\\]\nFor the normal component, starting from \\(\\nabla \\cdot \\vec{B}=0\\) and using the pillbox approach as with the electric field:\n\\[\n\\oint \\vec{B} \\cdot d\\vec{A}=0\n\\]\nThis leads directly to:\n\\[\nB_{1\\perp}=B_{2\\perp}\n\\tag{17}\\]\nSince \\(\\vec{B}=\\mu\\vec{H}\\), this implies a jump in the normal component of the H-field:\n\\[\n\\frac{H_{1\\perp}}{H_{2\\perp}}=\\frac{\\mu_2}{\\mu_1}\n\\tag{18}\\]\nThese boundary conditions for the magnetic field complement those for the electric field and are essential for determining the reflection and transmission coefficients at interfaces.\n\n\n\n\n\n\n\n\n\nSummary Boundary Conditions at an Interface\n\n\n\nFor a boundary between two media (1 and 2) with surface normal \\(\\hat{n}\\):\nElectric Field\n\nNormal component (with surface charge density \\(\\sigma_f\\)): \\[\\epsilon_1 E_{1\\perp} - \\epsilon_2 E_{2\\perp} = \\sigma_f\\]\nTangential component: \\[E_{1||} = E_{2||}\\]\n\nMagnetic Field\n\nNormal component: \\[B_{1\\perp} = B_{2\\perp}\\]\nTangential component (with surface current density \\(\\vec{K}\\)): \\[\\hat{n} \\times (\\vec{H}_2-\\vec{H}_1)=\\vec{K}\\]\n\nIn the absence of free charges (\\(\\sigma_f = 0\\)) and currents (\\(\\vec{K} = 0\\)), these reduce to:\n\n\\(\\epsilon_1 E_{1\\perp} = \\epsilon_2 E_{2\\perp}\\)\n\\(E_{1||} = E_{2||}\\)\n\\(B_{1\\perp} = B_{2\\perp}\\)\n\\(H_{1||} = H_{2||}\\)\n\n\n\n\n\nReflection/Refraction\n\nFrequency and Wavevector Matching\nReferring to Figure 5, we can explicitly write down the components of the wavevectors of the three waves in our coordinate system:\n\n\n\n\n\n\nFigure 5— Coordinate system for wave at interfaces.\n\n\n\nAccording to the coordinate system shown in Figure 5, we have:\n\\[\n\\begin{aligned}\n  \\vec{k}_I &=  k_I \\cos(\\theta_I)\\hat{e}_x+k_I \\sin(\\theta_I)\\hat{e}_z \\\\\n  \\vec{k}_R &=  -k_R \\cos(\\theta_R)\\hat{e}_x+k_R \\sin(\\theta_R)\\hat{e}_z \\\\\n  \\vec{k}_T &=  k_T \\cos(\\theta_T)\\hat{e}_x+k_T \\sin(\\theta_T)\\hat{e}_z\n\\end{aligned}\n\\tag{19}\\]\nNote that the component \\(\\hat{e}_x\\) always provides the wavevector component perpendicular to the interface, while \\(\\hat{e}_z\\) is the tangential (parallel) component. The total field on both sides is given by:\n\\[\n\\vec{E}=\\vec{E}_{inc}+\\vec{E}_{ref}\n\\quad \\text{(for } x&lt;0 \\text{)}\n\\tag{20}\\]\nand\n\\[\n\\vec{E}=\\vec{E}_{tra}\n\\quad \\text{(for } x&gt;0 \\text{)}\n\\tag{21}\\]\nFor these fields to match according to our previously described boundary conditions, we require:\n\\[\n\\omega_I=\\omega_R=\\omega_T\n\\tag{22}\\]\nThis frequency matching confirms our initial intuition. Along the interface, we also need phase matching of the waves as discussed in the wave optics chapter:\n\\[\n\\vec{k}_I\\cdot \\vec{r}=\\vec{k}_R\\cdot \\vec{r}=\\vec{k}_T\\cdot \\vec{r}\n\\tag{23}\\]\nat all positions \\(\\vec{r}\\) that belong to the interface (i.e., \\(x=0\\)). Therefore \\(\\vec{r}=\\lbrace 0,y,z \\rbrace\\) and the equalities yield:\n\\[\nk_I\\sin(\\theta_I)=k_R\\sin(\\theta_R)=k_T\\sin(\\theta_T)\n\\tag{24}\\]\nSince the magnitude of the wavevector of the incident and the reflected light is the same (both waves travel in the same material), we find:\n\\[\n\\theta_I=\\theta_R\n\\tag{25}\\]\nFor the incident and transmitted waves, we must account for the change in wavenumber:\n\\[\n\\begin{aligned}\nn_1 k_0\\sin(\\theta_I) &= n_2 k_0\\sin(\\theta_T) \\\\\nn_1 \\sin(\\theta_I) &= n_2 \\sin(\\theta_T)\n\\end{aligned}\n\\tag{26}\\]\nEquation 26 represents Snell’s law, which results from the conservation of the parallel component of the wavevector across an interface, while the normal component must have a jump according to the refractive indices.",
    "crumbs": [
      "Electromagnetic Optics",
      "Lecture 15",
      "Reflection and Refraction"
    ]
  },
  {
    "objectID": "electromagnetic-waves/Dispersion and Absorption Examples.html",
    "href": "electromagnetic-waves/Dispersion and Absorption Examples.html",
    "title": "Experimental Physics 3 Course on Optics and Quantum Mechanics",
    "section": "",
    "text": "### Example box: Abbe Refractometer\nThe Abbe refractometer provides a precise method for measuring refractive indices of liquids:\n\n1. Operating principle: Total internal reflection at critical angle\n2. Typical accuracy: ±0.0002\n3. Procedure:\n   - Place sample between prisms\n   - Adjust viewing angle until bright/dark boundary appears\n   - Read refractive index directly from scale\n4. Applications:\n   - Quality control in food/chemical industries\n   - Concentration measurements\n   - Purity testing\n\n\n\n### Example box: Prism Spectroscopy\nSimple but effective demonstration using:\n- White LED source\n- Glass prism\n- Screen\n\nObservations:\n1. Separation of white light into spectrum\n2. Different angles of deviation for different colors\n3. Measurement of dispersion relation n(λ)\n\n\n\n### Example box: Beer-Lambert Law Verification\nEquipment:\n- Spectrophotometer\n- Solutions of varying concentration\n- Cuvettes of different path lengths\n\nProcedure:\n1. Measure transmission vs. concentration\n2. Plot ln(I/I₀) vs. path length\n3. Determine absorption coefficient\n4. Verify linear relationship\n\n\n\n### Example box: Fiber Optic Pulse Propagation\nSetup:\n- Short pulse laser source (~ps)\n- Optical fiber of known length\n- Fast photodetector\n- Oscilloscope\n\nMeasurements:\n1. Pulse arrival time vs. fiber length\n2. Pulse width changes due to dispersion\n3. Calculate group velocity\n\n\n\n### Example box: Optical Communications\nDemonstration of dispersion effects in telecommunications:\n1. Signal transmission through optical fiber\n2. Pulse broadening measurement\n3. Dispersion compensation techniques\n4. Bit error rate measurements\n\n\n\n### Example box: Anomalous Dispersion\nUsing atomic vapor cells:\n1. Sodium vapor cell setup\n2. Tunable laser source\n3. Measurement of refractive index near D-lines\n4. Observation of rapid n(ω) variation\nYou might also add hands-on activities:\n\nStudent Exercises:\n\nMeasuring refractive indices of different materials\nPlotting dispersion curves\nAnalyzing absorption spectra\n\nVirtual Labs:\n\nInteractive simulations of wave propagation\nOnline spectroscopy experiments\nData analysis exercises\n\nReal-world Connections:\n\nFiber optic communications\nSpectroscopy in chemistry\nOptical imaging systems\nMedical diagnostics\n\nTroubleshooting Scenarios:\n\nCommon experimental problems\nError analysis\nCalibration procedures\n\n\nThese examples would help students connect theoretical concepts with practical applications and develop experimental skills."
  },
  {
    "objectID": "electromagnetic-waves/Dispersion and Absorption Examples.html#experimental-examples-and-demonstrations",
    "href": "electromagnetic-waves/Dispersion and Absorption Examples.html#experimental-examples-and-demonstrations",
    "title": "Experimental Physics 3 Course on Optics and Quantum Mechanics",
    "section": "",
    "text": "### Example box: Abbe Refractometer\nThe Abbe refractometer provides a precise method for measuring refractive indices of liquids:\n\n1. Operating principle: Total internal reflection at critical angle\n2. Typical accuracy: ±0.0002\n3. Procedure:\n   - Place sample between prisms\n   - Adjust viewing angle until bright/dark boundary appears\n   - Read refractive index directly from scale\n4. Applications:\n   - Quality control in food/chemical industries\n   - Concentration measurements\n   - Purity testing\n\n\n\n### Example box: Prism Spectroscopy\nSimple but effective demonstration using:\n- White LED source\n- Glass prism\n- Screen\n\nObservations:\n1. Separation of white light into spectrum\n2. Different angles of deviation for different colors\n3. Measurement of dispersion relation n(λ)\n\n\n\n### Example box: Beer-Lambert Law Verification\nEquipment:\n- Spectrophotometer\n- Solutions of varying concentration\n- Cuvettes of different path lengths\n\nProcedure:\n1. Measure transmission vs. concentration\n2. Plot ln(I/I₀) vs. path length\n3. Determine absorption coefficient\n4. Verify linear relationship\n\n\n\n### Example box: Fiber Optic Pulse Propagation\nSetup:\n- Short pulse laser source (~ps)\n- Optical fiber of known length\n- Fast photodetector\n- Oscilloscope\n\nMeasurements:\n1. Pulse arrival time vs. fiber length\n2. Pulse width changes due to dispersion\n3. Calculate group velocity\n\n\n\n### Example box: Optical Communications\nDemonstration of dispersion effects in telecommunications:\n1. Signal transmission through optical fiber\n2. Pulse broadening measurement\n3. Dispersion compensation techniques\n4. Bit error rate measurements\n\n\n\n### Example box: Anomalous Dispersion\nUsing atomic vapor cells:\n1. Sodium vapor cell setup\n2. Tunable laser source\n3. Measurement of refractive index near D-lines\n4. Observation of rapid n(ω) variation\nYou might also add hands-on activities:\n\nStudent Exercises:\n\nMeasuring refractive indices of different materials\nPlotting dispersion curves\nAnalyzing absorption spectra\n\nVirtual Labs:\n\nInteractive simulations of wave propagation\nOnline spectroscopy experiments\nData analysis exercises\n\nReal-world Connections:\n\nFiber optic communications\nSpectroscopy in chemistry\nOptical imaging systems\nMedical diagnostics\n\nTroubleshooting Scenarios:\n\nCommon experimental problems\nError analysis\nCalibration procedures\n\n\nThese examples would help students connect theoretical concepts with practical applications and develop experimental skills."
  },
  {
    "objectID": "electromagnetic-waves/Speed of Light Measurements.html",
    "href": "electromagnetic-waves/Speed of Light Measurements.html",
    "title": "Measurements of the Speed of Light",
    "section": "",
    "text": "The Michelson-Morley experiment of 1887 was designed to detect the hypothetical luminiferous ether through which light was thought to propagate. Using an interferometer, they split a light beam into two perpendicular paths and recombined them to create an interference pattern. The theoretical derivation considered the time for light to travel in both directions: along the direction of Earth’s motion through the ether, the outward and return journey times are given by:\n\\[t_1 = \\frac{L}{c-v}\\] \\[t_2 = \\frac{L}{c+v}\\]\nwhere \\(L\\) is the arm length, \\(c\\) is the speed of light, and \\(v\\) is Earth’s velocity through the ether. The total time for this path is therefore:\n\\[T_1 = t_1 + t_2 = \\frac{L}{c-v} + \\frac{L}{c+v} = \\frac{2Lc}{c^2-v^2}\\]\nFor the perpendicular arm, the time calculation involved the Pythagorean theorem, as light would travel diagonally relative to the ether, giving:\n\\[T_2 = \\frac{2L}{\\sqrt{c^2-v^2}}\\]\nThe time difference $T = \\(T_{1} - T_{2}\\), when expanded using the binomial theorem and keeping terms to second order in \\(v/c\\), yields:\n\\[\\Delta T = \\frac{L}{c} \\times \\frac{v^2}{c^2}\\]\nThis time difference corresponds to a path difference of:\n\\[\\Delta d = 2L\\frac{v^2}{c^2}\\]\nHowever, Michelson and Morley observed no significant fringe shift, contradicting the ether theory and paving the way for special relativity, which established the constancy of the speed of light in all inertial reference frames."
  },
  {
    "objectID": "electromagnetic-waves/Speed of Light Measurements.html#michelson-morley-experiment",
    "href": "electromagnetic-waves/Speed of Light Measurements.html#michelson-morley-experiment",
    "title": "Measurements of the Speed of Light",
    "section": "",
    "text": "The Michelson-Morley experiment of 1887 was designed to detect the hypothetical luminiferous ether through which light was thought to propagate. Using an interferometer, they split a light beam into two perpendicular paths and recombined them to create an interference pattern. The theoretical derivation considered the time for light to travel in both directions: along the direction of Earth’s motion through the ether, the outward and return journey times are given by:\n\\[t_1 = \\frac{L}{c-v}\\] \\[t_2 = \\frac{L}{c+v}\\]\nwhere \\(L\\) is the arm length, \\(c\\) is the speed of light, and \\(v\\) is Earth’s velocity through the ether. The total time for this path is therefore:\n\\[T_1 = t_1 + t_2 = \\frac{L}{c-v} + \\frac{L}{c+v} = \\frac{2Lc}{c^2-v^2}\\]\nFor the perpendicular arm, the time calculation involved the Pythagorean theorem, as light would travel diagonally relative to the ether, giving:\n\\[T_2 = \\frac{2L}{\\sqrt{c^2-v^2}}\\]\nThe time difference $T = \\(T_{1} - T_{2}\\), when expanded using the binomial theorem and keeping terms to second order in \\(v/c\\), yields:\n\\[\\Delta T = \\frac{L}{c} \\times \\frac{v^2}{c^2}\\]\nThis time difference corresponds to a path difference of:\n\\[\\Delta d = 2L\\frac{v^2}{c^2}\\]\nHowever, Michelson and Morley observed no significant fringe shift, contradicting the ether theory and paving the way for special relativity, which established the constancy of the speed of light in all inertial reference frames."
  },
  {
    "objectID": "electromagnetic-waves/Speed of Light Measurements.html#foucault-rotating-mirror",
    "href": "electromagnetic-waves/Speed of Light Measurements.html#foucault-rotating-mirror",
    "title": "Measurements of the Speed of Light",
    "section": "Foucault Rotating Mirror",
    "text": "Foucault Rotating Mirror\n\n\n\n\n\nThe Foucault Rotating Mirror Method uses a rotating mirror to measure the speed of light. Here’s how each equation contributes to the measurement:\nPath length difference: The total distance light travels is twice the sum of distances \\(f\\) and \\(b\\) \\[\n\\Delta s =2(f+b)\n\\]\nAngular displacement: Related to the mirror’s rotation frequency (\\(ν\\)) and time difference (\\(\\Delta t\\)) \\[\n\\Delta \\alpha=2\\pi\\nu \\Delta t\n\\]\nLinear displacement: The observed displacement at distance a from the mirror\n\\[\n\\Delta x = 2 \\Delta \\alpha a\n\\]\nGeometric relationship: Angular displacement in terms of linear displacement \\[\n\\Delta \\alpha=\\frac{\\Delta x}{2a}\n\\]\nCombining rotation and displacement: Substituting the angular relationships\n\\[\n\\frac{\\Delta x}{2a}=2\\pi\\nu \\Delta t\n\\]\nTime difference: Solved from the above equation \\[\n\\Delta t=\\frac{\\Delta x}{4\\pi\\nu a}\n\\]\nSpeed of light: Final equation combining path length and time difference \\[\nc=\\frac{\\Delta s}{\\Delta t}=\\frac{8\\pi\\nu (f+b)a}{\\Delta x}\n\\]\nThis method allows calculation of \\(c\\) by measuring the angular velocity of the mirror (\\(ν\\)), the distances (\\(f\\), \\(4\\), and \\(a\\)), and the observed displacement (\\(\\Delta x\\))."
  },
  {
    "objectID": "electromagnetic-waves/Optical Activity.html",
    "href": "electromagnetic-waves/Optical Activity.html",
    "title": "Optical Activity and Rotatory Dispersion",
    "section": "",
    "text": "Optical activity is a phenomenon where certain molecules rotate the plane of polarized light. While this basic definition is widely known, the underlying quantum mechanical and electromagnetic mechanisms reveal a fascinating interplay between molecular structure and light interaction.\nWhen light interacts with chiral molecules, it induces both electric (\\(\\vec{p}\\)) and magnetic (\\(\\vec{m}\\)) dipole moments. These moments are coupled through the molecule’s electronic structure:\n\\[\\vec{p} = \\alpha \\vec{E} + G\\vec{B}\\] \\[\\vec{m} = G\\vec{E} + \\beta \\vec{B}\\]\nwhere:\nThe crucial parameter \\(G\\) exists only in chiral molecules and directly leads to circular birefringence.",
    "crumbs": [
      "Electromagnetic Optics",
      "Lecture 18",
      "Optical Activity"
    ]
  },
  {
    "objectID": "electromagnetic-waves/Optical Activity.html#wavelength-dependence-and-the-cotton-effect",
    "href": "electromagnetic-waves/Optical Activity.html#wavelength-dependence-and-the-cotton-effect",
    "title": "Optical Activity and Rotatory Dispersion",
    "section": "Wavelength Dependence and the Cotton Effect",
    "text": "Wavelength Dependence and the Cotton Effect\nThe wavelength dependence of optical rotation becomes more complex near electronic absorption bands, leading to the Cotton effect. This phenomenon is described mathematically by the sum of two terms:\n\\[[\\alpha]_\\lambda = \\sum_i \\frac{A_i\\lambda}{\\lambda^2 - \\lambda_i^2} + \\sum_j \\frac{B_j\\lambda^3}{(\\lambda^2 - \\lambda_j^2)^2}\\]\nIn this expression, \\(A_i\\) and \\(B_j\\) represent amplitude constants that determine the strength of the optical rotation, while \\(\\lambda_i\\) and \\(\\lambda_j\\) correspond to the wavelengths of electronic absorption transitions in the molecule. The first term describes the normal optical rotatory dispersion away from absorption bands, while the second term becomes particularly important near absorption wavelengths, where it accounts for anomalous dispersion effects. When approaching an electronic transition, the optical rotation can change dramatically, even reversing sign, creating what is known as a Cotton curve. This behavior arises from the coupling between electronic transitions and the chiral structure of the molecule. The Cotton effect is a characteristic feature of optically active molecules and provides valuable information about their electronic structure, making it an important tool for investigating molecular conformations and electronic states in chiral systems.",
    "crumbs": [
      "Electromagnetic Optics",
      "Lecture 18",
      "Optical Activity"
    ]
  },
  {
    "objectID": "electromagnetic-waves/Optical Activity.html#sugar-solutions",
    "href": "electromagnetic-waves/Optical Activity.html#sugar-solutions",
    "title": "Optical Activity and Rotatory Dispersion",
    "section": "Sugar Solutions",
    "text": "Sugar Solutions\nIn sugar molecules, the optical activity arises from their asymmetric carbon centers and specific electronic structure:\n\nCoupled Chromophores: The oxygen atoms and hydroxyl groups create a network of coupled electronic transitions.\nHelical Electron Displacement: During light interaction, electrons follow a helical path:\n\n\\[\\Psi_{electron}(t) = \\sum_i c_i\\Psi_i e^{i(\\vec{k}\\cdot\\vec{r} - \\omega t + \\phi_i)}\\]\n\n\n\n\n\n\nFigure 1— The complex interplay between molecular rotation, light scattering, and multiple scattering events leads to the observed color effects in sugar solutions.\n\n\n\nThe colored scattering in sugar solutions results from three combined effects:\n\nWavelength-Dependent Rotation: As light passes through a sugar solution, different wavelengths experience different amounts of rotation. This wavelength dependence follows a modified Drude equation:\n\n\\[\\alpha(\\lambda) = \\frac{K}{\\lambda^2}\\left(1 + \\frac{a}{\\lambda^2} + \\frac{b}{\\lambda^4}\\right)\\]\nwhere \\(K\\) is related to the specific rotation of the sugar molecule, while \\(a\\) and \\(b\\) are correction terms accounting for electronic transitions. This relationship means that blue light (shorter wavelength) experiences significantly more rotation than red light (longer wavelength).\n\nDifferential Scattering: Different wavelengths scatter at different angles due to varying rotation angles. This creates a spatial separation of colors, as each wavelength emerges from the solution at a slightly different angle. The scattering angle \\(\\theta\\) for each wavelength is related to the rotation angle by:\n\n\\[\\theta(\\lambda) \\propto \\alpha(\\lambda)\\]\nThis relationship leads to a rainbow-like separation of colors in the scattered light.\n\nMultiple Scattering Effects: In real sugar solutions, light often undergoes multiple scattering events. The intensity of scattered light follows:\n\n\\[\\vec{I}_{scattered}(\\lambda) = \\vec{I}_0(\\lambda)e^{-\\mu(\\lambda)l}[1 - e^{-\\sigma(\\lambda)l}]\\]\nwhere \\(\\mu(\\lambda)\\) is the absorption coefficient, \\(\\sigma(\\lambda)\\) is the scattering coefficient, and \\(l\\) is the path length. Multiple scattering enhances the color separation effect and creates a more complex pattern of scattered light. The wavelength dependence of both \\(\\mu\\) and \\(\\sigma\\) further contributes to the observed color effects.",
    "crumbs": [
      "Electromagnetic Optics",
      "Lecture 18",
      "Optical Activity"
    ]
  },
  {
    "objectID": "electromagnetic-waves/Optical Activity.html#temperature-effects",
    "href": "electromagnetic-waves/Optical Activity.html#temperature-effects",
    "title": "Optical Activity and Rotatory Dispersion",
    "section": "Temperature Effects",
    "text": "Temperature Effects\nTemperature influences these processes through:\n\nMolecular rotation rates: \\[\\tau_c = \\frac{4\\pi\\eta r^3}{3k_BT}\\]\nConformational distribution: \\[N_i \\propto e^{-E_i/k_BT}\\]",
    "crumbs": [
      "Electromagnetic Optics",
      "Lecture 18",
      "Optical Activity"
    ]
  },
  {
    "objectID": "electromagnetic-waves/Optical Activity.html#applications-and-practical-implications",
    "href": "electromagnetic-waves/Optical Activity.html#applications-and-practical-implications",
    "title": "Optical Activity and Rotatory Dispersion",
    "section": "Applications and Practical Implications",
    "text": "Applications and Practical Implications\nUnderstanding these mechanisms is crucial for:\n\nDesign of polarimetric instruments\nIndustrial crystallization processes\nChiral separation techniques\nPharmaceutical analysis methods\n\nThe complex interplay between electronic structure, circular birefringence, and light scattering explains both the fundamental nature of optical activity and its practical applications in various fields.",
    "crumbs": [
      "Electromagnetic Optics",
      "Lecture 18",
      "Optical Activity"
    ]
  }
]