[
  {
    "objectID": "single_slit_kirchhoff.html",
    "href": "single_slit_kirchhoff.html",
    "title": "Experimental Physics 3 Course on Optics and Quantum Mechanics",
    "section": "",
    "text": "Derivation of Single Slit Diffraction Pattern Using Kirchhoff Diffraction Integral\n\nSetup\nConsider a monochromatic plane wave of wavelength \\(\\lambda\\) incident on a single slit of width \\(b\\). We want to find the diffraction pattern at a point \\(P\\) on a screen located at a distance \\(z\\) from the slit.\n\n\nKirchhoff Diffraction Integral\nThe Kirchhoff diffraction integral for the wave amplitude \\(U(P)\\) at point \\(P\\) is given by:\n\\[\nU(P) = \\frac{1}{i\\lambda} \\int_{\\text{aperture}} \\left( \\frac{\\partial U(Q)}{\\partial n} \\frac{e^{ikr}}{r} - U(Q) \\frac{\\partial}{\\partial n} \\left( \\frac{e^{ikr}}{r} \\right) \\right) dS\n\\]\nFor simplicity, we assume the incident wave is a plane wave \\(U_0\\) and the observation point \\(P\\) is in the far field (Fraunhofer approximation).\n\n\nSimplifications\n\nFar-Field Approximation: In the far field, the distance \\(r\\) from any point \\(Q\\) on the slit to the point \\(P\\) can be approximated as:\n\\[\nr \\approx z \\left( 1 + \\frac{x^2}{2z^2} \\right) \\approx z \\left( 1 + \\frac{x \\sin \\theta}{z} \\right) = z + x \\sin \\theta\n\\]\nwhere \\(x\\) is the coordinate along the slit width, and \\(\\theta\\) is the angle of diffraction.\nPlane Wave Approximation: The incident plane wave \\(U(Q)\\) can be taken as a constant \\(U_0\\).\nNeglecting Edge Effects: For simplicity, we neglect the edge effects and focus on the main term.\n\n\n\nIntegral Simplification\nThe Kirchhoff integral simplifies to:\n\\[\nU(P) \\approx \\frac{U_0}{i\\lambda z} \\int_{-b/2}^{b/2} e^{ikr} dx\n\\]\nSubstituting \\(r \\approx z + x \\sin \\theta\\):\n\\[\nU(P) \\approx \\frac{U_0 e^{ikz}}{i\\lambda z} \\int_{-b/2}^{b/2} e^{ik(x \\sin \\theta)} dx\n\\]\nSince \\(k = \\frac{2\\pi}{\\lambda}\\):\n\\[\nU(P) \\approx \\frac{U_0 e^{ikz}}{i\\lambda z} \\int_{-b/2}^{b/2} e^{i\\left(\\frac{2\\pi}{\\lambda}\\right)x \\sin \\theta} dx\n\\]\n\n\nEvaluating the Integral\nThe integral is:\n\\[\n\\int_{-b/2}^{b/2} e^{ikx \\sin \\theta} dx\n\\]\nThis is a standard integral of the form:\n\\[\n\\int_{-a}^{a} e^{iux} dx = \\frac{2 \\sin(ua)}{u}\n\\]\nHere, \\(a = \\frac{b}{2}\\) and \\(u = k \\sin \\theta\\):\n\\[\n\\int_{-b/2}^{b/2} e^{ikx \\sin \\theta} dx = \\frac{2 \\sin\\left( \\frac{kb \\sin \\theta}{2} \\right)}{k \\sin \\theta / 2}\n\\]\nSimplifying:\n\\[\n\\int_{-b/2}^{b/2} e^{ikx \\sin \\theta} dx = \\frac{2 \\sin\\left( \\frac{\\pi b \\sin \\theta}{\\lambda} \\right)}{2 \\pi \\sin \\theta / \\lambda} = \\frac{\\lambda \\sin\\left( \\frac{\\pi b \\sin \\theta}{\\lambda} \\right)}{\\pi \\sin \\theta}\n\\]\n\n\nFinal Expression\nSubstituting back into the expression for \\(U(P)\\):\n\\[\nU(P) \\approx \\frac{U_0 e^{ikz}}{i\\lambda z} \\cdot \\frac{\\sin\\left( \\frac{\\pi b \\sin \\theta}{\\lambda} \\right)}{\\pi \\sin \\theta}\n\\]\nSimplifying:\n\\[\nU(P) \\approx \\frac{U_0 e^{ikz}}{i z} \\cdot \\frac{\\sin\\left( \\frac{\\pi b \\sin \\theta}{\\lambda} \\right)}{\\pi \\sin \\theta}\n\\]\nThe intensity \\(I(\\theta)\\) is proportional to the square of the amplitude \\(U(P)\\):\n\\[\nI(\\theta) \\propto \\left| U(P) \\right|^2 \\propto \\left( \\frac{\\sin\\left( \\frac{\\pi b \\sin \\theta}{\\lambda} \\right)}{\\pi \\sin \\theta} \\right)^2\n\\]\nThus, the intensity distribution for single slit diffraction is:\n\\[\nI(\\theta) = I_0 \\left( \\frac{\\sin\\left( \\frac{\\pi b \\sin \\theta}{\\lambda} \\right)}{\\pi \\sin \\theta} \\right)^2\n\\]\nwhere \\(I_0\\) is the maximum intensity at \\(\\theta = 0\\)."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Experimental Physics 3",
    "section": "",
    "text": "Welcome to the Experimental Physics 3 Course!\nIn this Experimental Physics 3 course, we will explore fundamental experiments and mathematical descriptions related to light propagation, electromagnetic waves, and their material counterpart, matter waves. Specifically, we will focus on:\n\nGeometrical Optics\nWave Optics\nElectromagnetic Waves\nMatter Waves and Quantum Mechanics\n\nThe fields of optics and quantum mechanics are currently vibrant areas of research, with rapidly evolving optical technologies, high-resolution microscopy, and quantum information science. All of these advancements build upon the foundations that we will address in this course.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "geometrical-optics/Eye.html",
    "href": "geometrical-optics/Eye.html",
    "title": "Optical Instruments",
    "section": "",
    "text": "The human eye stands is one of the most remarkable sensory systems. This sophisticated organ combines an array of precisely crafted components—including an adjustable aperture, an adaptive lens, and a highly sensitive photodetector—all interconnected with a neural network capable of rapid and accurate pattern recognition. What’s truly astounding is that this entire system operates on mere watts of power.\n\n\n\n\n\n\n\n\n\n\n\n(a) Anatomy of the human eye\n\n\n\n\n\n\n\n\n\n\n\n(b) Retinal structure detail\n\n\n\n\n\n\n\nFigure 1: Left: Key components of the human eye, including the lens, vitreous body, and retina with its light-sensitive cells. Right: Detailed view of the retina, showing the arrangement and neural connections of rods and cones.\n\n\n\n\n\n\nPupil and Iris: The pupil, surrounded by the iris, acts as an adjustable aperture. It regulates the amount of light entering the eye and influences the depth of field. In bright conditions, a constricted pupil increases the depth of field, allowing a wider range of distances to be in focus simultaneously.\nLens: Connected to the ciliary muscles, the lens can change its curvature to adjust focal length, a process known as accommodation. This allows the eye to focus on objects at varying distances.\nVitreous Humor: This gel-like substance fills the eye cavity, maintaining its shape and contributing to the eye’s optical properties.\nRetina: The light-sensitive layer at the back of the eye, containing photoreceptor cells (rods and cones) that convert light into neural signals.\n\n\n\n\nThe retina contains two types of photoreceptor cells:\n\nCones: Responsible for color vision and high acuity in bright light. They are concentrated around the fovea, the area of highest visual acuity. There are about 6 Million cones in the human eye.\nRods: More sensitive to light but do not distinguish colors, providing vision in low light conditions. There are around 12 Million rods in the human eye.\n\nRods and cones obtain their function from a chromophore molecule called retina, which undergoes a conformational change when exposed to light. This change triggers a cascade of chemical reactions that ultimately lead to the generation of neural signals. The color vision is achieved with the same chromophore molecule that is embedded in slightly different protein structures in cones. This allows cones to be sensitive to different wavelengths of light.\n\n\n\n\n\n\nFigure 2: Distribution of cones and rods around the fovea, their microscopic structure, and spectral sensitivity.\n\n\n\nCones contain light-sensitive pigments based on retinal molecules, which undergo conformational changes when excited by light, triggering a cascade of chemical processes. There are three types of cones, each sensitive to different wavelengths of light, enabling color vision.\n\n\n\nVisual acuity, often measured using an eye chart, quantifies the eye’s ability to resolve fine details. It’s typically expressed as a fraction (e.g., 20/20 vision), where the numerator is the test distance and the denominator is the distance at which a person with normal acuity can read the same line.\nThe human eye’s remarkable performance in pattern recognition, depth perception, and adaptability to varying light conditions is achieved through the complex interplay of its optical components and neural processing. This sophisticated system continues to inspire developments in artificial vision systems and optical technologies.\n\n\n\nThe eye’s optical system is asymmetrical due to the different media it interfaces with (air on one side, vitreous humor on the other). This results in different focal lengths:\n\nFront focal length: \\(f_1 = 17\\) mm\nBack focal length: \\(f_2 = 22\\) mm\n\nThese values can change during accommodation for near vision:\n\nClose object front focal length: \\(f_1 = 14\\) mm\nClose object back focal length: \\(f_2 = 19\\) mm\n\nThe eye’s refractive power, measured in diopters (D), is the reciprocal of the focal length in meters. For a relaxed eye:\n\\[P = \\frac{1}{f} = \\frac{1}{0.022 \\text{ m}} \\approx 45.45 \\text{ D}\\]\nDuring accommodation, this can increase to about 52 D.\n\n\n\n\n\n\nFigure 3: Illustration of the eye’s focal distances.\n\n\n\n\n\n\nThe resolution of the eye is limited by diffraction and the spacing of photoreceptors. The minimum angle of resolution θ_min can be approximated by:\n\\[\\theta_{\\text{min}} \\approx \\frac{1.22\\lambda}{D}\\]\nwhere λ is the wavelength of light and D is the diameter of the pupil. For a 3 mm pupil and 555 nm light (peak sensitivity), this gives a theoretical resolution of about 1 arc minute.\n\n\n\nThe human eye, under normal conditions, focuses images of distant objects onto the retina at the back focal distance of approximately 22 mm. However, various refractive errors can occur due to imperfections in the eye’s optical system, primarily the cornea and lens. These errors affect the eye’s ability to focus light accurately on the retina, leading to vision problems.\nCommon refractive errors include:\n\nMyopia (Short-sightedness): Light from distant objects focuses in front of the retina, causing distant objects to appear blurry while near objects remain clear.\nHyperopia (Far-sightedness): Light focuses behind the retina, making nearby objects appear blurry while distant objects may remain clear.\nAstigmatism: The cornea or lens isn’t perfectly spherical, causing light to focus at multiple points rather than a single sharp point on the retina.\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Correction of Myopia\n\n\n\n\n\n\n\n\n\n\n\n(b) Correction of Hyperopia\n\n\n\n\n\n\n\nFigure 4: Left: Myopia correction using a concave lens. Right: Hyperopia correction using a convex lens.\n\n\n\nThe severity of refractive errors can be quantified using the concept of refractive power. The refractive error R of the eye, measured in diopters (D), is calculated as:\n\\[R = \\frac{1}{f_{\\text{required}}} - \\frac{1}{f_{\\text{actual}}}\\]\nwhere f_required is the focal length needed for perfect focus, and f_actual is the eye’s actual focal length. This formula helps determine the degree of correction needed for various eye defects.\nIn a normal, relaxed state, the human eye can observe objects clearly up to a distance of approximately \\(s_0=25\\) cm without additional accommodation of the lens. This distance, known as the range of clear visual sight, varies among individuals and is used as a standard in optical calculations. Objects within this range can be observed under a visual angle \\(\\epsilon_0\\). For small angles, which is typically the case in vision, the angular size \\(\\epsilon_0\\) of an object of height h at a distance \\(s_0\\) is approximated by:\n\\[\n\\epsilon_0 \\approx \\tan(\\epsilon_0) = \\frac{h}{s_0}\n\\]\nThis relationship is fundamental in understanding how objects are perceived and in designing corrective lenses and optical instruments.\n\n\n\n\n\n\nFigure 5: Diagram of a relaxed eye focusing on a distant object.\n\n\n\nhistory |grep git\nUnderstanding these concepts is crucial for diagnosing vision problems and designing appropriate corrective measures, whether through eyeglasses, contact lenses, or surgical interventions.\n\n\n\nHaving discussed the basic structure and function of the human eye, we now turn to how optical instruments can enhance our vision. Instead of calculating the magnification of optical instruments from object and image distances, we introduce a more relevant measure: the angular magnification.\nThe angular magnification, V, is defined as the ratio of the angle subtended by the image when viewed through the instrument to the angle subtended by the object when viewed with the naked eye at the near point. It is given by:\n\\[\nV=\\frac{\\tan(\\epsilon)}{\\tan(\\epsilon_0)}\\approx \\frac{\\epsilon}{\\epsilon_0}\n\\]\nwhere: - ε is the angle subtended by the image at the eye when viewed through the instrument - ε₀ is the angle subtended by the object when viewed with the naked eye at the near point\nThis concept is crucial in understanding how optical instruments like telescopes and microscopes enhance our vision. Angular magnification effectively increases the apparent size of objects by increasing the angle at which they are viewed. This measure is particularly useful as the actual image size is often not directly accessible or relevant to the viewer’s experience.",
    "crumbs": [
      "Geometrical Optics",
      "Lecture 4",
      "Optical Instruments- Eye"
    ]
  },
  {
    "objectID": "geometrical-optics/Eye.html#the-human-eye",
    "href": "geometrical-optics/Eye.html#the-human-eye",
    "title": "Optical Instruments",
    "section": "",
    "text": "The human eye stands is one of the most remarkable sensory systems. This sophisticated organ combines an array of precisely crafted components—including an adjustable aperture, an adaptive lens, and a highly sensitive photodetector—all interconnected with a neural network capable of rapid and accurate pattern recognition. What’s truly astounding is that this entire system operates on mere watts of power.\n\n\n\n\n\n\n\n\n\n\n\n(a) Anatomy of the human eye\n\n\n\n\n\n\n\n\n\n\n\n(b) Retinal structure detail\n\n\n\n\n\n\n\nFigure 1: Left: Key components of the human eye, including the lens, vitreous body, and retina with its light-sensitive cells. Right: Detailed view of the retina, showing the arrangement and neural connections of rods and cones.\n\n\n\n\n\n\nPupil and Iris: The pupil, surrounded by the iris, acts as an adjustable aperture. It regulates the amount of light entering the eye and influences the depth of field. In bright conditions, a constricted pupil increases the depth of field, allowing a wider range of distances to be in focus simultaneously.\nLens: Connected to the ciliary muscles, the lens can change its curvature to adjust focal length, a process known as accommodation. This allows the eye to focus on objects at varying distances.\nVitreous Humor: This gel-like substance fills the eye cavity, maintaining its shape and contributing to the eye’s optical properties.\nRetina: The light-sensitive layer at the back of the eye, containing photoreceptor cells (rods and cones) that convert light into neural signals.\n\n\n\n\nThe retina contains two types of photoreceptor cells:\n\nCones: Responsible for color vision and high acuity in bright light. They are concentrated around the fovea, the area of highest visual acuity. There are about 6 Million cones in the human eye.\nRods: More sensitive to light but do not distinguish colors, providing vision in low light conditions. There are around 12 Million rods in the human eye.\n\nRods and cones obtain their function from a chromophore molecule called retina, which undergoes a conformational change when exposed to light. This change triggers a cascade of chemical reactions that ultimately lead to the generation of neural signals. The color vision is achieved with the same chromophore molecule that is embedded in slightly different protein structures in cones. This allows cones to be sensitive to different wavelengths of light.\n\n\n\n\n\n\nFigure 2: Distribution of cones and rods around the fovea, their microscopic structure, and spectral sensitivity.\n\n\n\nCones contain light-sensitive pigments based on retinal molecules, which undergo conformational changes when excited by light, triggering a cascade of chemical processes. There are three types of cones, each sensitive to different wavelengths of light, enabling color vision.\n\n\n\nVisual acuity, often measured using an eye chart, quantifies the eye’s ability to resolve fine details. It’s typically expressed as a fraction (e.g., 20/20 vision), where the numerator is the test distance and the denominator is the distance at which a person with normal acuity can read the same line.\nThe human eye’s remarkable performance in pattern recognition, depth perception, and adaptability to varying light conditions is achieved through the complex interplay of its optical components and neural processing. This sophisticated system continues to inspire developments in artificial vision systems and optical technologies.\n\n\n\nThe eye’s optical system is asymmetrical due to the different media it interfaces with (air on one side, vitreous humor on the other). This results in different focal lengths:\n\nFront focal length: \\(f_1 = 17\\) mm\nBack focal length: \\(f_2 = 22\\) mm\n\nThese values can change during accommodation for near vision:\n\nClose object front focal length: \\(f_1 = 14\\) mm\nClose object back focal length: \\(f_2 = 19\\) mm\n\nThe eye’s refractive power, measured in diopters (D), is the reciprocal of the focal length in meters. For a relaxed eye:\n\\[P = \\frac{1}{f} = \\frac{1}{0.022 \\text{ m}} \\approx 45.45 \\text{ D}\\]\nDuring accommodation, this can increase to about 52 D.\n\n\n\n\n\n\nFigure 3: Illustration of the eye’s focal distances.\n\n\n\n\n\n\nThe resolution of the eye is limited by diffraction and the spacing of photoreceptors. The minimum angle of resolution θ_min can be approximated by:\n\\[\\theta_{\\text{min}} \\approx \\frac{1.22\\lambda}{D}\\]\nwhere λ is the wavelength of light and D is the diameter of the pupil. For a 3 mm pupil and 555 nm light (peak sensitivity), this gives a theoretical resolution of about 1 arc minute.\n\n\n\nThe human eye, under normal conditions, focuses images of distant objects onto the retina at the back focal distance of approximately 22 mm. However, various refractive errors can occur due to imperfections in the eye’s optical system, primarily the cornea and lens. These errors affect the eye’s ability to focus light accurately on the retina, leading to vision problems.\nCommon refractive errors include:\n\nMyopia (Short-sightedness): Light from distant objects focuses in front of the retina, causing distant objects to appear blurry while near objects remain clear.\nHyperopia (Far-sightedness): Light focuses behind the retina, making nearby objects appear blurry while distant objects may remain clear.\nAstigmatism: The cornea or lens isn’t perfectly spherical, causing light to focus at multiple points rather than a single sharp point on the retina.\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Correction of Myopia\n\n\n\n\n\n\n\n\n\n\n\n(b) Correction of Hyperopia\n\n\n\n\n\n\n\nFigure 4: Left: Myopia correction using a concave lens. Right: Hyperopia correction using a convex lens.\n\n\n\nThe severity of refractive errors can be quantified using the concept of refractive power. The refractive error R of the eye, measured in diopters (D), is calculated as:\n\\[R = \\frac{1}{f_{\\text{required}}} - \\frac{1}{f_{\\text{actual}}}\\]\nwhere f_required is the focal length needed for perfect focus, and f_actual is the eye’s actual focal length. This formula helps determine the degree of correction needed for various eye defects.\nIn a normal, relaxed state, the human eye can observe objects clearly up to a distance of approximately \\(s_0=25\\) cm without additional accommodation of the lens. This distance, known as the range of clear visual sight, varies among individuals and is used as a standard in optical calculations. Objects within this range can be observed under a visual angle \\(\\epsilon_0\\). For small angles, which is typically the case in vision, the angular size \\(\\epsilon_0\\) of an object of height h at a distance \\(s_0\\) is approximated by:\n\\[\n\\epsilon_0 \\approx \\tan(\\epsilon_0) = \\frac{h}{s_0}\n\\]\nThis relationship is fundamental in understanding how objects are perceived and in designing corrective lenses and optical instruments.\n\n\n\n\n\n\nFigure 5: Diagram of a relaxed eye focusing on a distant object.\n\n\n\nhistory |grep git\nUnderstanding these concepts is crucial for diagnosing vision problems and designing appropriate corrective measures, whether through eyeglasses, contact lenses, or surgical interventions.\n\n\n\nHaving discussed the basic structure and function of the human eye, we now turn to how optical instruments can enhance our vision. Instead of calculating the magnification of optical instruments from object and image distances, we introduce a more relevant measure: the angular magnification.\nThe angular magnification, V, is defined as the ratio of the angle subtended by the image when viewed through the instrument to the angle subtended by the object when viewed with the naked eye at the near point. It is given by:\n\\[\nV=\\frac{\\tan(\\epsilon)}{\\tan(\\epsilon_0)}\\approx \\frac{\\epsilon}{\\epsilon_0}\n\\]\nwhere: - ε is the angle subtended by the image at the eye when viewed through the instrument - ε₀ is the angle subtended by the object when viewed with the naked eye at the near point\nThis concept is crucial in understanding how optical instruments like telescopes and microscopes enhance our vision. Angular magnification effectively increases the apparent size of objects by increasing the angle at which they are viewed. This measure is particularly useful as the actual image size is often not directly accessible or relevant to the viewer’s experience.",
    "crumbs": [
      "Geometrical Optics",
      "Lecture 4",
      "Optical Instruments- Eye"
    ]
  },
  {
    "objectID": "geometrical-optics/Optical Elements II.html",
    "href": "geometrical-optics/Optical Elements II.html",
    "title": "Optical Elements Part II",
    "section": "",
    "text": "Prisms are wedge-shaped optical elements made of a transparent material, such as glass. A special form of such a prism is an isosceles prism with two sides of equal length. The two equal sides enclose an angle \\(\\gamma\\), known as the apex angle of the prism. When light passes through this prism, it undergoes refraction twice.\nFirst, the incident angle \\(\\alpha_1\\) is changed into a refracted angle \\(\\beta_1\\) as the light enters the prism. This refracted ray then hits the second interface at an angle \\(\\beta_2\\), leading to a second refraction as it exits the prism at an angle \\(\\alpha_2\\).\nOf particular interest is the total deflection of the incident ray, which is measured by the angle \\(\\delta\\). This deflection angle represents the difference between the final outgoing angle \\(\\alpha_2\\) and the initial incident angle \\(\\alpha_1\\).\nUnderstanding how this deflection angle changes based on the prism’s properties and the incident angle is crucial in various optical applications. In the following sections, we will explore how to calculate this deflection angle and examine its dependence on different parameters.\n\n\n\n\n\n\nFigure 1— Refraction of rays on a prism.\n\n\n\n\n\n\nWe can calculate the deflection angle \\(\\delta\\) from a number of considerations. First consider the following relations between the angles in the prism and Snell’s law\n\\[\\beta_1=\\sin^{-1}\\left (\\frac{n_0}{n_1}\\sin(\\alpha_1) \\right)\\] \\[\\beta_2=\\gamma-\\beta_1\\] \\[\\alpha_2=\\sin^{-1}\\left (\\frac{n_1}{n_0}\\sin(\\beta_2)\\right )\\] \\[\\theta_2=\\alpha_2-\\gamma\\]\nwhere \\(\\theta_2\\) is the angle between the incident surface normal and the outgoing ray. The total deflection angle \\(\\delta\\) is then\n\\[\\delta =\\alpha_1-\\beta_1+\\alpha_2-\\beta_2\\]\nor\n\\[\\delta =\\alpha_1+\\alpha_2-\\gamma\\]\nfrom which we obtain\n\\[\\delta=\\alpha_1+\\sin^{-1}\\left (\\frac{n_1}{n_0}\\sin\\left [\\gamma-\\sin^{-1}\\left (\\frac{n_0}{n_1}\\sin(\\alpha_1) \\right)\\right]\\right )-\\gamma\\]\nas the deflection angle.\n\n\nCode\ndef deflection(alpha_1,gamma,n0,n1):\n    g=gamma*np.pi/180\n    return(alpha_1+np.arcsin(n1*np.sin(g-np.arcsin(n0*np.sin(alpha_1)/n1))))-g\n\na_1=np.linspace(0.1,np.pi/2,100)\nplt.figure(figsize=(4,4))\nplt.plot(a_1*180/np.pi,deflection(a_1,45,1,1.5)*180/np.pi,label=r\"$\\gamma=45$ °\")\nplt.plot(a_1*180/np.pi,deflection(a_1,30,1,1.5)*180/np.pi,label=r\"$\\gamma=30$ °\")\nplt.plot(a_1*180/np.pi,deflection(a_1,10,1,1.5)*180/np.pi,label=r\"$\\gamma=10$ °\")\nplt.xlabel(r\"incindence angle $\\alpha_1$ [°]\")\nplt.ylabel(r\"deflection angle $\\delta$ [°]\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nFigure 2— Deflection angle as a function of the incidence angle for different prism angles.\n\n\n\n\n\n\n\n\nIf we now would like to know how the deflection angle changes with the incident angle \\(\\alpha_1\\), we calculate the derivative of the deflection angle \\(\\delta\\) with respect to \\(\\alpha_1\\), i.e.,\n\\[\\frac{\\mathrm d\\delta}{\\mathrm d\\alpha_1}=1+\\frac{\\mathrm d\\alpha_2}{\\mathrm d \\alpha_1}.\\]\nWe are here especially interested in the case, where this change in deflection is reaching a minimum, i.e., \\(\\mathrm d\\delta/\\mathrm d\\alpha_1 =0\\). This readily yields\n\\[\\mathrm d \\alpha_2=-\\mathrm d\\alpha_1.\\]\nThis means a change in the incidence angle \\(\\mathrm d\\alpha_1\\) yields an opposite change in the outgoing angle \\(-\\mathrm d\\alpha_2\\). We may later observe that in the experiment.\nAs both, the incident and the outgoing angle are related to each other by Snells’s law, we may introduce the derivatives of Snell’s law for both interfaces, e.g.,\n\n\\(\\cos(\\alpha_1)\\mathrm d\\alpha_1=n\\cos(\\beta_1)\\mathrm d\\beta_1\\)\n\\(\\cos(\\alpha_2)\\mathrm d\\alpha_2=n\\cos(\\beta_2)\\mathrm d\\beta_2\\)\n\nwhere \\(n\\) is the refractive index of the prism material and the material outside is air (\\(n_{\\rm air}=1\\)). Replacing \\(\\cos(\\alpha)=\\sqrt{1-\\sin^2(\\alpha)}\\) and dividing the two previous equations by each other readily yields\n\\[\\frac{1-\\sin^2(\\alpha_1)}{1-\\sin^2(\\alpha_2)}=\\frac{n^2-\\sin^2(\\alpha_1)}{n^2-\\sin^2(\\alpha_2)}.\\]\nThe latter equation is for \\(n\\neq 1\\) only satisfied if \\(\\alpha_1=\\alpha_2=\\alpha\\). In this case, the light path through the prism must be symmetric and we may write down the minimum deflection angle \\(\\delta_{\\rm min}\\):\n\n\n\n\n\n\nMinimum prism deflection\n\n\n\nThe minimum deflection angle of an isosceles prism with a prism angle \\(\\gamma\\) is given by\n\\[\\delta_{\\rm min}=2\\alpha-\\gamma.\\]\n\n\nGiven this minimum deflection angle \\(\\delta_{\\rm min}\\) and the properties of the prism, we may also write down Snell’s law using \\(\\sin(\\alpha)=n\\sin(\\beta)\\), which results in\n\\[\\sin \\left ( \\frac{\\delta_{\\rm min}+\\gamma}{2}\\right )=n\\sin\\left (\\frac{\\gamma}{2}\\right).\\]\nwhich indicates the dependence of the deflection in the refractive index \\(n\\) of the prism material.\n\n\n\nVery important applications now arise from the fact, that the refractive index is a material property, which depends on the color (frequency or wavelength) of light. We do not yet understand the origin of this dependence. The plots below show the wavelength dependence of three different glasses. You may find much more data on the refractive index of different materials in an online database.\n\n\nCode\nbk7=pd.read_csv(\"data/BK7.csv\",delimiter=\",\")\nsf10=pd.read_csv(\"data/SF10.csv\",delimiter=\",\")\nfk51a=pd.read_csv(\"data/FK51A.csv\",delimiter=\",\")\nplt.figure(figsize=(4,4))\nplt.plot(bk7.wl*1000,bk7.n,label=\"BK7\")\nplt.plot(sf10.wl*1000,sf10.n,label=\"SF10\")\nplt.plot(fk51a.wl*1000,fk51a.n,label=\"FK51A\")\nplt.xlim(300,900)\nplt.xlabel(\"wavelength [nm]\")\nplt.ylabel(\"refractive index n\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nFigure 3— Refractive index of different glasses as a function of the wavelength.\n\n\n\n\n\n\n\nCode\nbk7=pd.read_csv(\"data/BK7.csv\",delimiter=\",\")\na_1=np.linspace(0.15,np.pi/2,100)\nplt.figure(figsize=(7.5,4))\nplt.subplot(1,2,1)\nfor wl in np.linspace(0.400,0.700,100):\n    n1=np.interp(wl,bk7.wl,bk7.n)\n    c=wavelength_to_rgb(wl*1000, gamma=0.8)\n    plt.plot(a_1*180/np.pi,deflection(a_1,45,1,n1)*180/np.pi,color=c)\n\nplt.xlabel(r\"incindence angle $\\alpha_1$ [°]\")\nplt.ylabel(r\"deflection angle $\\delta$ [°]\")\n\n\nplt.subplot(1,2,2)\nfor wl in np.linspace(0.400,0.700,100):\n    n1=np.interp(wl,bk7.wl,bk7.n)\n    c=wavelength_to_rgb(wl*1000, gamma=0.8)\n    plt.plot(a_1*180/np.pi,deflection(a_1,45,1,n1)*180/np.pi,color=c)\n\nplt.xlabel(r\"incindence angle $\\alpha_1$ [°]\")\nplt.ylabel(r\"deflection angle $\\delta$ [°]\")\nplt.xlim(30,45)\nplt.ylim(25,30)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nFigure 4— Deflection angle as a function of the incidence angle for different wavelengths.\n\n\n\n\n\nThe plots have a general feature, which is that the refractive index is largest at small wavelength (blue colors), while it drops continuously with increasing wavelength towards the red (800 nm). If you would characterize the dependence by the slope, i.e., \\(\\mathrm dn/\\mathrm d\\lambda\\) then all displayed curves show in the visible range\n\n\\(\\frac{\\mathrm dn}{\\mathrm d\\lambda}&lt;0\\), is called normal dispersion\n\nwhile\n\n\\(\\frac{\\mathrm dn}{\\mathrm d\\lambda}&gt;0\\), is called anomalous dispersion\n\nThis wavelength dependence of the refractive index will yield a dependence of the deflection angle on the color of light as well. The change of the deflection angle with the refractive index can be calculated to be\n\\[\\frac{\\mathrm d\\delta}{\\mathrm d n}=\\frac{2\\sin(\\gamma/2)}{\\sqrt{1-n^2\\sin^2(\\gamma/2)}}\\]\ntogether with the relation\n\\[\\frac{\\mathrm d \\delta}{\\mathrm d \\lambda}=\\frac{\\mathrm d\\delta}{\\mathrm d n}\\frac{\\mathrm d n}{\\mathrm d\\lambda}\\]\nwe obtain\n\\[\\frac{\\mathrm d\\delta}{\\mathrm d\\lambda}=\\frac{2\\sin(\\gamma/2)}{\\sqrt{1-n^2\\sin^2(\\gamma/2)}}\\frac{\\mathrm d n}{\\mathrm d \\lambda}.\\]\nThe refraction of white light through a prism splits the different colors composing white light spatially into a colored spectrum. In this process, light with the longest wavelength (red) is deflected the least, while light with the shortest wavelength (violet) is deflected the most. This occurs because the refractive index of the prism material varies with wavelength, a phenomenon known as dispersion.\n\n\n\n\n\n\nFigure 5— Spectrum as created by a prism in the lecture.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Spectrum\n\n\n\n\n\n\n\n\n\n\n\n(b) Prism\n\n\n\n\n\n\n\nFigure 6— Deflection of different wavelengths of light in a prism with normal dispersion.\n\n\n\n\n\n\nThis wavelength-dependent refraction is crucial as it forms the basis for spectroscopy, a powerful analytical technique that measures and records the intensity of light as a function of wavelength. Spectroscopy allows scientists to analyze the composition and properties of matter by examining its interaction with light across different wavelengths.\n\n\n\n\n\n\n\n\n\n\n\n(a) Principle of a prism spectrometer\n\n\n\n\n\n\n\n\n\n\n\n(b) Technical realization of a prism spectrometer\n\n\n\n\n\n\n\nFigure 7— Principle and technical realization of a prism spectrometer.\n\n\n\nDIY prism\nIf you don’t have a prism at home (which most people don’t), you can create a simple substitute using a mirror and a basin of water. Here’s how:\n\nPlace a mirror in a basin of water, partially submerged.\nShine white light from a flashlight onto the mirror.\nObserve the reflected and refracted light, paying special attention to the edges.\n\nFor better results, you can create a small aperture by making a tiny hole in a piece of black paper and placing it in front of the flashlight.\n\n\n\n\n\n\nFigure 8— Home made water prism.\n\n\n\nWhile the dependence of water’s refractive index on wavelength is relatively weak, it’s still sufficient to demonstrate the familiar colors of the rainbow. This phenomenon will be referenced later in our discussion.\n\n\nCode\n#\nh2o=pd.read_csv(\"data/H2O.csv\",delimiter=\",\")\nplt.figure(figsize=(6,4))\nplt.plot(h2o.wl*1000,h2o.n,label=r\"$H_2O$\")\nplt.xlim(300,900)\nplt.ylim(1.3,1.36)\nplt.xlabel(\"wavelength [nm]\")\nplt.ylabel(\"refractive index n\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nFigure 9— Refractive index of water as a function of the wavelength.\n\n\n\n\n\n\n\n\n\n\n\nApplications of prims\n\n\n\n\n\nPrisms are versatile optical components with a wide range of applications across various fields. Here are some common uses of prisms:\n\n\nPorro prisms in traditional binoculars and roof prisms in modern designs serve to correct image inversion and provide a compact form. These prisms enable a longer optical path within a shorter physical length, enhancing magnification while maintaining portability. This design is crucial for both binoculars and some telescopes, offering users powerful magnification in a handheld device.\n\n\n\nRight-angle prisms are the key component in periscopes, redirecting light at 90-degree angles. This simple yet effective design allows viewers to see over obstacles or around corners, making periscopes invaluable in submarines and various military applications where direct line of sight is obstructed.\n\n\n\nCube beamsplitters play a vital role in dividing a single beam of light into two separate beams. This capability is essential in various scientific and medical applications, including interferometry, holography, and optical coherence tomography (OCT). The ability to split light beams precisely opens up numerous possibilities in research and diagnostics.\n\n\n\nRisley prisms, consisting of a pair of rotating wedge prisms, offer precise control over laser beam direction. This technology finds applications in laser scanning, target tracking, and adaptive optics. The ability to steer beams accurately is crucial in fields ranging from military applications to advanced scientific research.\n\n\n\nTotal Internal Reflection (TIR) prisms are a crucial component in Digital Light Processing (DLP) projectors. They direct light from the lamp to the Digital Micromirror Device (DMD) and then to the projection lens, enabling the high-quality image projection that DLP technology is known for.\n\n\n\nIn Single-Lens Reflex (SLR) cameras, pentaprisms play a critical role in the viewfinder system. They flip the image from the lens to appear upright and correctly oriented in the viewfinder, allowing photographers to accurately compose their shots.\n\n\n\nBrewster prisms find use in laser systems for polarization and wavelength separation. Additionally, dispersing prisms can be employed for wavelength tuning in certain laser setups, providing precise control over the laser’s output characteristics.\n\n\n\nIn the realm of telecommunications, prisms are utilized in some fiber optic connectors and switches. They help redirect light between fibers, playing a crucial role in maintaining signal integrity and enabling complex network architectures.\n\n\n\nFresnel lenses, a specialized type of prism, are employed in concentrated solar power systems. These lenses focus sunlight efficiently, contributing to the development of more effective solar energy collection technologies.\n\n\n\nPrisms are an integral part of HUD systems in both automotive and aviation contexts. They project crucial information onto the windshield or a combiner glass, allowing drivers or pilots to access important data without taking their eyes off their primary viewpoint.\n\n\n\nNomarski prisms enhance the capabilities of differential interference contrast microscopy. They increase contrast in transparent specimens, enabling scientists to observe details that would be difficult or impossible to see with conventional microscopy techniques.\n\n\n\nIn some OCT systems, prisms are employed for sample arm scanning and reference arm delay. This application of prisms contributes to the high-resolution imaging capabilities of OCT, which is particularly valuable in medical diagnostics, especially in ophthalmology.",
    "crumbs": [
      "Geometrical Optics",
      "Lecture 3",
      "Optical Elements II - Prims"
    ]
  },
  {
    "objectID": "geometrical-optics/Optical Elements II.html#prism",
    "href": "geometrical-optics/Optical Elements II.html#prism",
    "title": "Optical Elements Part II",
    "section": "",
    "text": "Prisms are wedge-shaped optical elements made of a transparent material, such as glass. A special form of such a prism is an isosceles prism with two sides of equal length. The two equal sides enclose an angle \\(\\gamma\\), known as the apex angle of the prism. When light passes through this prism, it undergoes refraction twice.\nFirst, the incident angle \\(\\alpha_1\\) is changed into a refracted angle \\(\\beta_1\\) as the light enters the prism. This refracted ray then hits the second interface at an angle \\(\\beta_2\\), leading to a second refraction as it exits the prism at an angle \\(\\alpha_2\\).\nOf particular interest is the total deflection of the incident ray, which is measured by the angle \\(\\delta\\). This deflection angle represents the difference between the final outgoing angle \\(\\alpha_2\\) and the initial incident angle \\(\\alpha_1\\).\nUnderstanding how this deflection angle changes based on the prism’s properties and the incident angle is crucial in various optical applications. In the following sections, we will explore how to calculate this deflection angle and examine its dependence on different parameters.\n\n\n\n\n\n\nFigure 1— Refraction of rays on a prism.\n\n\n\n\n\n\nWe can calculate the deflection angle \\(\\delta\\) from a number of considerations. First consider the following relations between the angles in the prism and Snell’s law\n\\[\\beta_1=\\sin^{-1}\\left (\\frac{n_0}{n_1}\\sin(\\alpha_1) \\right)\\] \\[\\beta_2=\\gamma-\\beta_1\\] \\[\\alpha_2=\\sin^{-1}\\left (\\frac{n_1}{n_0}\\sin(\\beta_2)\\right )\\] \\[\\theta_2=\\alpha_2-\\gamma\\]\nwhere \\(\\theta_2\\) is the angle between the incident surface normal and the outgoing ray. The total deflection angle \\(\\delta\\) is then\n\\[\\delta =\\alpha_1-\\beta_1+\\alpha_2-\\beta_2\\]\nor\n\\[\\delta =\\alpha_1+\\alpha_2-\\gamma\\]\nfrom which we obtain\n\\[\\delta=\\alpha_1+\\sin^{-1}\\left (\\frac{n_1}{n_0}\\sin\\left [\\gamma-\\sin^{-1}\\left (\\frac{n_0}{n_1}\\sin(\\alpha_1) \\right)\\right]\\right )-\\gamma\\]\nas the deflection angle.\n\n\nCode\ndef deflection(alpha_1,gamma,n0,n1):\n    g=gamma*np.pi/180\n    return(alpha_1+np.arcsin(n1*np.sin(g-np.arcsin(n0*np.sin(alpha_1)/n1))))-g\n\na_1=np.linspace(0.1,np.pi/2,100)\nplt.figure(figsize=(4,4))\nplt.plot(a_1*180/np.pi,deflection(a_1,45,1,1.5)*180/np.pi,label=r\"$\\gamma=45$ °\")\nplt.plot(a_1*180/np.pi,deflection(a_1,30,1,1.5)*180/np.pi,label=r\"$\\gamma=30$ °\")\nplt.plot(a_1*180/np.pi,deflection(a_1,10,1,1.5)*180/np.pi,label=r\"$\\gamma=10$ °\")\nplt.xlabel(r\"incindence angle $\\alpha_1$ [°]\")\nplt.ylabel(r\"deflection angle $\\delta$ [°]\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nFigure 2— Deflection angle as a function of the incidence angle for different prism angles.\n\n\n\n\n\n\n\n\nIf we now would like to know how the deflection angle changes with the incident angle \\(\\alpha_1\\), we calculate the derivative of the deflection angle \\(\\delta\\) with respect to \\(\\alpha_1\\), i.e.,\n\\[\\frac{\\mathrm d\\delta}{\\mathrm d\\alpha_1}=1+\\frac{\\mathrm d\\alpha_2}{\\mathrm d \\alpha_1}.\\]\nWe are here especially interested in the case, where this change in deflection is reaching a minimum, i.e., \\(\\mathrm d\\delta/\\mathrm d\\alpha_1 =0\\). This readily yields\n\\[\\mathrm d \\alpha_2=-\\mathrm d\\alpha_1.\\]\nThis means a change in the incidence angle \\(\\mathrm d\\alpha_1\\) yields an opposite change in the outgoing angle \\(-\\mathrm d\\alpha_2\\). We may later observe that in the experiment.\nAs both, the incident and the outgoing angle are related to each other by Snells’s law, we may introduce the derivatives of Snell’s law for both interfaces, e.g.,\n\n\\(\\cos(\\alpha_1)\\mathrm d\\alpha_1=n\\cos(\\beta_1)\\mathrm d\\beta_1\\)\n\\(\\cos(\\alpha_2)\\mathrm d\\alpha_2=n\\cos(\\beta_2)\\mathrm d\\beta_2\\)\n\nwhere \\(n\\) is the refractive index of the prism material and the material outside is air (\\(n_{\\rm air}=1\\)). Replacing \\(\\cos(\\alpha)=\\sqrt{1-\\sin^2(\\alpha)}\\) and dividing the two previous equations by each other readily yields\n\\[\\frac{1-\\sin^2(\\alpha_1)}{1-\\sin^2(\\alpha_2)}=\\frac{n^2-\\sin^2(\\alpha_1)}{n^2-\\sin^2(\\alpha_2)}.\\]\nThe latter equation is for \\(n\\neq 1\\) only satisfied if \\(\\alpha_1=\\alpha_2=\\alpha\\). In this case, the light path through the prism must be symmetric and we may write down the minimum deflection angle \\(\\delta_{\\rm min}\\):\n\n\n\n\n\n\nMinimum prism deflection\n\n\n\nThe minimum deflection angle of an isosceles prism with a prism angle \\(\\gamma\\) is given by\n\\[\\delta_{\\rm min}=2\\alpha-\\gamma.\\]\n\n\nGiven this minimum deflection angle \\(\\delta_{\\rm min}\\) and the properties of the prism, we may also write down Snell’s law using \\(\\sin(\\alpha)=n\\sin(\\beta)\\), which results in\n\\[\\sin \\left ( \\frac{\\delta_{\\rm min}+\\gamma}{2}\\right )=n\\sin\\left (\\frac{\\gamma}{2}\\right).\\]\nwhich indicates the dependence of the deflection in the refractive index \\(n\\) of the prism material.\n\n\n\nVery important applications now arise from the fact, that the refractive index is a material property, which depends on the color (frequency or wavelength) of light. We do not yet understand the origin of this dependence. The plots below show the wavelength dependence of three different glasses. You may find much more data on the refractive index of different materials in an online database.\n\n\nCode\nbk7=pd.read_csv(\"data/BK7.csv\",delimiter=\",\")\nsf10=pd.read_csv(\"data/SF10.csv\",delimiter=\",\")\nfk51a=pd.read_csv(\"data/FK51A.csv\",delimiter=\",\")\nplt.figure(figsize=(4,4))\nplt.plot(bk7.wl*1000,bk7.n,label=\"BK7\")\nplt.plot(sf10.wl*1000,sf10.n,label=\"SF10\")\nplt.plot(fk51a.wl*1000,fk51a.n,label=\"FK51A\")\nplt.xlim(300,900)\nplt.xlabel(\"wavelength [nm]\")\nplt.ylabel(\"refractive index n\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nFigure 3— Refractive index of different glasses as a function of the wavelength.\n\n\n\n\n\n\n\nCode\nbk7=pd.read_csv(\"data/BK7.csv\",delimiter=\",\")\na_1=np.linspace(0.15,np.pi/2,100)\nplt.figure(figsize=(7.5,4))\nplt.subplot(1,2,1)\nfor wl in np.linspace(0.400,0.700,100):\n    n1=np.interp(wl,bk7.wl,bk7.n)\n    c=wavelength_to_rgb(wl*1000, gamma=0.8)\n    plt.plot(a_1*180/np.pi,deflection(a_1,45,1,n1)*180/np.pi,color=c)\n\nplt.xlabel(r\"incindence angle $\\alpha_1$ [°]\")\nplt.ylabel(r\"deflection angle $\\delta$ [°]\")\n\n\nplt.subplot(1,2,2)\nfor wl in np.linspace(0.400,0.700,100):\n    n1=np.interp(wl,bk7.wl,bk7.n)\n    c=wavelength_to_rgb(wl*1000, gamma=0.8)\n    plt.plot(a_1*180/np.pi,deflection(a_1,45,1,n1)*180/np.pi,color=c)\n\nplt.xlabel(r\"incindence angle $\\alpha_1$ [°]\")\nplt.ylabel(r\"deflection angle $\\delta$ [°]\")\nplt.xlim(30,45)\nplt.ylim(25,30)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nFigure 4— Deflection angle as a function of the incidence angle for different wavelengths.\n\n\n\n\n\nThe plots have a general feature, which is that the refractive index is largest at small wavelength (blue colors), while it drops continuously with increasing wavelength towards the red (800 nm). If you would characterize the dependence by the slope, i.e., \\(\\mathrm dn/\\mathrm d\\lambda\\) then all displayed curves show in the visible range\n\n\\(\\frac{\\mathrm dn}{\\mathrm d\\lambda}&lt;0\\), is called normal dispersion\n\nwhile\n\n\\(\\frac{\\mathrm dn}{\\mathrm d\\lambda}&gt;0\\), is called anomalous dispersion\n\nThis wavelength dependence of the refractive index will yield a dependence of the deflection angle on the color of light as well. The change of the deflection angle with the refractive index can be calculated to be\n\\[\\frac{\\mathrm d\\delta}{\\mathrm d n}=\\frac{2\\sin(\\gamma/2)}{\\sqrt{1-n^2\\sin^2(\\gamma/2)}}\\]\ntogether with the relation\n\\[\\frac{\\mathrm d \\delta}{\\mathrm d \\lambda}=\\frac{\\mathrm d\\delta}{\\mathrm d n}\\frac{\\mathrm d n}{\\mathrm d\\lambda}\\]\nwe obtain\n\\[\\frac{\\mathrm d\\delta}{\\mathrm d\\lambda}=\\frac{2\\sin(\\gamma/2)}{\\sqrt{1-n^2\\sin^2(\\gamma/2)}}\\frac{\\mathrm d n}{\\mathrm d \\lambda}.\\]\nThe refraction of white light through a prism splits the different colors composing white light spatially into a colored spectrum. In this process, light with the longest wavelength (red) is deflected the least, while light with the shortest wavelength (violet) is deflected the most. This occurs because the refractive index of the prism material varies with wavelength, a phenomenon known as dispersion.\n\n\n\n\n\n\nFigure 5— Spectrum as created by a prism in the lecture.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Spectrum\n\n\n\n\n\n\n\n\n\n\n\n(b) Prism\n\n\n\n\n\n\n\nFigure 6— Deflection of different wavelengths of light in a prism with normal dispersion.\n\n\n\n\n\n\nThis wavelength-dependent refraction is crucial as it forms the basis for spectroscopy, a powerful analytical technique that measures and records the intensity of light as a function of wavelength. Spectroscopy allows scientists to analyze the composition and properties of matter by examining its interaction with light across different wavelengths.\n\n\n\n\n\n\n\n\n\n\n\n(a) Principle of a prism spectrometer\n\n\n\n\n\n\n\n\n\n\n\n(b) Technical realization of a prism spectrometer\n\n\n\n\n\n\n\nFigure 7— Principle and technical realization of a prism spectrometer.\n\n\n\nDIY prism\nIf you don’t have a prism at home (which most people don’t), you can create a simple substitute using a mirror and a basin of water. Here’s how:\n\nPlace a mirror in a basin of water, partially submerged.\nShine white light from a flashlight onto the mirror.\nObserve the reflected and refracted light, paying special attention to the edges.\n\nFor better results, you can create a small aperture by making a tiny hole in a piece of black paper and placing it in front of the flashlight.\n\n\n\n\n\n\nFigure 8— Home made water prism.\n\n\n\nWhile the dependence of water’s refractive index on wavelength is relatively weak, it’s still sufficient to demonstrate the familiar colors of the rainbow. This phenomenon will be referenced later in our discussion.\n\n\nCode\n#\nh2o=pd.read_csv(\"data/H2O.csv\",delimiter=\",\")\nplt.figure(figsize=(6,4))\nplt.plot(h2o.wl*1000,h2o.n,label=r\"$H_2O$\")\nplt.xlim(300,900)\nplt.ylim(1.3,1.36)\nplt.xlabel(\"wavelength [nm]\")\nplt.ylabel(\"refractive index n\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nFigure 9— Refractive index of water as a function of the wavelength.\n\n\n\n\n\n\n\n\n\n\n\nApplications of prims\n\n\n\n\n\nPrisms are versatile optical components with a wide range of applications across various fields. Here are some common uses of prisms:\n\n\nPorro prisms in traditional binoculars and roof prisms in modern designs serve to correct image inversion and provide a compact form. These prisms enable a longer optical path within a shorter physical length, enhancing magnification while maintaining portability. This design is crucial for both binoculars and some telescopes, offering users powerful magnification in a handheld device.\n\n\n\nRight-angle prisms are the key component in periscopes, redirecting light at 90-degree angles. This simple yet effective design allows viewers to see over obstacles or around corners, making periscopes invaluable in submarines and various military applications where direct line of sight is obstructed.\n\n\n\nCube beamsplitters play a vital role in dividing a single beam of light into two separate beams. This capability is essential in various scientific and medical applications, including interferometry, holography, and optical coherence tomography (OCT). The ability to split light beams precisely opens up numerous possibilities in research and diagnostics.\n\n\n\nRisley prisms, consisting of a pair of rotating wedge prisms, offer precise control over laser beam direction. This technology finds applications in laser scanning, target tracking, and adaptive optics. The ability to steer beams accurately is crucial in fields ranging from military applications to advanced scientific research.\n\n\n\nTotal Internal Reflection (TIR) prisms are a crucial component in Digital Light Processing (DLP) projectors. They direct light from the lamp to the Digital Micromirror Device (DMD) and then to the projection lens, enabling the high-quality image projection that DLP technology is known for.\n\n\n\nIn Single-Lens Reflex (SLR) cameras, pentaprisms play a critical role in the viewfinder system. They flip the image from the lens to appear upright and correctly oriented in the viewfinder, allowing photographers to accurately compose their shots.\n\n\n\nBrewster prisms find use in laser systems for polarization and wavelength separation. Additionally, dispersing prisms can be employed for wavelength tuning in certain laser setups, providing precise control over the laser’s output characteristics.\n\n\n\nIn the realm of telecommunications, prisms are utilized in some fiber optic connectors and switches. They help redirect light between fibers, playing a crucial role in maintaining signal integrity and enabling complex network architectures.\n\n\n\nFresnel lenses, a specialized type of prism, are employed in concentrated solar power systems. These lenses focus sunlight efficiently, contributing to the development of more effective solar energy collection technologies.\n\n\n\nPrisms are an integral part of HUD systems in both automotive and aviation contexts. They project crucial information onto the windshield or a combiner glass, allowing drivers or pilots to access important data without taking their eyes off their primary viewpoint.\n\n\n\nNomarski prisms enhance the capabilities of differential interference contrast microscopy. They increase contrast in transparent specimens, enabling scientists to observe details that would be difficult or impossible to see with conventional microscopy techniques.\n\n\n\nIn some OCT systems, prisms are employed for sample arm scanning and reference arm delay. This application of prisms contributes to the high-resolution imaging capabilities of OCT, which is particularly valuable in medical diagnostics, especially in ophthalmology.",
    "crumbs": [
      "Geometrical Optics",
      "Lecture 3",
      "Optical Elements II - Prims"
    ]
  },
  {
    "objectID": "geometrical-optics/Optical Elements III.html",
    "href": "geometrical-optics/Optical Elements III.html",
    "title": "Optical Elements Part III",
    "section": "",
    "text": "The most important optical elements are lenses, which come in many different flavors. They consist of curved surfaces, which most commonly have the shape of a part of a spherical cap. It is, therefore, useful to have a look at the refraction at spherical surfaces.\n\n\nFor our calculations of the refraction at spherical surfaces, we consider the sketch below.\n\n\n\n\n\n\nFigure 1: Refraction at a curved surface.\n\n\n\nTo derive an imaging equation for a lens, we aim to calculate the distance \\(b\\) and angle \\(\\theta_2\\) at which a ray crosses the optical axis, given its origin at distance \\(a\\) and angle \\(\\theta_1\\). We begin with Snell’s law for the geometry:\n\\[n_{1}\\sin(\\alpha+\\theta_1)=n_{2}\\sin(\\alpha-\\theta_2)\\]\nWe define key relationships:\n\\[\\sin(\\alpha)=\\frac{y}{R}, \\quad \\tan(\\theta_1)=\\frac{y}{a}, \\quad \\tan(\\theta_2)=\\frac{y}{b}\\]\nTo simplify this, we employ the paraxial approximation, which assumes all angles are small. This allows us to use first-order approximations of trigonometric functions, effectively linearizing them:\n\\[\\sin(\\theta) \\approx \\theta+ O(\\theta^{3}), \\quad \\tan(\\theta) \\approx \\theta + O(\\theta^{3}),\\quad \\cos(\\theta)\\approx 1 + O(\\theta^{2})\\]\nThis approach, common in optics, significantly simplifies our calculations while maintaining accuracy for most practical scenarios involving lenses.\nWith the help of these approximations we can write Snell’s law for the curved surface as\n\\[n_1(\\alpha+\\theta_1)=n_2(\\alpha-\\theta_2).\\]\nWith some slight transformation which you will find in the video of the online lecture we obtain, therefore,\n\\[\\theta_2=\\frac{n_2-n_1}{n_2 R}y -\\frac{n_1}{n_2}\\theta_1,\\]\nwhich is a purely linear equation in \\(y\\) and \\(\\theta_1\\).\n\n\n\n\n\n\nParaxial Approximation\n\n\n\n\n\nThe paraxial approximation is a fundamental simplification in optics that assumes all angles are small. This allows us to use linear approximations for trigonometric functions, significantly simplifying calculations while maintaining accuracy for most practical scenarios involving lenses.\nTo visualize the validity of this approximation, let’s examine two plots:\n\nThe first plot compares sin(θ) (blue line) with its linear approximation θ (red dashed line) for angles ranging from 0 to π/2 radians.\nThe second plot shows the absolute error between sin(θ) and θ.\n\nThese plots demonstrate that:\n\nFor small angles (roughly up to 0.5 radians or about 30 degrees), the approximation is very close to the actual sine function.\nThe error increases rapidly for larger angles, indicating the limitations of the paraxial approximation.\n\nIn most optical systems, especially those involving lenses, the angles of incident and refracted rays are typically small enough for this approximation to be valid. However, it’s important to be aware of its limitations when dealing with wide-angle optical systems or scenarios where precision is critical.\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n# Define the range of angles (in radians)\ntheta = np.linspace(0, np.pi/2, 1000)\n\n# Calculate sin(theta) and theta (linear approximation)\nsin_theta = np.sin(theta)\nlinear_approx = theta\n\n# Calculate the absolute error\nerror = np.abs(sin_theta - linear_approx)\n\n# Create the plot with two subplots side by side\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(7.5, 4))\n\n# Plot sin(theta) and theta on the first subplot\nax1.plot(theta, sin_theta, label='sin(θ)', color='blue')\nax1.plot(theta, linear_approx, label='θ', color='red', linestyle='--')\nax1.set_xlabel(r'$\\theta$ [rad]')\nax1.set_ylabel(r'$\\sin(x),x$')\nax1.legend()\n\n# Plot the error on the second subplot\nax2.plot(theta, error, label='Absolute Error', color='green')\nax2.set_xlabel(r'$\\theta$ [rad]')\nax2.set_ylabel('|sin(θ) - θ|')\nax2.legend()\n\n# Adjust the layout and display the plot\nplt.tight_layout()\nplt.show()\n\n\n\n\n\nVisualization of the paraxial approximation plotting the \\(\\sin(\\theta)\\) and the linear approximation \\(\\theta\\) (dashed line) for angles ranging from 0 to \\(\\pi/2\\) radians.\n\n\n\n\n\n\n\nConsider light originating from a point at distance \\(y\\) from the optical axis. We’ll analyze two rays: one traveling parallel to the optical axis and hitting the spherical surface at height \\(y\\), and another incident at \\(y=0\\).\n\n\n\n\n\n\nFigure 2: Image formation at a curved surface.\n\n\n\nApplying our derived formula to these two cases:\nFor the parallel ray (\\(\\theta_1=0\\)):\n\\[\\theta_2=\\frac{n_2-n_1}{n_2}\\frac{y}{R}\\] \\[\\theta_2=\\frac{y+\\Delta y}{b}\\]\nEquating these expressions:\n\\[\\frac{y+\\Delta y}{b}=\\frac{n_2-n_1}{n_2}\\frac{y}{R}\\]\nFor the ray through the center (\\(y=0\\)):\n\\[n_2\\frac{\\Delta y}{b}=n_1\\frac{y}{a}\\]\nCombining these equations yields the imaging equation for a curved surface:\n\\[\\frac{n_1}{a}+\\frac{n_2}{b}=\\frac{n_2-n_1}{R}\\]\nWe can define a new quantity, the focal length, which depends only on the properties of the curved surface:\n\\[f=\\frac{n_2}{n_2-n_1}R\\]\n\n\n\n\n\n\nImaging Equation for Spherical Refracting Surface\n\n\n\nThe sum of the inverse object and image distances equals the inverse focal length of the spherical refracting surface:\n\\[\\frac{n_1}{a}+\\frac{n_2}{b}\\approx\\frac{n_2}{f}\\]\nwhere the focal length of the refracting surface is given by:\n\\[f=\\frac{n_2}{n_2-n_1}R\\]\nin the paraxial approximation.",
    "crumbs": [
      "Geometrical Optics",
      "Lecture 3",
      "Optical Elements III - Lenses"
    ]
  },
  {
    "objectID": "geometrical-optics/Optical Elements III.html#derivation",
    "href": "geometrical-optics/Optical Elements III.html#derivation",
    "title": "Optical Elements Part III",
    "section": "Derivation",
    "text": "Derivation\nFor a lens with refractive index \\(n\\) in air, the focal lengths of the surfaces are:\n\\[\\frac{1}{f_1} = \\frac{1-n}{nR_1}, \\quad \\frac{1}{f_2} = \\frac{n-1}{R_2}\\]\nWhere \\(R_1\\) and \\(R_2\\) are the radii of curvature of the front and back surfaces.\nThe total system matrix is then\n\\[M_{total} = M_3 \\cdot M_2 \\cdot M_1\\]\nAfter multiplication the total matrix is\n\\[\nM=\\begin{bmatrix}\n  1 - \\frac{d \\left(1 - n\\right)}{R_{1}} & d\\\\\n  - \\frac{n-1}{R_{2} } - \\frac{\\left(1 - n\\right) \\left(n - \\frac{d n \\left( n-1\\right)}{R_{2}}\\right)}{R_{1} n} & \\frac{\\left(n - \\frac{d n \\left( n-1\\right)}{R_{2}}\\right)}{n}\n\\end{bmatrix}\n\\]\nwhere the element in the lower left corner is the inverse of the focal length of the thick lens. This can be simplified to the following expression:\n\\[-\\frac{1}{f} = -\\frac{1}{f_2} - \\frac{n}{f_1} -\\frac{d n}{f_1f_2}\\]\nSubstituting the expressions for \\(1/f_1\\) and \\(1/f_2\\):\n\\[\\frac{1}{f} = \\frac{n-1}{R_1} - \\frac{n-1}{R_2} + \\frac{d(n-1)^2}{nR_1R_2}\\]\nFactoring out \\((n-1)\\) gives the final expression for the focal length of a thick lens:\n\\[\\frac{1}{f} = (n-1)\\left[\\frac{1}{R_1} - \\frac{1}{R_2} + \\frac{(n-1)d}{R_1R_2}\\right]\\]\nThis is the Lensmaker’s equation for a thick lens.\nThe construction of ray diagrams for thick lenses is similar to that for thin lenses, but the object and image distances are measured from the principal planes. The magnification is also calculated using the distances from the principal planes. Principal planes are where a thick lens can be treated as an equivalent thin lens. At these planes, the magnification is unity.\nThe derivation of the local of the principle planes will be part of the seminar.\n\n\nCode\n# %% Importing libraries and defining symbols\nfrom sympy import *\nfrom IPython.display import display, Math\n\nn1, n2 , d, R1, R2, f1, f2, f    = symbols('n1 n2 d R1 R2 f1 f2 f')\ninit_session(quiet=True)\ninit_printing()\n\n# %% Definition of matrices\n#\nf1=1/((n2-n1)/R1/n2) ## First spherical refracting surface\nf2=1/((n1-n2)/R2/n1) ## Second spherical refracting surface\n\nM1=Matrix([[1,0],[-1/f1,n1/n2]]) # first refracting surface\nM2=Matrix([[1,n2*d],[0,1]]) # free space\nM3=Matrix([[1,0],[-1/f2,n2/n1]]) # second refracting surface\n\n# %% Thin lens calculation\nM_thin=M3*M1  # first and second refracting surfaces\n#display(Math('1/f ='+ latex(factor(collect(expand(simplify(-M_thin)[1,0]),[1/R1,1/R2],factor)))))\n\n# The result of the matrix multiplication for a thick lens with SymPy\n# %% Thick lens calculation\nM_thick=M3*M2*M1\n\ndisplay(Math('1/f ='+ latex(collect(expand(simplify(-M_thick)[1,0]),[1/R1,1/R2,1/(R1*R2)],factor))))\n\n\n\n\n\n\\(\\displaystyle 1/f =\\frac{n_{1} - n_{2}}{R_{2} n_{1}} - \\frac{n_{1} - n_{2}}{R_{1} n_{1}} + \\frac{d \\left(n_{1} - n_{2}\\right)^{2}}{R_{1} R_{2} n_{1}}\\)",
    "crumbs": [
      "Geometrical Optics",
      "Lecture 3",
      "Optical Elements III - Lenses"
    ]
  },
  {
    "objectID": "geometrical-optics/Imaging Errors.html",
    "href": "geometrical-optics/Imaging Errors.html",
    "title": "Imaging Errors",
    "section": "",
    "text": "During our derivation of the imaging equation for lenses and the lens-maker equation we have been working under the paraxial approximation. This approximation stated, that all rays are close to the optical axis and therefore make only small angles with the surface normals of the curved surfaces of lenses (but also mirrors). If we violate this approximation, i.e. if we use rays, which are incident for from the optical axis or strongly inclined, then we end up with reflections and refraction which do not obey the imaging equation. In addition we have seen that light propagation for different colors is subject to different refractive indices (remember the prism). Thus we will induce aberrations, related to color. According to Seidel, aberration are classified the following way"
  },
  {
    "objectID": "geometrical-optics/Imaging Errors.html#chromatic-aberration",
    "href": "geometrical-optics/Imaging Errors.html#chromatic-aberration",
    "title": "Imaging Errors",
    "section": "Chromatic Aberration",
    "text": "Chromatic Aberration\nChromatic Aberration are based on the fact that light of different color has a different speed of propgation and thus also a different refractive index. We experienced that also for the prism, where it was useful to create a spectrograph. Here it is causing colored edges in you image, which you do not want.\nAs the refractive index for shorter wavelength is typically higher, we expect that the blue color has a shorter focal distance than the red color.\n\n\n\n\n\n\n\n\n\n\n\n(a) Sketch\n\n\n\n\n\n\n\n\n\n\n\n\n\n(b) Lecture\n\n\n\n\n\n\n\n\n\n\n\n(c) Rendered\n\n\n\n\n\n\n\nFigure 1— Chromatic aberration. Left: Sketch of the chromatic aberration, focusing red light less strong than blue. Middle: Image from the lecture. Right: Rendered image using the refractive index for BK7 glass.\n\n\n\nHere is a plot for the variation of the focal distance of a lens with a radius of curvature of 100 mm as a function of the wavelength for three different glasses.\n\n\nCode\nbk7=pd.read_csv(\"data/BK7.csv\",delimiter=\",\")\nsf10=pd.read_csv(\"data/SF10.csv\",delimiter=\",\")\nfk51a=pd.read_csv(\"data/FK51A.csv\",delimiter=\",\")\n\nwavelengths = bk7.wl*1000\nn_bk7 = bk7.n\n\nR = 100  # radius of curvature in mm\ny_max = 50  # max height of lens\n\ndef f(n,R):\n    return 1/(n-1)*R/2\n\nplt.figure(figsize=get_size(8,8))\nplt.plot(bk7.wl*1000, f(bk7.n,R),label=\"BK7\")\nplt.plot(sf10.wl*1000, f(sf10.n,R),label=\"SF10\")\nplt.plot(fk51a.wl*1000, f(fk51a.n,R),label=\"FK51a\")\nplt.grid(True)\nplt.xlabel(r'wavelength $\\lambda$ [nm]')\nplt.ylabel('focal distance f [mm]')\nplt.xlim(400,700)\nplt.legend()\n#plt.ylim(94,98)\nplt.show()\n\n\n\n\n\nFocal distance of a Bk7, SF10 and FK51a lens with a radius of curvature of 100 mm as a function of the wavelength.\n\n\n\n\nSuch a chromatic aberrations may be corrected by using a system of two lenses as shown below.\n\n\n\n\n\n\nFigure 2— Correction of chromatic aberration by a lens doublet with a convex and a a concave lens.\n\n\n\nChromatic aberration can be corrected by using an achromatic lens. Achromatic lenses are typically constructed by combining two lenses with different optical properties: a biconvex lens made of crown glass (lower dispersion) bonded to a biconcave lens made of flint glass (higher dispersion). This combination allows for the correction of chromatic aberration. Each lens \\(i\\) has a focal length according to the lensmaker equation:\n\\[\n\\frac{1}{f_i}=(n_i-1)\\rho_i\n\\]\nwhere \\(\\rho_i\\) is given by:\n\\[\n\\rho_i=\\frac{(R_{i2}-R_{i1})}{R_{i1}R_{i2}}\n\\]\nFor a system of two lenses in contact, the total refractive power is:\n\\[\n\\frac{1}{f}=(n_1-1)\\rho_1+(n_2-1)\\rho_2\n\\]\nFor color correction, we require equal focusing of red and blue light:\n\\[\n(n_{1r}-1)\\rho_1+(n_{2r}-1)\\rho_2=(n_{1b}-1)\\rho_1+(n_{2b}-1)\\rho_2\n\\]\nThis transforms to:\n\\[\n\\frac{\\rho_1}{\\rho_2}=-\\frac{n_{2b}-n_{2r}}{n_{1b}-n_{1r}}\n\\]\nFor the specific geometry shown in the achromat figure where:\n\n\\(R_{12}=R_{21}\\) (common radius at contact surface)\n\\(R_{11}=R_1=-R_{12}=-R_{21}\\)\n\\(R_{22}=R_2\\)\n\nwe can express \\(\\rho_1\\) and \\(\\rho_2\\) as:\n\\[\n\\rho_1=\\frac{2}{R_1} \\quad \\text{and} \\quad \\rho_2=\\frac{-1}{R_1}+\\frac{1}{R_2}\n\\]\nSubstituting these into the color correction condition gives us the relationship between \\(R_1\\) and \\(R_2\\) needed for an achromatic doublet. Substituting the expressions for \\(\\rho_1\\) and \\(\\rho_2\\) into:\n\\[\n\\frac{\\rho_1}{\\rho_2}=-\\frac{n_{2b}-n_{2r}}{n_{1b}-n_{1r}}\n\\]\nwe get:\n\\[\n\\frac{2/R_1}{-1/R_1+1/R_2}=-\\frac{n_{2b}-n_{2r}}{n_{1b}-n_{1r}}\n\\]\nLet’s define the dispersion ratios (typically called V-numbers or Abbe numbers): \\[\nV_1=\\frac{n_{1r}-1}{n_{1b}-n_{1r}} \\quad \\text{and} \\quad V_2=\\frac{n_{2r}-1}{n_{2b}-n_{2r}}\n\\]\nThen, after some algebra, the relationship between \\(R_1\\) and \\(R_2\\) becomes:\n\\[\n\\frac{R_2}{R_1}=1+2\\frac{V_2(n_{1r}-1)}{V_1(n_{2r}-1)}\n\\]\nThis equation determines the ratio of radii needed to achieve an achromatic doublet for the chosen glass materials.\n\n\n\n\n\n\nChromatic Aberration\n\n\n\nAn optical aberration caused by the wavelength-dependent refractive index of materials, resulting in different colors focusing at different distances from the lens, typically with blue light focusing closer to the lens than red light."
  },
  {
    "objectID": "geometrical-optics/Imaging Errors.html#spherical-aberration",
    "href": "geometrical-optics/Imaging Errors.html#spherical-aberration",
    "title": "Imaging Errors",
    "section": "Spherical Aberration",
    "text": "Spherical Aberration\nThe spherical abberation arises due to the fact that we have always considered a simplification of the angluar functions to their first order Taylor series expansion. If the angles of incidence on the spherical surfaces get to large, we cannot do that anymore and need to consider higher order corrections.\nThe result is that parallel rays which are far from the optical axis are not imaged into the same focal point as the paraxial rays, but to points closer to the lens. You might have all seen such effect also in the case of your empty coffee cup, when the sunlight enters and causes a so-called caustics. This pattern, you observe there is also the result of a soherical aberration. The image below shows the spherical aberration of a lens.\n\n\n\n\n\n\n\n\n\n\n\n(a) Sketch\n\n\n\n\n\n\n\n\n\n\n\n(b) Experimental\n\n\n\n\n\n\n\nFigure 3— Spherical aberration. Left: Schematic illustration showing how parallel rays at different distances from the optical axis focus at different points. Right: Experimental demonstration from the lecture.\n\n\n\nTo be a bit more qauntitative, we would like to reconsider the refraction at a single spherical surface as depicted in the image below.\n\n\n\n\n\n\nFigure 4— Spherical aberration: Theoretical ray tracing showing the focal point variation with incident ray height.\n\n\n\nFor spherical surfaces, we can derive a more accurate expression for the focal length using the following relations: \\[\\sin(\\beta)=\\frac{\\sin(\\alpha)}{n}, \\quad \\sin(\\alpha)=\\frac{h}{R}, \\quad \\alpha=\\beta+\\gamma\\]\nUsing these relations, we obtain \\(f=R+b\\) and \\(b=R\\sin(\\beta)/\\sin(\\gamma)\\), which can be transformed into:\n\\[\nf=R\\left [ 1+ \\frac{1}{n\\cos(\\beta)-\\cos(\\alpha)}\\right ]\n\\]\nBy replacing the cosines with their corresponding expressions, we get:\n\\[\nf=R\\left [ 1+ \\frac{1}{n\\sqrt{1-\\frac{h^2}{n^2 R^2}}-\\sqrt{1-\\frac{h^2}{R^2}}}\\right ]\n\\]\nExpanding the square roots leads to:\n\\[\nf=R\\left [ \\frac{n}{n-1}- \\frac{h^2}{2n(n-1)R^2} \\right]\n\\]\nThis result reveals that the focal length depends on the height \\(h\\) at which the ray is incident on the spherical surface, similar to the case of concave mirrors. The second term in the square brackets represents this height-dependent contribution, which reduces the focal length when \\(h\\neq 0\\).\nFrom these relations, we can derive an imaging equation for a single spherical surface:\n\\[\n\\frac{1}{a}+\\frac{n}{b}=\\frac{n-1}{R}+h^2\\left [ \\frac{1}{2a}\\left ( \\frac{1}{a}+\\frac{1}{R}\\right )^2 +\\frac{n}{2b}\\left ( \\frac{1}{R}-\\frac{1}{b}\\right )^2\\right]\n\\]\nThis complex equation for a single surface demonstrates that the image is no longer formed on a plane; instead, its location depends on both \\(R\\) and \\(h\\). This height dependence for a single surface manifests in various image distortions, including field curvature.\n\n\n\n\n\n\nSpherical Aberration\n\n\n\nAn optical aberration where rays passing through a lens at different distances from the optical axis focus at different points along the axis, with rays through the outer regions of the lens focusing closer to the lens than rays passing near the center."
  },
  {
    "objectID": "geometrical-optics/Imaging Errors.html#field-curvature",
    "href": "geometrical-optics/Imaging Errors.html#field-curvature",
    "title": "Imaging Errors",
    "section": "Field Curvature",
    "text": "Field Curvature\nThe field curvature is related to our calculations of the spherical abberation. We have seen there, that the focal distance depends on the height \\(h\\) of the rays over the optical axis. This means also means that the image plane is actually not anymore a plane but a curved surface as shown below. The rays incident from point \\(A_0\\) and \\(A_1\\) do not meet in the same plane. This plane is even different for meridional and saggital rays. This typically results in the fact, that you may have the center of the image in focus, but not the edges or vice versa.\n\n\n\n\n\n\n\n\n\n\n\n(a) Sketch\n\n\n\n\n\n\n\n\n\n\n\n(b) Experimental\n\n\n\n\n\n\n\nFigure 5— Field curvature in optical systems. Left: Schematic diagram showing how a flat object plane is imaged onto a curved image surface (Petzval surface) rather than a flat image plane. This causes different regions of the image to focus at different distances from the lens. Right: Experimental demonstration showing how either the center or the edges of the image can be in focus, but not simultaneously, when using a flat detector. This aberration is particularly noticeable in wide-field imaging systems with simple lenses.\n\n\n\n\n\n\n\n\n\nField Curvature\n\n\n\nAn optical aberration where the image of a flat object is formed on a curved surface rather than a plane, causing the center and edges of the image field to not be simultaneously in focus on a flat detector or screen."
  },
  {
    "objectID": "geometrical-optics/Imaging Errors.html#coma",
    "href": "geometrical-optics/Imaging Errors.html#coma",
    "title": "Imaging Errors",
    "section": "Coma",
    "text": "Coma\nWhile our previous discussion focused on rays parallel to the optical axis at varying distances, significant aberrations also occur for rays emanating from off-axis object points (both at finite and infinite distances). One important example of such an aberration is “coma.”\nIn the case of coma, rays entering the lens at different heights with an angle to the optical axis do not converge to a single point in the image plane. Instead, they create a characteristic comet-shaped intensity distribution, where the light is asymmetrically distributed with a bright head and a diffuse tail pointing radially outward from the optical axis. This asymmetric distribution occurs because rays passing through different zones of the lens experience different effective magnifications, leading to the distinctive comet-like shape that gives this aberration its name.\nThe severity of coma typically increases with the distance from the optical axis and with larger apertures, making it particularly problematic in wide-field imaging systems or when using large-aperture optics.\n\n\n\n\n\n\n\n\n\n\n\n(a) Sketch\n\n\n\n\n\n\n\n\n\n\n\n(b) Experimental\n\n\n\n\n\n\n\nFigure 6— Coma aberration in optical systems. Left: Schematic illustration showing how oblique rays entering the lens at different heights focus at different positions in the image plane, creating a characteristic comet-shaped blur (coma). The rays passing through different zones of the lens have different effective focal lengths and magnifications, resulting in the asymmetric image formation. Right: Experimental demonstration from the lecture showing the characteristic comet-like shape of the aberration, where the intensity distribution is asymmetric around the central image point.\n\n\n\n\n\n\n\n\n\nComa\n\n\n\nAn optical aberration where rays from an off-axis point source passing through different zones of a lens focus at different positions in the image plane, creating a characteristic comet-shaped intensity distribution with a bright head and a diffuse tail pointing radially outward."
  },
  {
    "objectID": "geometrical-optics/Imaging Errors.html#astigmatism",
    "href": "geometrical-optics/Imaging Errors.html#astigmatism",
    "title": "Imaging Errors",
    "section": "Astigmatism",
    "text": "Astigmatism\nAstigmatism also occurs when imaging point sources located away from the optical axis. To understand this effect, we can analyze the rays from such a source by separating them into two categories:\n\nRays in the vertical (meridional) plane\nRays in the perpendicular (sagittal) plane\n\nAnalysis shows that meridional rays focus at a point closer to the lens compared to sagittal rays. This difference in focal positions creates a characteristic pattern in the image: when moving a screen through the focal region, the image of a point source transforms from a horizontal ellipse, through a circular point (at the circle of least confusion), to a vertical ellipse. This variation in image shape occurs because the focal surfaces for the meridional and sagittal rays are curved differently and intersect only at points along the optical axis.\nThe distance between these two focal surfaces increases with the distance from the optical axis, making astigmatism particularly noticeable for off-axis object points. This aberration is especially significant in systems where the object plane is not perpendicular to the optical axis or when using simple spherical lenses for wide-field imaging.\nFor an extended image as shown below, this results in the sperate focusing of vertical (left) and horizontal lines (right) in the image.\n\n\n\n\n\n\n\n\n\n\n\n(a) Sketch\n\n\n\n\n\n\n\n\n\n\n\n\n\n(b) Vertical Focus\n\n\n\n\n\n\n\n\n\n\n\n(c) Horizontal Focus\n\n\n\n\n\n\n\nFigure 7— Astigmatism in optical systems. Left: Schematic diagram illustrating how a tilted lens creates different focal planes for rays in different meridional planes. The tangential (vertical) and sagittal (horizontal) rays focus at different distances from the lens. Middle: Experimental image showing the focusing of vertical lines of a test object (letter “F”) at one focal position. Right: The same object at a different focal position where horizontal lines are in focus. This demonstrates how astigmatism causes different focal planes for vertical and horizontal features when a lens is tilted relative to the optical axis. The inability to focus both orientations simultaneously is a characteristic feature of astigmatic aberration.\n\n\n\nThis distortion, i.e. the elliptical shape of the focus has been used advatageously in single molecule microscopy to locate their position alsong the optical axis, which is typically a challenge for optical microscopy.\n\n\n\n\n\n\nAstigmatism\n\n\n\nAn optical aberration where rays from an off-axis point source focusing in two perpendicular planes (meridional and sagittal) have different focal lengths, resulting in image points that appear as ellipses oriented either horizontally or vertically, depending on the observation plane.\n\n\n\nDistortions\nBarrel or cushion shaped distortions in the image are found when inserting apertures in the optical path. This results in the removal of certain ray path ending up in field distortions.\n\n\n\n\n\n\n\n\n\n\n\n(a) Cushion Distortion\n\n\n\n\n\n\n\n\n\n\n\n(b) Barrel Distortion\n\n\n\n\n\n\n\nFigure 8— Geometric distortions in optical systems. Left: Cushion (or pincushion) distortion, where the magnification increases with distance from the optical axis, causing straight lines to bow inward and creating a cushion-like appearance. Right: Barrel distortion, where the magnification decreases with distance from the optical axis, causing straight lines to bow outward, resembling the shape of a barrel. These distortions maintain image sharpness but alter the geometric shape of the image, particularly noticeable in architectural photography or when imaging regular grid patterns.\n\n\n\nGeometric distortions arise from the position of the aperture relative to the lens and its effect on ray paths. This mechanism can be understood by analyzing how different rays contribute to image formation:\nWhen an aperture is placed behind the lens, rays that pass through create an image point \\(M_1\\) that is farther from the optical axis than the ideal image point \\(M\\) (where \\(M\\) is determined by the central ray from object point \\(A_0\\)). As the object point moves farther from the optical axis, the displacement between \\(M_1\\) and \\(M\\) increases proportionally. This progressive displacement transforms a regular grid pattern into a cushion (or pincushion) shape.\nConversely, when the aperture is placed in front of the lens, the opposite effect occurs. The rays that pass through the aperture create an image point closer to the optical axis than the ideal image point, resulting in barrel distortion. The magnitude of this displacement also increases with distance from the optical axis.\nThese theoretical predictions are confirmed by experimental observations, where:\n\nA rear aperture produces cushion distortion, causing straight lines to bow inward\nA front aperture produces barrel distortion, causing straight lines to bow outward\n\nThe severity of these distortions depends on both the aperture position and the distance of object points from the optical axis.\n\n\n\n\n\n\nFigure 9— Cushion (left) and barrel (right) type of distortions.\n\n\n\n\n\n\n\n\n\nCushion Distortion\n\n\n\nCushion Distortion (also called Pincushion Distortion) - An optical aberration where straight lines appear to bow inward toward the center of the image, like the sides of a cushion or pincushion. This type of distortion is typically seen in telephoto lenses and makes the center of the image appear to be pinched inward.\n\n\n\n\n\n\n\n\nBarrel Distortion\n\n\n\nBarrel Distortion - An optical aberration where straight lines appear to bow outward from the center of the image, like a barrel shape. This type of distortion is common in wide-angle lenses and makes the center of the image appear to bulge outward.\n\n\n\n\n\n\n\n\nAberration Characterization and Zernike Polynomials\n\n\n\n\n\nThe Zernike polynomials are a set of orthonormal polynomials that are widely used in optics to describe wavefronts and to characterize optical aberrations. As we did not discuss wavefronts and waves yet, this is a more advanced topic here and only for information. Zernike polynomials are defined over the unit disk and are particularly useful because they are orthogonal under the inner product, which involves integration over the unit circle. This makes them suitable for decomposing a wavefront into a sum of orthogonal modes, each representing a different type of aberration.\nThe general form of the Zernike polynomials can be expressed in polar coordinates \\((\\rho, \\phi)\\), where \\(\\rho\\) is the radial distance from the origin (normalized to the unit circle) and \\(\\phi\\) is the azimuthal angle. The Zernike polynomials are defined as:\n\\[\nZ_n^m(\\rho, \\phi) =\n\\begin{cases}\nR_n^m(\\rho) \\cos(m\\phi) & \\text{for } m \\geq 0 \\\\\nR_n^{|m|}(\\rho) \\sin(|m|\\phi) & \\text{for } m &lt; 0\n\\end{cases}\n\\]\nwhere \\(n\\) is a non-negative integer, \\(m\\) is an integer such that \\(n - |m|\\) is even and \\(0 \\leq |m| \\leq n\\), and \\(R_n^m(\\rho)\\) is the radial polynomial given by:\n\\[\nR_n^m(\\rho) = \\sum_{k=0}^{\\frac{n-m}{2}} \\frac{(-1)^k (n-k)!}{k! \\left(\\frac{n+m}{2} - k\\right)! \\left(\\frac{n-m}{2} - k\\right)!} \\rho^{n-2k}\n\\]\nThe radial polynomials \\(R_n^m(\\rho)\\) are only dependent on the radial distance \\(\\rho\\), and they modulate the angular functions \\(\\cos(m\\phi)\\) and \\(\\sin(|m|\\phi)\\) that describe the azimuthal variation of the wavefront.\nThe Zernike polynomials are indexed in several ways, with one common method being the Noll index, which provides a single index \\(j\\) to each polynomial. Another method uses the pair \\((n, m)\\) to index the polynomials, where \\(n\\) indicates the order of the polynomial and \\(m\\) its azimuthal frequency.\nThese polynomials are particularly useful in optics and ophthalmology for describing the shape of optical wavefronts and the aberrations of optical systems, including the human eye. They allow for the decomposition of a complex wavefront into simpler, orthogonal components, each corresponding to a specific type of aberration, such as defocus, astigmatism, coma, etc.\nThe plots below visualize the Zernike Polynomials up to a certain order.\n\n\nCode\ndef radial_polynomial(n, m, rho):\n    \"\"\"\n    Compute the radial component of the Zernike polynomial.\n    \"\"\"\n    R = np.zeros_like(rho)\n    for k in range((n - abs(m)) // 2 + 1):\n        R += ((-1)**k * sp.factorial(n - k) /\n              (sp.factorial(k) * sp.factorial((n + abs(m)) // 2 - k) *\n              sp.factorial((n - abs(m)) // 2 - k))) * rho**(n - 2*k)\n    return R\n\ndef zernike_polynomial(n, m, rho, phi):\n    \"\"\"\n    Compute the Zernike polynomial.\n    \"\"\"\n    if m &gt;= 0:\n        return radial_polynomial(n, m, rho) * np.cos(m * phi)\n    else:\n        return radial_polynomial(n, -m, rho) * np.sin(-m * phi)\n\nx = np.linspace(-1, 1, 400)\ny = np.linspace(-1, 1, 400)\nxx, yy = np.meshgrid(x, y)\nrho = np.sqrt(xx**2 + yy**2)\nphi = np.arctan2(yy, xx)\n\nmask = rho &gt; 1\nrho[mask] = np.nan\n\nfig, axs = plt.subplots(3, 6, figsize=(8, 4))\naxs = axs.flatten()\n\nindex = 0\nfor n in range(6):\n    for m in range(-n, n+1, 2):\n        if index &gt;= len(axs):\n            break\n        Z = zernike_polynomial(n, m, rho, phi)\n        Z[mask] = np.nan  # Apply mask\n        ax = axs[index]\n        c = ax.imshow(Z, extent=(-1, 1, -1, 1), origin='lower')\n        ax.set_title(f'n={n}, m={m}')\n        ax.axis('off')\n        index += 1\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "geometrical-optics/Optical Elements I.html",
    "href": "geometrical-optics/Optical Elements I.html",
    "title": "Optical Elements Part I",
    "section": "",
    "text": "When light radiates from a point \\(P\\) and reflects off a mirror, as shown in the image, the reflected rays diverge but appear to originate from a point \\(P'\\) located behind the mirror. According to the law of reflection, this image point is positioned at the same distance behind the mirror as the original object point is in front of it. As a result, an observer receiving these reflected rays, such as on their retina, perceives the point as if it were situated behind the mirror, even though no light actually travels behind the mirror surface.\n\n\n\n\n\n\n\n\n\n\n\n(a)\n\n\n\n\n\n\n\n\n\n\n\n(b)\n\n\n\n\n\n\n\nFigure 1: Image formation on a plane mirror.\n\n\n\nWhen multiple points of an object emit light towards the mirror, this principle applies to each point. As a result, the entire object appears as an image behind the mirror. Since each point of the image is equidistant from the mirror as its corresponding object point, the image has the same size as the object. This leads to the definition of magnification as:\n\\[\nM=\\frac{h_{\\text{image}}}{h_{\\text{object}}}\n\\]\n\n\n\n\n\n\nFigure 2: Image formation on a plane mirror.\n\n\n\n\n\n\n\n\n\nVirtual Images\n\n\n\nA virtual image is an optical illusion where light rays appear to come from a point, but don’t actually converge there. Unlike real images, virtual images can’t be projected onto a screen. They’re commonly seen in plane mirrors, convex mirrors, and when objects are closer to a lens than its focal point. Remember: for virtual images, light rays only seem to originate from the image when traced backwards.\n\n\n\n\n\n\n\n\nReal Images\n\n\n\nA real image forms when light rays actually meet at a point after reflection or refraction. These images can be projected onto a screen because light physically passes through the image location. Real images are often inverted and occur with concave mirrors and lenses when objects are beyond the focal point. Key point: real images involve actual convergence of light rays.\n\n\n\n\n\nFor a concave mirror (where the reflecting surface is on the inside of the spherical curve), applying the law of reflection yields interesting results. Light rays parallel to the optical axis, at a distance \\(h\\) from it, are reflected towards the axis and intersect it at a specific point \\(F\\). Due to the mirror’s symmetry, a parallel ray on the opposite side of the axis will also converge to this same point \\(F\\).\n\n\n\n\n\n\nFigure 3: Reflection of a parallel ray incident at a height \\(h\\) from the optical axis on a concave mirror.\n\n\n\nWe may calculate the position of the point \\(F\\), e.g. the distance from the mirror surface point \\(O\\), by applying the law of reflection. If the spherical mirror surface has a radius \\(R\\), then the distance between the center of the sphere \\(M\\) and the point \\(F\\) is given by\n\\[FM=\\frac{R}{2\\cos(\\alpha)}\\]\nTherefore, we can also calculate the distance of the mirror surface from the point \\(F\\), which results in\n\\[\\begin{equation}\nOF=R\\left (1-\\frac{1}{2\\cos(\\alpha)}\\right)=f\n\\end{equation}\\]\nThis distance is the so-called focal length of the concave mirror \\(f\\). For small angle \\(\\alpha\\), the above equation yields the so called paraxial limit (all angles are small and the rays are close to the optical axis). In this limit we find \\(\\cos(\\alpha)\\approx 1\\) and the focal length becomes \\(f=R/2\\). If we replace the cosine function by \\(\\cos(\\alpha)=\\sqrt{1-\\sin^2(\\alpha)}\\) with \\(\\sin(\\alpha)=h/R\\), we find\n\\[\\begin{equation}\nf=R\\left [ 1-\\frac{R}{2\\sqrt{R^2-h^2}}\\right ]\n\\end{equation}\\]\nThis equation is telling us, that the focal distance is not a single value for a concave mirror. The focal distance rather changes with the distance \\(h\\) from the optical axis. If \\(h\\) approaches \\(R\\) the focal length become shorter.\n\n\n\n\n\n\nFocal Length of a Concave Spherical Mirror\n\n\n\n\n\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Set up the plot\nfig,(ax1,ax2)=plt.subplots(1,2,figsize=(7, 3))\n\n\nax1.axhline(y=0, color='k', linestyle='--', linewidth=0.5)\nax1.axvline(x=0, color='k', linestyle='--', linewidth=0.5)\n\n# Define the spherical mirror\nradius = 4\n\ntheta = np.linspace(-np.pi/3, np.pi/3, 100)\nx = radius * np.sin(theta)\ny = radius * (1 - np.cos(theta))\n\n# Plot the spherical mirror\nax1.plot(x, y, 'b-', linewidth=2, label='Spherical Mirror')\n\n# Calculate and plot the paraxial focal point\nparaxial_focal_length = radius / 2\nax1.plot([0], [paraxial_focal_length], 'ro', markersize=5, label='Paraxial Focal Point')\n\ndef reflect_ray(x0, y0):\n    xc, yc = 0, radius\n\n    # Normal vector\n    nx, ny = x0 - xc, y0 - yc\n    norm = np.sqrt(nx**2 + ny**2)\n    nx, ny = nx/norm, ny/norm\n\n    ix, iy = 0, -1\n\n    # Reflected ray direction\n    dot_product = 2 * (ix*nx + iy*ny)\n    rx, ry = ix - dot_product*nx, iy - dot_product*ny\n\n    return rx, ry\n\n# Plot several reflected rays\nnum_rays = 10\nfor x0 in np.linspace(-3, 3, num_rays):\n    y0 = radius - np.sqrt(radius**2 - x0**2)\n\n    # Incident ray\n    ax1.plot([x0, x0], [5, y0], 'k-', linewidth=1)\n\n    # Reflected ray\n    rx, ry = reflect_ray(x0, y0)\n    t = (0 - x0) / rx  # parameter to reach x=0\n    x1, y1 = x0 + t*rx, y0 + t*ry\n    ax1.plot([x0, x1], [y0, y1], 'k-', linewidth=1)\n\nax1.set_xlabel('h')\nax1.set_ylabel('y')\nax1.grid(True, linestyle=':', alpha=0.7)\nax1.axis('equal')\n\n\ndef focal_length(h, R):\n    return R * (1 - R / (2 * np.sqrt(R**2 - h**2)))\n\nR = 4  # Radius of curvature\nh = np.linspace(0, R*0.99, 1000)  # Range of h values (avoiding h=R which would cause division by zero)\n\nf = focal_length(h, R)\n\nax2.plot(h, f, 'b-', linewidth=2)\n\nax2.axhline(y=R/2, color='r', linestyle='--', label='Paraxial focal length (R/2)')\n\nax2.set_xlabel('h')\nax2.set_ylabel('f')\nax2.grid(True, linestyle=':', alpha=0.7)\n\nax2.set_ylim(0, R/2 * 1.1)\n\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nFigure 4: Spherical mirror of radius \\(R=4\\) reflecting parallel rays, showing spherical aberration and focal distance as a function of the distance from the optical axis \\(h\\).\n\n\n\n\n\n\n\n\nTo obtain now an equation which predicts the point at which the reflected ray intersects the optical axis if it emerged at a point \\(A\\), we just consider the following sketch.\n\n\n\n\n\n\nFigure 5: Image formation on a concave mirror.\n\n\n\nFor this situation, we can write down immediately the following relations\n\\[\\delta=\\alpha+\\gamma\\]\n\\[\\gamma+\\beta=2\\delta\\]\nFurther under the assumption of small angles (paraxial approximation) we can write down\n\\[\\tan(\\gamma) \\approx \\gamma = \\frac{h}{g}\\] \\[\\tan(\\beta) \\approx \\beta = \\frac{h}{b}\\] \\[\\sin(\\delta) \\approx \\delta = \\frac{h}{R}\\]\nfrom which we obtain\n\\[\\frac{h}{g}+\\frac{h}{b}=2\\frac{h}{R}\\]\nand by divding by \\(h\\) finally the imaging equation:\n\\[\\frac{1}{g}+\\frac{1}{b}= \\frac{2}{R}= \\frac{1}{f}\\]\nwhere we have used the focal length \\(f=R/2\\). This equation has some surprising property. It is completely independent of \\(h\\) and \\(\\gamma\\). That means all points in a plane at a distance \\(g\\) are images into a plane at a distance \\(b\\). Both planes are therefore called conjugated planes.\n\n\n\n\n\n\nImaging Equation Concave Mirror\n\n\n\nThe sum of the inverse object and image distances equals the inverse focal length of the cocave mirror.\n\\[\\frac{1}{g}+\\frac{1}{b}\\approx\\frac{1}{f}\\]\n\n\nThis equation now helps to construct the image of an object in front of a concave mirror and we may define 3 different rays to identify the size of an image \\(h_{\\text{image}}\\) from the size of an object \\(h_{\\text{object}}\\).\n\n\n\n\n\n\nFigure 6: Image formation on a concave mirror.\n\n\n\nIn the diagram above, three key rays are used to construct the image:\n\nRed ray: Parallel to optical axis → reflects through focal point\nGreen ray: Through focal point → reflects parallel to optical axis\nCentral ray: Through center of curvature → reflects back along same path\n\nThe behavior of these reflected rays determines the nature of the image:\n\nIf the rays intersect on the same side of the mirror as the object, a real image forms. This image is inverted, as shown in the sketch.\nIf the rays diverge after reflection, they appear to intersect behind the mirror, creating a virtual image. This image is upright and located behind the mirror, though no actual ray intersection occurs.\n\nThe point where these rays meet (or appear to meet) determines the image size. By drawing a ray from the object’s tip through the mirror’s center (point O), we can easily determine the image height h_image. As an exercise, consider how this construction demonstrates that the magnification of a concave mirror is given by\n\\[ \\frac{h_{\\text{image}}}{h_{\\text{object}}}=-\\frac{b}{g}=M\\]\nThis ratio indeed represents the magnification \\(M\\). The negative sign in the expression reflects an important optical property: for real images formed by concave mirrors, the image is inverted relative to the object. This inversion is mathematically represented by the negative magnification value. Conversely, a positive magnification would indicate an upright image, which occurs with virtual images.\nWith the help of the imaging equation and the magnification we may in general differentiate between the following general situations:\n\n\n\n\n\n\n\n\n\nObject Distance\nImage Characteristics\nImage Position\nMagnification\n\n\n\n\n\\(g &gt; 2f\\)\nReal, inverted, smaller\nBetween f and 2f\n\\(|m|\\) &lt; 1\n\n\n\\(g = 2f\\)\nReal, inverted, same size\nAt 2f\n\\(|m|\\) = 1\n\n\n\\(f &lt; g &lt; 2f\\)\nReal, inverted, larger\nBeyond 2f\n\\(|m|\\) &gt; 1\n\n\n\\(g = f\\)\nImage at infinity\nAt infinity\nN/A\n\n\n\\(g &lt; f\\)\nVirtual, upright, larger\nBehind mirror\n\\(|m|\\) &gt; 1\n\n\n\n\n\n\n\n\n\nParabolic Mirrors Focus Parallel Rays\n\n\n\n\n\nWe would like to show in the following, that a parabolic mirror is a shape which reflects all light rays parallel to the principal axis to a single point, the focus. This is a fundamental property of parabolic mirrors and is used in many optical systems, such as telescopes, satellite dishes, and car headlights.\nFor this purpose, we would like to use Fermat’s principle. We examine a light ray originating from a point \\(x,y_0\\) and travelling parallel to the principal axis. The light ray is reflected at a point \\((x,y)\\) on the mirror and travels to the focus at \\((0,p)\\). The light path is therefore consisting out of two linear segments \\(A\\) and \\(B\\) for which we have to calculate the time of travel. The total duration of the light’s journey is then: \\[\nt = t_A + t_B\n\\]\nwhere:\n\n\\(t_A\\) is the time taken to travel from \\(x,y_0\\) to the mirror.\n\\(t_B\\) is the time taken to travel from \\((x,y)\\) to \\((0,p)\\).\n\n\n\nThe distance covered in path A is equal to \\(y_0 - y\\), where \\(y\\) represents the y-coordinate of the point where the ray meets the mirror. Consequently, the time taken for the light to traverse path A can be expressed as:\n\\[\nt_A = \\frac{y_0 - y}{c}\n\\]\nIn this equation, \\(c\\) represents the speed of light in the medium.\n\n\n\nAfter reflection, the light ray travels from the point \\((x, y)\\) on the mirror’s surface to the focal point located at \\((0, p)\\). The length of this segment of the path can be calculated using the distance formula:\n\\[\n\\sqrt{x^2 + (y - p)^2}\n\\]\nConsequently, the time required for the light to traverse path B is expressed as:\n\\[\nt_B = \\frac{\\sqrt{x^2 + (y - p)^2}}{c}\n\\]\n\n\n\nThe total time for the light ray’s journey is the sum of times for paths A and B:\n\\[\nt = \\frac{y_0 - y}{v} + \\frac{\\sqrt{x^2 + (y - p)^2}}{c}\n\\]\nAccording to Fermat’s principle, all light rays should take the same time. We can express this by setting the total time equal to a constant \\(t_c\\):\n\\[\n\\frac{y_0 - y}{v} + \\frac{\\sqrt{x^2 + (y - p)^2}}{v} = t_c\n\\]\nFor a ray traveling along the y-axis, reflecting at \\((0, 0)\\), the total distance is \\(y_0 + p\\). The time for this ray is:\n\\[\n\\frac{y_0 + p}{c}\n\\]\nThis gives us \\(t_c = \\frac{y_0 + p}{c}\\). Substituting into our general equation:\n\\[\n\\frac{y_0 - y}{v} + \\frac{\\sqrt{x^2 + (y - p)^2}}{c} = \\frac{y_0 + p}{c}\n\\]\nMultiplying by \\(c\\) and rearranging:\n\\[\ny_0 - y + \\sqrt{x^2 + (y - p)^2} = y_0 + p\n\\]\n\\[\n\\sqrt{x^2 + (y - p)^2} = y + p\n\\]\nSquaring both sides and simplifying:\n\\[\nx^2 + (y - p)^2 = (y + p)^2\n\\]\n\\[\nx^2 + y^2 - 2py + p^2 = y^2 + 2py + p^2\n\\]\n\\[\nx^2 = 4py\n\\]\nor\n\\[\ny=\\frac{1}{4p}x^2\n\\]\nThis final equation describes a parabola with its focus at \\((0, p)\\). The code below plots a parabolic mirror reflecting parallel rays to the focal point. Yet, I’m cheating a bit here. I’m not calculating the reflected rays, but just plotting them.\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(4, 4))\nplt.axhline(y=0, color='k', linestyle='--', linewidth=0.5)\nplt.axvline(x=0, color='k', linestyle='--', linewidth=0.5)\n\nfocal_length = 2\nx = np.linspace(-4, 4, 100)\ny = x**2 / (4 * focal_length)\n\n\nplt.plot([0], [focal_length], 'ro', markersize=5, label='Focal Point')\n\ndef plot_reflected_ray(x0, y0):\n    plt.plot([x0, x0], [5, y0], 'k-', linewidth=1)\n\n    m = 2 * (y0/x0)  # Slope of reflected ray\n    x1 = 0\n    y1 = focal_length\n    plt.plot([x0, x1], [y0, y1], 'k-', linewidth=1)\n\nfor x0 in np.linspace(-3.5, 3.5, 8):\n    y0 = x0**2 / (4 * focal_length)\n    plot_reflected_ray(x0, y0)\n\nplt.plot(x, y, 'b-', linewidth=3, label='Parabolic Mirror')\n\nplt.xlabel('x')\nplt.ylabel('y')\nplt.grid(True, linestyle=':', alpha=0.7)\nplt.axis('equal')\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nFigure 7: Parabolic mirror reflecting parallel rays to focal point\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nElliptical Mirrors and Fermat’s Principle\n\n\n\n\n\nThere is one interesting feature about elliptical mirrors: they can focus light from one focal point to the other. This is because the sum of the distances from any point on the ellipse to the two focal points is constant. This property is known as the ellipse’s geometric definition and you can try that at home with a piece of string and two pins.\nWe can now apply Fermat’s principle to proof that the light reflected from the ellipse travels a path length that is a saddle point. This means that the path length is stationary with respect to small perturbations in the path. Assuming for example that light travels from one focal point by a different path that is reflected from a line which is tangent to the ellipse at the point of reflection, the path length would be longer at any other point than the initial reflection point.\nOn the other side, if we reflect the ray on a surface that is a circle, which is intersecting the ellipse at the point of reflection, the path length would be shorter at any other point than the initial reflection point. This is a proof that the ellipse is a saddle point.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConsider an ellipse with semi-major axis \\(a\\) and semi-minor axis \\(b\\), defined by:\n\\[\\frac{x^2}{a^2} + \\frac{y^2}{b^2} = 1\\]\n\n\nThe focal points are located at \\(F_1(-c, 0)\\) and \\(F_2(c, 0)\\), where:\n\\[c^2 = a^2 - b^2\\]\n\n\n\nLet \\(P(x_0, y_0)\\) be a point on the ellipse. The total path length \\(L\\) from \\(F_1\\) to \\(F_2\\) via \\(P\\) is:\n\\[L = |F_1P| + |PF_2| = \\sqrt{(x_0+c)^2 + y_0^2} + \\sqrt{(x_0-c)^2 + y_0^2}\\]\n\n\n\nThe path length \\(L\\) is stationary with respect to small perturbations in \\(P\\):\n\\[\\frac{\\partial L}{\\partial x_0} = 0 \\quad \\text{and} \\quad \\frac{\\partial L}{\\partial y_0} = 0 \\quad \\text{at the reflection point}\\]\n\n\n\nThe tangent line to the ellipse at \\(P(x_0, y_0)\\) is given by:\n\\[\\frac{x_0x}{a^2} + \\frac{y_0y}{b^2} = 1\\]\nLet \\(Q\\) be any point on this tangent line different from \\(P\\). The path \\(F_1 \\to Q \\to F_2\\) is longer than \\(F_1 \\to P \\to F_2\\):\n\\[|F_1Q| + |QF_2| &gt; |F_1P| + |PF_2|\\]\n\n\n\nThe radius of curvature \\(R\\) at \\(P\\) is:\n\\[R = \\frac{(a^2b^2)^{3/2}}{(b^2x_0^2 + a^2y_0^2)^{3/2}}\\]\nThe center of curvature \\(C\\) is located at:\n\\[C = P + R\\cdot\\mathbf{n}\\]\nwhere \\(\\mathbf{n}\\) is the unit normal vector at \\(P\\).\nLet \\(Q\\) be any point on this circle different from \\(P\\). The path \\(F_1 \\to Q \\to F_2\\) is shorter than \\(F_1 \\to P \\to F_2\\):\n\\[|F_1Q| + |QF_2| &lt; |F_1P| + |PF_2|\\]\nAs a consequence, the path length for the reflection on and ellipse between the two focal points must be a saddle point.",
    "crumbs": [
      "Geometrical Optics",
      "Lecture 2",
      "Optical Elements I - Mirrors"
    ]
  },
  {
    "objectID": "geometrical-optics/Optical Elements I.html#mirrors",
    "href": "geometrical-optics/Optical Elements I.html#mirrors",
    "title": "Optical Elements Part I",
    "section": "",
    "text": "When light radiates from a point \\(P\\) and reflects off a mirror, as shown in the image, the reflected rays diverge but appear to originate from a point \\(P'\\) located behind the mirror. According to the law of reflection, this image point is positioned at the same distance behind the mirror as the original object point is in front of it. As a result, an observer receiving these reflected rays, such as on their retina, perceives the point as if it were situated behind the mirror, even though no light actually travels behind the mirror surface.\n\n\n\n\n\n\n\n\n\n\n\n(a)\n\n\n\n\n\n\n\n\n\n\n\n(b)\n\n\n\n\n\n\n\nFigure 1: Image formation on a plane mirror.\n\n\n\nWhen multiple points of an object emit light towards the mirror, this principle applies to each point. As a result, the entire object appears as an image behind the mirror. Since each point of the image is equidistant from the mirror as its corresponding object point, the image has the same size as the object. This leads to the definition of magnification as:\n\\[\nM=\\frac{h_{\\text{image}}}{h_{\\text{object}}}\n\\]\n\n\n\n\n\n\nFigure 2: Image formation on a plane mirror.\n\n\n\n\n\n\n\n\n\nVirtual Images\n\n\n\nA virtual image is an optical illusion where light rays appear to come from a point, but don’t actually converge there. Unlike real images, virtual images can’t be projected onto a screen. They’re commonly seen in plane mirrors, convex mirrors, and when objects are closer to a lens than its focal point. Remember: for virtual images, light rays only seem to originate from the image when traced backwards.\n\n\n\n\n\n\n\n\nReal Images\n\n\n\nA real image forms when light rays actually meet at a point after reflection or refraction. These images can be projected onto a screen because light physically passes through the image location. Real images are often inverted and occur with concave mirrors and lenses when objects are beyond the focal point. Key point: real images involve actual convergence of light rays.\n\n\n\n\n\nFor a concave mirror (where the reflecting surface is on the inside of the spherical curve), applying the law of reflection yields interesting results. Light rays parallel to the optical axis, at a distance \\(h\\) from it, are reflected towards the axis and intersect it at a specific point \\(F\\). Due to the mirror’s symmetry, a parallel ray on the opposite side of the axis will also converge to this same point \\(F\\).\n\n\n\n\n\n\nFigure 3: Reflection of a parallel ray incident at a height \\(h\\) from the optical axis on a concave mirror.\n\n\n\nWe may calculate the position of the point \\(F\\), e.g. the distance from the mirror surface point \\(O\\), by applying the law of reflection. If the spherical mirror surface has a radius \\(R\\), then the distance between the center of the sphere \\(M\\) and the point \\(F\\) is given by\n\\[FM=\\frac{R}{2\\cos(\\alpha)}\\]\nTherefore, we can also calculate the distance of the mirror surface from the point \\(F\\), which results in\n\\[\\begin{equation}\nOF=R\\left (1-\\frac{1}{2\\cos(\\alpha)}\\right)=f\n\\end{equation}\\]\nThis distance is the so-called focal length of the concave mirror \\(f\\). For small angle \\(\\alpha\\), the above equation yields the so called paraxial limit (all angles are small and the rays are close to the optical axis). In this limit we find \\(\\cos(\\alpha)\\approx 1\\) and the focal length becomes \\(f=R/2\\). If we replace the cosine function by \\(\\cos(\\alpha)=\\sqrt{1-\\sin^2(\\alpha)}\\) with \\(\\sin(\\alpha)=h/R\\), we find\n\\[\\begin{equation}\nf=R\\left [ 1-\\frac{R}{2\\sqrt{R^2-h^2}}\\right ]\n\\end{equation}\\]\nThis equation is telling us, that the focal distance is not a single value for a concave mirror. The focal distance rather changes with the distance \\(h\\) from the optical axis. If \\(h\\) approaches \\(R\\) the focal length become shorter.\n\n\n\n\n\n\nFocal Length of a Concave Spherical Mirror\n\n\n\n\n\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Set up the plot\nfig,(ax1,ax2)=plt.subplots(1,2,figsize=(7, 3))\n\n\nax1.axhline(y=0, color='k', linestyle='--', linewidth=0.5)\nax1.axvline(x=0, color='k', linestyle='--', linewidth=0.5)\n\n# Define the spherical mirror\nradius = 4\n\ntheta = np.linspace(-np.pi/3, np.pi/3, 100)\nx = radius * np.sin(theta)\ny = radius * (1 - np.cos(theta))\n\n# Plot the spherical mirror\nax1.plot(x, y, 'b-', linewidth=2, label='Spherical Mirror')\n\n# Calculate and plot the paraxial focal point\nparaxial_focal_length = radius / 2\nax1.plot([0], [paraxial_focal_length], 'ro', markersize=5, label='Paraxial Focal Point')\n\ndef reflect_ray(x0, y0):\n    xc, yc = 0, radius\n\n    # Normal vector\n    nx, ny = x0 - xc, y0 - yc\n    norm = np.sqrt(nx**2 + ny**2)\n    nx, ny = nx/norm, ny/norm\n\n    ix, iy = 0, -1\n\n    # Reflected ray direction\n    dot_product = 2 * (ix*nx + iy*ny)\n    rx, ry = ix - dot_product*nx, iy - dot_product*ny\n\n    return rx, ry\n\n# Plot several reflected rays\nnum_rays = 10\nfor x0 in np.linspace(-3, 3, num_rays):\n    y0 = radius - np.sqrt(radius**2 - x0**2)\n\n    # Incident ray\n    ax1.plot([x0, x0], [5, y0], 'k-', linewidth=1)\n\n    # Reflected ray\n    rx, ry = reflect_ray(x0, y0)\n    t = (0 - x0) / rx  # parameter to reach x=0\n    x1, y1 = x0 + t*rx, y0 + t*ry\n    ax1.plot([x0, x1], [y0, y1], 'k-', linewidth=1)\n\nax1.set_xlabel('h')\nax1.set_ylabel('y')\nax1.grid(True, linestyle=':', alpha=0.7)\nax1.axis('equal')\n\n\ndef focal_length(h, R):\n    return R * (1 - R / (2 * np.sqrt(R**2 - h**2)))\n\nR = 4  # Radius of curvature\nh = np.linspace(0, R*0.99, 1000)  # Range of h values (avoiding h=R which would cause division by zero)\n\nf = focal_length(h, R)\n\nax2.plot(h, f, 'b-', linewidth=2)\n\nax2.axhline(y=R/2, color='r', linestyle='--', label='Paraxial focal length (R/2)')\n\nax2.set_xlabel('h')\nax2.set_ylabel('f')\nax2.grid(True, linestyle=':', alpha=0.7)\n\nax2.set_ylim(0, R/2 * 1.1)\n\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nFigure 4: Spherical mirror of radius \\(R=4\\) reflecting parallel rays, showing spherical aberration and focal distance as a function of the distance from the optical axis \\(h\\).\n\n\n\n\n\n\n\n\nTo obtain now an equation which predicts the point at which the reflected ray intersects the optical axis if it emerged at a point \\(A\\), we just consider the following sketch.\n\n\n\n\n\n\nFigure 5: Image formation on a concave mirror.\n\n\n\nFor this situation, we can write down immediately the following relations\n\\[\\delta=\\alpha+\\gamma\\]\n\\[\\gamma+\\beta=2\\delta\\]\nFurther under the assumption of small angles (paraxial approximation) we can write down\n\\[\\tan(\\gamma) \\approx \\gamma = \\frac{h}{g}\\] \\[\\tan(\\beta) \\approx \\beta = \\frac{h}{b}\\] \\[\\sin(\\delta) \\approx \\delta = \\frac{h}{R}\\]\nfrom which we obtain\n\\[\\frac{h}{g}+\\frac{h}{b}=2\\frac{h}{R}\\]\nand by divding by \\(h\\) finally the imaging equation:\n\\[\\frac{1}{g}+\\frac{1}{b}= \\frac{2}{R}= \\frac{1}{f}\\]\nwhere we have used the focal length \\(f=R/2\\). This equation has some surprising property. It is completely independent of \\(h\\) and \\(\\gamma\\). That means all points in a plane at a distance \\(g\\) are images into a plane at a distance \\(b\\). Both planes are therefore called conjugated planes.\n\n\n\n\n\n\nImaging Equation Concave Mirror\n\n\n\nThe sum of the inverse object and image distances equals the inverse focal length of the cocave mirror.\n\\[\\frac{1}{g}+\\frac{1}{b}\\approx\\frac{1}{f}\\]\n\n\nThis equation now helps to construct the image of an object in front of a concave mirror and we may define 3 different rays to identify the size of an image \\(h_{\\text{image}}\\) from the size of an object \\(h_{\\text{object}}\\).\n\n\n\n\n\n\nFigure 6: Image formation on a concave mirror.\n\n\n\nIn the diagram above, three key rays are used to construct the image:\n\nRed ray: Parallel to optical axis → reflects through focal point\nGreen ray: Through focal point → reflects parallel to optical axis\nCentral ray: Through center of curvature → reflects back along same path\n\nThe behavior of these reflected rays determines the nature of the image:\n\nIf the rays intersect on the same side of the mirror as the object, a real image forms. This image is inverted, as shown in the sketch.\nIf the rays diverge after reflection, they appear to intersect behind the mirror, creating a virtual image. This image is upright and located behind the mirror, though no actual ray intersection occurs.\n\nThe point where these rays meet (or appear to meet) determines the image size. By drawing a ray from the object’s tip through the mirror’s center (point O), we can easily determine the image height h_image. As an exercise, consider how this construction demonstrates that the magnification of a concave mirror is given by\n\\[ \\frac{h_{\\text{image}}}{h_{\\text{object}}}=-\\frac{b}{g}=M\\]\nThis ratio indeed represents the magnification \\(M\\). The negative sign in the expression reflects an important optical property: for real images formed by concave mirrors, the image is inverted relative to the object. This inversion is mathematically represented by the negative magnification value. Conversely, a positive magnification would indicate an upright image, which occurs with virtual images.\nWith the help of the imaging equation and the magnification we may in general differentiate between the following general situations:\n\n\n\n\n\n\n\n\n\nObject Distance\nImage Characteristics\nImage Position\nMagnification\n\n\n\n\n\\(g &gt; 2f\\)\nReal, inverted, smaller\nBetween f and 2f\n\\(|m|\\) &lt; 1\n\n\n\\(g = 2f\\)\nReal, inverted, same size\nAt 2f\n\\(|m|\\) = 1\n\n\n\\(f &lt; g &lt; 2f\\)\nReal, inverted, larger\nBeyond 2f\n\\(|m|\\) &gt; 1\n\n\n\\(g = f\\)\nImage at infinity\nAt infinity\nN/A\n\n\n\\(g &lt; f\\)\nVirtual, upright, larger\nBehind mirror\n\\(|m|\\) &gt; 1\n\n\n\n\n\n\n\n\n\nParabolic Mirrors Focus Parallel Rays\n\n\n\n\n\nWe would like to show in the following, that a parabolic mirror is a shape which reflects all light rays parallel to the principal axis to a single point, the focus. This is a fundamental property of parabolic mirrors and is used in many optical systems, such as telescopes, satellite dishes, and car headlights.\nFor this purpose, we would like to use Fermat’s principle. We examine a light ray originating from a point \\(x,y_0\\) and travelling parallel to the principal axis. The light ray is reflected at a point \\((x,y)\\) on the mirror and travels to the focus at \\((0,p)\\). The light path is therefore consisting out of two linear segments \\(A\\) and \\(B\\) for which we have to calculate the time of travel. The total duration of the light’s journey is then: \\[\nt = t_A + t_B\n\\]\nwhere:\n\n\\(t_A\\) is the time taken to travel from \\(x,y_0\\) to the mirror.\n\\(t_B\\) is the time taken to travel from \\((x,y)\\) to \\((0,p)\\).\n\n\n\nThe distance covered in path A is equal to \\(y_0 - y\\), where \\(y\\) represents the y-coordinate of the point where the ray meets the mirror. Consequently, the time taken for the light to traverse path A can be expressed as:\n\\[\nt_A = \\frac{y_0 - y}{c}\n\\]\nIn this equation, \\(c\\) represents the speed of light in the medium.\n\n\n\nAfter reflection, the light ray travels from the point \\((x, y)\\) on the mirror’s surface to the focal point located at \\((0, p)\\). The length of this segment of the path can be calculated using the distance formula:\n\\[\n\\sqrt{x^2 + (y - p)^2}\n\\]\nConsequently, the time required for the light to traverse path B is expressed as:\n\\[\nt_B = \\frac{\\sqrt{x^2 + (y - p)^2}}{c}\n\\]\n\n\n\nThe total time for the light ray’s journey is the sum of times for paths A and B:\n\\[\nt = \\frac{y_0 - y}{v} + \\frac{\\sqrt{x^2 + (y - p)^2}}{c}\n\\]\nAccording to Fermat’s principle, all light rays should take the same time. We can express this by setting the total time equal to a constant \\(t_c\\):\n\\[\n\\frac{y_0 - y}{v} + \\frac{\\sqrt{x^2 + (y - p)^2}}{v} = t_c\n\\]\nFor a ray traveling along the y-axis, reflecting at \\((0, 0)\\), the total distance is \\(y_0 + p\\). The time for this ray is:\n\\[\n\\frac{y_0 + p}{c}\n\\]\nThis gives us \\(t_c = \\frac{y_0 + p}{c}\\). Substituting into our general equation:\n\\[\n\\frac{y_0 - y}{v} + \\frac{\\sqrt{x^2 + (y - p)^2}}{c} = \\frac{y_0 + p}{c}\n\\]\nMultiplying by \\(c\\) and rearranging:\n\\[\ny_0 - y + \\sqrt{x^2 + (y - p)^2} = y_0 + p\n\\]\n\\[\n\\sqrt{x^2 + (y - p)^2} = y + p\n\\]\nSquaring both sides and simplifying:\n\\[\nx^2 + (y - p)^2 = (y + p)^2\n\\]\n\\[\nx^2 + y^2 - 2py + p^2 = y^2 + 2py + p^2\n\\]\n\\[\nx^2 = 4py\n\\]\nor\n\\[\ny=\\frac{1}{4p}x^2\n\\]\nThis final equation describes a parabola with its focus at \\((0, p)\\). The code below plots a parabolic mirror reflecting parallel rays to the focal point. Yet, I’m cheating a bit here. I’m not calculating the reflected rays, but just plotting them.\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(4, 4))\nplt.axhline(y=0, color='k', linestyle='--', linewidth=0.5)\nplt.axvline(x=0, color='k', linestyle='--', linewidth=0.5)\n\nfocal_length = 2\nx = np.linspace(-4, 4, 100)\ny = x**2 / (4 * focal_length)\n\n\nplt.plot([0], [focal_length], 'ro', markersize=5, label='Focal Point')\n\ndef plot_reflected_ray(x0, y0):\n    plt.plot([x0, x0], [5, y0], 'k-', linewidth=1)\n\n    m = 2 * (y0/x0)  # Slope of reflected ray\n    x1 = 0\n    y1 = focal_length\n    plt.plot([x0, x1], [y0, y1], 'k-', linewidth=1)\n\nfor x0 in np.linspace(-3.5, 3.5, 8):\n    y0 = x0**2 / (4 * focal_length)\n    plot_reflected_ray(x0, y0)\n\nplt.plot(x, y, 'b-', linewidth=3, label='Parabolic Mirror')\n\nplt.xlabel('x')\nplt.ylabel('y')\nplt.grid(True, linestyle=':', alpha=0.7)\nplt.axis('equal')\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nFigure 7: Parabolic mirror reflecting parallel rays to focal point\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nElliptical Mirrors and Fermat’s Principle\n\n\n\n\n\nThere is one interesting feature about elliptical mirrors: they can focus light from one focal point to the other. This is because the sum of the distances from any point on the ellipse to the two focal points is constant. This property is known as the ellipse’s geometric definition and you can try that at home with a piece of string and two pins.\nWe can now apply Fermat’s principle to proof that the light reflected from the ellipse travels a path length that is a saddle point. This means that the path length is stationary with respect to small perturbations in the path. Assuming for example that light travels from one focal point by a different path that is reflected from a line which is tangent to the ellipse at the point of reflection, the path length would be longer at any other point than the initial reflection point.\nOn the other side, if we reflect the ray on a surface that is a circle, which is intersecting the ellipse at the point of reflection, the path length would be shorter at any other point than the initial reflection point. This is a proof that the ellipse is a saddle point.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConsider an ellipse with semi-major axis \\(a\\) and semi-minor axis \\(b\\), defined by:\n\\[\\frac{x^2}{a^2} + \\frac{y^2}{b^2} = 1\\]\n\n\nThe focal points are located at \\(F_1(-c, 0)\\) and \\(F_2(c, 0)\\), where:\n\\[c^2 = a^2 - b^2\\]\n\n\n\nLet \\(P(x_0, y_0)\\) be a point on the ellipse. The total path length \\(L\\) from \\(F_1\\) to \\(F_2\\) via \\(P\\) is:\n\\[L = |F_1P| + |PF_2| = \\sqrt{(x_0+c)^2 + y_0^2} + \\sqrt{(x_0-c)^2 + y_0^2}\\]\n\n\n\nThe path length \\(L\\) is stationary with respect to small perturbations in \\(P\\):\n\\[\\frac{\\partial L}{\\partial x_0} = 0 \\quad \\text{and} \\quad \\frac{\\partial L}{\\partial y_0} = 0 \\quad \\text{at the reflection point}\\]\n\n\n\nThe tangent line to the ellipse at \\(P(x_0, y_0)\\) is given by:\n\\[\\frac{x_0x}{a^2} + \\frac{y_0y}{b^2} = 1\\]\nLet \\(Q\\) be any point on this tangent line different from \\(P\\). The path \\(F_1 \\to Q \\to F_2\\) is longer than \\(F_1 \\to P \\to F_2\\):\n\\[|F_1Q| + |QF_2| &gt; |F_1P| + |PF_2|\\]\n\n\n\nThe radius of curvature \\(R\\) at \\(P\\) is:\n\\[R = \\frac{(a^2b^2)^{3/2}}{(b^2x_0^2 + a^2y_0^2)^{3/2}}\\]\nThe center of curvature \\(C\\) is located at:\n\\[C = P + R\\cdot\\mathbf{n}\\]\nwhere \\(\\mathbf{n}\\) is the unit normal vector at \\(P\\).\nLet \\(Q\\) be any point on this circle different from \\(P\\). The path \\(F_1 \\to Q \\to F_2\\) is shorter than \\(F_1 \\to P \\to F_2\\):\n\\[|F_1Q| + |QF_2| &lt; |F_1P| + |PF_2|\\]\nAs a consequence, the path length for the reflection on and ellipse between the two focal points must be a saddle point.",
    "crumbs": [
      "Geometrical Optics",
      "Lecture 2",
      "Optical Elements I - Mirrors"
    ]
  },
  {
    "objectID": "geometrical-optics/reflection.html",
    "href": "geometrical-optics/reflection.html",
    "title": "Reflection",
    "section": "",
    "text": "Historical Context of Reflection Laws\n\n\n\n\n\nThe study of reflection has a rich history dating back to ancient times:\n\nAncient Greece (300 BCE): Euclid, in his work “Catoptrics,” was among the first to formally describe the law of reflection. He stated that the angle of incidence equals the angle of reflection.\nAncient Rome (50 CE): Hero of Alexandria expanded on Euclid’s work, applying the principle that light travels along the path of least distance.\nIslamic Golden Age (1000 CE): Ibn al-Haytham (Alhazen) made significant contributions to optics in his “Book of Optics.” He conducted experiments to verify the law of reflection and explored the properties of spherical and parabolic mirrors.\n17th Century: Fermat’s Principle, formulated by Pierre de Fermat, provided a more general framework for understanding reflection (and refraction) based on the principle of least time.\nModern Era: The understanding of reflection has been further refined with the development of electromagnetic theory by James Clerk Maxwell in the 19th century and quantum optics in the 20th century.\n\n\n\n\nThe law of reflection is probably the most simple one. Yet the simplicity gives us the chance to define some basic objects which we will further use for the description of light rays and their propagation.\n\nLaw of Reflection\nThe sketch below shows the reflection of an incoming light ray (red) on an interface. This incoming light ray has an angle \\(\\theta_{1}\\) with the axis (dashed line), which is perpendicular to the reflecting surface. As compared to X-ray diffraction, we measure the angle to the normal of the surface and not to the surface itself.\n\n\n\n\n\n\n\n\n\n\n\n(a) Law of reflection\n\n\n\n\n\n\n\n\n\n\n\n(b) Experimental Demonstration\n\n\n\n\n\n\n\nFigure 1— Figure 1 (a) illustrates the law of reflection, while Figure Figure 1 (b) shows an experimental demonstration.\n\n\n\nFigure 1 (a) shows the reflection of an incoming light ray (red) on an interface. This incoming light ray has an angle \\(\\theta_{1}\\) with the axis (dashed line), which is perpendicular to the reflecting surface. As compared to X-ray diffraction, we measure the angle to the normal of the surface and not to the surface itself.\nThe law of reflection tells us now, that the outgoing reflected ray is now leaving the surface under an angle \\(\\theta_2=\\theta_1\\). So both angles are the same for the reflection.\n\n\n\n\n\n\nLaw of Reflection\n\n\n\nIf a ray is incident to a reflecting surface under an angle \\(\\theta_1\\) it will be reflected towards under an angle \\(\\theta_2=\\theta_1\\) to the same side of the surface.\n\n\n\n\nFermat’s Principle\nThe law of reflection can be actually obtained from a variational principle saying the light rays propagate along those path on which the propagation time is an extremum. This variational principle is called Fermat’s principle.\n\n\n\n\n\n\nFigure 2— Sketch for deriving the law of reflection from Fermat’s principle\n\n\n\nConsider now a light ray that should travel from point \\(A\\) to point \\(C\\) via a point \\(B\\) on the mirror surface. In general multiple paths are possible such as the one indicated in the above picture. Clearly this path is not satisfying our reflection law formulated above. Fermat’s principle now restricts the path length from \\(A\\) to \\(C\\) to be the one, which takes the least amount of time.\n\n\n\n\n\n\nFermat’s principle\n\n\n\nThe path taken by a ray between two given points A, B is the path that can be traversed in the least time.\nMore precise alternative: A ray going in a certain particular path has the property that if we make a small change in the ray in any manner whatever, say in the location at which it comes to the mirror, or the shape of the curve, or anything, there will be no first-order change in the time; there will be only a second-order change in the time.\n\n\nSo let us consider that contraints to the path length. The total length the light hast to travel via the three points is\n\\[\nl=l_{1}+l_{2}=\\sqrt{(x-x_1)^2+y_1^2}+\\sqrt{(x_2-x)^2+y_2^2}\n\\]\nThe time that is required by the light to travel that distance \\(l\\) is then given by\n\\[\nt=\\frac{l}{c},\n\\]\nwhere \\(c\\) is the speed of light in the medium above the mirror. If this time should now be a minimum, we have to take the derivative of the time \\(t\\) with respect to the position \\(x\\) on the mirror and set that to zero, i.e.,\n\\[\\frac{\\mathrm dt}{\\mathrm dx}=0. \\tag{1}\\]\nThis results in Eq. 1\n\\[\n\\frac{x-x_1}{\\sqrt{(x-x_1)^2+y_{1}^2}}=\\frac{x_2-x}{\\sqrt{(x_2-x)^2+y_{2}^2}},\n\\]\nwhich is actually\n\\[\n\\frac{x-x_1}{l_1}=\\frac{x_2-x}{l_2}\n\\]\nor\n\\[\n\\sin(\\theta_1)=\\sin(\\theta_2)\n\\]\nwhich finally requires\n\\[\n\\theta_1=\\theta_2\n\\]\nand is our law of reflection. Thus, reflection satisfies Fermat’s principle, i.e. the light rays propagate along those path on which the propagation time is an extremum.\n\n\n\n\n\n\nPrinciple of Least Action (Hamilton’s Principle)\n\n\n\n\n\nThe Principle of Least Action, also known as Hamilton’s Principle, is a fundamental concept in classical mechanics. It states that the path taken by a physical system between two states is the one for which the action integral is stationary (usually a minimum).\n\nAction Integral\nThe action \\(S\\) is defined as the integral of the Lagrangian \\(L\\) over time:\n\\[\nS = \\int_{t_1}^{t_2} L \\, dt\n\\]\n\n\nLagrangian\nThe Lagrangian \\(L\\) is a function that summarizes the dynamics of the system. For a system with generalized coordinates \\(q_i\\) and velocities \\(\\dot{q}_i\\), the Lagrangian is typically given by:\n\\[\nL = T - V\n\\]\nwhere:\n\n\\(T\\) is the kinetic energy of the system.\n\\(V\\) is the potential energy of the system.\n\n\n\nEuler-Lagrange Equations\nHamilton’s Principle leads to the Euler-Lagrange equations, which are the equations of motion for the system. These equations are derived by requiring that the action \\(S\\) be stationary with respect to variations in the path \\(q_i(t)\\):\n\\[\n\\delta S = 0\n\\]\nThis condition leads to the following differential equations:\n\\[\n\\frac{d}{dt} \\left( \\frac{\\partial L}{\\partial \\dot{q}_i} \\right) - \\frac{\\partial L}{\\partial q_i} = 0\n\\]\nThese are the Euler-Lagrange equations, and they provide a powerful method for deriving the equations of motion for a wide variety of physical systems.\n\n\nExample: Simple Harmonic Oscillator\nFor a simple harmonic oscillator with mass \\(m\\) and spring constant \\(k\\), the Lagrangian is:\n\\[\nL = \\frac{1}{2} m \\dot{x}^2 - \\frac{1}{2} k x^2\n\\]\nApplying the Euler-Lagrange equation:\n\\[\n\\frac{d}{dt} \\left( \\frac{\\partial L}{\\partial \\dot{x}} \\right) - \\frac{\\partial L}{\\partial x} = 0\n\\]\nwe get:\n\\[\nm \\ddot{x} + k x = 0\n\\]\nwhich is the familiar equation of motion for a simple harmonic oscillator.\nHamilton’s Principle and the associated Euler-Lagrange equations are foundational in classical mechanics and have far-reaching implications in other areas of physics, including quantum mechanics and field theory.",
    "crumbs": [
      "Geometrical Optics",
      "Lecture 1",
      "Reflection"
    ]
  },
  {
    "objectID": "geometrical-optics/refraction-total-internal-reflection.html",
    "href": "geometrical-optics/refraction-total-internal-reflection.html",
    "title": "Refraction and Total Internal Reflection",
    "section": "",
    "text": "Historical Context of Refraction\n\n\n\n\n\nThe understanding of refraction has evolved over centuries, with contributions from various cultures and scientific traditions. This timeline highlights key milestones in the discovery and formalization of refraction, showcasing how our comprehension of this fundamental optical phenomenon has deepened over time:\n\nAncient Greece (3rd century BCE): Euclid noticed that a stick partially submerged in water appears bent. Archimedes studied the refraction of light in water.\nAncient Rome (1st century CE): Ptolemy conducted experiments on refraction and compiled tables of refraction angles for different media.\nIslamic Golden Age (10th-11th centuries): Ibn Sahl (940-1000) discovered the law of refraction, describing it geometrically. Alhazen (965-1040) studied lenses and the human eye, contributing significantly to optics.\nMiddle Ages: Robert Grosseteste (1175-1253) and Roger Bacon (1214-1294) studied refraction and its application to lenses.\nRenaissance: Thomas Harriot (1560-1621) rediscovered the law of refraction but didn’t publish his findings.\n17th Century: Willebrord Snellius (1580-1626) derived the mathematical law of refraction (Snell’s law) around 1621. René Descartes (1596-1650) independently derived and published the law of refraction in 1637. Pierre de Fermat (1607-1665) derived the law of refraction using his principle of least time.\n19th Century: Augustin-Jean Fresnel (1788-1827) developed the wave theory of light, explaining refraction in terms of changes in wave speed.\n20th Century: The quantum mechanical understanding of light, which emerged in the early 20th century, significantly impacted our view of refraction. Max Planck’s work on black body radiation in 1900 and Albert Einstein’s explanation of the photoelectric effect in 1905 laid the groundwork for the quantum nature of light. This quantum perspective provided a complementary explanation to the wave theory, describing refraction in terms of photons interacting with the atoms in the medium. While this quantum view offers insights into certain aspects of refraction, it’s important to note that both the wave and particle descriptions of light are necessary for a complete understanding of optical phenomena.\n\n\n\n\nThe law of refraction is the second important law of geometrical optics. It relates the refractive index \\(n_1\\) and angle of incidence \\(\\theta_1\\) on one side of an interface to the refractive index \\(n_2\\) and angle of refraction \\(\\theta_2\\) on the other side. Both the law of reflection and the law of refraction can be derived from more fundamental principles such as Fermat’s principle of least time and are consistent with the conservation of energy. Their relation to momentum is more complex and involves considering the interaction of light with the medium at an atomic level. These laws provide a mathematical framework for predicting how light behaves when it encounters interfaces between different media, forming the basis for understanding a wide range of optical phenomena and the design of optical devices.\n\n\nThe refractive index \\(n\\) is a material constant representing the factor by which the speed of light is reduced in the medium compared to its speed in vacuum. For most natural materials and visible light, the refractive index is \\(n \\ge 1\\), as light typically travels slower in media than in vacuum. However, in certain special cases—such as for X-rays in some materials or in engineered metamaterials—the refractive index can be less than 1 or even negative. Understanding these exotic cases requires a deeper exploration of the electromagnetic properties of materials and the origin of the refractive index, which we will address later.\n\n\n\n \n\n\n\n\n\n\nLaw of Refraction (Snell’s Law)\n\n\n\nThe law of refraction (Snell’s law) is given for the above sketch by the equation:\n\\[\nn_1 \\sin(\\theta_1)=n_2 \\sin(\\theta_2)\n\\]\n\n\nYou can explore the law of refraction using the interactive visualization below. The visualization shows a light ray incident on an interface between two media with different refractive indices. You can adjust the angle of incidence and the refractive index of the first medium to see how the angle of refraction changes according to Snell’s law.\n\n\n\nIncident Angle: 45°\n\nRefractive Index n₁: 1.0\n\nRefractive Index n₂: 1.5\n\n\n\n\nSnell’s law leads to some general patterns in the behavior of light rays at interfaces, which are worth remembering. Consider these two cases:\n\nWhen light moves from a medium with lower refractive index to one with higher refractive index (\\(n_1 &lt; n_2\\)):\n\nThe refracted ray bends towards the normal (optical axis)\nThe angle of refraction is smaller than the angle of incidence (\\(\\theta_2 &lt; \\theta_1\\))\n\nWhen light moves from a medium with higher refractive index to one with lower refractive index (\\(n_1 &gt; n_2\\)):\n\nThe refracted ray bends away from the normal (optical axis)\nThe angle of refraction is larger than the angle of incidence (\\(\\theta_2 &gt; \\theta_1\\))\n\n\nFigure 1 illustrates these principles with three plots showing how the refracted angle changes with the incident angle for two common interface scenarios: glass-to-air and air-to-glass. These plots clearly demonstrate the different behaviors described above.\n\n\n\nCode\ndef snell(n1, n2, theta1):\n    sin_theta2 = n1 * np.sin(theta1) / n2\n    theta2 = np.arcsin(np.clip(sin_theta2, -1, 1))\n    theta2[sin_theta2 &gt; 1] = np.nan\n    return theta2\n\nfig, ax = plt.subplots(figsize=(4, 4))\n\ntheta1 = np.linspace(0, np.pi/2, 1000)\n\ntheta2_1_to_1_5 = snell(1.0, 1.5, theta1)\ntheta2_1_5_to_1 = snell(1.5, 1.0, theta1)\ntheta2_1_to_1 = snell(1.0, 1.0, theta1)\n\nax.plot(np.degrees(theta1), np.degrees(theta2_1_to_1_5), color='blue')\nax.plot(np.degrees(theta1), np.degrees(theta2_1_5_to_1), color='red')\nax.plot(np.degrees(theta1), np.degrees(theta2_1_to_1), color='green', linestyle='--')\n\nax.set_xlabel(r'$\\theta_1$ [°]')\nax.set_ylabel(r'$\\theta_2$ [°]')\nax.set_xlim(0, 90)\nax.set_ylim(0, 90)\n\nax.plot([0, 90], [0, 90], color='gray', linestyle=':', label='y=x')\n\nax.annotate(r'$\\frac{n_2}{n_1}=1.5$', xy=(60, 35), xytext=(50, 20),\n            arrowprops=dict(arrowstyle='-&gt;'), color='blue')\nax.annotate(r'$\\frac{n_1}{n_2}=1.5$', xy=(30, 50), xytext=(10, 70),\n            arrowprops=dict(arrowstyle='-&gt;'), color='red')\nax.annotate(r'$\\frac{n_2}{n_1}=1$', xy=(45, 45), xytext=(65, 50),\n            arrowprops=dict(arrowstyle='-&gt;'), color='green')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nFigure 1— Snell’s law for different combinations of refractive indices. The plots show the relationship between incident angle (\\(\\theta_1\\)) and refracted angle (\\(\\theta_2\\)) for three scenarios: (a) light passing from air to glass, (b) light passing from glass to air, and (c) a comparison of both cases. Note how the curves differ when light moves into a medium with higher refractive index versus a lower refractive index.\n\n\n\n\n\n\n\n\nThe above diagram reveals a special case occurring when \\(n_1 &gt; n_2\\). Under these conditions, we can increase the incident angle \\(\\theta_1\\) until the outgoing angle reaches \\(\\theta_2 = \\frac{\\pi}{2}\\). At this point, the refracted ray would be traveling along the interface between the two media. For any incident angle \\(\\theta_1\\) larger than this critical angle, there is no refracted ray at all; instead, we observe only a reflected ray. This phenomenon, known as total internal reflection, occurs despite the fact that the material with refractive index \\(n_2\\) is completely transparent.\nLet’s formalize this concept mathematically. Using Snell’s law and setting \\(\\theta_2 = \\frac{\\pi}{2}\\), we obtain the equation for the critical angle \\(\\theta_c\\):\n\\[\\theta_1 = \\theta_c = \\sin^{-1}\\left(\\frac{n_2}{n_1}\\right)\\]\nNote that the \\(\\sin^{-1}()\\) function requires an argument \\(\\le 1\\), which is why this phenomenon only occurs when \\(n_2 &lt; n_1\\).\nIt’s important to understand that during total internal reflection, all of the light energy is reflected back into the first medium, hence the term ‘total’. However, electromagnetic optics reveals an interesting subtlety: an evanescent wave penetrates a short distance into the second medium, though it doesn’t propagate energy across the boundary.\nWhen the incident angle exceeds the critical angle, Snell’s law as we’ve written it no longer applies. Instead, we observe perfect reflection, where the angle of reflection equals the angle of incidence, just as in regular reflection from a mirror. This reflection occurs without any loss of energy to the second medium, making it an extremely efficient process.\n \n\n\n\n\n\n\nTotal Internal Reflection\n\n\n\nTotal internal reflection occurs when light is passing from higher refractive index to lower refractive index materials for incidence angle larger than a critical angle\n\\[\n\\theta_c=\\sin^{-1}\\left (\\frac{n_2}{n_1}\\right )\n\\]\n\n\nWe can demonstrate total internal reflection very easily with a water basin, for example, where we couple in light from a laser from the side.\n \nBut you could try that yourself also in the bath tub diving below the water surface.\nTotal internal reflection has numerous practical applications:\n\nFiber optic communications: Light signals can travel long distances with minimal loss through optical fibers.\nOptical instruments: Prisms in binoculars and telescopes use total internal reflection to manipulate light paths.\nGemstones: The sparkle of diamonds is enhanced by total internal reflection trapping light within the stone.\nMedical endoscopes: Total internal reflection helps guide light through flexible tubes for internal imaging.\n\nOptical Fibers and Total Internal Reflection\nTotal internal reflection plays a crucial role in modern telecommunications, particularly in optical fibers, which are also part of many experimental setups. These fibers are essentially ultra-thin glass wires, ranging in diameter from a few micrometers to several hundred micrometers, designed to transport light over long distances with minimal loss.\nThe structure of an optical fiber is key to its function:\n\nCore: A central glass core with a refractive index \\(n_1\\)\nCladding: A surrounding layer with a slightly lower refractive index \\(n_2\\)\n\nThis difference in refractive indices is what allows total internal reflection to occur within the fiber.\n \nFor light to propagate effectively through the fiber, it must enter at an angle that ensures total internal reflection at the core-cladding interface. This leads to the concept of the acceptance angle, \\(\\theta_a\\), which is the maximum angle at which light can enter the fiber and still undergo total internal reflection.\nTo characterize this acceptance angle, optical engineers use a parameter called the Numerical Aperture (NA).\n\n\n\n\n\n\nNumerical Aperture\n\n\n\nThe Numerical Aperture of a fiber is defined as the sine of the maximum acceptance angle:\n\\[\\begin{equation}\nNA = \\sin(\\theta_a) = \\sqrt{n_1^2 - n_2^2}\n\\end{equation}\\]\n\n\nThis equation relates the NA directly to the refractive indices of the core and cladding. The derivation of this formula involves applying Snell’s law at the air-fiber interface and at the core-cladding interface, then using the condition for total internal reflection.\nIn practice, typical values for the refractive indices might be \\(n_1 = 1.475\\) for the core and \\(n_2 = 1.46\\) for the cladding. Plugging these into our equation:\n\\[\\begin{equation}\nNA = \\sqrt{1.475^2 - 1.46^2} \\approx 0.2\n\\end{equation}\\]\nThis means that light entering the fiber within a cone of about 11.5° (arcsin(0.2)) from the fiber’s axis will be transmitted through the fiber via total internal reflection.\nThe NA is an important parameter in fiber optic design:\n\nIt determines the light-gathering ability of the fiber.\nIt affects the fiber’s bandwidth and its susceptibility to certain types of signal distortion.\nIt influences how easily the fiber can be coupled to light sources and other fibers.\n\nOptical fibers come in various types, each optimized for different applications. Some fibers are designed to transmit light over long distances with minimal loss, while others are engineered for specific wavelengths or to guide light in unusual ways. The figure below shows a few examples of optical fiber types.\n\n\n\n\n\n\nFigure 2— Rendering of different optical fibers types (from left to right): Hollow core optical fiber, hollow core bragg fiber, photonic crystal fiber, conventional fiber\n\n\n\n\n\n\nWhile before we have considered Fermat’s principle for the special case of refraction and light propagation in a homogeneous medium, we can define a more general version of it correponding to the following situation also involving an inhomogeneous refractive index \\(n(\\vec{r})\\).\n\n\n\n\n\n\nFigure 3— Sketch for a general description of Fermat’s principle\n\n\n\nFor this general scenario of light traveling along a path, we can define an optical path length (OPL) as\n\\[\\begin{equation}\n\\text{OPL} = \\int\\limits_{A}^{C} n(\\mathbf{r}) \\mathrm ds=0,\n\\end{equation}\\]\nwith a varying refractive index \\(n(\\mathbf{r})\\). Fermat’s Principle states that the actual path taken by the light makes the OPL stationary:\n\\[\n\\delta \\left( \\int_A^B n(\\mathbf{r}) \\, ds \\right) = 0\n\\]\nUsing the calculus of variations, this leads to the Euler-Lagrange equation for the path of light. In Cartesian coordinates, if the path is parameterized by \\(\\mathbf{r}(s) = (x(s), y(s), z(s))\\), the Euler-Lagrange equations become:\n\\[\n\\frac{d}{ds} \\left( n \\frac{d\\mathbf{r}}{ds} \\right) = \\nabla n\n\\]\nwhere \\(\\nabla n\\) is the gradient of the refractive index. This equation describes how the light ray bends in response to changes in the refractive index of the medium.\nFermat’s Principle is a cornerstone of geometrical optics and has applications in designing optical systems, understanding mirages, and analyzing the behavior of light in various media.\n\n\n\n\n\n\nFermat’s Principle and Snells Law\n\n\n\n\n\nWe would like to apply Fermat’s principle to derive Snell’s law, which is a more lengthy calculation. To do this, we consider a light ray traveling from point \\(A\\) in medium 1 (with refractive index \\(n_1\\)) to point \\(C\\) in medium 2 (with refractive index \\(n_2\\)), crossing the interface at point \\(B\\). Let the coordinates of points \\(A\\), \\(B\\), and \\(C\\) be \\((x_A, y_A)\\), \\((x_B, y_B)\\), and \\((x_C, y_C)\\), respectively. Assume the interface between the two media is at \\(y = y_B\\). The optical path length (OPL) is given by:\n\\[\n\\delta \\int_{A}^{C} n(\\vec{r}) \\, ds = 0,\n\\]\nwhere \\(n(\\vec{r})\\) is the refractive index at position \\(\\vec{r}\\), and \\(ds\\) is an infinitesimal element of the path.\nConsider a light ray traveling from point \\(A\\) in medium 1 (with refractive index \\(n_1\\)) to point \\(C\\) in medium 2 (with refractive index \\(n_2\\)), crossing the interface at point \\(B\\). Let the coordinates of points \\(A\\), \\(B\\), and \\(C\\) be \\((x_A, y_A)\\), \\((x_B, y_B)\\), and \\((x_C, y_C)\\), respectively. Assume the interface between the two media is at \\(y = y_B\\).\n\n\nThe optical path length (OPL) is given by:\n\\[\n\\text{OPL} = n_1 \\int_{A}^{B} ds_1 + n_2 \\int_{B}^{C} ds_2,\n\\]\nwhere \\(ds_1\\) and \\(ds_2\\) are the infinitesimal path lengths in media 1 and 2, respectively.\n\n\n\nThe path lengths \\(ds_1\\) and \\(ds_2\\) can be expressed in terms of the coordinates:\n\\[\nds_1 = \\sqrt{(dx_1)^2 + (dy_1)^2}, \\quad ds_2 = \\sqrt{(dx_2)^2 + (dy_2)^2}.\n\\]\nSince the interface is at \\(y = y_B\\), we have \\(dy_1 = y_B - y_A\\) and \\(dy_2 = y_C - y_B\\). The total optical path length is:\n\\[\n\\text{OPL} = n_1 \\sqrt{(x_B - x_A)^2 + (y_B - y_A)^2} + n_2 \\sqrt{(x_C - x_B)^2 + (y_C - y_B)^2}.\n\\]\n\n\n\nTo find the stationary path, we take the variation of the OPL with respect to \\(x_B\\):\n\\[\n\\delta \\text{OPL} = \\delta \\left[ n_1 \\sqrt{(x_B - x_A)^2 + (y_B - y_A)^2} + n_2 \\sqrt{(x_C - x_B)^2 + (y_C - y_B)^2} \\right] = 0.\n\\]\nTaking the derivative with respect to \\(x_B\\):\n\\[\n\\frac{\\partial}{\\partial x_B} \\left[ n_1 \\sqrt{(x_B - x_A)^2 + (y_B - y_A)^2} + n_2 \\sqrt{(x_C - x_B)^2 + (y_C - y_B)^2} \\right] = 0.\n\\]\n\n\n\nDifferentiating each term separately:\n\\[\nn_1 \\frac{\\partial}{\\partial x_B} \\sqrt{(x_B - x_A)^2 + (y_B - y_A)^2} + n_2 \\frac{\\partial}{\\partial x_B} \\sqrt{(x_C - x_B)^2 + (y_C - y_B)^2} = 0.\n\\]\nUsing the chain rule:\n\\[\nn_1 \\frac{x_B - x_A}{\\sqrt{(x_B - x_A)^2 + (y_B - y_A)^2}} + n_2 \\frac{x_B - x_C}{\\sqrt{(x_C - x_B)^2 + (y_C - y_B)^2}} = 0.\n\\]\n\n\n\nLet \\(\\theta_1\\) be the angle of incidence and \\(\\theta_2\\) be the angle of refraction. Then:\n\\[\n\\sin \\theta_1 = \\frac{x_B - x_A}{\\sqrt{(x_B - x_A)^2 + (y_B - y_A)^2}}, \\quad \\sin \\theta_2 = \\frac{x_C - x_B}{\\sqrt{(x_C - x_B)^2 + (y_C - y_B)^2}}.\n\\]\nSubstituting these into the equation:\n\\[\nn_1 \\sin \\theta_1 + n_2 \\sin \\theta_2 = 0.\n\\]\nSince \\(\\sin \\theta_2\\) is in the opposite direction, we have:\n\\[\nn_1 \\sin \\theta_1 = n_2 \\sin \\theta_2.\n\\]\nThis is Snell’s law, which describes the relationship between the angles of incidence and refraction when light passes from one medium to another.\n\n\n\nBy applying Fermat’s principle and taking the variation of the optical path length, we have derived Snell’s law:\n\\[\nn_1 \\sin \\theta_1 = n_2 \\sin \\theta_2.\n\\]\nThis demonstrates how the principle of least time leads to the well-known law of refraction in optics.\n\n\n\n\n\n\n\n\n\n\nExample: Light in a Graded-Index Medium\n\n\n\n\n\nConsider a medium where the refractive index varies with height \\(y\\) as \\(n(y) = n_0 (1 - \\frac{\\alpha^2}{2 n_0} y^2)\\). The path of light in such a medium can be found by using Fermat’s principle in differential form:\n\\[\n\\frac{d}{ds}\\left (n(\\textbf{r})\\frac{d\\textbf{r}}{ds}\\right)=\\nabla n(\\textbf{r})\n\\]\nTypically, this requires to express the coordinates in terms of a parameter, such as \\(x(s)\\) and \\(y(s)\\), and then solve the differential equation. The solution will give the path of light in the medium. This is difficult and commonly done numerically. In paraxial optics, when the light is propagating roughly in the direction of \\(z\\), the differential element \\(ds\\) can be approximated as \\(dz\\) since then\n\\[\nds=dz\\sqrt{1+\\left (\\frac{dy}{dz}\\right )^2+\\left (\\frac{dx}{dz}\\right)^2}\\approx dz\n\\]\nwhich yields\n\\[\n\\frac{d}{dz}\\left (n\\frac{dx}{dz}\\right)\\approx \\frac{dn}{dx}\n\\]\nand\n\\[\n\\frac{d}{dz}\\left (n\\frac{dy}{dz}\\right )\\approx \\frac{dn}{dy}\n\\]\nThis readily yields the path of light in a homogeneous medium, where \\(n\\) is constant. In this case we have\n\\[\n\\frac{d^2 x}{dz^2}=\\frac{d^2 y}{dz^2}=0\n\\]\nwhich is true for a straight line. In a graded-index medium, the path of light can be found by solving the differential equation\n\\[\n\\frac{d^2 y}{dz^2}=-\\alpha^2 y\n\\]\nwhich is reminiscent of the equation of motion of a harmonic oscillator. The solution is therefore an oscillating function\n\\[\ny(z)=y_0\\cos(\\alpha z)+\\frac{\\theta_0}{\\alpha}\\sin(\\alpha z  )\n\\]\nwhere the angle \\(\\theta_0\\) is the initial angle of the light ray with respect to the \\(z\\) axis. This solution describes the path of light in a graded-index medium.\n\n\n\n\n\n\n\n\n\nFermats’s Principle in Integral and Differential Form\n\n\n\n\n\nWe have described Fermat’t principle in an integral form specifiying the optical path length \\(S\\) as\n\\[\nOPL=\\int n(\\textbf{r})ds\n\\]\nThe path length \\(ds\\) can be given in terms of two coordinates \\(x_1\\) and \\(x_2\\) parametrized by \\(\\lambda\\) such that\n\\[\nds=\\sqrt{\\dot{x}_1^{2}+\\dot{x}_2^{2}}d\\lambda\n\\]\nwhere \\(\\dot{x}_1=\\frac{dx_{1}}{d\\lambda}\\). We can therefore write Fermat’s principle as\n\\[\n\\delta OPL=\\int\\left[\\left(\\frac{\\partial n}{\\partial x_i} \\delta x_i\\right) \\sqrt{\\dot{x}_1^2+\\dot{x}_2^2}+n \\frac{1}{\\sqrt{\\dot{x}_1^2+\\dot{x}_2^2}} \\dot{x}_i \\delta \\dot{x}_i\\right] d \\lambda = 0\n\\]\nTo evaluate this integral we would like to integrate by parts. We can write the integrand as \\[\nu = n \\frac{1}{\\sqrt{\\dot{x}_1^2+\\dot{x}_2^2}} \\dot{x}_i\n\\]\nand\n\\[\ndv = \\delta \\dot{x}_i d\\lambda\n\\]\nWe can now calculate \\(du\\) and \\(v\\) and obtain\n\\[\ndu = \\frac{d}{d\\lambda}\\left[n \\frac{1}{\\sqrt{\\dot{x}_1^2+\\dot{x}_2^2}} \\dot{x}_i\\right] d\\lambda\n\\]\nand\n\\[\nv = \\delta x_i\n\\]\nWith these expressions we can now apply the integration by parts formula \\(\\int u dv = uv - \\int v du\\), we get:\n\\[\n\\int n \\frac{1}{\\sqrt{\\dot{x}_1^2+\\dot{x}_2^2}} \\dot{x}_i \\delta \\dot{x}_i d\\lambda = \\left[n \\frac{1}{\\sqrt{\\dot{x}_1^2+\\dot{x}_2^2}} \\dot{x}_i \\delta x_i\\right]|_{\\lambda_1}^{\\lambda_2} - \\int \\delta x_i \\frac{d}{d\\lambda}\\left[n \\frac{1}{\\sqrt{\\dot{x}_1^2+\\dot{x}_2^2}} \\dot{x}_i\\right] d\\lambda\n\\]\nThis can be substituted back into the original equation to obtain\n\\[\n\\begin{aligned}\n\\delta OPL &= \\int \\left[\\left(\\frac{\\partial n}{\\partial x_i} \\delta x_i\\right) \\sqrt{\\dot{x}_1^2+\\dot{x}_2^2}\\right] d\\lambda \\\\\n&+ \\left[n \\frac{1}{\\sqrt{\\dot{x}_1^2+\\dot{x}_2^2}} \\dot{x}_i \\delta x_i\\right]|_{\\lambda_1}^{\\lambda_2} \\\\\n&- \\int \\delta x_i \\frac{d}{d\\lambda}\\left[n \\frac{1}{\\sqrt{\\dot{x}_1^2+\\dot{x}_2^2}} \\dot{x}_i\\right] d\\lambda = 0\n\\end{aligned}\n\\]\nAfter rearranging the terms we get\n\\[\n\\begin{aligned}\n\\delta OPL &= \\int \\left\\{\\frac{\\partial n}{\\partial x_i} \\sqrt{\\dot{x}_1^2+\\dot{x}_2^2} - \\frac{d}{d\\lambda}\\left[n \\frac{1}{\\sqrt{\\dot{x}_1^2+\\dot{x}_2^2}} \\dot{x}_i\\right]\\right\\} \\delta x_i d\\lambda \\\\\n&+ \\left[n \\frac{1}{\\sqrt{\\dot{x}_1^2+\\dot{x}_2^2}} \\dot{x}_i \\delta x_i\\right]|_{\\lambda_1}^{\\lambda_2} = 0\n\\end{aligned}\n\\]\nand therefore finally\n\\[\n\\delta OPL=\\int\\left[\\left(\\frac{\\partial n}{\\partial x_i}\\right) \\sqrt{\\dot{x}_1{ }^2+\\dot{x}_2{ }^2}-\\frac{d}{d \\lambda}\\left(n \\frac{1}{\\sqrt{\\dot{x}_1^2+\\dot{x}_2^2}} \\dot{x}_i\\right)\\right] \\delta x_i d \\lambda+\\text { boundary terms }\n\\]\nfor which we choose the parameter \\(\\lambda\\) such that the boundary terms vanish.\n\\[\n\\lambda=s\n\\]\nsuch that\n\\[\n\\sqrt{\\dot{x}_1^2+\\dot{x}_2^2}=1\n\\]\nand finally leads to the Euler-Lagrange equation\n\\[\n\\left(\\frac{\\partial n}{\\partial x_i}\\right)-\\frac{d}{d s}\\left(n \\dot{x}_i\\right)=0\n\\]\nwhich is the differential form of the Fermat’s principle.",
    "crumbs": [
      "Geometrical Optics",
      "Lecture 1",
      "Refraction"
    ]
  },
  {
    "objectID": "geometrical-optics/refraction-total-internal-reflection.html#refraction",
    "href": "geometrical-optics/refraction-total-internal-reflection.html#refraction",
    "title": "Refraction and Total Internal Reflection",
    "section": "",
    "text": "Historical Context of Refraction\n\n\n\n\n\nThe understanding of refraction has evolved over centuries, with contributions from various cultures and scientific traditions. This timeline highlights key milestones in the discovery and formalization of refraction, showcasing how our comprehension of this fundamental optical phenomenon has deepened over time:\n\nAncient Greece (3rd century BCE): Euclid noticed that a stick partially submerged in water appears bent. Archimedes studied the refraction of light in water.\nAncient Rome (1st century CE): Ptolemy conducted experiments on refraction and compiled tables of refraction angles for different media.\nIslamic Golden Age (10th-11th centuries): Ibn Sahl (940-1000) discovered the law of refraction, describing it geometrically. Alhazen (965-1040) studied lenses and the human eye, contributing significantly to optics.\nMiddle Ages: Robert Grosseteste (1175-1253) and Roger Bacon (1214-1294) studied refraction and its application to lenses.\nRenaissance: Thomas Harriot (1560-1621) rediscovered the law of refraction but didn’t publish his findings.\n17th Century: Willebrord Snellius (1580-1626) derived the mathematical law of refraction (Snell’s law) around 1621. René Descartes (1596-1650) independently derived and published the law of refraction in 1637. Pierre de Fermat (1607-1665) derived the law of refraction using his principle of least time.\n19th Century: Augustin-Jean Fresnel (1788-1827) developed the wave theory of light, explaining refraction in terms of changes in wave speed.\n20th Century: The quantum mechanical understanding of light, which emerged in the early 20th century, significantly impacted our view of refraction. Max Planck’s work on black body radiation in 1900 and Albert Einstein’s explanation of the photoelectric effect in 1905 laid the groundwork for the quantum nature of light. This quantum perspective provided a complementary explanation to the wave theory, describing refraction in terms of photons interacting with the atoms in the medium. While this quantum view offers insights into certain aspects of refraction, it’s important to note that both the wave and particle descriptions of light are necessary for a complete understanding of optical phenomena.\n\n\n\n\nThe law of refraction is the second important law of geometrical optics. It relates the refractive index \\(n_1\\) and angle of incidence \\(\\theta_1\\) on one side of an interface to the refractive index \\(n_2\\) and angle of refraction \\(\\theta_2\\) on the other side. Both the law of reflection and the law of refraction can be derived from more fundamental principles such as Fermat’s principle of least time and are consistent with the conservation of energy. Their relation to momentum is more complex and involves considering the interaction of light with the medium at an atomic level. These laws provide a mathematical framework for predicting how light behaves when it encounters interfaces between different media, forming the basis for understanding a wide range of optical phenomena and the design of optical devices.\n\n\nThe refractive index \\(n\\) is a material constant representing the factor by which the speed of light is reduced in the medium compared to its speed in vacuum. For most natural materials and visible light, the refractive index is \\(n \\ge 1\\), as light typically travels slower in media than in vacuum. However, in certain special cases—such as for X-rays in some materials or in engineered metamaterials—the refractive index can be less than 1 or even negative. Understanding these exotic cases requires a deeper exploration of the electromagnetic properties of materials and the origin of the refractive index, which we will address later.\n\n\n\n \n\n\n\n\n\n\nLaw of Refraction (Snell’s Law)\n\n\n\nThe law of refraction (Snell’s law) is given for the above sketch by the equation:\n\\[\nn_1 \\sin(\\theta_1)=n_2 \\sin(\\theta_2)\n\\]\n\n\nYou can explore the law of refraction using the interactive visualization below. The visualization shows a light ray incident on an interface between two media with different refractive indices. You can adjust the angle of incidence and the refractive index of the first medium to see how the angle of refraction changes according to Snell’s law.\n\n\n\nIncident Angle: 45°\n\nRefractive Index n₁: 1.0\n\nRefractive Index n₂: 1.5\n\n\n\n\nSnell’s law leads to some general patterns in the behavior of light rays at interfaces, which are worth remembering. Consider these two cases:\n\nWhen light moves from a medium with lower refractive index to one with higher refractive index (\\(n_1 &lt; n_2\\)):\n\nThe refracted ray bends towards the normal (optical axis)\nThe angle of refraction is smaller than the angle of incidence (\\(\\theta_2 &lt; \\theta_1\\))\n\nWhen light moves from a medium with higher refractive index to one with lower refractive index (\\(n_1 &gt; n_2\\)):\n\nThe refracted ray bends away from the normal (optical axis)\nThe angle of refraction is larger than the angle of incidence (\\(\\theta_2 &gt; \\theta_1\\))\n\n\nFigure 1 illustrates these principles with three plots showing how the refracted angle changes with the incident angle for two common interface scenarios: glass-to-air and air-to-glass. These plots clearly demonstrate the different behaviors described above.\n\n\n\nCode\ndef snell(n1, n2, theta1):\n    sin_theta2 = n1 * np.sin(theta1) / n2\n    theta2 = np.arcsin(np.clip(sin_theta2, -1, 1))\n    theta2[sin_theta2 &gt; 1] = np.nan\n    return theta2\n\nfig, ax = plt.subplots(figsize=(4, 4))\n\ntheta1 = np.linspace(0, np.pi/2, 1000)\n\ntheta2_1_to_1_5 = snell(1.0, 1.5, theta1)\ntheta2_1_5_to_1 = snell(1.5, 1.0, theta1)\ntheta2_1_to_1 = snell(1.0, 1.0, theta1)\n\nax.plot(np.degrees(theta1), np.degrees(theta2_1_to_1_5), color='blue')\nax.plot(np.degrees(theta1), np.degrees(theta2_1_5_to_1), color='red')\nax.plot(np.degrees(theta1), np.degrees(theta2_1_to_1), color='green', linestyle='--')\n\nax.set_xlabel(r'$\\theta_1$ [°]')\nax.set_ylabel(r'$\\theta_2$ [°]')\nax.set_xlim(0, 90)\nax.set_ylim(0, 90)\n\nax.plot([0, 90], [0, 90], color='gray', linestyle=':', label='y=x')\n\nax.annotate(r'$\\frac{n_2}{n_1}=1.5$', xy=(60, 35), xytext=(50, 20),\n            arrowprops=dict(arrowstyle='-&gt;'), color='blue')\nax.annotate(r'$\\frac{n_1}{n_2}=1.5$', xy=(30, 50), xytext=(10, 70),\n            arrowprops=dict(arrowstyle='-&gt;'), color='red')\nax.annotate(r'$\\frac{n_2}{n_1}=1$', xy=(45, 45), xytext=(65, 50),\n            arrowprops=dict(arrowstyle='-&gt;'), color='green')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nFigure 1— Snell’s law for different combinations of refractive indices. The plots show the relationship between incident angle (\\(\\theta_1\\)) and refracted angle (\\(\\theta_2\\)) for three scenarios: (a) light passing from air to glass, (b) light passing from glass to air, and (c) a comparison of both cases. Note how the curves differ when light moves into a medium with higher refractive index versus a lower refractive index.\n\n\n\n\n\n\n\n\nThe above diagram reveals a special case occurring when \\(n_1 &gt; n_2\\). Under these conditions, we can increase the incident angle \\(\\theta_1\\) until the outgoing angle reaches \\(\\theta_2 = \\frac{\\pi}{2}\\). At this point, the refracted ray would be traveling along the interface between the two media. For any incident angle \\(\\theta_1\\) larger than this critical angle, there is no refracted ray at all; instead, we observe only a reflected ray. This phenomenon, known as total internal reflection, occurs despite the fact that the material with refractive index \\(n_2\\) is completely transparent.\nLet’s formalize this concept mathematically. Using Snell’s law and setting \\(\\theta_2 = \\frac{\\pi}{2}\\), we obtain the equation for the critical angle \\(\\theta_c\\):\n\\[\\theta_1 = \\theta_c = \\sin^{-1}\\left(\\frac{n_2}{n_1}\\right)\\]\nNote that the \\(\\sin^{-1}()\\) function requires an argument \\(\\le 1\\), which is why this phenomenon only occurs when \\(n_2 &lt; n_1\\).\nIt’s important to understand that during total internal reflection, all of the light energy is reflected back into the first medium, hence the term ‘total’. However, electromagnetic optics reveals an interesting subtlety: an evanescent wave penetrates a short distance into the second medium, though it doesn’t propagate energy across the boundary.\nWhen the incident angle exceeds the critical angle, Snell’s law as we’ve written it no longer applies. Instead, we observe perfect reflection, where the angle of reflection equals the angle of incidence, just as in regular reflection from a mirror. This reflection occurs without any loss of energy to the second medium, making it an extremely efficient process.\n \n\n\n\n\n\n\nTotal Internal Reflection\n\n\n\nTotal internal reflection occurs when light is passing from higher refractive index to lower refractive index materials for incidence angle larger than a critical angle\n\\[\n\\theta_c=\\sin^{-1}\\left (\\frac{n_2}{n_1}\\right )\n\\]\n\n\nWe can demonstrate total internal reflection very easily with a water basin, for example, where we couple in light from a laser from the side.\n \nBut you could try that yourself also in the bath tub diving below the water surface.\nTotal internal reflection has numerous practical applications:\n\nFiber optic communications: Light signals can travel long distances with minimal loss through optical fibers.\nOptical instruments: Prisms in binoculars and telescopes use total internal reflection to manipulate light paths.\nGemstones: The sparkle of diamonds is enhanced by total internal reflection trapping light within the stone.\nMedical endoscopes: Total internal reflection helps guide light through flexible tubes for internal imaging.\n\nOptical Fibers and Total Internal Reflection\nTotal internal reflection plays a crucial role in modern telecommunications, particularly in optical fibers, which are also part of many experimental setups. These fibers are essentially ultra-thin glass wires, ranging in diameter from a few micrometers to several hundred micrometers, designed to transport light over long distances with minimal loss.\nThe structure of an optical fiber is key to its function:\n\nCore: A central glass core with a refractive index \\(n_1\\)\nCladding: A surrounding layer with a slightly lower refractive index \\(n_2\\)\n\nThis difference in refractive indices is what allows total internal reflection to occur within the fiber.\n \nFor light to propagate effectively through the fiber, it must enter at an angle that ensures total internal reflection at the core-cladding interface. This leads to the concept of the acceptance angle, \\(\\theta_a\\), which is the maximum angle at which light can enter the fiber and still undergo total internal reflection.\nTo characterize this acceptance angle, optical engineers use a parameter called the Numerical Aperture (NA).\n\n\n\n\n\n\nNumerical Aperture\n\n\n\nThe Numerical Aperture of a fiber is defined as the sine of the maximum acceptance angle:\n\\[\\begin{equation}\nNA = \\sin(\\theta_a) = \\sqrt{n_1^2 - n_2^2}\n\\end{equation}\\]\n\n\nThis equation relates the NA directly to the refractive indices of the core and cladding. The derivation of this formula involves applying Snell’s law at the air-fiber interface and at the core-cladding interface, then using the condition for total internal reflection.\nIn practice, typical values for the refractive indices might be \\(n_1 = 1.475\\) for the core and \\(n_2 = 1.46\\) for the cladding. Plugging these into our equation:\n\\[\\begin{equation}\nNA = \\sqrt{1.475^2 - 1.46^2} \\approx 0.2\n\\end{equation}\\]\nThis means that light entering the fiber within a cone of about 11.5° (arcsin(0.2)) from the fiber’s axis will be transmitted through the fiber via total internal reflection.\nThe NA is an important parameter in fiber optic design:\n\nIt determines the light-gathering ability of the fiber.\nIt affects the fiber’s bandwidth and its susceptibility to certain types of signal distortion.\nIt influences how easily the fiber can be coupled to light sources and other fibers.\n\nOptical fibers come in various types, each optimized for different applications. Some fibers are designed to transmit light over long distances with minimal loss, while others are engineered for specific wavelengths or to guide light in unusual ways. The figure below shows a few examples of optical fiber types.\n\n\n\n\n\n\nFigure 2— Rendering of different optical fibers types (from left to right): Hollow core optical fiber, hollow core bragg fiber, photonic crystal fiber, conventional fiber\n\n\n\n\n\n\nWhile before we have considered Fermat’s principle for the special case of refraction and light propagation in a homogeneous medium, we can define a more general version of it correponding to the following situation also involving an inhomogeneous refractive index \\(n(\\vec{r})\\).\n\n\n\n\n\n\nFigure 3— Sketch for a general description of Fermat’s principle\n\n\n\nFor this general scenario of light traveling along a path, we can define an optical path length (OPL) as\n\\[\\begin{equation}\n\\text{OPL} = \\int\\limits_{A}^{C} n(\\mathbf{r}) \\mathrm ds=0,\n\\end{equation}\\]\nwith a varying refractive index \\(n(\\mathbf{r})\\). Fermat’s Principle states that the actual path taken by the light makes the OPL stationary:\n\\[\n\\delta \\left( \\int_A^B n(\\mathbf{r}) \\, ds \\right) = 0\n\\]\nUsing the calculus of variations, this leads to the Euler-Lagrange equation for the path of light. In Cartesian coordinates, if the path is parameterized by \\(\\mathbf{r}(s) = (x(s), y(s), z(s))\\), the Euler-Lagrange equations become:\n\\[\n\\frac{d}{ds} \\left( n \\frac{d\\mathbf{r}}{ds} \\right) = \\nabla n\n\\]\nwhere \\(\\nabla n\\) is the gradient of the refractive index. This equation describes how the light ray bends in response to changes in the refractive index of the medium.\nFermat’s Principle is a cornerstone of geometrical optics and has applications in designing optical systems, understanding mirages, and analyzing the behavior of light in various media.\n\n\n\n\n\n\nFermat’s Principle and Snells Law\n\n\n\n\n\nWe would like to apply Fermat’s principle to derive Snell’s law, which is a more lengthy calculation. To do this, we consider a light ray traveling from point \\(A\\) in medium 1 (with refractive index \\(n_1\\)) to point \\(C\\) in medium 2 (with refractive index \\(n_2\\)), crossing the interface at point \\(B\\). Let the coordinates of points \\(A\\), \\(B\\), and \\(C\\) be \\((x_A, y_A)\\), \\((x_B, y_B)\\), and \\((x_C, y_C)\\), respectively. Assume the interface between the two media is at \\(y = y_B\\). The optical path length (OPL) is given by:\n\\[\n\\delta \\int_{A}^{C} n(\\vec{r}) \\, ds = 0,\n\\]\nwhere \\(n(\\vec{r})\\) is the refractive index at position \\(\\vec{r}\\), and \\(ds\\) is an infinitesimal element of the path.\nConsider a light ray traveling from point \\(A\\) in medium 1 (with refractive index \\(n_1\\)) to point \\(C\\) in medium 2 (with refractive index \\(n_2\\)), crossing the interface at point \\(B\\). Let the coordinates of points \\(A\\), \\(B\\), and \\(C\\) be \\((x_A, y_A)\\), \\((x_B, y_B)\\), and \\((x_C, y_C)\\), respectively. Assume the interface between the two media is at \\(y = y_B\\).\n\n\nThe optical path length (OPL) is given by:\n\\[\n\\text{OPL} = n_1 \\int_{A}^{B} ds_1 + n_2 \\int_{B}^{C} ds_2,\n\\]\nwhere \\(ds_1\\) and \\(ds_2\\) are the infinitesimal path lengths in media 1 and 2, respectively.\n\n\n\nThe path lengths \\(ds_1\\) and \\(ds_2\\) can be expressed in terms of the coordinates:\n\\[\nds_1 = \\sqrt{(dx_1)^2 + (dy_1)^2}, \\quad ds_2 = \\sqrt{(dx_2)^2 + (dy_2)^2}.\n\\]\nSince the interface is at \\(y = y_B\\), we have \\(dy_1 = y_B - y_A\\) and \\(dy_2 = y_C - y_B\\). The total optical path length is:\n\\[\n\\text{OPL} = n_1 \\sqrt{(x_B - x_A)^2 + (y_B - y_A)^2} + n_2 \\sqrt{(x_C - x_B)^2 + (y_C - y_B)^2}.\n\\]\n\n\n\nTo find the stationary path, we take the variation of the OPL with respect to \\(x_B\\):\n\\[\n\\delta \\text{OPL} = \\delta \\left[ n_1 \\sqrt{(x_B - x_A)^2 + (y_B - y_A)^2} + n_2 \\sqrt{(x_C - x_B)^2 + (y_C - y_B)^2} \\right] = 0.\n\\]\nTaking the derivative with respect to \\(x_B\\):\n\\[\n\\frac{\\partial}{\\partial x_B} \\left[ n_1 \\sqrt{(x_B - x_A)^2 + (y_B - y_A)^2} + n_2 \\sqrt{(x_C - x_B)^2 + (y_C - y_B)^2} \\right] = 0.\n\\]\n\n\n\nDifferentiating each term separately:\n\\[\nn_1 \\frac{\\partial}{\\partial x_B} \\sqrt{(x_B - x_A)^2 + (y_B - y_A)^2} + n_2 \\frac{\\partial}{\\partial x_B} \\sqrt{(x_C - x_B)^2 + (y_C - y_B)^2} = 0.\n\\]\nUsing the chain rule:\n\\[\nn_1 \\frac{x_B - x_A}{\\sqrt{(x_B - x_A)^2 + (y_B - y_A)^2}} + n_2 \\frac{x_B - x_C}{\\sqrt{(x_C - x_B)^2 + (y_C - y_B)^2}} = 0.\n\\]\n\n\n\nLet \\(\\theta_1\\) be the angle of incidence and \\(\\theta_2\\) be the angle of refraction. Then:\n\\[\n\\sin \\theta_1 = \\frac{x_B - x_A}{\\sqrt{(x_B - x_A)^2 + (y_B - y_A)^2}}, \\quad \\sin \\theta_2 = \\frac{x_C - x_B}{\\sqrt{(x_C - x_B)^2 + (y_C - y_B)^2}}.\n\\]\nSubstituting these into the equation:\n\\[\nn_1 \\sin \\theta_1 + n_2 \\sin \\theta_2 = 0.\n\\]\nSince \\(\\sin \\theta_2\\) is in the opposite direction, we have:\n\\[\nn_1 \\sin \\theta_1 = n_2 \\sin \\theta_2.\n\\]\nThis is Snell’s law, which describes the relationship between the angles of incidence and refraction when light passes from one medium to another.\n\n\n\nBy applying Fermat’s principle and taking the variation of the optical path length, we have derived Snell’s law:\n\\[\nn_1 \\sin \\theta_1 = n_2 \\sin \\theta_2.\n\\]\nThis demonstrates how the principle of least time leads to the well-known law of refraction in optics.\n\n\n\n\n\n\n\n\n\n\nExample: Light in a Graded-Index Medium\n\n\n\n\n\nConsider a medium where the refractive index varies with height \\(y\\) as \\(n(y) = n_0 (1 - \\frac{\\alpha^2}{2 n_0} y^2)\\). The path of light in such a medium can be found by using Fermat’s principle in differential form:\n\\[\n\\frac{d}{ds}\\left (n(\\textbf{r})\\frac{d\\textbf{r}}{ds}\\right)=\\nabla n(\\textbf{r})\n\\]\nTypically, this requires to express the coordinates in terms of a parameter, such as \\(x(s)\\) and \\(y(s)\\), and then solve the differential equation. The solution will give the path of light in the medium. This is difficult and commonly done numerically. In paraxial optics, when the light is propagating roughly in the direction of \\(z\\), the differential element \\(ds\\) can be approximated as \\(dz\\) since then\n\\[\nds=dz\\sqrt{1+\\left (\\frac{dy}{dz}\\right )^2+\\left (\\frac{dx}{dz}\\right)^2}\\approx dz\n\\]\nwhich yields\n\\[\n\\frac{d}{dz}\\left (n\\frac{dx}{dz}\\right)\\approx \\frac{dn}{dx}\n\\]\nand\n\\[\n\\frac{d}{dz}\\left (n\\frac{dy}{dz}\\right )\\approx \\frac{dn}{dy}\n\\]\nThis readily yields the path of light in a homogeneous medium, where \\(n\\) is constant. In this case we have\n\\[\n\\frac{d^2 x}{dz^2}=\\frac{d^2 y}{dz^2}=0\n\\]\nwhich is true for a straight line. In a graded-index medium, the path of light can be found by solving the differential equation\n\\[\n\\frac{d^2 y}{dz^2}=-\\alpha^2 y\n\\]\nwhich is reminiscent of the equation of motion of a harmonic oscillator. The solution is therefore an oscillating function\n\\[\ny(z)=y_0\\cos(\\alpha z)+\\frac{\\theta_0}{\\alpha}\\sin(\\alpha z  )\n\\]\nwhere the angle \\(\\theta_0\\) is the initial angle of the light ray with respect to the \\(z\\) axis. This solution describes the path of light in a graded-index medium.\n\n\n\n\n\n\n\n\n\nFermats’s Principle in Integral and Differential Form\n\n\n\n\n\nWe have described Fermat’t principle in an integral form specifiying the optical path length \\(S\\) as\n\\[\nOPL=\\int n(\\textbf{r})ds\n\\]\nThe path length \\(ds\\) can be given in terms of two coordinates \\(x_1\\) and \\(x_2\\) parametrized by \\(\\lambda\\) such that\n\\[\nds=\\sqrt{\\dot{x}_1^{2}+\\dot{x}_2^{2}}d\\lambda\n\\]\nwhere \\(\\dot{x}_1=\\frac{dx_{1}}{d\\lambda}\\). We can therefore write Fermat’s principle as\n\\[\n\\delta OPL=\\int\\left[\\left(\\frac{\\partial n}{\\partial x_i} \\delta x_i\\right) \\sqrt{\\dot{x}_1^2+\\dot{x}_2^2}+n \\frac{1}{\\sqrt{\\dot{x}_1^2+\\dot{x}_2^2}} \\dot{x}_i \\delta \\dot{x}_i\\right] d \\lambda = 0\n\\]\nTo evaluate this integral we would like to integrate by parts. We can write the integrand as \\[\nu = n \\frac{1}{\\sqrt{\\dot{x}_1^2+\\dot{x}_2^2}} \\dot{x}_i\n\\]\nand\n\\[\ndv = \\delta \\dot{x}_i d\\lambda\n\\]\nWe can now calculate \\(du\\) and \\(v\\) and obtain\n\\[\ndu = \\frac{d}{d\\lambda}\\left[n \\frac{1}{\\sqrt{\\dot{x}_1^2+\\dot{x}_2^2}} \\dot{x}_i\\right] d\\lambda\n\\]\nand\n\\[\nv = \\delta x_i\n\\]\nWith these expressions we can now apply the integration by parts formula \\(\\int u dv = uv - \\int v du\\), we get:\n\\[\n\\int n \\frac{1}{\\sqrt{\\dot{x}_1^2+\\dot{x}_2^2}} \\dot{x}_i \\delta \\dot{x}_i d\\lambda = \\left[n \\frac{1}{\\sqrt{\\dot{x}_1^2+\\dot{x}_2^2}} \\dot{x}_i \\delta x_i\\right]|_{\\lambda_1}^{\\lambda_2} - \\int \\delta x_i \\frac{d}{d\\lambda}\\left[n \\frac{1}{\\sqrt{\\dot{x}_1^2+\\dot{x}_2^2}} \\dot{x}_i\\right] d\\lambda\n\\]\nThis can be substituted back into the original equation to obtain\n\\[\n\\begin{aligned}\n\\delta OPL &= \\int \\left[\\left(\\frac{\\partial n}{\\partial x_i} \\delta x_i\\right) \\sqrt{\\dot{x}_1^2+\\dot{x}_2^2}\\right] d\\lambda \\\\\n&+ \\left[n \\frac{1}{\\sqrt{\\dot{x}_1^2+\\dot{x}_2^2}} \\dot{x}_i \\delta x_i\\right]|_{\\lambda_1}^{\\lambda_2} \\\\\n&- \\int \\delta x_i \\frac{d}{d\\lambda}\\left[n \\frac{1}{\\sqrt{\\dot{x}_1^2+\\dot{x}_2^2}} \\dot{x}_i\\right] d\\lambda = 0\n\\end{aligned}\n\\]\nAfter rearranging the terms we get\n\\[\n\\begin{aligned}\n\\delta OPL &= \\int \\left\\{\\frac{\\partial n}{\\partial x_i} \\sqrt{\\dot{x}_1^2+\\dot{x}_2^2} - \\frac{d}{d\\lambda}\\left[n \\frac{1}{\\sqrt{\\dot{x}_1^2+\\dot{x}_2^2}} \\dot{x}_i\\right]\\right\\} \\delta x_i d\\lambda \\\\\n&+ \\left[n \\frac{1}{\\sqrt{\\dot{x}_1^2+\\dot{x}_2^2}} \\dot{x}_i \\delta x_i\\right]|_{\\lambda_1}^{\\lambda_2} = 0\n\\end{aligned}\n\\]\nand therefore finally\n\\[\n\\delta OPL=\\int\\left[\\left(\\frac{\\partial n}{\\partial x_i}\\right) \\sqrt{\\dot{x}_1{ }^2+\\dot{x}_2{ }^2}-\\frac{d}{d \\lambda}\\left(n \\frac{1}{\\sqrt{\\dot{x}_1^2+\\dot{x}_2^2}} \\dot{x}_i\\right)\\right] \\delta x_i d \\lambda+\\text { boundary terms }\n\\]\nfor which we choose the parameter \\(\\lambda\\) such that the boundary terms vanish.\n\\[\n\\lambda=s\n\\]\nsuch that\n\\[\n\\sqrt{\\dot{x}_1^2+\\dot{x}_2^2}=1\n\\]\nand finally leads to the Euler-Lagrange equation\n\\[\n\\left(\\frac{\\partial n}{\\partial x_i}\\right)-\\frac{d}{d s}\\left(n \\dot{x}_i\\right)=0\n\\]\nwhich is the differential form of the Fermat’s principle.",
    "crumbs": [
      "Geometrical Optics",
      "Lecture 1",
      "Refraction"
    ]
  },
  {
    "objectID": "course-info/resources.html",
    "href": "course-info/resources.html",
    "title": "Resources",
    "section": "",
    "text": "This website makes use of the hypothes.is annotation service. You can use it to leave comments and feedback on the content of this website. To do so, you need to create a hypothes.is account. You can then highlight text on the website and leave comments. You can also reply to comments left by others and create your own nodes. We use this service for the first time, so please let us know if you like that. The annotation sidebar can be reached with the icons depicted in the figure above, wich are located at the right side of the screen. Here is the Link to the Hypothes.is group for this course.",
    "crumbs": [
      "Course Info",
      "Ressourcen"
    ]
  },
  {
    "objectID": "course-info/resources.html#comments-and-feedback",
    "href": "course-info/resources.html#comments-and-feedback",
    "title": "Resources",
    "section": "",
    "text": "This website makes use of the hypothes.is annotation service. You can use it to leave comments and feedback on the content of this website. To do so, you need to create a hypothes.is account. You can then highlight text on the website and leave comments. You can also reply to comments left by others and create your own nodes. We use this service for the first time, so please let us know if you like that. The annotation sidebar can be reached with the icons depicted in the figure above, wich are located at the right side of the screen. Here is the Link to the Hypothes.is group for this course.",
    "crumbs": [
      "Course Info",
      "Ressourcen"
    ]
  },
  {
    "objectID": "course-info/resources.html#books",
    "href": "course-info/resources.html#books",
    "title": "Resources",
    "section": "Books",
    "text": "Books\nThe course will be mainly built on a number of excellent books on electrodynamics and optics as well as on the basics of quantum mechanics.\n\nOptics and Electrodynamics\n\nDemtröder: Electrodynamics and Optics, Springer, 2019\nSaleh/Teich: Fundamentals of Photonics, Wiley, 2007\nJackson: Classical Electrodynamics, Wiley, 1998\nHecht: Optics, Pearson, 2016\n\n\n\nQuantum Mechanics\n\nDemtröder: Atoms, Molecules and Photons, Springer, 2010\nHaken, Wolf: The Physics of Atoms and Quanta: Introduction to Experiments and Theory, Springer, 2005\nHarnwel, Livingood: Experimental Atomic Physics, McGraw-Hill Book Company, Inc, 1933",
    "crumbs": [
      "Course Info",
      "Ressourcen"
    ]
  },
  {
    "objectID": "course-info/resources.html#molecular-nanophotonics-group",
    "href": "course-info/resources.html#molecular-nanophotonics-group",
    "title": "Resources",
    "section": "Molecular Nanophotonics Group",
    "text": "Molecular Nanophotonics Group\nBesides the books, you may also want to have a look at the following websites maintained by the group:\n\nMolecular Nanophotonics Group Website\nComputer-based Physical Modeling Website @ MONA",
    "crumbs": [
      "Course Info",
      "Ressourcen"
    ]
  },
  {
    "objectID": "course-info/intructors.html",
    "href": "course-info/intructors.html",
    "title": "Instructors",
    "section": "",
    "text": "Linnéstr. 5, 04103 Leipzig\nOffice: 322\nPhone: +49 341 97 32571\nEmail: lastname@physik.uni-leipzig.de",
    "crumbs": [
      "Course Info",
      "Instructor"
    ]
  },
  {
    "objectID": "course-info/intructors.html#prof.-dr.-frank-cichos",
    "href": "course-info/intructors.html#prof.-dr.-frank-cichos",
    "title": "Instructors",
    "section": "",
    "text": "Linnéstr. 5, 04103 Leipzig\nOffice: 322\nPhone: +49 341 97 32571\nEmail: lastname@physik.uni-leipzig.de",
    "crumbs": [
      "Course Info",
      "Instructor"
    ]
  },
  {
    "objectID": "course-info/intructors.html#axel-märcker",
    "href": "course-info/intructors.html#axel-märcker",
    "title": "Instructors",
    "section": "Axel Märcker",
    "text": "Axel Märcker\n\nVorlesungsexperimente\nLinnéstr. 5, 04103 Leipzig",
    "crumbs": [
      "Course Info",
      "Instructor"
    ]
  },
  {
    "objectID": "course-info/intructors.html#dr.-diptabrata-paul",
    "href": "course-info/intructors.html#dr.-diptabrata-paul",
    "title": "Instructors",
    "section": "Dr. Diptabrata Paul",
    "text": "Dr. Diptabrata Paul\n\nLinnéstr. 5, 04103 Leipzig\nOffice: 333a\nPhone: +49 341 97 32570\nEmail: firstname.lastname@physik.uni-leipzig.de",
    "crumbs": [
      "Course Info",
      "Instructor"
    ]
  },
  {
    "objectID": "course-info/intructors.html#dr.-markus-anton",
    "href": "course-info/intructors.html#dr.-markus-anton",
    "title": "Instructors",
    "section": "Dr. Markus Anton",
    "text": "Dr. Markus Anton\n\nLinnéstr. 5, 04103 Leipzig\nOffice: 333a\nPhone: +49 341 97 32570\nEmail: lastname@physik.uni-leipzig.de",
    "crumbs": [
      "Course Info",
      "Instructor"
    ]
  },
  {
    "objectID": "wave-optics/PC.html",
    "href": "wave-optics/PC.html",
    "title": "Calculating Band Structure for 2D Photonic Crystals",
    "section": "",
    "text": "A 2D photonic crystal consists of a periodic arrangement of dielectric materials. For a square lattice with lattice constant a, the dielectric function \\epsilon(\\mathbf{r}) is periodic:\n\\epsilon(\\mathbf{r}) = \\epsilon(\\mathbf{r} + \\mathbf{R})\nwhere \\mathbf{R} = n_1\\mathbf{a}_1 + n_2\\mathbf{a}_2 is any lattice vector.\n\n\n\nFor 2D photonic crystals, Maxwell’s equations can be separated into TE and TM modes. For TM modes (E-field parallel to rods), we solve:\n\\nabla \\times \\frac{1}{\\epsilon(\\mathbf{r})} \\nabla \\times \\mathbf{E} = \\frac{\\omega^2}{c^2}\\mathbf{E}\n\n\n\nThe dielectric function can be expanded in reciprocal lattice vectors:\n\\epsilon(\\mathbf{r}) = \\sum_\\mathbf{G} \\epsilon_\\mathbf{G} e^{i\\mathbf{G}\\cdot\\mathbf{r}}\nFor circular rods of radius R in a square lattice:\n\\epsilon_\\mathbf{G} = \\epsilon_a + (\\epsilon_b - \\epsilon_a)f\\frac{2J_1(|\\mathbf{G}|R)}{|\\mathbf{G}|R}\nwhere: - \\epsilon_a is the background dielectric constant - \\epsilon_b is the rod dielectric constant - f is the filling fraction (\\pi R^2/a^2 for circular rods) - J_1 is the Bessel function of first kind\n\n\n\nThe electric field can be expanded using Bloch’s theorem:\n\\mathbf{E}(\\mathbf{r}) = e^{i\\mathbf{k}\\cdot\\mathbf{r}}\\sum_\\mathbf{G} \\mathbf{E}_\\mathbf{G} e^{i\\mathbf{G}\\cdot\\mathbf{r}}\n\n\n\nThis leads to the eigenvalue equation:\n\\sum_{\\mathbf{G}'} |\\mathbf{k} + \\mathbf{G}|^2 \\epsilon_{\\mathbf{G}-\\mathbf{G}'} E_{\\mathbf{G}'} = \\frac{\\omega^2}{c^2}E_\\mathbf{G}\n\n\n\nFor numerical calculations, we truncate the plane wave expansion to a finite number of G vectors. The matrix elements of the eigenvalue problem are:\nH_{\\mathbf{G}\\mathbf{G}'} = |\\mathbf{k} + \\mathbf{G}|^2\\delta_{\\mathbf{G}\\mathbf{G}'} + V_{\\mathbf{G}-\\mathbf{G}'}\nwhere:\nV_{\\mathbf{G}} = (\\epsilon_b - \\epsilon_a)f\\frac{2J_1(|\\mathbf{G}|R)}{|\\mathbf{G}|R}\n\n\n\nFor a square lattice, the high symmetry points in the first Brillouin zone are:\n\n\\Gamma: (0,0)\nX: (\\pi/a,0)\nM: (\\pi/a,\\pi/a)\n\n\n\n\nA complete photonic band gap exists when there is a frequency range where:\n\\max_{\\mathbf{k}}(\\omega_n(\\mathbf{k})) &lt; \\min_{\\mathbf{k}}(\\omega_{n+1}(\\mathbf{k}))\nfor some band index n."
  },
  {
    "objectID": "wave-optics/PC.html#theory-and-formulas",
    "href": "wave-optics/PC.html#theory-and-formulas",
    "title": "Calculating Band Structure for 2D Photonic Crystals",
    "section": "",
    "text": "A 2D photonic crystal consists of a periodic arrangement of dielectric materials. For a square lattice with lattice constant a, the dielectric function \\epsilon(\\mathbf{r}) is periodic:\n\\epsilon(\\mathbf{r}) = \\epsilon(\\mathbf{r} + \\mathbf{R})\nwhere \\mathbf{R} = n_1\\mathbf{a}_1 + n_2\\mathbf{a}_2 is any lattice vector.\n\n\n\nFor 2D photonic crystals, Maxwell’s equations can be separated into TE and TM modes. For TM modes (E-field parallel to rods), we solve:\n\\nabla \\times \\frac{1}{\\epsilon(\\mathbf{r})} \\nabla \\times \\mathbf{E} = \\frac{\\omega^2}{c^2}\\mathbf{E}\n\n\n\nThe dielectric function can be expanded in reciprocal lattice vectors:\n\\epsilon(\\mathbf{r}) = \\sum_\\mathbf{G} \\epsilon_\\mathbf{G} e^{i\\mathbf{G}\\cdot\\mathbf{r}}\nFor circular rods of radius R in a square lattice:\n\\epsilon_\\mathbf{G} = \\epsilon_a + (\\epsilon_b - \\epsilon_a)f\\frac{2J_1(|\\mathbf{G}|R)}{|\\mathbf{G}|R}\nwhere: - \\epsilon_a is the background dielectric constant - \\epsilon_b is the rod dielectric constant - f is the filling fraction (\\pi R^2/a^2 for circular rods) - J_1 is the Bessel function of first kind\n\n\n\nThe electric field can be expanded using Bloch’s theorem:\n\\mathbf{E}(\\mathbf{r}) = e^{i\\mathbf{k}\\cdot\\mathbf{r}}\\sum_\\mathbf{G} \\mathbf{E}_\\mathbf{G} e^{i\\mathbf{G}\\cdot\\mathbf{r}}\n\n\n\nThis leads to the eigenvalue equation:\n\\sum_{\\mathbf{G}'} |\\mathbf{k} + \\mathbf{G}|^2 \\epsilon_{\\mathbf{G}-\\mathbf{G}'} E_{\\mathbf{G}'} = \\frac{\\omega^2}{c^2}E_\\mathbf{G}\n\n\n\nFor numerical calculations, we truncate the plane wave expansion to a finite number of G vectors. The matrix elements of the eigenvalue problem are:\nH_{\\mathbf{G}\\mathbf{G}'} = |\\mathbf{k} + \\mathbf{G}|^2\\delta_{\\mathbf{G}\\mathbf{G}'} + V_{\\mathbf{G}-\\mathbf{G}'}\nwhere:\nV_{\\mathbf{G}} = (\\epsilon_b - \\epsilon_a)f\\frac{2J_1(|\\mathbf{G}|R)}{|\\mathbf{G}|R}\n\n\n\nFor a square lattice, the high symmetry points in the first Brillouin zone are:\n\n\\Gamma: (0,0)\nX: (\\pi/a,0)\nM: (\\pi/a,\\pi/a)\n\n\n\n\nA complete photonic band gap exists when there is a frequency range where:\n\\max_{\\mathbf{k}}(\\omega_n(\\mathbf{k})) &lt; \\min_{\\mathbf{k}}(\\omega_{n+1}(\\mathbf{k}))\nfor some band index n."
  },
  {
    "objectID": "wave-optics/PC.html#implementation-in-python",
    "href": "wave-optics/PC.html#implementation-in-python",
    "title": "Calculating Band Structure for 2D Photonic Crystals",
    "section": "Implementation in Python",
    "text": "Implementation in Python\nThe numerical implementation requires:\n\nConstructing the reciprocal lattice vectors:\n\nG = 2*np.pi/a * np.array([\n    [0, 0],\n    [1, 0], [-1, 0], [0, 1], [0, -1],\n    [1, 1], [-1, -1], [1, -1], [-1, 1]\n])\n\nBuilding the Hamiltonian matrix:\n\nH[i,j] = np.sum(k_plus_G_i**2) if i == j else \\\n         (epsilon - 1) * np.pi * radius**2 / a**2 * \\\n         np.exp(-np.sum(G_diff**2) * radius**2/4)\n\nSolving the eigenvalue problem:\n\neigenvalues = linalg.eigvalsh(H)"
  },
  {
    "objectID": "wave-optics/PC.html#required-parameters",
    "href": "wave-optics/PC.html#required-parameters",
    "title": "Calculating Band Structure for 2D Photonic Crystals",
    "section": "Required Parameters",
    "text": "Required Parameters\n\n\n\nParameter\nDescription\nTypical Values\n\n\n\n\na\nLattice constant\nUnit length\n\n\n\\epsilon_b\nRod dielectric constant\n8.9 (Al₂O₃)\n\n\n\\epsilon_a\nBackground dielectric constant\n1 (air)\n\n\nR\nRod radius\n0.2a - 0.4a\n\n\nN_G\nNumber of G vectors\n9-25"
  },
  {
    "objectID": "wave-optics/PC.html#numerical-considerations",
    "href": "wave-optics/PC.html#numerical-considerations",
    "title": "Calculating Band Structure for 2D Photonic Crystals",
    "section": "Numerical Considerations",
    "text": "Numerical Considerations\n\nConvergence: Check convergence with respect to:\n\nNumber of plane waves\nk-point sampling\nSize of computational domain\n\nSymmetry: Use symmetry to reduce computational cost:\n\nConsider only irreducible Brillouin zone\nApply appropriate boundary conditions\n\nBand Gap Accuracy: For accurate band gap calculations:\n\nUse dense k-point sampling near band edges\nInclude sufficient number of plane waves\nCheck convergence of gap size"
  },
  {
    "objectID": "wave-optics/PC.html#references",
    "href": "wave-optics/PC.html#references",
    "title": "Calculating Band Structure for 2D Photonic Crystals",
    "section": "References",
    "text": "References\n\nJoannopoulos, J. D., et al. “Photonic Crystals: Molding the Flow of Light”\nSakoda, K. “Optical Properties of Photonic Crystals”"
  },
  {
    "objectID": "wave-optics/Diffraction Integral.html",
    "href": "wave-optics/Diffraction Integral.html",
    "title": "Diffraction Integral",
    "section": "",
    "text": "In the last section about Fresnel zones and the zone plate, we considered how different paths contribute to the intensity at a point on the optical axis. We would like to generalize this idea to an integral formulation that allows us to calculate any kind of diffraction pattern.\nAssume we have a light source \\(S\\) as shown in the image above, which emits a spherical wave (though it does not necessarily have to be a spherical wave). The spatial amplitude of this wave at the point \\(P(x,y)\\) at a tiny aperture element \\(d\\sigma\\) is given by:\n\\[\nU_s(x,y) = U_0(x,y)e^{i\\phi(x,y)}\n\\]\nwhere\n\\[\nU_0 = \\frac{A}{R} = \\frac{A}{\\sqrt{g^2 + x^2 + y^2}}\n\\]\nand\n\\[\n\\phi(x,y) = -kR\n\\]\nThis represents the amplitude of the Huygens wave, which emanates from the point \\(P(x,y)\\) and propagates towards the screen at \\(P(x',y')\\). This Huygens wave contributes a fraction of an amplitude \\(dU_p\\) to the total amplitude at point \\(P(x',y')\\), which is given by:\n\\[\ndU_p = C \\frac{U_s d\\sigma}{r} e^{-ikr}\n\\]\nwith \\(C = \\frac{i \\cos(\\theta)}{\\lambda}\\), known as the obliquity factor, found through a more detailed calculation.\nThe total amplitude at the point \\(P(x',y')\\) is then given by the integral over all contributions:\n\\[\nU_p = \\iint C U_s \\frac{e^{-ikr}}{r} dx dy\n\\]\nwhere \\(dx dy = d\\sigma\\). The integral runs over all positions in the aperture plane \\((x,y)\\) where there is an opening. This integral is called the Fresnel-Kirchhoff diffraction integral and allows us to calculate complex scalar diffraction patterns.\nThis formulation generalizes the concept of Fresnel zones and provides a powerful tool for analyzing and predicting diffraction patterns for various aperture shapes and configurations."
  },
  {
    "objectID": "wave-optics/Diffraction Integral.html#fresnel-approximation",
    "href": "wave-optics/Diffraction Integral.html#fresnel-approximation",
    "title": "Diffraction Integral",
    "section": "Fresnel Approximation",
    "text": "Fresnel Approximation\nThe diffraction integral does not always need to be calculated in full; we can use approximations to obtain diffraction patterns in different regimes. One such approximation is the Fresnel approximation, which yields the diffraction pattern in the near field.\nThe distance \\(r\\) from the point \\(P(x,y)\\) to the point \\(P(x',y')\\) can be written as:\n\\[\nr = \\sqrt{z_0^2 + (x - x')^2 + (y - y')^2}\n\\]\nUsing a binomial expansion for small angles, we can approximate this as:\n\\[\nr \\approx z_0 \\left(1 + \\frac{(x - x')^2}{2z_0^2} + \\frac{(y - y')^2}{2z_0^2} + \\ldots \\right)\n\\]\nIn this approximation, we assume that \\(\\cos(\\theta) = z_0 / r \\approx 1\\) and \\(C = i / \\lambda\\), considering small diffraction angles. Using this approximation, we find the amplitude of the wave at a point \\(P(x',y')\\):\n\\[\nU(x', y', z_0) = i \\frac{e^{-ikz_0}}{\\lambda z_0} \\iint U_s(x, y) \\exp \\left[ -\\frac{ik}{2z_0} \\left( (x - x')^2 + (y - y')^2 \\right) \\right] dx dy\n\\]\nAs the integration is over \\(x\\) and \\(y\\), we can factor out all screen coordinate elements, yielding:\n\\[\nU(x', y', z_0) = i \\frac{e^{-ikz_0}}{\\lambda z_0} e^{-\\frac{ik}{2z_0}(x'^2 + y'^2)} \\iint U_s(x, y) e^{-\\frac{ik}{2z_0}(x^2 + y^2)} e^{\\frac{ik}{2z_0}(xx' + yy')} dx dy\n\\]\nThis is the Fresnel approximation. It simplifies the calculation of the diffraction pattern in the near field by making reasonable assumptions about the geometry and angles involved."
  },
  {
    "objectID": "wave-optics/Diffraction Integral.html#fraunhofer-approximation",
    "href": "wave-optics/Diffraction Integral.html#fraunhofer-approximation",
    "title": "Diffraction Integral",
    "section": "Fraunhofer Approximation",
    "text": "Fraunhofer Approximation\nIf we further assume that the aperture is small as compared to the distance at which we observe the diffraction pattern, we can further simplify the Fresnel approximation to yield the Fraunhofer approximation giving the diffraction patter in the far field. The condition is\n\\[\nz_0\\gg\\frac{1}{\\lambda}(x^2+y^2)\n\\]\nIn this case we can neglect the term\n\\[\ne^{ -\\frac{ik}{2z_0}(x^2+y^2)} \\approx 1\n\\]\nwhich results in\n\\[\nU(x^{\\prime},y^{\\prime},z_0)=i\\frac{e^{-ikz_0}}{\\lambda z_0} e^{-\\frac{ik}{2z_0}(x^{\\prime 2}+y^{\\prime 2})}\n\\iint U_{s}(x,y)\ne^{\\frac{ik}{2z_0}(xx^{\\prime}+yy^{\\prime})} dx dy\n\\]\n\n\n\nDiffraction pattern of a slit in the near field (Fresnel diffraction, left) and the far field (Fraunhofer diffraction, right).\n\n\nWhile these formulas provide the mathematical tools, we may obtain a more intuitive idea about the different approximation in the following way. Consider the image below, where we would like to know about the diffraction intensity of a slit of width \\(b\\) at the optical axis at a distance \\(D\\).\n\n\n\nIllustration of the importance of additional geometrical path length difference for the discrimination of Fresnel (near-field) and Fraunhofer (far-field) diffraction.\n\n\nThe waves from the center of the slit and the edge have to travel towards that point a different pathlength, whcih we may calculate to\n\\[\\begin{eqnarray}\n\\Delta s &=&  \\sqrt{\\frac{b^2}{4}+D^2}-D\\\\\n&=& D\\sqrt{\\frac{b^2}{4D^2}+1}-D\n\\end{eqnarray}\\]\nWe may develop the square root into a Taylor series and obtain\n\\[\\begin{eqnarray}\n\\Delta s &=& \\frac{b^2}{8D}-\\frac{b^4}{128 D^3}+O(4)\\\\\n&\\approx & \\frac{b^2}{8D}\n\\end{eqnarray}\\]\nThe second order correction term \\(\\frac{b^2}{8D}\\) decreases quadratic with the distance \\(D\\) of the point, which means that at large distances, we can safely assume \\(\\Delta s=0\\) on the axis, i.e. all waves arriving at that point have to travel the same distance. This corresponds to the far-field approximation. To be more specific we require\n\\[\n\\frac{b^2}{8D^2}&lt;\\frac{\\lambda}{8}\n\\]\nor\n\\[\n\\frac{b^2}{\\lambda D}&lt;1\n\\]\nto be fullfilled to be in the far field.\n\\[\nF=\\frac{b^2}{\\lambda D}\n\\begin{cases}\n\\ll 1 ,&\\textrm{Fraunhofer}\\\\\n\\approx 1,& \\textrm{Fresnel}\\\\\n\\gg 1, & \\textrm{Full vector}\n\\end{cases}\n\\]\nThis number \\(F\\) is called the Frensel number and gives us an idea by how far the dimensions of the opening contribute to the diffraction pattern rather than the direction of the wave propagation only."
  },
  {
    "objectID": "wave-optics/Diffraction Integral.html#babinets-principle",
    "href": "wave-optics/Diffraction Integral.html#babinets-principle",
    "title": "Diffraction Integral",
    "section": "Babinet’s Principle",
    "text": "Babinet’s Principle\nThe above considerations of diffraction have some intruiging consequence. Consider the two apertures in the image below.\n\n\n\nTwo complementary apertures, which have the same diffraction pattern in the far field.\n\n\nThe left aperture will create in the far field an amplitude distribution \\(U_h\\), while the inverse aperture on the right will cause an amplitude \\(U_d\\). If we combine both amplitudes in the far field, we obtain a total amplitude distribution\n\\[\nU=U_h+U_d\n\\]\nIn the case when we have two complementary apertures, that total amplitude has to be zeor, when hole and dot are placed at the same position. We therefore obtain\n\\[\nU_h=-U_d\n\\]\nand therefore\n\\[\nI_h=I_d\n\\]\nThis is the Principle of Babinet which states:\n\n\n\n\n\n\nBabinet’s Principle\n\n\n\nBabinet’s principle states that the far-field diffraction intensity distribution of complementary apertures is identical. This means that an opaque object and its complementary aperture (where the object is replaced by a transparent region and vice versa) produce the same diffraction pattern in the far field.\n\n\nThe images below show an experimental demonstration of Babinet’s principle on a slit and a wire.\n\n\n\nBabinet’s principle demonstrated experimentally on a slit (left) and a wire (right)."
  },
  {
    "objectID": "wave-optics/MultiWave Interference.html",
    "href": "wave-optics/MultiWave Interference.html",
    "title": "Multiple Wave Interference",
    "section": "",
    "text": "So far we looked at the interference of two waves, which was a simplification as I mentioned already earlier. Commonly there will be a multitude of partial waves contribute to the oberved intereference. This is what we would like to have a look at now. We will do that in a quite general fashion, as the resulting formulas will appear several times again for different problems.\nNevertheless we will make a difference between\n\nmultiwave interference of waves with the constant amplitude\nmultiwave interference of waves with decreasing amplitude\n\nEspecially the latter is often occuring, if we have multiple reflections and each reflection is only a fraction of the incident amplitude.\n\nMultiple Wave Interference with Constant Amplitude\nIn the case of constant amplitude (for example realized by a grating, which we talk about later), the total wave amplitude is given according to the picture below by\n\\[\nU=U_1+U_2+U_1+U_3+\\ldots+U_M\n\\]\nwhere we sum the amplitude over \\(M\\) partial waves. Between the neighboring waves (e.g. \\(U_1\\) and \\(U_2\\)), we will assume a phase difference (because of a path length difference for example), which we denote as \\(\\Delta \\phi\\).\nThe amplitude of the p-th wave is then given by\n\\[\nU_p=\\sqrt{I_0}e^{i(p-1)\\Delta \\phi}\n\\]\nwith the index \\(p\\) being an interger \\(p=1,2,\\ldots,M\\), \\(h=e^{i\\Delta \\phi}\\) and \\(\\sqrt{I_0}\\) as the amplitude of each individual wave. The total amplitude \\(U\\) can be then expressed as\n\\[\nU=\\sqrt{I_0}\\left (1+h+h^2+\\ldots +h^{M-1}\\right)\n\\]\nwhich is a geometric sum. We can apply the sum formula for geometric sums to obtain\n\\[\nU=\\sqrt{I_0}\\frac{1-h^M}{1-h}=\\sqrt{I_0}\\frac{1-e^{iM\\Delta \\phi}}{1-e^{i\\Delta \\phi}}\n\\]\nWe now have to calculate the intensity of the total amplitude\n\\[\nI=|U|^2=I_{0}\\left | \\frac{e^{-iM\\Delta \\phi/2}-e^{iM\\Delta \\phi/2}}{e^{-i\\Delta \\phi/2}-e^{i\\Delta \\phi/2}}\\right |^2\n\\]\nwhich we can further simplify to give\n\\[\nI=I_{0}\\frac{\\sin^2(M\\Delta \\phi/2)}{\\sin^2(\\Delta \\phi/2)}\n\\]\n\nCode\n# Parameters\nM = 6  # number of phasors\nphi = np.pi/8  # example phase difference between successive phasors\n\ndef plot_angle(ax, pos, angle, length=0.95, acol=\"C0\", **kwargs):\n    vec2 = np.array([np.cos(np.deg2rad(angle)), np.sin(np.deg2rad(angle))])\n    xy = np.c_[[length, 0], [0, 0], vec2*length].T + np.array(pos)\n    ax.plot(*xy.T, color=acol)\n    return AngleAnnotation(pos, xy[0], xy[2], ax=ax, **kwargs)\n\n# Calculate phasor positions\ndef calculate_phasors(phi, M):\n    # Initialize arrays for arrow start and end points\n    x_start = np.zeros(M)\n    y_start = np.zeros(M)\n    x_end = np.zeros(M)\n    y_end = np.zeros(M)\n\n    # Running sum of phasors\n    x_sum = 0\n    y_sum = 0\n\n    for i in range(M):\n        # Current phasor\n        x = np.cos(i * phi)\n        y = np.sin(i * phi)\n\n        # Store start point (end of previous phasor)\n        x_start[i] = x_sum\n        y_start[i] = y_sum\n\n        # Add current phasor\n        x_sum += x\n        y_sum += y\n\n        # Store end point\n        x_end[i] = x_sum\n        y_end[i] = y_sum\n\n    return x_start, y_start, x_end, y_end\n\nx_start, y_start, x_end, y_end = calculate_phasors(phi, M)\n\nplt.figure(figsize=get_size(6, 6))\nax = plt.gca()\n\nfor i in range(M):\n    plt.arrow(x_start[i], y_start[i],\n             x_end[i]-x_start[i], y_end[i]-y_start[i],\n             head_width=0.15, head_length=0.2, fc='k', ec='k',\n             length_includes_head=True,\n             label=f'E{i+1}' if i == 0 else \"\")\n\nplt.arrow(0, 0, x_end[-1], y_end[-1],\n         head_width=0.15, head_length=0.2, fc='r', ec='r',\n         length_includes_head=True, label='Resultant')\n\nax.set_aspect('equal')\nxx = np.linspace(-1, 3, 100)\nax.plot(xx,(xx-1)*np.tan(phi),'k--',lw=0.5)\nax.plot([1,3],[0,0],'k--',lw=0.5)\nkw = dict(size=195, unit=\"points\", text=r\"$\\Delta \\phi$\")\nplot_angle(ax, (1.0, 0), phi*180/np.pi, textposition=\"inside\", **kw)\nplt.axis('off')\nmax_range = max(abs(x_end[-1]), abs(y_end[-1])) * 1.2\nplt.xlim(-0, max_range/1.5)\nplt.ylim(-0.1, max_range/1.)\n\nplt.show()\n# Parameters\nM = 6\nphi = np.linspace(-4*np.pi, 4*np.pi, 10000)  # increased resolution\nI0 = 1\n\ndef multiple_beam_pattern(phi, M):\n    numerator = np.sin(M * phi/2)**2\n    denominator = np.sin(phi/2)**2\n    I = np.where(denominator != 0, numerator/denominator, M**2)\n    return I\n\nI = I0 * multiple_beam_pattern(phi, M)\n\nfirst_min = 2*np.pi/M  # theoretical value\n\ndef find_nearest(array, value):\n    array = np.asarray(array)\n    idx = (np.abs(array - value)).argmin()\n    return array[idx], idx\n\nhalf_max = M**2/2\n\nphi_positive = phi[phi &gt;= 0]  # only positive values\nI_positive = I[phi &gt;= 0]\n_, idx_half = find_nearest(I_positive, half_max)\nhalf_width = phi_positive[idx_half]\n\n# Create plot\nplt.figure(figsize=get_size(10, 6))\nplt.plot(phi/np.pi, I, 'b-', label=f'M={M}')\n\n#plt.plot(first_min/np.pi, multiple_beam_pattern(first_min, M), 'ro')\n#plt.annotate(f'First minimum\\nφ = 2π/M = {first_min/np.pi:.2f}π',\n\nplt.axvline(x=first_min/np.pi, color='r', linestyle='--', label=f'φ = 2π/M = {first_min/np.pi:.2f}π')\n\n#plt.plot(half_width/np.pi, half_max, 'go')\n\nplt.xlabel(r'phase $\\Delta \\phi/\\pi$')\nplt.ylabel('intensity I/I₀')\nplt.title(f'Multiple Beam Interference Pattern (M={M})')\nplt.ylim(0, M**2 + 15)\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nMultiple wave interference of \\(M=6\\) waves with a phase difference of \\(\\phi=\\pi/8\\). The black arrows represent the individual waves, the red arrow the sum of all waves.\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 1— Multiple beam interference pattern for M=6 beams. The intensity distribution is shown as a function of the phase shift \\(\\phi\\). The first minimum is at \\(\\phi=2\\pi/M\\). The intensity distribution is symmetric around \\(\\phi=0\\).\n\n\n\n\n\n\n\nThe result is therefore an oscillating function. The numerator \\(\\sin^2(M\\Delta \\phi/2)\\) shows and oscillation frequency, which is by a factor of \\(M\\) higher than the one in the denominator \\(\\sin^2 (\\Delta \\phi/2)\\). Therefore the intensity pattern is oscillating rapidly and creating a first minimum at\n\\[\n\\Delta \\phi=\\frac{2\\pi}{M}\n\\]\nThis is an important result, since it shows that the number of sources \\(M\\) determines the position of the first minimum and the interference peak gets narrower with increasing \\(M\\). Since the phase difference \\(\\Delta \\phi\\) between neighboring sources is the same as for the double slit experiment, i.e. \\(\\Delta \\phi=2\\pi d/\\lambda \\sin(\\theta)\\), we can also determine the angular position of the first minimum. This is given by\n\\[\n\\sin(\\theta_\\textrm{min})=\\frac{1}{M}\\frac{\\lambda}{d}\n\\]\nThis again has the common feature that it scales as \\(\\lambda/d\\). A special situation occurs, whenever the numerator and the denominator become zero. This will happen whenever\n\\[\n\\Delta \\phi=m 2\\pi\n\\]\nwhere \\(m\\) is an integer and denotes the interference order, i.e. the number of wavelength that neighboring partial waves have as path length difference. In this case, the intensity distributiion will give us\n\\[\nI=I_0 \\frac{0}{0}\n\\]\nand we have to determine the limit with the help of l’Hospitals rule. The outcome of this calculation is, that\n\\[\nI(\\Delta \\phi=m2\\Delta \\pi)=M^2 I_0\n\\]\nwhich can be also realized when using the small angle approximation for the sine functions.\n\nWavevector Representation\nWe would like to introduce a different representation of the multiple wave interference of the grating, which is quite insightful. The first order (\\(m=1\\)) constructive interference condition is given by\n\\[\n\\frac{1}{\\lambda}\\sin{\\theta}= \\frac{1}{d}\n\\]\nwhich also means that\n\\[\n\\frac{2\\pi}{\\lambda}\\sin{\\theta}= \\frac{2\\pi}{d}\n\\]\nThis can be written as\n\\[\nk \\sin{\\theta}= K\n\\]\nwhere \\(k\\) is the magnitude of the wavevector of the light and \\(K\\) is the wavevector magnitude that corresponds to the grating period \\(d\\). As the magnitude of the wavevector of the light is conserved, the wavevectors of the incident light and the light traveling along the direction of the first interence peak form the sides of an equilateral triangle. This is shown in the following figure.\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\nk = 1  # Magnitude of k₁ and k₂\n\norigin = np.array([0, 0])\n\nk1 = np.array([k, 0])\n\ntheta_deg = 30  # θ = 30 degrees\ntheta_rad = np.deg2rad(theta_deg)\n\nk2 = k * np.array([np.cos(theta_rad), np.sin(theta_rad)])\n\nK = k2 - k1\n\npoint_O = origin\npoint_A = point_O + k1\npoint_B = point_O + k2\n\n\nplt.figure(figsize=get_size(10, 10))\nax = plt.gca()\n\n# Plot vector k₁\nax.arrow(point_O[0], point_O[1], k1[0], k1[1],\n         head_width=0.02, head_length=0.03, fc='k', ec='k', length_includes_head=True)\n\n\nax.arrow(point_A[0], point_A[1], K[0], K[1],\n         head_width=0.02, head_length=0.03, fc='b', ec='b', length_includes_head=True)\n\nax.arrow(point_O[0], point_O[1], k2[0], k2[1],\n         head_width=0.02, head_length=0.03, fc='k', ec='k', length_includes_head=True)\n\n# Label vectors\nax.text(k1[0]/2 - 0.05, k1[1]/2 - 0.05, r'$\\mathbf{k}$', fontsize=14, color='k')\nax.text(point_A[0] + K[0]/2 , point_A[1] + K[1]/2 + 0.05, r'$\\mathbf{K}$', fontsize=14, color='b')\nax.text(k2[0]/2 + 0.0, k2[1]/2+0.1, r'$\\mathbf{k}$', fontsize=14, color='k')\n\n# Indicate angle θ between k₁ and k₂ at the origin\narc_radius = 0.3  # Radius of the arc representing θ\nangle_range = np.linspace(0, theta_rad, 100)\narc_x = arc_radius * np.cos(angle_range)\narc_y = arc_radius * np.sin(angle_range)\nax.plot(arc_x, arc_y, color='k')\n\nax.text(arc_radius * np.cos(theta_rad / 2) + 0.02,\n        arc_radius * np.sin(theta_rad / 2) + 0.02,\n        r'$\\theta$', fontsize=14)\n\n# Set equal aspect ratio\nax.set_aspect('equal', adjustable='box')\n\nall_x = [point_O[0], point_A[0], point_B[0]]\nall_y = [point_O[1], point_A[1], point_B[1]]\nmargin = 0.2\nax.set_xlim(min(all_x) - margin, max(all_x) + margin)\nax.set_ylim(min(all_y) - margin, max(all_y) + margin)\nplt.axis('off')\n\n# Display the plot\nplt.show()\n\n\n\n\n\nWavevector summation for the diffraction grating. The wavevector of the incident light \\(k\\) and the wavevector of the light traveling along the direction of the first interference peak \\(K\\) form an equilateral triangle.\n\n\n\n\nThis means that the diffraction grating is providing a wavevector \\(K\\) to alter the direction of the incident light. This is again a common feature reappearing in many situations as for example in the X-ray diffraction of crystals.\n\n\n\nMultiple Wave Interference with Decreasing Amplitude\nWe will turn our attention now to a slight modification of the previous multiwave interference. We will introduce a decreasing amplitude of the individual waves. The first wave shall have an amplitude \\(U_1=\\sqrt{I_0}\\). The next wave, however, will not only be phase shifted but also have a smaller amplitude.\n\\[\nU_2=h U_1\n\\]\nwhere \\(h=re^{i\\phi}\\) with \\(|h|=r&lt;1\\). \\(r\\) can be regarded as a reflection coefficient, which deminishes the amplitude of the incident wave. According to that the intensity is reduced by\n\\[\nI_2=|U_2|^2=|h U_1|^2=r^2 I_1\n\\]\nThe intensity of the incident wave is multiplied by a factor \\(r^2\\), while the amplitude is multiplied by \\(r\\). Note that the phase factor \\(e^{i\\Delta\\phi}\\) is removed when taking the square of this complex number.\n\n\n\n\n\n\nIntensity at Boundaries\n\n\n\nThe amplitude of the reflected wave is diminished by a factor \\(r\\le 1\\), which is called the reflection coefficient. The intensity is diminished by a factor \\(R=|r|^2\\le1\\), which is the reflectance.\nIn the absence of absorption, reflectance \\(R\\) and transmittance \\(T\\) add to one due to energy conservation.\n\\[\nR+T=1\n\\]\n\n\nConsequently, the third wave would be now \\(U_3=hU_2=h^2U_1\\). The total amplitude is thus\n\\[\nU=U_1+U_2+U_3+\\ldots+U_M = \\sqrt{I_0}(1+h+h^2+\\ldots)\n\\]\n\nCode\nM = 18  # number of phasors\nphi = np.pi/6  # example phase difference between successive phasors\nr = 0.95  # reduction factor for each subsequent phasor\n\ndef plot_angle(ax, pos, angle, length=0.95, acol=\"C0\", **kwargs):\n    vec2 = np.array([np.cos(np.deg2rad(angle)), np.sin(np.deg2rad(angle))])\n    xy = np.c_[[length, 0], [0, 0], vec2*length].T + np.array(pos)\n    ax.plot(*xy.T, color=acol)\n    return AngleAnnotation(pos, xy[0], xy[2], ax=ax, **kwargs)\n\ndef calculate_phasors(phi, M, r):\n    x_start = np.zeros(M)\n    y_start = np.zeros(M)\n    x_end = np.zeros(M)\n    y_end = np.zeros(M)\n\n    x_sum = 0\n    y_sum = 0\n\n    for i in range(M):\n        amplitude = r**i  # exponential decrease\n        x = amplitude * np.cos(i * phi)\n        y = amplitude * np.sin(i * phi)\n\n        x_start[i] = x_sum\n        y_start[i] = y_sum\n\n        x_sum += x\n        y_sum += y\n\n        x_end[i] = x_sum\n        y_end[i] = y_sum\n\n    return x_start, y_start, x_end, y_end\n\nx_start, y_start, x_end, y_end = calculate_phasors(phi, M, r)\n\nplt.figure(figsize=get_size(6, 6),dpi=150)\nax = plt.gca()\n\nfor i in range(M):\n    plt.arrow(x_start[i], y_start[i],\n             x_end[i]-x_start[i], y_end[i]-y_start[i],\n             head_width=0.15, head_length=0.2,\n             fc='k', ec='k',\n             length_includes_head=True,\n             label=f'E{i+1}' if i == 0 else \"\")\n\nplt.arrow(0, 0, x_end[-1], y_end[-1],\n         head_width=0.15, head_length=0.2, fc='r', ec='r',\n         length_includes_head=True, label='Resultant')\n\nax.set_aspect('equal')\nxx = np.linspace(-1, 3, 100)\nax.plot(xx,(xx-1)*np.tan(phi),'k--',lw=0.5)\nax.plot([1,3],[0,0],'k--',lw=0.5)\nkw = dict(size=195, unit=\"points\", text=r\"$\\phi$\")\nplot_angle(ax, (1.0, 0), phi*180/np.pi, textposition=\"inside\", **kw)\nplt.axis('off')\nmax_range = max(abs(x_end[-1]), abs(y_end[-1])) * 1.2\nplt.xlim(-max_range/1.8, max_range/0.8)\nplt.ylim(-0.1, max_range/0.9)\n\nplt.show()\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Create phase array from -2π to 2π\nphi = np.linspace(-2*np.pi, 2*np.pi, 1000)\n\ndef calculate_intensity(phi, F):\n    return 1/(1 + 4*(F/np.pi)**2 * np.sin(phi/2)**2)\n\nplt.figure(figsize=get_size(10, 6))\n\nfinesse_values = [1, 4, 20]\nstyles = ['-', '--', ':']\n\nfor F, style in zip(finesse_values, styles):\n    I = calculate_intensity(phi, F)\n    plt.plot(phi/np.pi, I, style, label=f'$\\\\mathcal{{F}}={F}$')\n\nplt.xlabel('Phase $\\\\phi/\\\\pi$')\nplt.ylabel('$I/I_{\\\\mathrm{max}}$')\nplt.grid(True, alpha=0.3)\nplt.legend()\nplt.ylim(0, 1.1)\n\nplt.show()\n\n\n\n\n\n\n\n\nPhase construction of a multiwave intereference with M waves with decreasing amplitude due to a reflection coefficient \\(r=0.95\\).\n\n\n\n\n\n\n\n\n\nMultiple wave interference with decreasing amplitude. The graph shows the intensity distribution over the phase angle \\(\\phi\\) for different values of the Finesse \\(\\mathcal{F}\\).\n\n\n\n\n\n\nThis yields again\n\\[\nU=\\sqrt{I_0}\\frac{(1-h^M)}{1-h}=\\frac{\\sqrt{I_0}}{1-r e^{i\\Delta\\phi}}\n\\]\nCalculating the intensity of the waves is giving\n\\[\nI=|U|^2=\\frac{I_{0}}{|1-re^{i\\Delta\\phi}|^2}=\\frac{I_0}{(1-r)^2+4r\\sin^2(\\Delta\\phi/2)}\n\\]\nwhich is also known as the Airy function. This function can be further simplified by the following abbrevations\n\\[\nI_{\\rm max}=\\frac{I_0}{(1-r)^2}\n\\]\nand\n\\[\n\\mathcal{F}=\\frac{\\pi \\sqrt{r}}{1-r}\n\\]\nwhere the latter is called the Finesse. With those abbrevations, we obtain\n\\[\nI=\\frac{I_{\\rm max}}{1+4\\left(\\frac{\\mathcal{F}}{\\pi}\\right)^2\\sin^{2}(\\Delta\\phi/2)}\n\\]\nfor the interference of multiple waves with decreasing amplitude.\nThis intensity distribution has a different shape than the one we obtained for multiple waves with the same amplitude.\nWe clearly observe that with increasing Finesse the intensity maxima, which occur at multiples fo \\(\\pi\\) get much narrower. In addition the regions between the maxima show better contrast and fopr higher Finesse we get complete destructive interference.",
    "crumbs": [
      "Geometrical Optics",
      "Lecture 9",
      "Multi Wave Interference"
    ]
  },
  {
    "objectID": "wave-optics/Sagnac_Interferometer.html",
    "href": "wave-optics/Sagnac_Interferometer.html",
    "title": "Sagnac Interferometer",
    "section": "",
    "text": "A Sagnac interferometer operates by splitting a beam of light into two separate beams that travel in opposite directions around a closed loop. These beams are then recombined at the end of the loop, resulting in an interference pattern. If the interferometer is rotating, the path lengths of the two beams differ, leading to a phase shift.\nThe phase shift, denoted as \\(\\Delta \\phi\\), can be calculated using the formula:\n\\[\n\\Delta \\phi = \\frac{8 \\pi A \\Omega}{\\lambda c}\n\\]\nwhere \\(A\\) represents the area enclosed by the light path, \\(\\Omega\\) is the angular velocity of the rotation, \\(\\lambda\\) is the wavelength of the light, and \\(c\\) is the speed of light.\n\n\nTo derive the phase shift, we start by considering the path length difference. Assume a loop with a perimeter \\(L\\) and an area \\(A\\). In the absence of rotation, the time taken for light to travel around the loop is given by \\(T = \\frac{L}{c}\\).\nWhen the interferometer rotates with an angular velocity \\(\\Omega\\), the effective path length changes. For the beam traveling in the direction of rotation, the path length increases, while for the beam traveling opposite to the direction of rotation, the path length decreases.\nThe time difference \\(\\Delta T\\) between the two beams can be expressed as:\n\\[\n\\Delta T = \\frac{4 A \\Omega}{c^2}\n\\]\nThe phase shift \\(\\Delta \\phi\\) is related to this time difference by the equation:\n\\[\n\\Delta \\phi = \\frac{2 \\pi \\Delta T}{T} = \\frac{8 \\pi A \\Omega}{\\lambda c}\n\\]\nThis relationship shows how the rotation of the interferometer causes a measurable phase shift in the interference pattern, which can be used to determine the angular velocity of the rotation."
  },
  {
    "objectID": "wave-optics/Sagnac_Interferometer.html#sagnac-interferometer-overview",
    "href": "wave-optics/Sagnac_Interferometer.html#sagnac-interferometer-overview",
    "title": "Sagnac Interferometer",
    "section": "",
    "text": "A Sagnac interferometer operates by splitting a beam of light into two separate beams that travel in opposite directions around a closed loop. These beams are then recombined at the end of the loop, resulting in an interference pattern. If the interferometer is rotating, the path lengths of the two beams differ, leading to a phase shift.\nThe phase shift, denoted as \\(\\Delta \\phi\\), can be calculated using the formula:\n\\[\n\\Delta \\phi = \\frac{8 \\pi A \\Omega}{\\lambda c}\n\\]\nwhere \\(A\\) represents the area enclosed by the light path, \\(\\Omega\\) is the angular velocity of the rotation, \\(\\lambda\\) is the wavelength of the light, and \\(c\\) is the speed of light.\n\n\nTo derive the phase shift, we start by considering the path length difference. Assume a loop with a perimeter \\(L\\) and an area \\(A\\). In the absence of rotation, the time taken for light to travel around the loop is given by \\(T = \\frac{L}{c}\\).\nWhen the interferometer rotates with an angular velocity \\(\\Omega\\), the effective path length changes. For the beam traveling in the direction of rotation, the path length increases, while for the beam traveling opposite to the direction of rotation, the path length decreases.\nThe time difference \\(\\Delta T\\) between the two beams can be expressed as:\n\\[\n\\Delta T = \\frac{4 A \\Omega}{c^2}\n\\]\nThe phase shift \\(\\Delta \\phi\\) is related to this time difference by the equation:\n\\[\n\\Delta \\phi = \\frac{2 \\pi \\Delta T}{T} = \\frac{8 \\pi A \\Omega}{\\lambda c}\n\\]\nThis relationship shows how the rotation of the interferometer causes a measurable phase shift in the interference pattern, which can be used to determine the angular velocity of the rotation."
  },
  {
    "objectID": "wave-optics/Fresnel Zones.html",
    "href": "wave-optics/Fresnel Zones.html",
    "title": "Fresnel Zones",
    "section": "",
    "text": "We want to take a more general look at diffraction by exploring a concept known as Fresnel zones. Consider spherical waves of wavelength \\(\\lambda\\) emitted from a source, as indicated by the solid line in the sketch below.\nWe will examine the intensity of the wave at a point \\(P\\). To do this, we consider the amplitude contributions from all points on the wavefront, as each point on the wavefront acts as a Huygens source contributing to the intensity at point \\(P\\).\nInstead of calculating the intensity explicitly, we will analyze the distances of individual points on the wavefront from point \\(P\\). Specifically, we look at concentric circles around point \\(P\\), where the radius of each circle increases by \\(\\lambda/2\\), i.e.,\n\\[\nr_m = r_0 + m \\frac{\\lambda}{2}\n\\]\nwhere \\(m\\) is an integer. The regions between \\(r_m\\) and \\(r_{m+1}\\) are called Fresnel zones. If we consider two neighboring zones, each zone contains pairs of points that are exactly \\(\\lambda/2\\) out of phase. This means that these pairs of points would lead to destructive interference. If we remove these points, we are left with constructive interference along the optical axis only. We can construct such an aperture by calculating the ring radius\n\\[\n\\rho_{m}^2 = \\left( r_0 + m \\frac{\\lambda}{2} \\right)^2 - r_0^2\n\\]\naccording to the sketch above. This yields\n\\[\n\\rho_m^2 = r_0 m \\lambda + m^2 \\frac{\\lambda^2}{4}\n\\]\nFor \\(r_{0} \\gg \\lambda\\), we can simplify the above formula to\n\\[\n\\rho_m = \\sqrt{m r_0 \\lambda}\n\\]\nwhich gives the radius of the individual zones. The width of the zones is given by\n\\[\n\\Delta \\rho_m = \\rho_{m+1} - \\rho_m = \\sqrt{r_0 \\lambda} (\\sqrt{m+1} - \\sqrt{m})\n\\]",
    "crumbs": [
      "Geometrical Optics",
      "Lecture 11",
      "Fresnel Zone Plate"
    ]
  },
  {
    "objectID": "wave-optics/Fresnel Zones.html#fresnel-zone-plate",
    "href": "wave-optics/Fresnel Zones.html#fresnel-zone-plate",
    "title": "Fresnel Zones",
    "section": "Fresnel Zone Plate",
    "text": "Fresnel Zone Plate\nIf we now fill the ring from \\(\\rho_m\\) to \\(\\rho_{m+1}\\) on a glass slide but leave the ring from \\(\\rho_{m+1}\\) to \\(\\rho_{m+2}\\) transparent, we create a so-called Fresnel zone plate. Here, the radius in the first zone \\(r\\) ranges from \\(r_0\\) to \\(r_0 + \\lambda/2\\). The next zone will range from \\(r_0 + \\lambda/2\\) to \\(r_0 + \\lambda\\) but is removed from its contribution to the point.\n\n\n\nFresnel zone plate removing destructive interference to the point on the optical axis.\n\n\nThe Fresnel zone plate can be constructed by defining the inner reference zone in an arbitrary way. One may either block or transmit the direct path from the light source along the optical axis, resulting in either the odd or even zones being transparent.\n\n\n\nFresnel zone plates with odd (left) or even (right) zones transparent delivering the same result.\n\n\n \nSuch zone plates are important for applications where focusing of radiation is required but the refractive indices are not large enough to create strong enough refraction. This is especially true for X-ray radiation.\n\n\n\nFresnel zone plates for X-ray radiation. Image taken from Ion beam lithography for Fresnel zone plates in X-ray microscopy - Optics Express, Vol. 21 Issue 10, pp.11747-11756 (2013).",
    "crumbs": [
      "Geometrical Optics",
      "Lecture 11",
      "Fresnel Zone Plate"
    ]
  },
  {
    "objectID": "wave-optics/Fresnel Zones.html#applications-and-importance-of-fresnel-zone-plates",
    "href": "wave-optics/Fresnel Zones.html#applications-and-importance-of-fresnel-zone-plates",
    "title": "Fresnel Zones",
    "section": "Applications and Importance of Fresnel Zone Plates",
    "text": "Applications and Importance of Fresnel Zone Plates\nFresnel zone plates are used in various applications, particularly where traditional lenses are ineffective. Some key applications include:\nX-ray Microscopy: Fresnel zone plates are used to focus X-rays, which have very short wavelengths and require special techniques for focusing. Traditional lenses are not effective for X-rays due to their low refractive indices.\nOptical Systems: In optical systems, Fresnel zone plates can be used to create focal points without the need for bulky lenses. This is particularly useful in compact optical devices.\nHolography: Fresnel zone plates are used in holography to create and reconstruct holograms. They help in manipulating the wavefronts to produce the desired holographic images.\nAstronomy: In astronomy, Fresnel zone plates can be used in telescopes to focus light from distant stars and galaxies. They offer an alternative to traditional lenses and mirrors.",
    "crumbs": [
      "Geometrical Optics",
      "Lecture 11",
      "Fresnel Zone Plate"
    ]
  },
  {
    "objectID": "wave-optics/index.html",
    "href": "wave-optics/index.html",
    "title": "EXP3 Quarto",
    "section": "",
    "text": "This is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites."
  },
  {
    "objectID": "wave-optics/FabryPerotDummy.html",
    "href": "wave-optics/FabryPerotDummy.html",
    "title": "Experimental Physics 3 Course on Optics and Quantum Mechanics",
    "section": "",
    "text": "The contents of this Topic will only be presented in the lectures and not part of the online publications."
  },
  {
    "objectID": "wave-optics/Diffraction Grating.html",
    "href": "wave-optics/Diffraction Grating.html",
    "title": "Diffraction Grating",
    "section": "",
    "text": "We would like to combine now the diffraction on individual slits with the multiple inteference from many slits. Such objects are called diffraction gratings and have large importance for spectroscopy but also for the compression of short laser pulses.\nLet’s have a look at the sketch below.\nWe consider a number of \\(N\\) slits of width \\(b\\). The slits have a distance \\(d\\) from each other. Each slit acts like the slit before giving rise to a diffraction pattern, that is oscillating with decreasing amplitude. The width of this diffraction pattern is determined by \\(\\lambda/b\\) and the pattern is given by\n\\[\nI(\\theta)=I_s\\frac{\\sin^2\\left (\\pi \\frac{b}{\\lambda}\\sin(\\theta)\\right)}{\\left( \\pi \\frac{b}{\\lambda}\\sin(\\theta)\\right)^2}\n\\]\nNow we have multiple of these “slit” sources. Each Huygens source in a slit has a corresponding Huygens source in a neighboring slit at a distance \\(d\\). So these pairs of sources interfer like in our multiple wave interference\n\\[\nI=I_{0}\\frac{\\sin^2(N\\phi/2)}{\\sin^2(\\phi/2)}\n\\]\nwhere the phase difference between neighboring waves is given by\n\\[\n    \\phi=k\\Delta s=\\frac{2\\pi}{\\lambda}d\\sin(\\theta)\n\\]\nwhich finally gives\n\\[\nI=I_{0}\\frac{\\sin^2(N\\pi\\frac{d}{\\lambda}\\sin(\\theta))}{\\sin^2(\\pi\\frac{d}{\\lambda}\\sin(\\theta))}\n\\]\nThe intensity distribution behind a diffraction grating is now given as the product of the two contributions of single slit diffraction and multiple source interference."
  },
  {
    "objectID": "wave-optics/Diffraction Grating.html#properties-of-the-diffraction-pattern",
    "href": "wave-optics/Diffraction Grating.html#properties-of-the-diffraction-pattern",
    "title": "Diffraction Grating",
    "section": "Properties of the diffraction pattern",
    "text": "Properties of the diffraction pattern\nWe may now have a look at the properties of this intensity distribution. The graph below plots the intensity distribution for a diffraction grating with \\(N=8\\) slits illuminated, a distance of slits \\(d=4\\) µm, a width of the slits of \\(b=2\\) µm and a wavelength of 532 nm. We make the following general observations:\n\nThe intensity pattern is consisting as we already calculated for the multiple wave interference. The main maxima are called diffraction orders charachetrized by an integer number. The central peak is the 0th order peak. The first main peak to the right is 1st diffraction order and so on.\nThe main peaks are seperated by \\(N-2\\) secondary peaks and \\(N-1\\) minima.\nThe intensity distribution is characterized by an envelope, which is the diffraction pattern of a single slit (dashed line). Thus in the example below the 2nd order peak is suppressed. The envelope will become wider, if the slits become narrower."
  },
  {
    "objectID": "wave-optics/Diffraction Grating.html#position-of-the-main-peaks",
    "href": "wave-optics/Diffraction Grating.html#position-of-the-main-peaks",
    "title": "Diffraction Grating",
    "section": "Position of the Main Peaks",
    "text": "Position of the Main Peaks\nThe position of the main peaks requires that the numerator and the denominator are zero. This is given whenever the denominator argument is a integer multiple of \\(\\pi\\), i.e. \\(\\pi d/\\lambda\\sin(\\theta)=m\\pi\\) or \\(\\sin(\\theta)=m\\lambda/d\\). So the first order diffraction maximum is found at \\(\\sin(\\theta)=\\lambda/d\\) independent of the slit number \\(N\\). This means that the position of the main peaks increases linearly with the wavelength \\(\\lambda\\) and decreases with increasing distance of the slits \\(d\\).\n\n\n\nFig.: Diffraction pattern of a grating wher 8 slits with a width of 2 µm and a distance of 4 micrometers are illuminated by a wavelength of 532 nm."
  },
  {
    "objectID": "wave-optics/Diffraction Grating.html#influence-of-the-slit-width",
    "href": "wave-optics/Diffraction Grating.html#influence-of-the-slit-width",
    "title": "Diffraction Grating",
    "section": "Influence of the Slit Width",
    "text": "Influence of the Slit Width\nThe two plots below show the influence of the slit width while the slit distance is the same. We have again \\(N=8\\) slits participating with \\(d=4\\) µm while the slit width is \\(b=2\\) µm on the left side and \\(b=1\\) µm on the right side. The result is clearly an increased width of the envelope. The first minimum of the slit diffraction pattern occurs at \\(\\sin(\\theta)=\\lambda/b\\).\n\n\n\nFig.: (Left) Diffraction pattern of a grating with \\(N=8\\) slits (\\(d=4\\) µm, \\(b=2\\) µm) with \\(\\lambda=532\\) nm. (Right) Diffraction pattern of a grating with \\(N=8\\) slits (\\(d=4\\) µm, \\(b=1\\) µm) with \\(\\lambda=532\\) nm."
  },
  {
    "objectID": "wave-optics/Diffraction Grating.html#influence-on-the-slit-number",
    "href": "wave-optics/Diffraction Grating.html#influence-on-the-slit-number",
    "title": "Diffraction Grating",
    "section": "Influence on the Slit Number",
    "text": "Influence on the Slit Number\nWhen using an increased slit number, we obtain the main diffraction peaks are becoming sharper. The location of the main peaks for the wavelength is unchanged, but as we have now \\(N-2\\) secondary maxima inbetween. This decreased width of the main peaks is important for the spectral resolution of the grating.\n\n\n\nFig.: (Left) Diffraction pattern of a grating with \\(N=16\\) slits (\\(d=4\\) µm, \\(b=1\\) µm) with \\(\\lambda=532\\) nm. (Right) Diffraction pattern of a grating with \\(N=100\\) slits (\\(d=4\\) µm, \\(b=1\\) µm) with \\(\\lambda=532\\) nm."
  },
  {
    "objectID": "wave-optics/Diffraction Grating.html#spectral-resolution",
    "href": "wave-optics/Diffraction Grating.html#spectral-resolution",
    "title": "Diffraction Grating",
    "section": "Spectral resolution",
    "text": "Spectral resolution\nFor the spectral resolution we have to define a criterium again, that allows us to quantify the spectral resolution. We borrow the idea we used from the optical resolution of the microscope, i.e. that two peaks are separable, if the second peak is located at the minimum of the first diffraction pattern. Here the diffraction patterns refer not to different objects on space but to different wavelength \\(\\lambda_1\\) and \\(\\lambda_2\\).\n\n\n\nFig.: Rayleigh resolution limit a grating with \\(N=100\\) slits (\\(d=4\\) µm, \\(b=1\\) µm) with \\(\\lambda_1=532\\) nm and \\(\\lambda_2=537\\) nm in the first order diffraction peak (left) and the second order peak (right).\n\n\nLet us have a look at the \\(m\\)th order diffraction peak for the wavelength \\(\\lambda_1\\). This occurs at\n\\[\n\\sin(\\theta)=m\\frac{\\lambda_1}{d}\n\\]\nThe next secondary minimum to larger angles of the diffraction pattern is then located at a position, where the numerator of the multiple wave interference\n\\[\n\\sin^2(N\\pi\\frac{d}{\\lambda}\\sin(\\theta))\n\\]\nbecomes zero or the argument\n\\[\nN\\pi\\frac{d}{\\lambda}\\sin(\\theta)=l\\pi\n\\]\nbecomes a multiple \\(l\\) of \\(\\pi\\). For the first order main peak we have had already \\(N-2\\) intermediate peaks as well as the 0th and now the first order peak. Therefore \\(m=l/N\\) and the next mimimum after the 1st order peak is at\n\\[\n\\sin(\\theta_1)=\\frac{l+1}{N}\\frac{\\lambda_1}{d}\n\\]\nThis angle has to correspond to the position of the main peak of the first order diffraction of the wavelength \\(\\lambda_2\\), so\n\\[\n\\sin(\\theta_1)=m\\frac{\\lambda_2}{d}\n\\]\nCombining both equations for the two wavelength yields\n\\[\n\\left (m+\\frac{1}{N} \\right )\\frac{\\lambda_1}{d}=m\\frac{\\lambda_2}{d}\n\\]\nand after some rearrangements (and setting _1=)\n\\[\nR=\\frac{\\lambda}{\\Delta \\lambda}=mN\n\\]\nThis is the resolving power \\(R\\) of a grating. The ability to resolve two wavelength therefore increases with the diffraction order \\(m\\) and the number of slits used for the diffraction. Yet, the intensity of higher diffraction orders rapidly decreases due to the grating envelope. Therefore, the main parameter to change is the number of illuminted slits.\nOur finding is illustrated in the Figure above. Where we achieve a resolution of about 5 nm, when using \\(N=100\\) slits at a distance of \\(d=4\\) µm.\n\n \n\nFig.: Diffraction pattern observed for a grating in the lecture with red light (left) and white light (right)."
  },
  {
    "objectID": "wave-optics/Dummy.html",
    "href": "wave-optics/Dummy.html",
    "title": "Contents",
    "section": "",
    "text": "The contents of this Topic will only be presented in the lectures and not part of the online publications.",
    "crumbs": [
      "Geometrical Optics",
      "Lecture 10",
      "Fabry Perot Interferometer"
    ]
  },
  {
    "objectID": "wave-optics/Thin Film Interference.html",
    "href": "wave-optics/Thin Film Interference.html",
    "title": "Thin Film Interference",
    "section": "",
    "text": "The reflection and transmission of waves on a thin film can also be regarded as an interference of two waves. A light wave is incident on a thin film as depicted below. A part of the wave is reflected on the first boundary (1). Another part is transmitted through the first boundary and reflected at the second boundary to be transmitted in the same direction (2) as the first reflected part. Note that the lines and arrows denote the direction of the wavevector \\(\\vec{k}\\) of the partial waves.\nThis picture of a single reflection at each interface is a simplification. In reality, we would have multiple reflections occurring at both interfaces, leading to an infinite number of partial waves. However, for interfaces with weak reflection coefficients (like the air/glass interface where r ≈ 4%), the contribution of higher-order reflections becomes negligible. After two reflections, the amplitude is already reduced to 4% of 4% = 0.16% of the incident wave. Therefore, considering just the first two partial waves provides a good approximation for weak reflections.\nFor the geometry shown in the figure above, we consider a medium with refractive index \\(n_1\\) surrounding a film with \\(n_2\\). The path difference Δs between waves 1 and 2 consists of two contributions:\n\\[\n\\Delta s=\\frac{2n_2d}{\\cos(\\beta)}-2d\\tan(\\beta)\\sin(\\alpha)\n\\]\nThe first term represents the optical path inside the film (wave 2), while the second term accounts for the additional path of wave 1 after reflection (shown by the dotted line).\nUsing Snell’s law, \\(n_1\\sin(\\alpha) = n_2\\sin(\\beta)\\), and setting \\(n_1 = 1\\) and \\(n_2 = n\\), we can simplify the path difference:\n\\[\n\\Delta s =\\frac{2nd}{\\cos(\\beta)}-\\frac{2nd\\sin^2(\\beta)}{\\cos(\\beta)}=2n d \\cos(\\beta)=2d\\sqrt{n^2-\\sin^2(\\alpha)}\n\\]\nThe total phase difference Δφ between the waves includes both the path difference and interface effects:\n\\[\n\\Delta \\phi=\\frac{2\\pi}{\\lambda}\\Delta s +\\pi\n\\]\nThe additional π term arises from the reflection at the first interface where \\(n_1 &lt; n_2\\). This phase jump occurs whenever light reflects from an optically denser medium. No such phase jump occurs at the second interface where \\(n_2 &gt; n_1\\).\nTo get to know the properties of thin film interference a bit better we consider the normal incidence \\(\\alpha=0\\), which leaves us with\n\\[\n\\Delta \\phi=\\frac{2\\pi}{\\lambda}2dn+\\pi\n\\]\nIn case we are searching for constructive interference, this phase shift should correspond to an integer multiple of \\(2\\pi\\), e.g. \\(\\Delta \\phi =m2\\pi\\). From the last equation we see already, that for \\(d=0\\), we have in principle a residual phase shift of \\(\\pi\\), meaning that there is only destructive interference. Yet a film thickness of zero does not really make sense.\nWe would like to discuss two different situations in the following in an example. For that we either look at the thickness under which a constructive interference at a wavelength of \\(\\lambda\\) occurs, or we ask what kind of wavelength do show constructive interference for a fixed thickness.",
    "crumbs": [
      "Geometrical Optics",
      "Lecture 9",
      "Thin Film Interference"
    ]
  },
  {
    "objectID": "wave-optics/Thin Film Interference.html#newton-rings",
    "href": "wave-optics/Thin Film Interference.html#newton-rings",
    "title": "Thin Film Interference",
    "section": "Newton Rings",
    "text": "Newton Rings\nA similar interference pattern is also observed in the case of a hemi-spherical surface touching a planar surface as sketched in the image below.\n\n\n\nNewton Rings. Interference of waves from a spherical and a planar surface in close contact.\n\n\nIf light is incident normal to the top surface, reflections occur at several interfaces. The important reflections occur at the spherical surface and the planar surface below. The vertical distance between these surfaces is \\(d\\), though refraction will deflect the beam slightly, making the actual path longer. If we stay close to the axis of the spherical surface (\\(r\\ll R\\)), where \\(R\\) is the radius of the spherical surface, we can neglect this refraction effect.\nUnder these conditions, the path length difference between a wave reflected at the curved and the planar surface is\n\\[\n\\Delta s=2d+\\frac{\\lambda}{2}\n\\]\nThe additional term \\(\\lambda/2\\) arises from the phase jump when reflecting at the planar boundary, as this reflection occurs at an optically denser material.\nHaving the path length difference, we can now calculate the condition for destructive interference:\n\\[\n\\Delta s=\\frac{2m+1}{2}\\lambda=2d+\\frac{\\lambda}{2}\n\\]\nwhere \\(m\\) is an integer. The distance \\(d\\) can be expressed as a function of the radial distance \\(r\\) from the contact point between the spherical surface and the plane surface. From the geometry of a circle, we have:\n\\[\nr^2=d(2R-d)\n\\]\nwith \\(R\\) being the radius of the spherical surface. Since \\(d\\ll R\\), the term \\(d^2\\) becomes negligible compared to \\(2Rd\\), allowing us to simplify to:\n\\[\nr^2=2dR\n\\]\nfrom which we obtain:\n\\[\nd=\\frac{r^2}{2R}\n\\]\nInserting this distance into the interference condition yields the radius \\(r_m\\) where destructive interference is observed:\n\\[\nr_m=\\sqrt{m\\lambda R}\n\\]\nThis equation shows that the radius of the interference rings increases with the square root of the integer \\(m\\). Each wavelength creates its own ring pattern, with the radius depending on both the wavelength and the sphere’s radius. This relationship makes Newton rings a useful tool for measuring either the wavelength of light (if \\(R\\) is known) or the radius of curvature of the spherical surface (if \\(\\lambda\\) is known).\n\n\n\nObservation of Newton Rings using white light in the lecture.\n\n\nWhen using white light, as shown above, each wavelength creates its own set of rings, leading to the colored pattern observed. The spacing and size of these rings provide a precise method for optical measurements and quality control of optical surfaces.",
    "crumbs": [
      "Geometrical Optics",
      "Lecture 9",
      "Thin Film Interference"
    ]
  },
  {
    "objectID": "thin_film_test.html",
    "href": "thin_film_test.html",
    "title": "Experimental Physics 3 Course on Optics and Quantum Mechanics",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\n\n# Constants\nn1 = 1.0    # refractive index of air\nn2 = 1.33   # refractive index of water\nn3 = n1     # refractive index of bottom medium (air)\n\n# Create arrays for thickness and wavelength\nd_values = np.linspace(90e-9, 200e-9, 500)  # thickness from 50nm to 2µm\nwavelengths = np.linspace(380e-9, 750e-9, 200)  # visible spectrum\n\ndef calculate_reflection(wavelength, d):\n    k = 2 * np.pi / wavelength\n    delta = 2 * n2 * d * k\n    phi_12 = np.pi if n1 &lt; n2 else 0\n    phi_23 = np.pi if n2 &lt; n3 else 0\n    total_phase = delta + phi_12 + phi_23\n    I = 4*np.cos(total_phase/2)**2\n    return I\n\ndef find_interference_maxima(d, wavelengths, intensities):\n    \"\"\"Find wavelengths where interference maxima occur\"\"\"\n    maxima_idx = []\n    for i in range(1, len(wavelengths)-1):\n        if (intensities[i] &gt; intensities[i-1] and\n            intensities[i] &gt; intensities[i+1] and\n            intensities[i] &gt; 2.0):\n            maxima_idx.append(i)\n    return wavelengths[maxima_idx], intensities[maxima_idx]\n\ndef wavelength_to_rgb(wavelength):\n    gamma = 0.8\n    wavelength = wavelength * 1e9\n\n    if wavelength &lt; 380 or wavelength &gt; 750:\n        return (0, 0, 0)\n\n    if wavelength &lt; 440:\n        R = (440 - wavelength) / (440 - 380)\n        G = 0\n        B = 1\n    elif wavelength &lt; 490:\n        R = 0\n        G = (wavelength - 440) / (490 - 440)\n        B = 1\n    elif wavelength &lt; 510:\n        R = 0\n        G = 1\n        B = (510 - wavelength) / (510 - 490)\n    elif wavelength &lt; 580:\n        R = (wavelength - 510) / (580 - 510)\n        G = 1\n        B = 0\n    elif wavelength &lt; 645:\n        R = 1\n        G = (645 - wavelength) / (645 - 580)\n        B = 0\n    else:\n        R = 1\n        G = 0\n        B = 0\n\n    R = np.power(R, gamma) if R &gt; 0 else 0\n    G = np.power(G, gamma) if G &gt; 0 else 0\n    B = np.power(B, gamma) if B &gt; 0 else 0\n\n    return np.array([R, G, B])\n\ndef mix_colors(wavelengths, intensities):\n    if len(wavelengths) == 0:\n        return np.array([0, 0, 0, 0])  # Added alpha channel\n\n    mixed_color = np.zeros(4)  # RGBA\n    max_intensity = 0\n\n    for wave, intensity in zip(wavelengths, intensities):\n        color = wavelength_to_rgb(wave)\n        mixed_color[:3] += color * (intensity/4.0)\n        max_intensity = max(max_intensity, intensity)\n\n    # Set alpha based on maximum intensity\n    mixed_color[3] = max_intensity / 4.0  # normalize to maximum possible intensity\n\n    if np.max(mixed_color[:3]) &gt; 0:\n        if len(wavelengths) &gt; 3:\n            white_factor = min((len(wavelengths) - 3) / 5, 0.7)\n            mixed_color[:3] = mixed_color[:3] * (1 - white_factor) + white_factor\n        else:\n            mixed_color[:3] = mixed_color[:3] / np.max(mixed_color[:3])\n\n    return mixed_color\n\n# Calculate colors for each thickness\nrgba_image = np.zeros((len(d_values), 4))  # RGBA\nfor i, d in enumerate(d_values):\n    intensities = np.array([calculate_reflection(w, d) for w in wavelengths])\n    max_wavelengths, max_intensities = find_interference_maxima(d, wavelengths, intensities)\n    rgba_image[i] = mix_colors(max_wavelengths, max_intensities)\n\n# Create a checkerboard background\nbg_size = 10\nbg = np.zeros((len(d_values), 1, 3))\nbg[::bg_size] = 0.8  # lighter squares\nbg[bg_size//2::bg_size] = 0.2  # darker squares\n\n# Plot with background\nplt.figure(figsize=(2, 6))\nplt.imshow(bg, aspect='auto', origin='lower')  # background\nplt.imshow(rgba_image.reshape(-1, 1, 4), aspect='auto', origin='lower')  # colored film\nplt.ylabel('Thickness (nm)')\ntick_positions = np.linspace(0, len(d_values)-1, 6)\ntick_labels = [f'{d*1e9:.0f}' for d in np.linspace(d_values[0], d_values[-1], 6)]\nplt.yticks(tick_positions, tick_labels)\nplt.xticks([])\nplt.title('Reflected Colors')\nplt.show()\n\n# Print theoretical wavelengths for verification\ntest_thicknesses = [100e-9, 200e-9, 300e-9]\nprint(\"\\nExpected wavelengths of constructive interference:\")\nfor d in test_thicknesses:\n    print(f\"\\nThickness {d*1e9:.0f} nm:\")\n    for m in range(1, 4):\n        wavelength = 4 * n2 * d / (2*m - 1)\n        if 380e-9 &lt;= wavelength &lt;= 750e-9:\n            print(f\"m={m}: {wavelength*1e9:.0f} nm\")\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Constants\nn1 = 1.0    # refractive index of air\nn2 = 1.33   # refractive index of water\nn3 = n1     # refractive index of bottom medium (air)\n\ndef calculate_reflection(wavelength, d):\n    k = 2 * np.pi / wavelength\n    delta = 2 * n2 * d * k\n    phi_12 = np.pi if n1 &lt; n2 else 0\n    phi_23 = np.pi if n2 &lt; n3 else 0\n    total_phase = delta + phi_12 + phi_23\n    I = 4*np.cos(total_phase/2)**2\n    return I\n\n# Calculate reflection for a range of thicknesses\nd_values = np.linspace(0, 500e-9, 1000)  # 0 to 500 nm\nwavelength = 520e-9  # green light\n\nintensities = [calculate_reflection(wavelength, d) for d in d_values]\n\n# Calculate theoretical destructive interference positions\ndef destructive_thickness(m, wavelength):\n    return (2*m - 1) * wavelength/(4*n2)\n\n# Plot reflection intensity vs thickness\nplt.figure(figsize=(10, 6))\nplt.plot(d_values*1e9, intensities)\nplt.xlabel('Thickness (nm)')\nplt.ylabel('Reflection Intensity')\nplt.title('Reflection Intensity vs Film Thickness')\n\n# Mark destructive interference positions\nfor m in range(1, 4):\n    d = destructive_thickness(m, wavelength)\n    plt.axvline(x=d*1e9, color='r', linestyle='--', alpha=0.5)\n    plt.text(d*1e9, 0.5, f'm={m}', rotation=90)\n\nplt.grid(True)\nplt.show()\n\n# Print destructive interference thicknesses\nprint(\"\\nDestructive interference thicknesses:\")\nfor m in range(1, 4):\n    d = destructive_thickness(m, wavelength)\n    print(f\"m={m}: {d*1e9:.1f} nm\")\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Constants\nn1 = 1.0    # refractive index of air\nn2 = 1.33   # refractive index of water\nn3 = n1     # refractive index of bottom medium (air)\n\ndef calculate_reflection(wavelength, d):\n    k = 2 * np.pi / wavelength\n    delta = 2 * n2 * d * k  # path difference phase\n    phi_12 = np.pi if n1 &lt; n2 else 0  # first interface phase shift\n    phi_23 = 0  # second interface phase shift\n    total_phase = delta + phi_12 + phi_23\n    I = 4*np.cos(total_phase/2)**2\n    return I\n\n# Calculate reflection for very thin films\nd_values = np.linspace(0, 200e-9, 1000)  # 0 to 200 nm\nwavelength = 550e-9  # green light\n\nintensities = [calculate_reflection(wavelength, d) for d in d_values]\n\nplt.figure(figsize=(10, 6))\nplt.plot(d_values*1e9, intensities)\nplt.xlabel('Thickness (nm)')\nplt.ylabel('Reflection Intensity')\nplt.title('Reflection Intensity vs Film Thickness')\n\n# Highlight the Newton black film region\nplt.axvspan(0, 20, color='gray', alpha=0.3, label='Newton black film region')\n\nplt.grid(True)\nplt.legend()\nplt.show()\n\n# Print phase contributions for very thin film\nd_thin = 10e-9  # 10 nm\npath_phase = 4 * np.pi * n2 * d_thin / wavelength\nprint(f\"\\nFor d = {d_thin*1e9:.1f} nm:\")\nprint(f\"Path difference phase: {path_phase:.3f} radians\")\nprint(f\"Interface phase shift: π radians\")\nprint(f\"Total phase: {path_phase + np.pi:.3f} radians\")"
  },
  {
    "objectID": "wave-optics/Interference.html",
    "href": "wave-optics/Interference.html",
    "title": "Interference",
    "section": "",
    "text": "Interference is a fundamental physical phenomenon that demonstrates the superposition principle for linear systems. This principle, which states that the net response to multiple stimuli is the sum of the individual responses, is central to our understanding of wave physics. Interference appears across many domains of physics: in optics where it enables high-precision measurements and holography, in quantum mechanics where it reveals the wave nature of matter, and in acoustics where it forms the basis for noise cancellation technology. The ability of waves to interfere constructively (amplifying each other) or destructively (canceling each other) has profound practical applications, from the anti-reflective coatings on optical elements to the operational principles of interferometric gravitational wave detectors like LIGO. Understanding interference is therefore not just of theoretical interest but crucial for modern technology and experimental physics.\nWhen two wave solutions \\(U_1(\\mathbf{r})\\) and \\(U_2(\\mathbf{r})\\) combine, their superposition gives:\n\\[\nU(\\mathbf{r})=U_1(\\mathbf{r})+U_2(\\mathbf{r})\n\\]\nThe resulting intensity is:\n\\[\\begin{eqnarray}\nI &= &|U|^2\\\\\n&= &|U_1+U_2|^2\\\\\n&= &|U_1|^2+|U_2|^2+U^{*}_1 U_2 + U_1 U^{*}_2\n\\end{eqnarray}\\]\nThe individual wave intensities are given by \\(I_1=|U_1|^2\\) and \\(I_2=|U_2|^2\\). Using this, we can express each complex wave amplitude in polar form, separating its magnitude (related to intensity) and phase:\n\\[\nU_1=\\sqrt{I_1}e^{i\\phi_1}\n\\] \\[\nU_2=\\sqrt{I_2}e^{i\\phi_2}\n\\]\nSubstituting these expressions back into our interference equation and performing the algebra, the total intensity becomes:\n\\[\nI=I_1+I_2+2\\sqrt{I_1 I_2}\\cos(\\Delta \\phi)\n\\]\nwhere \\(\\Delta \\phi=\\phi_2-\\phi_1\\) is the phase difference between the waves. This equation is known as the interference formula and contains three terms:\n\n\\(I_1\\) and \\(I_2\\): the individual intensities\n\\(2\\sqrt{I_1 I_2}\\cos(\\Delta \\phi)\\): the interference term that can be positive or negative\n\nA particularly important special case occurs when the interfering waves have equal intensities (\\(I_1=I_2=I_0\\)). The equation then simplifies to:\n\\[\nI=2I_0(1+\\cos(\\Delta \\phi))=4I_0\\cos^2\\left(\\frac{\\Delta \\phi}{2}\\right)\n\\]\nThis last form clearly shows that:\n\nMaximum intensity (\\(4I_0\\)) occurs when \\(\\Delta \\phi = 2\\pi n\\) (constructive interference)\nZero intensity occurs when \\(\\Delta \\phi = (2n+1)\\pi\\) (destructive interference)\nThe intensity varies sinusoidally with the phase difference\n\n\n\n\n\n\n\nConstructive Interference\n\n\n\nOccurs when \\(\\Delta \\phi=2\\pi m\\) (where \\(m\\) is an integer), resulting in \\(I=4I_0\\)\n\n\n\n\nCode\nx=np.linspace(0,2,1000)\nwavelength=0.532\nk=2*np.pi/0.532\ny1=np.cos(k*x)\n\nfig,[ax1,ax2,ax3]=plt.subplots(3,1,figsize=get_size(10,8))\nax1.plot(x/wavelength,y1,label='Wave 1')\nax2.plot(x/wavelength,y1,label='Wave 1')\nax3.plot(x/wavelength,2*y1,label='Wave 1')\nax3.set_xlabel(r\"distance [$\\lambda$]\")\nax1.set_ylabel(r\"$U_1$\")\nax2.set_ylabel(r\"$U_2$\")\nax3.set_ylabel(r\"$U_1+U_2$\")\nplt.tight_layout()\nplt.show()\n\n\n\n\n\nConstructive interference of two waves (top, middle) and the sum of the two wave amplitudes (bottom)\n\n\n\n\n\n\n\n\n\n\nDestructive Interference\n\n\n\nOccurs when \\(\\Delta \\phi=(2m-1)\\pi\\) (where \\(m\\) is an integer), resulting in \\(I=0\\)\n\n\n\n\nCode\nx=np.linspace(0,2,1000)\nwavelength=0.532\nk=2*np.pi/0.532\ny1=np.cos(k*x)\ny2=np.cos(k*x+np.pi)\n\nfig,[ax1,ax2,ax3]=plt.subplots(3,1,figsize=get_size(10,8))\nax1.plot(x/wavelength,y1,label='Wave 1')\nax2.plot(x/wavelength,y2,label='Wave 1')\nax3.plot(x/wavelength,y1+y2,label='Wave 1')\nax3.set_xlabel(r\"distance [$\\lambda$]\")\nax1.set_ylabel(r\"$U_1$\")\nax2.set_ylabel(r\"$U_2$\")\nax3.set_ylabel(r\"$U_1+U_2$\")\nax3.set_ylim(-1,1)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\nDestructive interference of two waves (top, middle) and the sum of the two wave amplitudes (bottom)\n\n\n\n\n\nPhase and Path Difference\nThe phase difference \\(\\Delta \\phi\\) can be related to the path difference \\(\\Delta s\\) between the two waves. For two waves with the same frequency \\(\\omega\\), we can write their complete phase expressions as:\n\\[\\phi_1(\\mathbf{r},t) = \\mathbf{k}_1\\cdot\\mathbf{r} - \\omega t + \\phi_{01}\\] \\[\\phi_2(\\mathbf{r},t) = \\mathbf{k}_2\\cdot\\mathbf{r} - \\omega t + \\phi_{02}\\]\nwhere:\n\n\\(\\mathbf{k}_i\\) are the wave vectors\n\\(\\mathbf{r}\\) is the position vector\n\\(\\omega\\) is the angular frequency\n\\(\\phi_{0i}\\) are initial phase constants\n\nThe instantaneous phase difference is then:\n\\[\n\\Delta\\phi(\\mathbf{r},t) = \\phi_2(\\mathbf{r},t) - \\phi_1(\\mathbf{r},t) = (\\mathbf{k}_2-\\mathbf{k}_1)\\cdot\\mathbf{r} + (\\phi_{02}-\\phi_{01})\n\\]\nFor stationary interference patterns, we typically observe the time-independent phase difference. When the waves travel along similar paths (same direction), this reduces to:\n\\[\\Delta\\phi = k\\Delta s + \\Delta\\phi_0\\]\nwhere \\(\\Delta s\\) is the path difference and \\(\\Delta\\phi_0\\) is any initial phase difference between the sources.\n\n\n\n\n\n\nPhase Difference and Path Difference\n\n\n\nA path difference \\(\\Delta s\\) corresponds to a phase difference \\(k\\Delta s=2\\pi\\Delta s/\\lambda\\). Path differences of integer multiples of \\(\\lambda\\) result in phase differences of integer multiples of \\(2\\pi\\).\n\n\n\n\nInterference of Waves in Space\n\n\nCode\ndef plane_wave(k,omega,r,t):\n    return(np.exp(1j*(np.dot(k,r)-omega*t)))\n\nwavelength=532e-9\nk0=2*np.pi/wavelength\nc=299792458\nomega0=k0*c\n\nvec=np.array([0.0,0.,1.])\nvec1=np.array([1.0,0.,1.])\nvec=vec/np.sqrt(np.dot(vec,vec))\nvec1=vec1/np.sqrt(np.dot(vec1,vec1))\n\nk=k0*vec\nk1=k0*vec1\n\nx=np.linspace(-2.5e-6,2.5e-6,300)\nz=np.linspace(0,5e-6,300)\n\nX,Z=np.meshgrid(x,z)\nr=np.array([X,0,Z],dtype=object)\n\nfig,ax=plt.subplots(2,2,figsize=get_size(10,10))\nfield=plane_wave(k,omega0,r,0)\nfield1=plane_wave(k1,omega0,r,0)\n\nextent = np.min(z)*1e6, np.max(z)*1e6,np.min(x)*1e6, np.max(x)*1e6\nax[0,0].imshow(np.real(field.transpose()),extent=extent,vmin=-1,vmax=1,cmap='seismic')\nax[0,0].set_title('wave 1')\nax[0,1].imshow(np.real(field1.transpose()),extent=extent,vmin=-1,vmax=1,cmap='seismic')\nax[0,1].set_title('wave 2')\nax[1,0].imshow(np.real(field.transpose()+field1.transpose()),extent=extent,vmin=-1,vmax=1,cmap='seismic')\nax[1,0].set_title('sum')\nax[1,1].imshow(np.abs(field.transpose()+field1.transpose())**2,extent=extent,cmap='gray')\nax[1,1].set_title('intensity')\nax[1,1].set_xlabel('z-position [µm]')\nax[1,0].set_xlabel('z-position [µm]')\nax[1,0].set_ylabel('x-position [µm]')\nax[0,0].set_ylabel('x-position [µm]')\nplt.tight_layout()\nplt.show()\n\n\n\n\n\nInterference of two plane waves propagating under an angle of 45°. The two left graphs show the original waves. The two right show the total amplitude and the intensity pattern.\n\n\n\n\n\n\nCode\ndef spherical_wave(k,omega,r,r0,t):\n    k=np.linalg.norm(k)\n    d=np.linalg.norm(r-r0)\n    return( np.exp(1j*(k*d-omega*t))/d)\n\n\n\nx=np.linspace(-5e-6,5e-6,300)\nz=np.linspace(-5e-6,5e-6,300)\n\nX,Z=np.meshgrid(x,z)\nr=np.array([X,0,Z],dtype=object)\n\nwavelength=532e-9\nk0=2*np.pi/wavelength\nc=299792458\nomega0=k0*c\n\nk=k0*np.array([0,1.0,0])\nr0=np.array([0,2e-6,0])\n\nfield=spherical_wave(k,omega0,r,r0,0)\nfield1=plane_wave(k,omega0,r,0)\n\nextent = np.min(z)*1e6, np.max(z)*1e6,np.min(x)*1e6, np.max(x)*1e6\n\nfig,ax=plt.subplots(2,2,figsize=get_size(10,10))\nax[0,0].imshow(np.real(field.transpose()+0*field1.transpose()),extent=extent,cmap='seismic')\nax[0,0].set_title('Spherical wave')\nax[0,1].imshow(np.real(0*field.transpose()+field1.transpose()),extent=extent,cmap='seismic')\nax[0,1].set_title('Plane wave')\nax[1,0].imshow(np.real(0.00001*field.transpose()+field1.transpose()),extent=extent,cmap='seismic')\nax[0,1].set_title('Sum')\nax[1,1].imshow(np.abs(0.00001*field.transpose()+field1.transpose())**2,extent=extent,cmap='gray')\nax[0,1].set_title('Intensity')\nax[1,0].set_xlabel('z [µm]')\nax[1,1].set_xlabel('z [µm]')\nax[1,0].set_ylabel('x [µm]')\nax[0,0].set_ylabel('x [µm]')\nplt.show()\n\n\n\n\n\nInterference of a spherical wave and a plane wave. The top graphs show the original waves. The two bottom show the total amplitude and the intensity pattern.\n\n\n\n\nThe interference of the spherical and the plane wave (also the one of the two plane waves) give also an interesting result. The intensity resembles to be a snapshot of the shape of the wavefronts of the spherical wave. We can therefore measure the wavefronts of the spherical wave by interfering it with a plane wave. This is also the basic principle behind holography. There we use a reference wave to interfere with the wave that we want to measure. The interference pattern is recorded and can be used to reconstruct the wavefronts of the wave.\n\nA super nice website to try out interference interactively is here.\n\n\n\nCoherence\nIn the earlier consideration we obtained a general description for the phase difference between two waves. TIt is given by and contains the pathlength difference \\(\\Delta s\\) and some intrinsic phase \\(\\Delta\\phi_0\\) that could be part of the wave generation process.\n\\[\\Delta\\phi = k\\Delta s + \\Delta\\phi_0\\]\nTo observe stationary interference, it is important that these two quantities are also stationary, i.e. the phase relation between the two waves is stationary. This relation between the phase of two waves is called coherence and was assumed in all the examples before.\n\n\n\nTwo waves of different frequency over time.\n\n\nThe above image shows the timetrace of the amplitude of two wave with slightly different frequency. Due to the frequency, the waves run out of phase and have acquired a phase different of \\(\\pi\\) after \\(40\\) fs.\nThe temporal coherence of two waves is now defined by the time it takes for the two waves to obtain a phase difference of \\(2\\pi\\). The phase difference between two wave of frequency \\(\\nu_1\\) and \\(\\nu_2\\) is given by\n\\[\n\\Delta \\phi = 2\\pi (\\nu_2-\\nu_1)(t-t_0)\n\\]\nHere \\(t_0\\) refers to the time, when thw two waves were perfectly in sync. Lets assume that the two frequencies are seperarated from a central frequency \\(\\nu_0\\) such that\n\\[\n\\nu_1=\\nu_0-\\Delta \\nu/2\n\\] \\[\n\\nu_2=\\nu_0+\\Delta \\nu/2\n\\]\nInserting this into the first equation yields\n\\[\n\\Delta \\phi = 2\\pi \\Delta \\nu \\Delta t\n\\]\nwith \\(\\Delta t=t-t_0\\). We can now define the coherence time as the time interval over which the phase shift \\(\\Delta \\phi\\) grows to \\(2\\pi\\), i.e. \\(\\Delta \\phi=2\\pi\\). The coherence time is thus\n\\[\n\\tau_{c}=\\Delta t =\\frac{1}{\\Delta \\nu}\n\\]\nThus the temporal coherence and the frequency distribution of the light are intrisincly connected. Monochromatic light has \\(\\Delta nu=0\\) and thus the coherence time is infinitely long. Light with a wide spectrum (white light for example) therefore has and extremly short coherence time.\nThe coherence time is also connected to a coherence length. The coherence length \\(L_c\\) is given by the distance light travels within the coherence time \\(\\tau_c\\), i.e.\n\\[\nL_c=c\\tau_c\n\\]\n\n\n\n\n\n\nCoherence\n\n\n\nTwo waves are called coherent, if they exihibit a fixed phase relation in space or time relation over time. It measures their ability to interfer. The main types of coherence are\n\nTemporal Coherence\n\nMeasures phase correlation of a wave with itself at different times\nCharacterized by coherence time \\(\\tau_c\\) and coherence length \\(L_c = c\\tau_c\\)\nRelated to spectral width: \\(\\tau_c = 1/\\Delta\\nu\\)\nPerfect for monochromatic waves (single frequency)\nLimited for broad spectrum sources (like thermal light)\n\n\n\nSpatial Coherence\n\nMeasures phase correlation between different points in space\nImportant for interference from extended sources\nDetermines ability to form interference patterns\nRelated to source size and geometry\n\nCoherence is a property of the light source and is connected to the frequency distribution of the light. Sources can be:\n\nFully coherent: ideal laser\nPartially coherent: real laser\nIncoherent: thermal light\n\n\n\n\n\n\nMore General Description of Coherence\nWhile the above definition provides an intuitive picture based on frequency spread, we can describe coherence more rigorously using correlation functions. These functions measure how well a wave maintains its phase relationships:\nIn real physical systems, perfect coherence (constant phase relationship) between waves is rare. Partial coherence describes the degree to which waves maintain a consistent phase relationship over time and space. We can characterize this using correlation functions:\n\nTemporal Coherence The complex degree of temporal coherence is given by:\n\n\\[g^{(1)}(\\tau) = \\frac{\\langle U(t)U^*(t+\\tau)\\rangle}{\\sqrt{\\langle|U(t)|^2\\rangle\\langle|U(t+\\tau)|^2\\rangle}}\\]\nwhere:\n\n\\(\\tau\\) is the time delay\n\\(U(t)\\) is the electric field\n\\(\\langle...\\rangle\\) denotes time averaging\n\n\nSpatial Coherence Similarly, spatial coherence between two points is characterized by:\n\n\\[g^{(1)}(\\mathbf{r}_1,\\mathbf{r}_2) = \\frac{\\langle U(\\mathbf{r}_1)U^*(\\mathbf{r}_2)\\rangle}{\\sqrt{\\langle|U(\\mathbf{r}_1)|^2\\rangle\\langle|U(\\mathbf{r}_2)|^2\\rangle}}\\]\nThe obtained correlation functions can be used to calculate the coherence time and length and have the following properties:\n\n\\(|g^{(1)}| = 1\\) indicates perfect coherence\n\\(|g^{(1)}| = 0\\) indicates complete incoherence\n\\(0 &lt; |g^{(1)}| &lt; 1\\) indicates partial coherence\n\nA finite coherence time and length is leads to partial coherence affects interference visibility through:\n\nReduced contrast in interference patterns\nLimited coherence length/area\nSpectral broadening\n\n\n\nCode\nomega0 = 2.0\ndelta_omega = 0.05  # frequency difference\ntau_c = np.pi/delta_omega  # coherence time (corrected)\nbeat_period = 2*np.pi/delta_omega  # time for full beat cycle\n\nt = np.linspace(0, 1000, 10000)\ntau = np.linspace(0, 500, 200)\n\ndef generate_waves(t):\n    wave1 = np.exp(1j * omega0 * t)\n    wave2 = np.exp(1j * (omega0 + delta_omega) * t)\n    return wave1, wave2\n\ndef calc_correlation(wave, tau):\n    g = np.zeros(len(tau), dtype=complex)\n    N = len(wave)\n\n    for i, dt in enumerate(tau):\n        shift = int(dt * 10)\n        if shift &gt;= N:\n            g[i] = 0\n        else:\n            g[i] = np.mean(wave[:(N-shift)] * np.conj(wave[shift:]))\n\n    return g / np.abs(g[0])\n\n\nwave1, wave2 = generate_waves(t)\nwave_total = wave1 + wave2\n\n# Calculate correlation\ng = calc_correlation(wave_total, tau)\n\n# Plot\nfig, (ax1, ax2) = plt.subplots(2, 1, figsize=get_size(10, 8))\n\n# Plot waves\nax1.plot(t[:500], np.real(wave1[:500]), label='Wave 1', alpha=0.7)\nax1.plot(t[:500], np.real(wave2[:500]), label='Wave 2', alpha=0.7)\nax1.plot(t[:500], np.real(wave_total[:500]), 'k', label='Sum', alpha=0.7,lw=0.5)\nax1.set_title('wave superposition')\nax1.set_xlabel('time')\nax1.set_ylabel('amplitude')\nax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n\n\n# Plot correlation\nax2.plot(tau, np.abs(g))\nax2.axvline(x=tau_c, color='r', linestyle='--', label=r'$\\tau_c$ ')\nax2.axvline(x=beat_period, color='g', linestyle=':', label=f'Beat period')\nax2.set_title('|g⁽¹⁾(τ)|')\nax2.set_xlabel('τ')\nax2.set_ylabel('|g⁽¹⁾(τ)|')\nax2.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\nplt.tight_layout()\nplt.subplots_adjust(right=0.85)\n\nplt.show()\n\n\n\n\n\nTemporal correlation for two waves with slightly different frequencies. The vertical line indicates the coherence time τc = π/Δω.\n\n\n\n\nBesides different frequencies the coherence time can also be affected by phase jumps. The following example shows two waves with the same frequency but multiple phase jumps. The temporal correlation function shows the decoherence due to the phase jumps.\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nomega0 = 1.0  # same frequency for both waves\ntau = np.linspace(0, 500, 200)\n\nt = np.linspace(0, 1000, 10000)\n\ndef generate_waves_with_jumps(t, n_jumps=10):\n    # Create two identical waves\n    wave1 = np.exp(1j * omega0 * t)\n    wave2 = np.exp(1j * omega0 * t)  # same frequency\n\n    # Create regularly spaced jumps within first 500 time units\n    jump_positions = np.linspace(0, 500, n_jumps+1)[:-1]  # exclude last point\n    jump_indices = [int(pos * len(t)/t[-1]) for pos in jump_positions]\n    phase_shifts = np.random.uniform(0, 2*np.pi, n_jumps)\n\n    # Apply phase shifts to wave2\n    wave2_with_jumps = wave2.copy()\n    current_phase = 0\n\n    for i in range(n_jumps):\n        start_idx = jump_indices[i]\n        if i &lt; n_jumps-1:\n            end_idx = jump_indices[i+1]\n        else:\n            end_idx = len(t)\n\n        current_phase += phase_shifts[i]\n        wave2_with_jumps[start_idx:end_idx] *= np.exp(1j * current_phase)\n\n    return wave1, wave2_with_jumps, jump_positions\n\n\ndef calc_correlation(wave, tau):\n    g = np.zeros(len(tau), dtype=complex)\n    N = len(wave)\n\n    for i, dt in enumerate(tau):\n        shift = int(dt * 10)\n        if shift &gt;= N:\n            g[i] = 0\n        else:\n            g[i] = np.mean(wave[:(N-shift)] * np.conj(wave[shift:]))\n\n    return g / np.abs(g[0])\n\n# Generate waves with 30 jumps\nwave1, wave2, jump_positions = generate_waves_with_jumps(t, n_jumps=30)\nwave_total = wave1 + wave2\n\ng = calc_correlation(wave_total, tau)\n\n\nfig, (ax1, ax2) = plt.subplots(2, 1, figsize=get_size(10, 8))\n\nax1.plot(t[:2000], np.real(wave1[:2000]), label='Wave 1', alpha=0.9)\nax1.plot(t[:2000], np.real(wave2[:2000]), label='Wave 2', alpha=0.9)\nax1.plot(t[:2000], np.real(wave_total[:2000]), 'k-', label='Sum', lw=0.5)\nax1.set_xlim(0, 200)\n# Add vertical lines for phase jumps in wave plot\nfor pos in jump_positions:\n    ax1.axvline(x=pos, color='r', linestyle='--', alpha=0.3)\n\nax1.set_title('Superposition with Multiple Phase Jumps')\nax1.set_xlabel('time')\nax1.set_ylabel('amplitude')\nax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n\n# Plot correlation\nax2.plot(tau, np.abs(g))\n\nax2.set_title('|g⁽¹⁾(τ)|')\nax2.set_xlabel('τ')\nax2.set_ylabel('|g⁽¹⁾(τ)|')\nax2.set_xlim(0, 200)\nax2.set_ylim(0, 1)\n\n# Adjust layout\nplt.tight_layout()\nplt.subplots_adjust(right=0.85)\n\nplt.show()\n\n\n\n\n\nTemporal correlation for two waves of same frequency showing decoherence due to multiple phase jumps. Vertical lines indicate positions of phase jumps.\n\n\n\n\n\n\n\n\n\n\nCoherence of Thermal radiation\n\n\n\n\n\nThermal radiation is a common example of incoherent light. While it is called incoherent, there is no complete incoherence, but the coherence length of a few 10 micrometers. Sun light, for example, has been measured to have a coherence length of about 50 micrometers (Shawn Divitt and Lukas Novotny, “Spatial coherence of sunlight and its implications for light management in photovoltaics,” Optica 2, 95-103 (2015)). The following factors contribute to the incoherence of thermal radiation:\nRandom Emission Process - Individual atoms/molecules emit light independently - Each emission event has a random phase - The emission timing is random - These random events effectively create continuous phase jumps\nMultiple Emitters - Many atoms/molecules emit simultaneously - Each emitter acts independently - There’s no phase relationship between different emitters - This leads to spatially incoherent radiation\nThermal Motion - Atoms/molecules are in constant thermal motion - This motion causes Doppler shifts - The shifts result in frequency variations - Motion also affects the phase of emitted radiation\nCollision Effects - Frequent atomic/molecular collisions - Each collision can cause phase jumps - At higher temperatures, more frequent collisions - This leads to shorter coherence times\n\n\n\n\n\n\n\n\n\nPartial Coherence in Lasers\n\n\n\n\n\nThe coherence of laser light is limited by various physical mechanisms that cause fluctuations in phase and frequency. While perfect coherence is theoretically impossible, some lasers can achieve remarkable coherence lengths. Single-frequency solid-state lasers, when properly stabilized, are particularly noteworthy in this regard. For instance, a laser with a Lorentzian spectrum of 10 kHz linewidth can achieve a coherence length of 9.5 km.\nThe fundamental limit to laser coherence is set by quantum noise, as described by the Schawlow-Townes linewidth. However, modern laser systems, particularly those developed for optical clocks, have pushed these boundaries further. Some of these systems have been stabilized to achieve linewidths below one hertz, corresponding to coherence lengths exceeding 300,000 km.\nSpontaneous Emission - Not all emission in a laser is stimulated - Some spontaneous emission is always present - Adds random phase jumps to the laser field - Sets fundamental quantum limit to coherence\nTechnical Noise Sources - Mechanical vibrations of cavity mirrors - Thermal fluctuations in gain medium - Pump power fluctuations - Current noise in diode lasers\nGain Medium Properties - Finite linewidth of the lasing transition - Thermal motion of atoms/molecules - Pressure broadening in gas lasers - Population fluctuations\nCavity Effects - Finite cavity lifetime - Multiple longitudinal modes - Temperature-induced length changes",
    "crumbs": [
      "Geometrical Optics",
      "Lecture 8",
      "Interference and Coherence"
    ]
  },
  {
    "objectID": "wave-optics/Double Slit.html",
    "href": "wave-optics/Double Slit.html",
    "title": "Double Slit Interference",
    "section": "",
    "text": "Two Point Sources - Double Slit Interference\nThe interference of two point sources is a classic example of wave interference. It is often referred to as double slit interference. The interference pattern is created by two point sources that emit waves with the same wavelength and amplitude. The intereference of the two waves depends then on the path length difference between the two waves\n\nCode\ndef plot_angle(ax, pos, angle, length=0.95, acol=\"C0\", **kwargs):\n    vec2 = np.array([np.cos(np.deg2rad(angle)), np.sin(np.deg2rad(angle))])\n    xy = np.c_[[length, 0], [0, 0], vec2*length].T + np.array(pos)\n    ax.plot(*xy.T, color=acol,ls=\"--\")\n    return AngleAnnotation(pos, xy[0], xy[2], ax=ax, **kwargs)\n\n\n\nplt.figure(figsize=get_size(12,12))\n\n# Point sources positions\nd = 2  # source separation\ny1, z1 = 0, -d/2  # source 1\ny2, z2 = 0, d/2   # source 2\n\n# Draw circular wavefronts\ntheta = np.linspace(0, 2*np.pi, 100)\nn_circles = 5\nwavelength = 2  # spacing between wavefronts\n\nfor i in range(n_circles):\n    r = i * wavelength\n    # Wavefronts from source 1\n    plt.plot(r*np.cos(theta) + y1, r*np.sin(theta) + z1, 'b:', alpha=0.5)\n    # Wavefronts from source 2\n    plt.plot(r*np.cos(theta) + y2, r*np.sin(theta) + z2, 'r:', alpha=0.5)\n\n# Draw screen\nscreen_z = np.linspace(-10, 10, 100)\nscreen_y = np.ones_like(screen_z) * 16\nplt.plot(screen_y, screen_z, 'k-', linewidth=2, label='Screen')\n\n# Example point on screen\nP = np.array([16, 4])  # point coordinates [y, z]\n\n# Draw paths from sources to point P\nplt.plot([y1, P[0]], [z1, P[1]], 'b-', label='Path 1')\nplt.plot([y2, P[0]], [z2, P[1]], 'r-', label='Path 2')\nplt.plot([0, P[0]], [z2, P[1]], 'k-', label='Path 2')\n\n# Calculate and show path lengths\nr1 = np.sqrt((P[0]-y1)**2 + (P[1]-z1)**2)\nr2 = np.sqrt((P[0]-y2)**2 + (P[1]-z2)**2)\npath_diff = abs(r2 - r1)\n\n# Add sources\nplt.plot(y1, z1, 'bo', label='Source 1')\nplt.plot(y2, z2, 'ro', label='Source 2')\n\n# Label source separation\nplt.plot([y1-0.5, y1-0.5], [z1, z2], 'k-', linewidth=1)\nplt.text(y1-2, -.2, 'd', fontsize=12)\n\n# Add angle annotation\ncenter = np.array([0, 0])  # center between sources\nangle = np.arctan2(P[1], P[0])  # angle to point P\nkw = dict(size=500, unit=\"points\", text=r\"$\\theta$\")\nplot_angle(plt.gca(), center, angle*180/np.pi, length=16,acol=\"k\",textposition=\"inside\", **kw)\n\nplt.xlabel('y')\nplt.ylabel('z')\nplt.axis(\"equal\")\nplt.axis('off')\n\nplt.show()\n\n\n\n\n\n\n\n\nDouble slit interference as the interference from two point sources on the left and the wave amplitudes on the right. The interference pattern is created by two point sources that emit waves with the same wavelength and amplitude. The intereference of the two waves depends then on the path length difference between the two waves.\n\n\n\n\n\n\n    Wave Interference Pattern\n    \n    \n\n\n\n    \n    \n        Source Separation: \n        \n    \n    \n        Wavelength: \n        \n    \n\n\n\n\n\n\n\nThe interference pattern depends on the relative phase of the two waves. The phase difference can be calculated from the path length difference between the two waves and the path length difference can be calculated considering the angle \\(\\theta\\) between the line connecting the two sources and the line connecting the sources to the point on the screen. The path length difference is then given by\n\\[\n\\Delta s = s_2 - s_1 = d \\sin(\\theta)\n\\]\nand consequently the phase difference is given by\n\\[\n\\Delta \\phi = \\frac{2\\pi}{\\lambda} \\Delta s = \\frac{2\\pi}{\\lambda} d \\sin(\\theta)\n\\]\n\n\n\n\n\n\nCorrect path length difference\n\n\n\n\n\nThe path length difference given above is only approximately correct. The exact calculation would involve the geometry of the problem and the path length difference would be calculated as \\(\\Delta s = \\sqrt{d^2 + L^2 - 2dL \\cos(\\theta)} - \\sqrt{d^2 + L^2 - 2dL \\cos(\\theta)}\\). Note that when observing the pattern on the screen with the help of a lens that is placed at the focal distance from the screen, the two path would correspond to parallel rays and the path length difference assumed above would be correct.\n\n\n\nAs constructive interference occurs when the phase difference is a multiple of, i.e. \\(m 2\\pi\\), the constructive interference will be observed when\n\\[\n\\sin(\\theta) = m \\frac{\\lambda}{d}\n\\]\n\n\n\n\n\n\nConstructive interference from two sources\n\n\n\nConstructive interference from two sources separated by a distance \\(d\\) will be observed at an angle \\(\\theta\\) when \\(\\sin(\\theta) = m \\frac{\\lambda}{d}\\), where \\(m\\) is an integer. The orders of the constructive interference are labeled as \\(m = 0, 1, 2, 3, \\ldots\\) and the \\(m=0\\) constructive interference is the central maximum. The first order constructive interference angle with scale with the wavelength as \\(\\lambda\\) and the inverse distance between the sources as \\(1/d\\), i.e. larger wavelength will lead to larger angles and larger source separation will lead to smaller angles.\nThis scaling is a common feature in many interference applications and the foundation of spectrocopy!\n\n\nIf the screen is at a distance \\(L\\) from the sources, the angle \\(\\theta\\) can be calculated as \\(\\theta = \\arctan(y/L)\\), where \\(y\\) is the distance from the center of the screen.\nInserting the phase difference into the intensity formula, we get\n\\[\nI = 2 I_1 + 2 I_2 + 2 \\sqrt{I_1 I_2} \\cos\\left(\\frac{2\\pi d}{\\lambda} \\sin(\\theta)\\right)\n\\]\nor when assuming the same intensity from the two sources\n\\[\nI= 4I_0\\cos^2\\left(\\frac{d\\pi}{\\lambda}\\sin(\\theta)\\right)\n\\]\nThe plot below shows this intensity pattern for two sources separated by a distance \\(d = 2\\) µm and a wavelength of \\(\\lambda = 0.532\\) micrometers.\n\n\nCode\n# Plot intensity pattern\nL = 16  # screen distance\ny = np.linspace(-20, 20, 1000)  # screen positions\ntheta = np.arctan(y/L)  # angles\nwavelength = 0.532  # wavelength in micrometers\nd = 2  # source separation\n\n# Calculate phase difference\ndelta_phi = (2*np.pi/wavelength) * d * np.sin(theta)\n\n# Calculate intensity (assuming I1 = I2 = 1)\nI = 2 * (1 + np.cos(delta_phi))\n\nplt.figure(figsize=get_size(10,6))\nplt.plot(y, I)\nplt.xlabel('position y on screen')\nplt.ylabel('intensity ')\nplt.grid(True, alpha=0.3)\nplt.show()\n\n\n\n\n\nIntensity pattern of two sources at a screen at a distance L. The sources are separated by a distance d and the wavelength of the waves is \\(\\lambda\\).\n\n\n\n\nThe interference from two point sources has immediate consequences for the resolution of optical instruments. The resolution of an optical instrument is the ability to distinguish between two closely spaced objects. The Abbe criterion states the the minimum resolvable distance \\(d\\) between two objects is given by\n\\[\nd = \\frac{\\lambda}{2 \\sin(\\theta)}\n\\]\nwhere \\(\\lambda\\) is the wavelength of the light and \\(\\theta\\) is the angle subtended by the two objects at the lens. The Abbe criterion is derived from the condition that the microscopy lens has to collect at least the first minimum of the interference pattern of the two objects. This first destructive interference is the information that is needed to separate the two objects from one object.\n\n\n\n\n\n\nFresnel double mirror and biprism experiment\n\n\n\n\n\nOne of the first experiments that demonstrated the wave nature of light was the Fresnel double mirror experiment. In this experiment, a light source is placed in front of two tilted mirrors. The light is reflected from this mirror to a screen. The interference pattern that is observed on the screen is due to the interference of the light that is reflected from the two mirrors. The interference pattern is similar to the one that is observed in the Young’s double slit experiment as the two mirrors “immitate” two virtual light sources behind the tilted mirror.\n\n\n\nFresnel double mirror experiment\n\n\nA similar experiment is done with the so-called Fresnel biprism. The Fresnel biprism is a prism that is cut in half and the two halves are separated by a small distance. The light that is incident on the biprism is split into two beams that are then recombined on a screen. The interference pattern that is observed on the screen is due to the interference of the two beams.\n\n\n\nFresnel double mirror experiment",
    "crumbs": [
      "Geometrical Optics",
      "Lecture 8",
      "Double Slit Interference"
    ]
  },
  {
    "objectID": "wave-optics/Interferometers.html",
    "href": "wave-optics/Interferometers.html",
    "title": "Interferometers and other Coherence Applications",
    "section": "",
    "text": "Michelson Interferometer\n\n\n\nMichelson Interferometer\n\n\n\nLIGO Interferometer Overview\nThe Laser Interferometer Gravitational-Wave Observatory (LIGO) is designed to detect gravitational waves—ripples in spacetime caused by massive accelerating objects, such as merging black holes or neutron stars. LIGO uses a Michelson interferometer configuration with two perpendicular arms, each several kilometers long. A laser beam is split into two beams that travel down these arms, reflect off mirrors at the ends, and then recombine at the beam splitter. Under normal conditions, the lengths of the arms are such that the beams interfere destructively, resulting in no light reaching the detector.\nWhen a gravitational wave passes through the interferometer, it causes a tiny but measurable change in the lengths of the arms. This change alters the interference pattern of the recombined beams, allowing the detection of the gravitational wave. The sensitivity of LIGO is such that it can detect changes in arm length smaller than a thousandth of the diameter of a proton.\nThe phase shift \\(\\Delta \\phi\\) caused by a gravitational wave can be expressed as:\n\\[\n\\Delta \\phi = \\frac{4 \\pi \\Delta L}{\\lambda}\n\\]\nwhere \\(\\Delta L\\) is the change in the length of the interferometer arms due to the gravitational wave, and \\(\\lambda\\) is the wavelength of the laser light used in the interferometer.\n\nDerivation of the Phase Shift\nTo understand the phase shift in LIGO, consider the effect of a gravitational wave passing through the interferometer. The wave causes a differential change in the lengths of the two arms, denoted as \\(\\Delta L\\). This change in length affects the travel time of the laser beams in each arm.\nThe time difference \\(\\Delta T\\) between the beams traveling in the two arms can be expressed as:\n\\[\n\\Delta T = \\frac{\\Delta L}{c}\n\\]\nThe phase shift \\(\\Delta \\phi\\) is then related to this time difference by the equation:\n\\[\n\\Delta \\phi = \\frac{2 \\pi \\Delta T}{T} = \\frac{4 \\pi \\Delta L}{\\lambda}\n\\]\nThis phase shift alters the interference pattern observed at the detector, allowing LIGO to measure the presence and properties of gravitational waves. The extraordinary precision of LIGO’s measurements enables it to detect incredibly small disturbances in spacetime, providing valuable insights into some of the most energetic events in the universe.\n\n\n\n\n\n\nLIGO Details\n\n\n\n\n\nLIGO consists of two large interferometers located in the United States: one in Hanford, Washington, and the other in Livingston, Louisiana. These facilities are operated by the LIGO Scientific Collaboration (LSC), which includes scientists from various institutions around the world.\n\nInterferometer Design\n\nMichelson Interferometer Configuration:\n\nLIGO uses a Michelson interferometer configuration with 4-kilometer-long arms.\nEach interferometer has two perpendicular arms, forming an “L” shape.\nA laser beam is split into two beams that travel down the arms, reflect off mirrors, and recombine at the beam splitter.\n\nFabry-Pérot Cavities:\n\nEach arm of the interferometer contains a Fabry-Pérot cavity to increase the effective path length of the laser beams.\nThe cavities are formed by highly reflective mirrors placed at the ends of the arms.\nThe laser beams bounce back and forth multiple times within the cavities, effectively increasing the arm length to several hundred kilometers.\n\nLaser System:\n\nLIGO uses a high-power, stabilized laser operating at a wavelength of 1064 nm (infrared).\nThe laser power is typically around 200 watts, but the effective power in the interferometer arms is increased to several kilowatts using power recycling techniques.\n\nSuspension and Isolation:\n\nThe mirrors and other optical components are suspended by a system of pendulums to isolate them from ground vibrations and other noise sources.\nThe suspension system includes multiple stages of isolation, including active and passive damping mechanisms.\n\nVacuum System:\n\nThe interferometer arms are housed in ultra-high vacuum tubes to eliminate air molecules that could scatter the laser beams and introduce noise.\nThe vacuum system maintains a pressure of around \\(10^{-9}\\) torr.\n\n\n\n\nDetection Principle\n\nGravitational Waves:\n\nGravitational waves are ripples in spacetime caused by accelerating massive objects, such as merging black holes or neutron stars.\nAs a gravitational wave passes through the interferometer, it stretches and compresses the spacetime along the arms, causing tiny changes in the arm lengths.\n\nInterference Pattern:\n\nThe changes in arm lengths cause a phase shift in the laser beams when they recombine at the beam splitter.\nThis phase shift results in a change in the interference pattern, which is detected by photodetectors.\n\nSensitivity:\n\nLIGO is designed to detect changes in arm lengths as small as \\(10^{-19}\\) meters, which is less than one-thousandth the diameter of a proton.\nThe sensitivity is achieved through advanced noise reduction techniques, including seismic isolation, thermal noise reduction, and quantum noise reduction.\n\n\n\n\nData Analysis\n\nSignal Processing:\n\nThe data from the photodetectors are processed to identify potential gravitational wave signals.\nAdvanced algorithms and computational techniques are used to filter out noise and extract the signals.\n\nEvent Detection:\n\nWhen a potential gravitational wave event is detected, the data are analyzed to determine the properties of the source, such as the masses and spins of merging black holes or neutron stars.\nThe detection is confirmed by comparing data from both LIGO detectors and, if available, data from other gravitational wave observatories like Virgo.\n\n\n\n\n\n\n\n\n\n\nMach Zehnder Interferometer\n\n\n\nMach Zehnder Interferometer\n\n\n\n\n\n\n\n\n\n\n\nMach Zehnder Interferometer with a Gaussian\n\n\n\n\n\n\n\nMach Zehnder Interferometer with a Bessel Beam\n\n\n\n\n\n\n\nSagnac Interferometer Overview\nA Sagnac interferometer operates by splitting a beam of light into two separate beams that travel in opposite directions around a closed loop. These beams are then recombined at the end of the loop, resulting in an interference pattern. If the interferometer is rotating, the path lengths of the two beams differ, leading to a phase shift.\n\n\n\nSagnac Interferometer\n\n\nThe phase shift, denoted as \\(\\Delta \\phi\\), can be calculated using the formula:\n\\[\n\\Delta \\phi = \\frac{8 \\pi A \\Omega}{\\lambda c}\n\\]\nwhere \\(A\\) represents the area enclosed by the light path, \\(\\Omega\\) is the angular velocity of the rotation, \\(\\lambda\\) is the wavelength of the light, and \\(c\\) is the speed of light.\n\nDerivation of the Phase Shift\nTo derive the phase shift, we start by considering the path length difference. Assume a loop with a perimeter \\(L\\) and an area \\(A\\). In the absence of rotation, the time taken for light to travel around the loop is given by \\(T = \\frac{L}{c}\\).\nWhen the interferometer rotates with an angular velocity \\(\\Omega\\), the effective path length changes. For the beam traveling in the direction of rotation, the path length increases, while for the beam traveling opposite to the direction of rotation, the path length decreases.\nThe time difference \\(\\Delta T\\) between the two beams can be expressed as:\n\\[\n\\Delta T = \\frac{4 A \\Omega}{c^2}\n\\]\nThe phase shift \\(\\Delta \\phi\\) is related to this time difference by the equation:\n\\[\n\\Delta \\phi = \\frac{2 \\pi \\Delta T}{T} = \\frac{8 \\pi A \\Omega}{\\lambda c}\n\\]\n:::{.callout-note collapse = true} ### Derivation Details To derive the formula for the time difference \\(\\Delta T\\) between two counter-propagating beams in a Sagnac interferometer, we start by considering a loop of perimeter \\(L\\) and area \\(A\\). The interferometer is rotating with an angular velocity \\(\\Omega\\). Light travels in opposite directions around the loop, creating two counter-propagating beams.\nIn a non-rotating frame, the time taken for light to travel around the loop is \\(T = \\frac{L}{c}\\). When the interferometer rotates with angular velocity \\(\\Omega\\), the effective path lengths for the two beams differ due to the rotation. For the beam traveling in the direction of rotation, the effective path length increases, while for the beam traveling opposite to the direction of rotation, the effective path length decreases.\nThe relative velocity of light with respect to the rotating frame is \\(c \\pm v\\), where \\(v = \\Omega R\\) is the tangential velocity at the perimeter of the loop. For small angular velocities, we can approximate the effect using the area \\(A\\) and the angular velocity \\(\\Omega\\).\nThe time taken for the beam traveling in the direction of rotation is: \\[\nT_+ = \\frac{L}{c + v}\n\\] and the time taken for the beam traveling opposite to the direction of rotation is: \\[\nT_- = \\frac{L}{c - v}\n\\]\nFor small \\(v\\), we can use the binomial expansion to approximate the times: \\[\nT_+ \\approx \\frac{L}{c} \\left(1 - \\frac{v}{c}\\right)\n\\] \\[\nT_- \\approx \\frac{L}{c} \\left(1 + \\frac{v}{c}\\right)\n\\]\nThe time difference between the two beams is: \\[\n\\Delta T = T_+ - T_- = \\frac{L}{c} \\left(1 - \\frac{v}{c}\\right) - \\frac{L}{c} \\left(1 + \\frac{v}{c}\\right)\n\\] \\[\n\\Delta T = \\frac{L}{c} \\left(- \\frac{v}{c} - \\frac{v}{c}\\right)\n\\] \\[\n\\Delta T = -\\frac{2Lv}{c^2}\n\\]\nThe tangential velocity \\(v\\) is related to the angular velocity \\(\\Omega\\) and the radius \\(R\\) of the loop: \\[\nv = \\Omega R\n\\]\nThe area \\(A\\) of the loop is related to the radius \\(R\\) and the perimeter \\(L\\): \\[\nA = \\pi R^2\n\\]\nCombining these, we get: \\[\nR = \\frac{L}{2\\pi}\n\\] \\[\nv = \\Omega \\frac{L}{2\\pi}\n\\]\nSubstituting \\(v = \\Omega \\frac{L}{2\\pi}\\) into the expression for \\(\\Delta T\\): \\[\n\\Delta T = -\\frac{2L \\left(\\Omega \\frac{L}{2\\pi}\\right)}{c^2}\n\\] \\[\n\\Delta T = -\\frac{2L^2 \\Omega}{2\\pi c^2}\n\\] \\[\n\\Delta T = -\\frac{L^2 \\Omega}{\\pi c^2}\n\\]\nUsing the relationship \\(L^2 = 4A\\), we get: \\[\nL^2 = 4A\n\\]\nSubstituting \\(L^2 = 4A\\) into the expression for \\(\\Delta T\\): \\[\n\\Delta T = -\\frac{4A \\Omega}{c^2}\n\\]\nSince the time difference \\(\\Delta T\\) is typically considered in magnitude, we take the absolute value: \\[\n\\Delta T = \\frac{4 A \\Omega}{c^2}\n\\] :::"
  },
  {
    "objectID": "wave-optics/Wave Optics.html",
    "href": "wave-optics/Wave Optics.html",
    "title": "Wave Optics",
    "section": "",
    "text": "Historical Development of Scalar Wave Optics\n\n\n\n\n\nWave optics represents a fundamental shift in our understanding of light’s nature. Here are the key developments in its history:\nAncient Times - 16th Century: Geometric Optics Dominance - Ancient civilizations understood basic reflection and refraction. - Focus was primarily on ray-based descriptions of light.\n1660s: Robert Hooke’s Wave Theory - Proposed that light might be a rapid vibrational motion. - Observed interference effects in thin films (“Newton’s Rings,” though named later).\n1690: Christiaan Huygens’ Wave Theory - Published “Traité de la Lumière” (Treatise on Light). - Introduced the concept of wavefronts. - Developed principle for wave propagation (Huygens’ Principle).\n1704: Newton’s “Opticks” - Despite observing interference effects, favored particle theory. - His authority led to wave theory being largely dismissed for nearly a century.\n1801: Thomas Young’s Double-Slit Experiment - Demonstrated interference of light definitively. - Measured wavelengths of different colors. - Introduced the concept of transverse waves.\n\n\n\nYoung’s double-slit experiment\n\n\n1818: Augustin-Jean Fresnel - Developed comprehensive mathematical theory of diffraction. - Explained polarization through transverse waves. - Created Fresnel equations for reflection and refraction.\nWave optics extends our understanding beyond the limitations of geometric optics by treating light as a wave phenomenon. This approach explains effects that cannot be accounted for by ray tracing alone, such as:\nLight is part of the electromagnetic spectrum, which spans an enormous range of frequencies. The visible region, extending approximately from 400 nm (violet) to 700 nm (red), represents only a small fraction of this spectrum. This wave description is essential for understanding many optical phenomena that geometric optics cannot explain, particularly when dealing with structures comparable in size to the wavelength of light.\nIn the following, we would like to introduce wave by discarding the fact, that light is related to electric and magnetic fields. This is useful as the vectorial nature of the electric and magnetic field further complicates the calculations, but we do not need those yet. Accordingly we also do not understand how light really interacts with matter and we therefore have to introduce some postulates as well.",
    "crumbs": [
      "Geometrical Optics",
      "Lecture 7",
      "Wave Optics"
    ]
  },
  {
    "objectID": "wave-optics/Wave Optics.html#postulates-of-wave-optics",
    "href": "wave-optics/Wave Optics.html#postulates-of-wave-optics",
    "title": "Wave Optics",
    "section": "Postulates of Wave Optics",
    "text": "Postulates of Wave Optics\n\n\n\n\n\n\nWave\n\n\n\nA wave corresponds to a physical quantity which oscillates in space and time. Its energy current density is related to the square magnitude of the amplitude.\n\n\n\nWave equation\n\\[\n\\nabla^2 u - \\frac{1}{c^2}\\frac{\\partial^2 u}{\\partial t^2}=0\n\\]\nwhere the Laplace operator \\(\\nabla^2\\) is defined as:\n\\[\n\\nabla^2 =\\frac{\\partial^2}{\\partial x^2}+\\frac{\\partial^2}{\\partial y^2}+\\frac{\\partial^2}{\\partial z^2}\n\\]\nThe wave equation is a linear differential equation, which implies that the superposition principle holds. Specifically, if \\(u_1(\\mathbf{r},t)\\) and \\(u_2(\\mathbf{r},t)\\) are solutions of the wave equation, then any linear combination:\n\\[\nu(\\mathbf{r},t)=a_1u_1(\\mathbf{r},t)+a_2u_2(\\mathbf{r},t)\n\\]\nis also a solution, where \\(a_1\\) and \\(a_2\\) are arbitrary constants.\n\n\nMonochromatic Wave\nA monochromatic wave consists of a single frequency \\(\\omega\\). By definition, such a wave must be infinite in time and free from phase disturbances (such as sudden jumps). The mathematical expression for a monochromatic wave is:\n\\[u(\\mathbf{r},t)=a(\\mathbf{r})\\cos(\\omega t + \\phi(\\mathbf{r}))\\]\nwhere:\n\n\\(a(\\mathbf{r})\\) represents the amplitude\n\\(\\phi(\\mathbf{r})\\) represents the spatial phase\n\\(\\omega\\) represents the angular frequency\n\n\n\n\n\n\n\nFigure 2— Representation of a wavefunction over time (constant position) denoting the phase \\(\\phi\\) and the period \\(T=1/\\nu\\)\n\n\n\n\nComplex Amplitude\nThe wave can be represented in complex form as:\n\\[\nU(\\mathbf{r},t)=a(\\mathbf{r})e^{i\\phi(\\mathbf{r})}e^{i\\omega t}\n\\]\nThis is known as the complex wavefunction.\n\n\n\n\n\n\nFigure 3— Phasor diagram of the complex amplitude \\(U(\\mathbf{r})\\) (left) and \\(U(t)\\) (right)\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nA phasor displays the complex amplitude with magnitude and phase as a vector in the complex plane.\n\n\nThe relationship between the complex and real wavefunctions is:\n\\[\nu(\\mathbf{r},t)=\\text{Re}\\{U(\\mathbf{r},t)\\}=\\frac{1}{2}[U(\\mathbf{r},t)+U^*(\\mathbf{r},t)]\n\\]\nThe complex wavefunction satisfies the same wave equation:\n\\[\n\\nabla^2 U - \\frac{1}{c^2}\\frac{\\partial^2 U}{\\partial t^2}=0\n\\]\nWe can separate the complex wavefunction into spatial and temporal components:\n\\[\nU(\\mathbf{r},t)=U(\\mathbf{r})e^{i\\omega t}\n\\]\nwhere\n\\[\nU(\\mathbf{r})=a(\\mathbf{r})e^{i\\phi(\\mathbf{r})}\n\\]\nHere, \\(\\phi\\) represents the spatial phase of the wavefunction. Substituting this into the wave equation and noting that the time derivatives bring down factors of \\(i\\omega\\):\n\\[\\nabla^2 [U(\\mathbf{r})e^{i\\omega t}] - \\frac{1}{c^2}\\frac{\\partial^2}{\\partial t^2}[U(\\mathbf{r})e^{i\\omega t}] = 0\\] \\[\\nabla^2 U(\\mathbf{r})e^{i\\omega t} + \\frac{\\omega^2}{c^2}U(\\mathbf{r})e^{i\\omega t} = 0\\]\nThe time dependence \\(e^{i\\omega t}\\) factors out, leaving us with the Helmholtz equation:\n\\[\\nabla^2 U(\\mathbf{r}) + k^2U(\\mathbf{r}) = 0\\]\nwhere \\(k = \\omega/c\\) is the wave number. This equation describes the spatial behavior of monochromatic waves.\n\n\nIntensity of Waves\nThe intensity of a wave at position \\(\\mathbf{r}\\) and time \\(t\\) is defined as:\n\\[\nI(\\mathbf{r},t)=2\\langle u^2(\\mathbf{r},t)\\rangle\n\\]\nwhere \\(I\\) is measured in units of \\(\\left[\\frac{W}{m^2}\\right]\\). The angle brackets \\(\\langle \\ldots \\rangle\\) represent a time average over one oscillation cycle of \\(u\\). For visible light, this averaging occurs over an extremely brief period - for example, light with a wavelength of 600 nm has a cycle duration of just 2 femtoseconds.\nThe optical power \\(P\\) of a wave can be calculated by integrating the intensity over a surface area \\(A\\):\n\\[\nP=\\int_A I(\\mathbf{r},t) \\, dA\n\\]\nInserting the seperation of the complex wavefunction into spatial and temporal components leads to the following expression for the intensity:\n\\[\nI(\\mathbf{r})=|U(\\mathbf{r})|^2\n\\]\nThus the physical quantity forming the spatial and temporal oscillation of the wavefunction is also providing the intensity of the wave when its magnitude is squared. This is a fundamental property of wavefunctions and for example not the case when temperature oscillates in space and time in a medium.\n\n\nWavefronts\nWavefronts are surfaces in space where the phase is constant:\n\\[\n\\phi(\\mathbf{r})=\\text{const}\n\\]\nTypically, this constant is chosen to represent points of maximum spatial amplitude, such that:\n\\[\n\\phi(\\mathbf{r})=2\\pi q\n\\]\nwhere \\(q\\) is an integer.\nThe direction normal to these wavefronts can be described by the gradient vector:\n\\[\n\\mathbf{n}=\\nabla\\phi=\\left(\\frac{\\partial \\phi}{\\partial x},\\frac{\\partial \\phi}{\\partial y},\\frac{\\partial \\phi}{\\partial z}\\right)\n\\]\nThis vector \\(\\mathbf{n}\\) is always perpendicular to the wavefront surface and points in the direction of wave propagation. The evolution of these wavefronts in time provides important information about the wave’s propagation characteristics.",
    "crumbs": [
      "Geometrical Optics",
      "Lecture 7",
      "Wave Optics"
    ]
  },
  {
    "objectID": "wave-optics/Wave Optics.html#plane-waves",
    "href": "wave-optics/Wave Optics.html#plane-waves",
    "title": "Wave Optics",
    "section": "Plane Waves",
    "text": "Plane Waves\nA plane wave represents a fundamental solution of the homogeneous wave equation. In its complex form, it is expressed as:\n\\[\\begin{equation}\nU(\\mathbf{r},t)=Ae^{-i\\mathbf{k}\\cdot \\mathbf{r}}e^{i\\omega t}\n\\end{equation}\\]\nwhere:\n\nThe first exponential term contains the spatial phase\nThe second exponential term contains the temporal phase\n\\(A\\) is the (potentially complex) amplitude of the plane wave\n\nThe wavefront of a plane wave is defined by:\n\\[\\mathbf{k}\\cdot \\mathbf{r}=2\\pi q + \\text{arg}(A)\\]\nwhere \\(1\\) is an integer. It just means that the projection of the position vector \\(\\mathbf{r}\\) onto the wavevector \\(\\mathbf{k}\\) is a multiple of \\(2\\pi\\). This equation describes a plane perpendicular to the wavevector \\(\\mathbf{k}\\). Adjacent wavefronts are separated by the wavelength \\(\\lambda=2\\pi/k\\), where \\(k\\) represents the spatial frequency of the wave oscillation.\nThe spatial component of the plane wave is given by:\n\\[\\begin{equation}\nU(\\mathbf{r})=Ae^{-i\\mathbf{k}\\cdot \\mathbf{r}}\n\\end{equation}\\]\nIn vacuum, the wavevector \\(\\mathbf{k}=\\mathbf{k}_0\\) is real-valued and can be written as:\n\\[\\begin{equation}\n\\mathbf{k}_0=\n\\begin{pmatrix}\nk_{0x} \\\\\nk_{0y}\\\\\nk_{0z}\\\\\n\\end{pmatrix}\n\\end{equation}\\]\n\n\nCode\ndef plane_wave(k,omega,r,t):\n    return(np.exp(1j*(np.dot(k,r)-omega*t)))\n\nwavelength=532e-9\nk0=2*np.pi/wavelength\nc=299792458\nomega0=k0*c\n\nvec=np.array([0.0,0.,1.])\nvec=vec/np.sqrt(np.dot(vec,vec))\n\nk=k0*vec\n\nx=np.linspace(-2.5e-6,2.5e-6,300)\nz=np.linspace(0,5e-6,300)\n\nX,Z=np.meshgrid(x,z)\nr=np.array([X,0,Z],dtype=object)\n\nplt.figure(figsize=get_size(6,6))\n\nfield=plane_wave(k,omega0,r,0)\n\nextent = np.min(z)*1e6, np.max(z)*1e6,np.min(x)*1e6, np.max(x)*1e6\nplt.imshow(np.real(field.transpose()),extent=extent,vmin=-1,vmax=1,cmap='seismic')\nplt.xlabel('z-position [µm]')\nplt.ylabel('x-position [µm]')\n\nplt.show()\n\n\n\n\n\nPlane wave",
    "crumbs": [
      "Geometrical Optics",
      "Lecture 7",
      "Wave Optics"
    ]
  },
  {
    "objectID": "wave-optics/Wave Optics.html#dispersion-relation",
    "href": "wave-optics/Wave Optics.html#dispersion-relation",
    "title": "Wave Optics",
    "section": "Dispersion Relation",
    "text": "Dispersion Relation\nUsing the plane wave solution\n\\[\\begin{equation}\nU(\\mathbf{r},t)=Ae^{-i\\mathbf{k}\\cdot \\mathbf{r}}e^{i\\omega t}\n\\end{equation}\\]\nwe can write down the sum of the spatial and temporal phase as\n\\[\n\\phi(r,t)=\\omega t-\\mathbf{k}\\cdot \\mathbf{r}\n\\]\nIf we select a point on the wavefront \\(\\mathbf{r}_{m}\\), and follow that over time, the phase \\(\\phi(t)=\\text{const}\\). Taking the time derivative results in\n\\[\n\\mathbf{k}\\cdot \\frac{d\\mathbf{r}_{m}}{dt}=\\omega\n\\]\nIf we choose the direction of the wavevector for measuring the propagation speed, i.e. \\(\\mathbf{r}_{m}=r_{m}\\mathbf{e}_k\\) then we find for the propagation speed\n\\[\n\\frac{dr_{m}}{dt}=\\frac{\\omega}{k}\n\\]\nor in vacuum\n\\[\\begin{equation}\nc_0=\\frac{\\omega}{k_0}\n\\end{equation}\\]\nThis fundamental relationship connects:\n\nThe momentum (\\(k\\)),\nThe energy (\\(\\omega\\))\n\nand is called a dispersion relation despite the fact, that we do not really understand why those quantities are related to energy and momentum.\n\n\n\n\n\n\nNote\n\n\n\nLight in free space exhibits a linear dispersion relation, i.e. the frequency of light changes linearly with the wavevector magnitude.\n\n\nNote that if we choose a different propagation direction \\(\\mathbf{e}\\) than the one along the wavevector \\(\\mathbf{e}_k\\), we can write the phase velocity as\n\\[\n\\mathbf{k}\\cdot\\mathbf{e} \\frac{dr}{dt}=k\\cos(\\measuredangle\\mathbf{k},\\mathbf{e}) \\frac{dr}{dt}=\\omega\n\\]\nor\n\\[\n\\frac{dr}{dt}=\\frac{\\omega}{k\\cos(\\measuredangle\\mathbf{k},\\mathbf{e})}\n\\]\nwhich means that if you observe the wavepropagation not in the direction of the wavevector, the phase velocity is actually bigger than the speed of light and even tends to infinity if the angle between the wavevector and the observation direction tends to 90°.",
    "crumbs": [
      "Geometrical Optics",
      "Lecture 7",
      "Wave Optics"
    ]
  },
  {
    "objectID": "wave-optics/Wave Optics.html#propagation-in-a-medium",
    "href": "wave-optics/Wave Optics.html#propagation-in-a-medium",
    "title": "Wave Optics",
    "section": "Propagation in a Medium",
    "text": "Propagation in a Medium\nWhen a wave propagates through a medium:\n\nThe frequency \\(\\omega\\) remains constant (determined by the source)\nThe wave speed changes according to: \\[\nc=\\frac{c_0}{n}\n\\] where \\(n\\) is the refractive index of the medium\n\nThis leads to changes in:\n\nthe wavelength, which becomes shorter in the medium \\[\n\\lambda=\\frac{\\lambda_0}{n}\n\\]\nthe length of the wavevector, which increases in the medium \\[\nk=nk_0\n\\]",
    "crumbs": [
      "Geometrical Optics",
      "Lecture 7",
      "Wave Optics"
    ]
  },
  {
    "objectID": "wave-optics/Wave Optics.html#snells-law",
    "href": "wave-optics/Wave Optics.html#snells-law",
    "title": "Wave Optics",
    "section": "Snells Law",
    "text": "Snells Law\nThe change in the length of the wavevector has some simple consequence for Snells law. We can write Snells law as\n\\[\nn_1k_0\\sin(\\theta_1)=n_2k_0\\sin(\\theta_2)\n\\]\nwhere \\(k_0\\) is the wavevector length in vacuum. As the \\(n_1k_0\\) is the magnitude of the wavevector in medium 1, and \\(n_2k_0\\) is the magnitude of the wavevector in medium 2, we can rewrite Snells law as\n\\[\nk_1\\sin(\\theta_1)=k_2\\sin(\\theta_2)\n\\]\nwhich means that the component of the wavevector parallel to the interface is conserved. If the wavevector has constant length then the wavevector incident at different angles is between a point on a circle and the origin in the diagram below. The circle corresponds to an isofrequency surface.\n\nCode\ntheta_upper = np.linspace(0, np.pi, 100)  # Upper half circle\ntheta_lower = np.linspace(np.pi, 2*np.pi, 100)  # Lower half circle\n\n# Radii for the circles\nr1 = 1.51  # Radius for upper half circle\nr2 = 1.01  # Radius for lower half circle\n\nx_upper = r1 * np.cos(theta_upper)\ny_upper = r1 * np.sin(theta_upper)\n\nx_lower = r2 * np.cos(theta_lower)\ny_lower = r2 * np.sin(theta_lower)\n\n# Create the plot\nplt.figure(figsize=get_size(4, 3))\nplt.plot(x_upper, y_upper, 'b-', label=f'Upper radius = {r1}')\nplt.plot(x_lower, y_lower, 'r-', label=f'Lower radius = {r2}')\n\n# Add arrow\n# Calculate arrow start point (on the upper circle at 135 degrees)\narrow_start_x = r1 * np.cos(3*np.pi/4.2)  # 135 degrees in radians\narrow_start_y = r1 * np.sin(3*np.pi/4.2)\n# Add arrow to origin (0,0)\nplt.arrow(arrow_start_x, arrow_start_y, -arrow_start_x, -arrow_start_y,\n          head_width=0.1, head_length=0.2, fc='b', ec='b',\n          length_includes_head=True, label='45° arrow')\n\ndy=np.sqrt(r2**2-arrow_start_x**2)\nplt.arrow(0, 0, -arrow_start_x, -dy,\n          head_width=0.1, head_length=0.2, fc='r', ec='r',\n          length_includes_head=True, label='45° arrow')\n\nplt.axhline(y=0, color='k', linestyle='-', alpha=0.3)\nplt.axvline(x=0, color='k', linestyle='-', alpha=0.3)\nplt.axvline(x=-arrow_start_x, color='k', linestyle='--',lw=0.5)\nplt.axvline(x=arrow_start_x, color='k', linestyle='--', lw=0.5)\n\nplt.axis('square')\n\nplt.grid(True, alpha=0.3)\nplt.xlabel(r'$k_x/k_0$')\nplt.ylabel(r'$k_y/k_0$')\nplt.xlim(-2,2 )\nplt.ylim(-2,2 )\n\n# Show the plot\nplt.show()\n\n\n\n\n\n\n\n\nSnells law construction using the conservation of the wavevector component parallel to the interface. The vertical dashed lines indicate the parallal component of the wavevector in the two media.\n\n\n\n\n\n\n\n\nElectron microscopy image of a 2D photonic crystal\n\n\n\n\n\n\n\nIsofrequency surfaces of a photonic crystal\n\n\n\n\n\nIsofrequency surfaces can have non-spherical shape. In anisotropic media, they can be ellipsoids. In photonic crystals, i.e. crystals with a periodic structure on the scale of the wavelength, they can have a more complex shape.",
    "crumbs": [
      "Geometrical Optics",
      "Lecture 7",
      "Wave Optics"
    ]
  },
  {
    "objectID": "wave-optics/Wave Optics.html#spherical-waves",
    "href": "wave-optics/Wave Optics.html#spherical-waves",
    "title": "Wave Optics",
    "section": "Spherical Waves",
    "text": "Spherical Waves\nA spherical wave, like a plane wave, consists of spatial and temporal components, but with wavefronts forming spherical surfaces. For spherical waves, \\(|\\mathbf{k}||\\mathbf{r}|=kr=\\text{const}\\). Given a source at position \\(\\mathbf{r}_0\\), the spherical wave can be expressed as:\n\\[\\begin{equation}\nU=\\frac{A}{|\\mathbf{r}-\\mathbf{r}_0|}e^{-ik|\\mathbf{r}-\\mathbf{r}_0|} e^{i\\omega t}\n\\end{equation}\\]\n\n\n\n\n\n\nImportant\n\n\n\nThe \\(1/|\\mathbf{r}-\\mathbf{r}_0|\\) factor in the amplitude is necessary for energy conservation - ensuring that the total energy flux through any spherical surface centered on the source remains constant.\n\n\n\n\nCode\ndef spherical_wave(k,omega,r,r0,t):\n    k=np.linalg.norm(k)\n    d=np.linalg.norm(r-r0)\n    return( np.exp(1j*(k*d-omega*t))/d)\n\nplt.figure(figsize=get_size(5,5))\n\nx=np.linspace(-5e-6,5e-6,300)\nz=np.linspace(-5e-6,5e-6,300)\n\nX,Z=np.meshgrid(x,z)\nr=np.array([X,0,Z],dtype=object)\n\nwavelength=532e-9\nk0=2*np.pi/wavelength\nc=299792458\nomega0=k0*c\n\nk=k0*np.array([0,0,1.])\nr0=np.array([0,0,0])\n\nfield=spherical_wave(k,omega0,r,r0,0)\n\nextent = np.min(z)*1e6, np.max(z)*1e6,np.min(x)*1e6, np.max(x)*1e6\nplt.imshow(np.real(field.transpose()),extent=extent,vmin=-5e6,vmax=5e6,cmap='seismic')\n\nplt.xlabel('z [µm]')\nplt.ylabel('x [µm]')\nplt.show()\n\n\n\n\n\nSpherical wave propagation. The wave is emitted from the origin and propagates in the positive z-direction. The wavefronts are spherical surfaces. The wave is visualized in the xz-plane.\n\n\n\n\n\n\n\n\n\n\nFigure 5— Spherical wave amplitude and intensity of the spherical wave as a function of distance from the source\n\n\n\nThe plots demonstrate that:\n\nThe field amplitude decays rapidly with distance\nThe intensity follows a \\(1/r^2\\) law (with slight deviations at small distances due to discretization artifacts)\n\nNote: The direction of wave propagation can be reversed by changing the sign of the wavenumber \\(k\\).",
    "crumbs": [
      "Geometrical Optics",
      "Lecture 7",
      "Wave Optics"
    ]
  },
  {
    "objectID": "wave-optics/FabryPerot.html",
    "href": "wave-optics/FabryPerot.html",
    "title": "Fabry Perot Interferometer",
    "section": "",
    "text": "The Fabry-Perot interferometer demonstrates multiple-wave interference with decreasing amplitude. It consists of two parallel mirrors separated by a distance \\(d\\), creating multiple reflections of incident light.\n\n\n\nSimplified Sketch of a Fabry-Perot Interferometer.\n\n\nWhen light with amplitude \\(A_0\\) enters the interferometer, it undergoes a series of transmissions and reflections. The first transmitted wave has amplitude:\n\\[\nU_1=A_0t_1 t_2\n\\]\nwhere \\(t_1\\) and \\(t_2\\) are the transmission coefficients of the first and second mirrors. The second transmitted wave includes reflections from both mirrors (\\(r_1\\) and \\(r_2\\)) and a phase shift \\(\\Delta\\phi\\):\n\\[\nU_2=A_0t_1 t_2 r_1 r_2 e^{i\\phi}=U_1 r_1 r_2 e^{i\\Delta\\phi}\n\\]\nThis follows our earlier treatment of multiple-wave interference with decreasing amplitude, where \\(\\sqrt{I_0}=A_0 t_1 t_2\\) and \\(r=r_1r_2\\). The phase shift between successive reflections is:\n\\[\n\\phi=\\frac{2\\pi}{\\lambda} \\Delta s = \\frac{2\\pi}{\\lambda} 2d\\cos(\\theta)\n\\]\nwhere \\(\\Delta s=2d\\cos(\\theta)\\) represents the path difference between adjacent rays.\nThe resulting intensity distribution is:\n\\[\nI=|U|^2=\\frac{I_{0}}{|1-re^{i\\phi}|^2}=\\frac{I_0}{(1-r)^2+4r\\sin^2\\left (\\frac{2\\pi}{\\lambda} d\\cos(\\theta)\\right)}\n\\]\n\n\n\nFabry Perot Interferometer.\n\n\n\nFinesse and Spectral Properties\nThe quality of interference in a Fabry-Perot interferometer is characterized by the Finesse \\(\\mathcal{F}\\):\n\\[\n\\mathcal{F}=\\frac{\\pi \\sqrt{r}}{1-r}\n\\]\nwhere \\(r=r_1r_2\\) is the product of the mirrors’ reflection coefficients. As \\(r\\) approaches 1 (higher reflectivity), the Finesse increases, resulting in sharper interference peaks.\nFor normal incidence (\\(\\theta=0\\)), the phase difference simplifies to:\n\\[\n\\Delta\\phi=\\frac{4\\pi d}{\\lambda}\n\\]\nConstructive interference occurs when \\(\\Delta\\phi=m2\\pi\\) (where \\(m\\) is an integer), giving us the wavelengths of transmission maxima:\n\\[\n\\lambda_m=\\frac{2d}{m}\n\\]\n\nFree Spectral Range\nThe spacing between adjacent transmission peaks in an optical system can be expressed in terms of either wavelength or frequency. This spacing is known as the free spectral range (FSR).\nIn Wavelength:\nThe difference in wavelength between adjacent transmission peaks is given by:\n\\[\n   \\delta \\lambda = \\lambda_{m} - \\lambda_{m+1} = \\frac{\\lambda_m}{m+1}\n   \\]\nHere, \\(\\lambda_m\\) is the wavelength corresponding to the \\(m\\)-th transmission peak.\nIn Frequency:\nThe difference in frequency between adjacent transmission peaks is given by:\n\\[\n   \\delta \\nu = \\nu_{m+1} - \\nu_m = \\frac{c}{2d}\n   \\]\nHere, \\(c\\) is the speed of light, and \\(d\\) is the distance between the reflecting surfaces in the optical system.\nThe free spectral range (FSR) represents the interval between successive transmission peaks and is a crucial parameter in the design and analysis of optical systems, such as Fabry-Pérot interferometers and optical resonators.\n\n\nSpectral Resolution\nThe spectral resolution of an interferometer is determined by the width of its interference peaks, which indicates the instrument’s ability to distinguish between closely spaced wavelengths. This width is often characterized by the full width at half maximum (FWHM) of the peaks.\nTo find the FWHM, we start with the intensity ratio at half maximum:\n\\[\n\\frac{I}{I_{\\rm max}} = \\frac{1}{2} = \\frac{1}{1 + \\left( \\frac{\\mathcal{F}}{\\pi} \\right)^2 \\Delta \\phi_{1/2}^2 }\n\\]\nSolving for the phase difference \\(\\Delta \\phi_{1/2}\\) at half maximum, we can determine the corresponding frequency width:\n\\[\n\\Delta \\nu = \\frac{c}{2d \\mathcal{F}} = \\frac{\\delta \\nu}{\\mathcal{F}}\n\\]\nHere, \\(\\delta \\nu\\) is the free spectral range, \\(c\\) is the speed of light, \\(d\\) is the distance between the reflecting surfaces, and \\(\\mathcal{F}\\) is the finesse of the interferometer.\nThe finesse \\(\\mathcal{F}\\) is defined as the ratio of the free spectral range to the FWHM:\n\\[\n\\mathcal{F} = \\frac{\\delta \\nu}{\\Delta \\nu} = \\frac{\\lambda}{\\Delta \\lambda}\n\\]\nThis ratio provides a measure of the interferometer’s spectral resolution, indicating how well it can separate two closely spaced spectral lines.\nThe overall resolving power \\(\\mathcal{R}\\) of the interferometer is given by:\n\\[\n\\mathcal{R} = m \\mathcal{F}\n\\]\nwhere \\(m\\) is the order of the interference. The resolving power \\(\\mathcal{R}\\) quantifies the ability of the interferometer to resolve spectral features, with higher values indicating better resolution.\n\n\n\nTwo different wavelengths interfering constructively in a Fabry Perot interferometer.\n\n\n\n\n\n\n\n\nFree Spectral Range and Spectral Resolution\n\n\n\n\n\nFree Spectral Range (FSR):\nThe free spectral range is the spacing between adjacent transmission maxima in a Fabry-Perot interferometer. It can be expressed in terms of wavelength or frequency:\n\nIn wavelength: \\[\n\\delta \\lambda = \\lambda_{m} - \\lambda_{m+1} = \\frac{\\lambda_m}{m+1}\n\\]\nIn frequency: \\[\n\\delta \\nu = \\nu_{m+1} - \\nu_m = \\frac{c}{2d}\n\\]\n\nThe FSR indicates the range over which the interferometer can distinguish between different wavelengths or frequencies before the next order of interference occurs.\nSpectral Resolution:\nThe spectral resolution of a Fabry-Perot interferometer is determined by the width of the interference peaks. It is often quantified by the Finesse (\\(\\mathcal{F}\\)), which is the ratio of the free spectral range to the full width at half maximum (FWHM) of the peaks:\n\\[\n\\mathcal{F} = \\frac{\\delta \\nu}{\\Delta \\nu} = \\frac{\\lambda}{\\Delta \\lambda}\n\\]\nThe resolving power (\\(\\mathcal{R}\\)) of the interferometer is given by:\n\\[\n\\mathcal{R} = m \\mathcal{F}\n\\]\nwhere \\(m\\) is the interference order. The resolving power indicates the ability of the interferometer to distinguish between closely spaced spectral lines.\n\n\n\n\n\n\nRing Pattern Formation\nWhen a Fabry-Perot interferometer is used with an extended monochromatic light source and appropriate optics, it produces a characteristic ring pattern:\n\n\n\nFabry Perot Interferometer and interference pattern observed in the lecture.\n\n\nThe rings represent contours of constant phase difference, becoming more closely spaced with increasing radius as demonstrated in these experimental observations:\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 1— Fabry Perot Interferometer and interference pattern observed in the lecture.\n\n\n\nThis ring pattern is a powerful tool for spectroscopic analysis, as different wavelengths produce distinct ring patterns, allowing precise wavelength measurements and spectral analysis.\n\n\n\n\n\n\nApplications in Modern Research and Technology\n\n\n\n\n\nSpectroscopy:\n\nHigh-Resolution Spectroscopy: Fabry-Perot interferometers are used to achieve high spectral resolution, allowing precise measurements of spectral lines. This is crucial in fields like astrophysics, where detailed analysis of stellar spectra can reveal information about the composition, temperature, and motion of celestial objects.\n\n\n\n\nSodium D Lines measured as 593.0 +/- 4.5 nm, 591.1 +/- 5.0 nm with a difference of 0.604 +/- 0.025 (matching the accepted values of 589.5924 nm, 588.9951 with a difference of 0.5973 nm). Also courtesy of Lake Forest College\n\n\n\nLaser Spectroscopy: They are used to analyze the spectral properties of lasers, including linewidth, mode structure, and stability.\n\nOptical Communications:\n\nWavelength Division Multiplexing (WDM): Fabry-Perot filters are used in WDM systems to separate and combine different wavelength channels, increasing the data-carrying capacity of optical fibers.\nLaser Stabilization: They help stabilize the wavelength of lasers used in optical communication systems, ensuring consistent performance and reducing signal degradation.\n\nMetrology:\n\nPrecision Measurement: Fabry-Perot interferometers are used for precise distance and displacement measurements. They can measure changes in length with sub-nanometer accuracy, making them valuable in applications like semiconductor manufacturing and materials science.\nRefractive Index Measurement: They are used to measure the refractive index of gases, liquids, and solids with high precision.\n\nLaser Technology:\n\nMode-Locking: Fabry-Perot cavities are used in mode-locked lasers to produce ultra-short pulses of light, which are essential for applications in time-resolved spectroscopy, medical imaging, and telecommunications.\nLaser Tuning: They are used to tune the wavelength of lasers, enabling precise control over the output wavelength for various applications.\n\nEnvironmental Monitoring:\n\nGas Analysis: Fabry-Perot interferometers are used in gas analyzers to detect and quantify trace gases in the atmosphere. This is important for monitoring air quality, greenhouse gas emissions, and industrial processes.\nRemote Sensing: They are used in remote sensing instruments to analyze the spectral properties of reflected or emitted light from the Earth’s surface and atmosphere, providing valuable data for climate studies and environmental monitoring.\n\nAstronomy:\n\nInterferometric Imaging: Fabry-Perot interferometers are used in telescopes to enhance the resolution of astronomical images. They can be used to study fine details of celestial objects, such as the structure of galaxies and the dynamics of star-forming regions.\nDoppler Spectroscopy: They are used to measure the Doppler shift of spectral lines, allowing astronomers to determine the radial velocity of stars and planets, which is crucial for the detection of exoplanets.\n\nBiomedical Applications:\n\nOptical Coherence Tomography (OCT): Fabry-Perot interferometers are used in OCT systems to achieve high-resolution cross-sectional imaging of biological tissues. This is valuable for medical diagnostics, particularly in ophthalmology and dermatology. \nFluorescence Microscopy: They are used to enhance the spectral resolution of fluorescence microscopes, enabling detailed analysis of biological samples.\n\nQuantum Optics:\n\nCavity Quantum Electrodynamics (CQED): Fabry-Perot cavities are used to study the interaction between light and matter at the quantum level. This research is fundamental for the development of quantum information technologies and quantum computing.\nSingle-Photon Sources: They are used to create and manipulate single-photon sources, which are essential for quantum communication and cryptography.\n\nThese applications highlight the versatility and importance of Fabry-Perot interferometers in advancing scientific research and technological innovation across various fields."
  },
  {
    "objectID": "wave-optics/Diffraction2.html",
    "href": "wave-optics/Diffraction2.html",
    "title": "Diffraction in Applications",
    "section": "",
    "text": "The human eye provides an excellent real-world example of circular aperture diffraction through the pupil (the opening in the iris). By examining how light diffracts as it enters the eye, we can understand fundamental limits on visual resolution and how the eye is naturally optimized to these constraints.\nCalculating the Diffraction Limit of the Eye\nWhen light passes through the circular aperture of the pupil, it undergoes diffraction, producing an Airy disk pattern on the retina. The angle to the first minimum (dark ring) of the diffraction pattern is given by:\n\\[\n\\sin(\\theta_1) = 0.61\\, \\frac{\\lambda}{R}\n\\]\nwhere: - \\(\\theta_1\\) is the angle to the first minimum, - \\(\\lambda\\) is the wavelength of the light, - \\(R\\) is the radius of the aperture (pupil).\nFor an average pupil radius of \\(R = 2.5\\, \\text{mm}\\) and green light with a wavelength of \\(\\lambda = 532\\, \\text{nm}\\) (to which the human eye is most sensitive), we have:\n\\[\n\\sin(\\theta_1) = 0.61 \\times \\frac{532 \\times 10^{-9}\\, \\text{m}}{2.5 \\times 10^{-3}\\, \\text{m}} = 0.61 \\times 2.128 \\times 10^{-4} \\approx 1.298 \\times 10^{-4}\n\\]\nThus, the angle to the first minimum is approximately:\n\\[\n\\theta_1 \\approx \\sin^{-1}(1.298 \\times 10^{-4}) \\approx 0.00744^\\circ\n\\]\nDetermining the Size of the Airy Disk on the Retina\nThe distance from the pupil to the retina (the image plane) is approximately \\(L = 20\\, \\text{mm}\\) (or \\(2\\, \\text{cm}\\)). The linear radius \\(r\\) of the Airy disk on the retina is calculated by:\n\\[\nr = L \\sin(\\theta_1) = 20\\, \\text{mm} \\times 1.298 \\times 10^{-4} = 2.596 \\times 10^{-3}\\, \\text{mm} = 2.596\\, \\mu\\text{m}\n\\]\nSo, the diameter \\(D\\) of the Airy disk (central bright spot) is:\n\\[\nD = 2r = 2 \\times 2.596\\, \\mu\\text{m} = 5.192\\, \\mu\\text{m}\n\\]\nThis means that the smallest spot of light that can be formed on the retina due to diffraction is about \\(5.19\\, \\mu\\text{m}\\) in diameter.\nComparing with Photoreceptor Spacing in the Fovea\nThe fovea is a small region in the retina responsible for sharp central vision. It contains a high density of cone photoreceptor cells. The average density of cones in the fovea is approximately \\(150,000\\) cells per square millimeter. To find the average spacing \\(d\\) between these cells, we proceed as follows:\nArea per Cell:\n\\[\n   \\text{Area per cell} = \\frac{1\\, \\text{mm}^2}{150,000} = 6.667 \\times 10^{-6}\\, \\text{mm}^2 = 6.667\\, \\mu\\text{m}^2\n   \\]\nLinear Spacing Between Cells:\nAssuming a square packing (for simplicity), the linear spacing \\(d\\) is:\n\\[\n   d = \\sqrt{\\text{Area per cell}} = \\sqrt{6.667\\, \\mu\\text{m}^2} \\approx 2.58\\, \\mu\\text{m}\n   \\]\nIn reality, the photoreceptors are more closely packed in a hexagonal arrangement, but this calculation gives a good approximation.\n\n\n\n\n\n\nAnalysis of the Results\n\n\n\n\n\nThe analysis reveals that the diameter of the Airy disk is approximately \\(5.192\\, \\mu\\text{m}\\), while the center-to-center spacing of photoreceptors in the human eye is about \\(2.58\\, \\mu\\text{m}\\). This observation is significant because the diameter of the Airy disk is roughly twice the photoreceptor spacing, indicating that the central maximum of the diffraction pattern spans about two photoreceptors.\nThe close correspondence between the diffraction limit of the eye and the spacing of photoreceptor cells is noteworthy for several reasons. Firstly, the diffraction limit establishes the fundamental constraint on the resolving power of the eye, determining the smallest angular separation between two points of light that can be distinguished. Secondly, the density of photoreceptors is sufficiently high to sample the details provided by the optical system up to this diffraction limit.\nIncreasing the density of photoreceptors within the area of the Airy disk would not enhance visual resolution due to two primary factors. The first factor is the physical limitation imposed by the diffraction limit, which is a fundamental constraint arising from the wave nature of light and the size of the pupil. Consequently, resolution cannot be improved beyond this limit merely by increasing photoreceptor density. The second factor is related to signal intensity. Adding more photoreceptors in the same area would result in each cell receiving less light, given that the total light intensity is fixed. This reduction in light per photoreceptor could potentially decrease the signal-to-noise ratio, making it more challenging to detect light.\n\n\nThe design of the human eye exemplifies a natural optimization process. The density of photoreceptors is matched to the optical resolving power of the eye, ensuring that the visual system extracts the maximum amount of information without unnecessary redundancy. This efficient use of resources reflects an evolutionary adaptation, where biological systems have evolved to align anatomical structures with physical laws, optimizing functions such as vision to confer survival advantages. Over time, this alignment has resulted in a visual system that is finely tuned to the constraints and capabilities imposed by the physics of light and the anatomy of the eye.\n\nLand, M. F., & Nilsson, D.-E. (2012). Animal Eyes (2nd ed.). Oxford University Press.\nWilliams, D. R. (1988). Topography of the foveal cone mosaic in the living human eye. Vision Research, 28(3), 433–454.",
    "crumbs": [
      "Geometrical Optics",
      "Lecture 11",
      "Diffraction"
    ]
  },
  {
    "objectID": "wave-optics/Diffraction2.html#application-diffraction-in-the-human-eye",
    "href": "wave-optics/Diffraction2.html#application-diffraction-in-the-human-eye",
    "title": "Diffraction in Applications",
    "section": "",
    "text": "The human eye provides an excellent real-world example of circular aperture diffraction through the pupil (the opening in the iris). By examining how light diffracts as it enters the eye, we can understand fundamental limits on visual resolution and how the eye is naturally optimized to these constraints.\nCalculating the Diffraction Limit of the Eye\nWhen light passes through the circular aperture of the pupil, it undergoes diffraction, producing an Airy disk pattern on the retina. The angle to the first minimum (dark ring) of the diffraction pattern is given by:\n\\[\n\\sin(\\theta_1) = 0.61\\, \\frac{\\lambda}{R}\n\\]\nwhere: - \\(\\theta_1\\) is the angle to the first minimum, - \\(\\lambda\\) is the wavelength of the light, - \\(R\\) is the radius of the aperture (pupil).\nFor an average pupil radius of \\(R = 2.5\\, \\text{mm}\\) and green light with a wavelength of \\(\\lambda = 532\\, \\text{nm}\\) (to which the human eye is most sensitive), we have:\n\\[\n\\sin(\\theta_1) = 0.61 \\times \\frac{532 \\times 10^{-9}\\, \\text{m}}{2.5 \\times 10^{-3}\\, \\text{m}} = 0.61 \\times 2.128 \\times 10^{-4} \\approx 1.298 \\times 10^{-4}\n\\]\nThus, the angle to the first minimum is approximately:\n\\[\n\\theta_1 \\approx \\sin^{-1}(1.298 \\times 10^{-4}) \\approx 0.00744^\\circ\n\\]\nDetermining the Size of the Airy Disk on the Retina\nThe distance from the pupil to the retina (the image plane) is approximately \\(L = 20\\, \\text{mm}\\) (or \\(2\\, \\text{cm}\\)). The linear radius \\(r\\) of the Airy disk on the retina is calculated by:\n\\[\nr = L \\sin(\\theta_1) = 20\\, \\text{mm} \\times 1.298 \\times 10^{-4} = 2.596 \\times 10^{-3}\\, \\text{mm} = 2.596\\, \\mu\\text{m}\n\\]\nSo, the diameter \\(D\\) of the Airy disk (central bright spot) is:\n\\[\nD = 2r = 2 \\times 2.596\\, \\mu\\text{m} = 5.192\\, \\mu\\text{m}\n\\]\nThis means that the smallest spot of light that can be formed on the retina due to diffraction is about \\(5.19\\, \\mu\\text{m}\\) in diameter.\nComparing with Photoreceptor Spacing in the Fovea\nThe fovea is a small region in the retina responsible for sharp central vision. It contains a high density of cone photoreceptor cells. The average density of cones in the fovea is approximately \\(150,000\\) cells per square millimeter. To find the average spacing \\(d\\) between these cells, we proceed as follows:\nArea per Cell:\n\\[\n   \\text{Area per cell} = \\frac{1\\, \\text{mm}^2}{150,000} = 6.667 \\times 10^{-6}\\, \\text{mm}^2 = 6.667\\, \\mu\\text{m}^2\n   \\]\nLinear Spacing Between Cells:\nAssuming a square packing (for simplicity), the linear spacing \\(d\\) is:\n\\[\n   d = \\sqrt{\\text{Area per cell}} = \\sqrt{6.667\\, \\mu\\text{m}^2} \\approx 2.58\\, \\mu\\text{m}\n   \\]\nIn reality, the photoreceptors are more closely packed in a hexagonal arrangement, but this calculation gives a good approximation.\n\n\n\n\n\n\nAnalysis of the Results\n\n\n\n\n\nThe analysis reveals that the diameter of the Airy disk is approximately \\(5.192\\, \\mu\\text{m}\\), while the center-to-center spacing of photoreceptors in the human eye is about \\(2.58\\, \\mu\\text{m}\\). This observation is significant because the diameter of the Airy disk is roughly twice the photoreceptor spacing, indicating that the central maximum of the diffraction pattern spans about two photoreceptors.\nThe close correspondence between the diffraction limit of the eye and the spacing of photoreceptor cells is noteworthy for several reasons. Firstly, the diffraction limit establishes the fundamental constraint on the resolving power of the eye, determining the smallest angular separation between two points of light that can be distinguished. Secondly, the density of photoreceptors is sufficiently high to sample the details provided by the optical system up to this diffraction limit.\nIncreasing the density of photoreceptors within the area of the Airy disk would not enhance visual resolution due to two primary factors. The first factor is the physical limitation imposed by the diffraction limit, which is a fundamental constraint arising from the wave nature of light and the size of the pupil. Consequently, resolution cannot be improved beyond this limit merely by increasing photoreceptor density. The second factor is related to signal intensity. Adding more photoreceptors in the same area would result in each cell receiving less light, given that the total light intensity is fixed. This reduction in light per photoreceptor could potentially decrease the signal-to-noise ratio, making it more challenging to detect light.\n\n\nThe design of the human eye exemplifies a natural optimization process. The density of photoreceptors is matched to the optical resolving power of the eye, ensuring that the visual system extracts the maximum amount of information without unnecessary redundancy. This efficient use of resources reflects an evolutionary adaptation, where biological systems have evolved to align anatomical structures with physical laws, optimizing functions such as vision to confer survival advantages. Over time, this alignment has resulted in a visual system that is finely tuned to the constraints and capabilities imposed by the physics of light and the anatomy of the eye.\n\nLand, M. F., & Nilsson, D.-E. (2012). Animal Eyes (2nd ed.). Oxford University Press.\nWilliams, D. R. (1988). Topography of the foveal cone mosaic in the living human eye. Vision Research, 28(3), 433–454.",
    "crumbs": [
      "Geometrical Optics",
      "Lecture 11",
      "Diffraction"
    ]
  },
  {
    "objectID": "wave-optics/Diffraction2.html#application-resolution-of-an-optical-microscope",
    "href": "wave-optics/Diffraction2.html#application-resolution-of-an-optical-microscope",
    "title": "Diffraction in Applications",
    "section": "Application: Resolution of an Optical Microscope",
    "text": "Application: Resolution of an Optical Microscope\nThe resolution of an optical microscope is fundamentally limited by the diffraction of light as it passes through the optical components, particularly the objective lens. Diffraction causes point sources of light to produce blurred images rather than perfect points, affecting the microscope’s ability to distinguish between two closely spaced objects.\n\nRayleigh’s Criterion for Resolution\nKey Question: How close can two point sources be while still being perceived as distinct entities by an optical system?\nTo answer this, we need to consider two essential aspects of how a lens modifies light:\n\nWavefront Transformation: A lens alters the curvature of incoming wavefronts, focusing parallel rays (plane waves) to a point in the focal plane.\nFinite Aperture Effects: The lens has a finite size and acts as a circular aperture, introducing diffraction effects that spread the image of a point source into a diffraction pattern known as the Airy disk.\n\nVisual Representation:\n\n\n\nIllustration showing two point sources and their overlapping diffraction patterns as they approach each other.\n\n\nEach point source produces its own diffraction pattern. As the sources move closer, their patterns begin to overlap, making it harder to distinguish between them.\nRayleigh’s Resolution Criterion:\n\nTwo point sources are considered just resolvable when the principal maximum (center) of one Airy pattern coincides with the first minimum (dark ring) of the other.\n\n\n\n\nGraph depicting Rayleigh’s criterion, showing the intensity profiles of two overlapping Airy patterns.\n\n\nFor incoherent light sources (where the light waves are not in phase), this criterion corresponds to a 26% dip in intensity between the two peaks, which is generally sufficient for the human eye or detectors to distinguish the two sources as separate.\nAngle to the First Minimum:\nThe angle \\(\\theta_1\\) to the first minimum of the diffraction pattern from a circular aperture of radius \\(R\\) is given by:\n\\[\n   \\sin(\\theta_1) = 1.22\\, \\frac{\\lambda}{2R}\n   \\]\nSince the diameter of the aperture \\(D = 2R\\), this can also be written as:\n\\[\n   \\sin(\\theta_1) = 1.22\\, \\frac{\\lambda}{D}\n   \\]\nThe factor 1.22 arises from the first zero of the Bessel function \\(J_1\\) that describes the diffraction pattern of a circular aperture.\nSmall Angle Approximation:\nFor small angles (common in optical systems), \\(\\sin(\\theta_1) \\approx \\theta_1\\) in radians.\nRelating Angular to Linear Separation in the Image Plane:\nThe angular resolution \\(\\theta_1\\) corresponds to a linear separation \\(\\Delta x\\) in the image plane (at image distance \\(b\\)):\n\\[\n   \\theta_1 = \\frac{\\Delta x}{b}\n   \\]\nCombining the Equations:\nSubstituting \\(\\theta_1\\):\n\\[\n   \\frac{\\Delta x}{b} = 1.22\\, \\frac{\\lambda}{D}\n   \\]\nSolving for \\(\\Delta x\\):\n\\[\n   \\Delta x = 1.22\\, \\frac{\\lambda b}{D}\n   \\]\nConsidering the Object Plane:\nThe magnification \\(M\\) of the optical system is:\n\\[\n   M = \\frac{b}{g}\n   \\]\nwhere \\(g\\) is the object distance. The corresponding separation in the object plane (\\(\\Delta d\\)) is:\n\\[\n   \\Delta d = \\frac{\\Delta x}{M} = \\frac{\\Delta x \\, g}{b}\n   \\]\nSubstituting \\(\\Delta x\\):\n\\[\n   \\Delta d = 1.22\\, \\frac{\\lambda b}{D} \\times \\frac{g}{b} = 1.22\\, \\frac{\\lambda g}{D}\n   \\]\nIntroducing Numerical Aperture (NA):\nThe numerical aperture (NA) of the lens is defined as:\n\\[\n   \\text{NA} = n \\sin(\\alpha)\n   \\]\nwhere:\n\n\\(n\\) is the refractive index of the medium between the object and the lens.\n\\(\\alpha\\) is the half-angle of the maximum cone of light that can enter or exit the lens.\n\nSince \\(\\sin(\\alpha) = \\frac{R}{g}\\), we have:\n\\[\n   D = 2R = 2 g \\sin(\\alpha)\n   \\]\nSubstituting \\(D\\) into \\(\\Delta d\\):\n\\[\n   \\Delta d = 1.22\\, \\frac{\\lambda g}{2 g \\sin(\\alpha)} = \\frac{1.22\\, \\lambda}{2 \\sin(\\alpha)} = \\frac{0.61\\, \\lambda}{\\sin(\\alpha)}\n   \\]\nTherefore, incorporating the refractive index \\(n\\):\n\\[\n   \\Delta d = \\frac{0.61\\, \\lambda}{n \\sin(\\alpha)} = \\frac{0.61\\, \\lambda}{\\text{NA}}\n   \\]\nUnder Rayleigh’s resolution criterion, several key factors influence the resolving power of an optical system.\nFirstly, a higher numerical aperture (NA) improves resolution. This increase can be achieved by enhancing either the refractive index \\(n\\) of the medium between the object and the lens or the sine of the collection angle \\(\\sin(\\alpha)\\). Since the NA is defined as \\(\\text{NA} = n \\sin(\\alpha)\\), a larger NA allows the lens to gather more diffracted light, thereby resolving finer details in the image. In air, where the refractive index is approximately \\(n \\approx 1\\), the maximum achievable NA is less than 1, which limits the resolution. This limitation arises because the maximum value of \\(\\sin(\\alpha)\\) is 1 (when \\(\\alpha = 90^\\circ\\)), so the NA in air cannot exceed 1. In practical systems, the collection angle \\(\\alpha\\) is much less than \\(90^\\circ\\), further reducing the NA and thus the resolution. Immersion lenses, which use a medium with a higher refractive index (such as water or oil), can achieve higher NAs, overcoming this limitation and improving resolution.\nSecondly, using shorter wavelengths \\((\\lambda)\\) of light leads to better resolution. According to the formula \\(\\Delta d = \\frac{0.61\\, \\lambda}{\\text{NA}}\\), the minimum resolvable distance \\(\\Delta d\\) is directly proportional to the wavelength. Therefore, decreasing the wavelength reduces \\(\\Delta d\\), allowing the optical system to distinguish smaller features of the object.\n\n\n\n\n\n\nNote\n\n\n\n\n\nRayleigh’s Resolution Criterion\nTwo incoherent point sources can be resolved when their minimum separation \\(\\Delta d\\) satisfies:\n\\[\n\\Delta d \\geq \\frac{0.61\\, \\lambda}{\\text{NA}}\n\\]\nWhere:\n\n\\(\\Delta d\\) is the minimum resolvable distance between the two point sources.\n\\(\\lambda\\) is the wavelength of the light used for imaging.\n\\(\\text{NA} = n \\sin(\\alpha)\\) is the numerical aperture of the optical system.\n\n\\(n\\) is the refractive index of the medium.\n\\(\\alpha\\) is the half-angle of the maximum cone of light entering the lens.\n\n\n\n\n\n\n\nAbbe’s Criterion for Resolution\nLimitations of Rayleigh’s Criterion:\n\nRayleigh’s criterion applies to incoherent light sources, where the intensities of the diffraction patterns add directly.\nIt does not fully account for the effects of coherence and interference in the imaging process.\n\nErnst Abbe developed a theory that considers the imaging of coherent light sources, where the phases of the waves are correlated. It emphasizes the importance of diffracted orders and spatial frequencies in the formation of images.\nThe key concepts in Abbe’s theory are\nDiffraction Grating Analogy:\n\nAn object with fine details can be thought of as a diffraction grating that scatters light into multiple diffraction orders.\nThe ability to resolve these fine details depends on the optical system’s capacity to capture these diffracted orders.\n\nSpatial Frequencies:\n\nThe finer the details in the object, the higher the spatial frequency.\nHigh spatial frequencies correspond to larger angles in the diffraction pattern.\n\nOptical Transfer Function:\n\nDescribes how different spatial frequencies are transmitted through the optical system.\nAn optical system with a larger NA can transmit higher spatial frequencies, improving resolution.\n\nFollowing that analogy, Abbe’s criterion states that the minimum resolvable distance \\(\\Delta d\\) between two points in the object plane is given by:\n\\[\n\\Delta d = \\frac{\\lambda}{2 \\text{NA}}\n\\]\n\n\n\n\n\n\nRayleigh’s and Abbe’s criteria\n\n\n\n\nAbbe’s Limit:\n\n\\(\\Delta d = \\frac{\\lambda}{2 \\text{NA}}\\)\nEmphasizes coherent imaging and the transmission of at least two diffracted orders (zeroth and first) for resolution.\n\nRayleigh’s Limit:\n\n\\(\\Delta d = \\frac{0.61\\, \\lambda}{\\text{NA}}\\)\nBased on the visibility of intensity dips in the overlapping Airy patterns of incoherent sources.\n\n\nImplications in Microscopy:\nCoherent Illumination:\n\nTechniques like phase-contrast or interference microscopy rely on coherent light.\nAbbe’s criterion is more appropriate for these methods.\n\nIncoherent Illumination:\n\nCommon in conventional bright-field microscopy.\nRayleigh’s criterion provides a practical resolution limit.\n\nImportance of Abbe’s Criterion:\n\nHighlights the role of interference between diffracted waves in image formation.\nDemonstrates that resolution is fundamentally limited by the wavelength of light and the NA of the system.\nSuggests that capturing higher spatial frequencies (larger NA) leads to better resolution.",
    "crumbs": [
      "Geometrical Optics",
      "Lecture 11",
      "Diffraction"
    ]
  },
  {
    "objectID": "wave-optics/Diffraction2.html#using-huygens-sources-for-more",
    "href": "wave-optics/Diffraction2.html#using-huygens-sources-for-more",
    "title": "Diffraction in Applications",
    "section": "Using Huygens Sources for more",
    "text": "Using Huygens Sources for more\nThe Huygens principle is a powerful tool to calculate the diffraction pattern of an aperture. The idea is to consider the aperture as a collection of point sources, which emit spherical waves. The superposition of all these waves will then give the total wave field. Below is a Python code which demonstrates the calculation of the diffraction pattern of a spherical mirror. It uses Huygens sources placed on an arc (see left). The right image shows the resulting diffraction pattern in the focal plane of the mirror.\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef spherical_wave(k, omega, r, r0, t):\n    k_norm = np.linalg.norm(k)\n    d = np.linalg.norm(r - r0[:, np.newaxis, np.newaxis], axis=0)\n    return np.exp(1j * (k_norm * d - omega * t)) / d\n\n# Parameters\nwavelength = 532e-9  # Wavelength in meters (green light)\nk0 = 2 * np.pi / wavelength  # Wave number\nc = 299792458  # Speed of light in m/s\nomega0 = k0 * c  # Angular frequency\nt = 0  # Time\n\nx = np.linspace(-15e-6, 15e-6, 900)  # x-axis from -5 µm to 5 µm\nz = np.linspace(-15e-6, 15e-6, 900)  # z-axis from -5 µm to 5 µm\nX, Z = np.meshgrid(x, z)\nr = np.array([X, np.zeros_like(X), Z])  # Observation points in 3D space (y=0)\n\nnum_sources = 100  # Number of point sources along the arc\narc_angle = np.deg2rad(100)  # Total arc angle in radians (60 degrees)\ntheta_sources = np.linspace(-arc_angle / 2, arc_angle / 2, num_sources)  # Source angles\nradius = 10e-6  # Radius of the arc (10 µm)\n\ntotal_field = np.zeros_like(X, dtype=complex)\n\nfor theta in theta_sources:\n    # Calculate source position (x0, z0) on the arc\n    x0 = radius * np.cos(theta)\n    z0 = radius * np.sin(theta)\n    r0 = np.array([x0, 0, z0])  # Source position in 3D space\n    field = spherical_wave(k0, omega0, r, r0, t)\n    total_field += field\n\nintensity = np.abs(total_field)**2\n\nintensity/=intensity[450,450]\nfig,ax=plt.subplots(1,2,figsize=get_size(18, 10))\n\nextent = [np.min(z)*1e6, np.max(z)*1e6, np.min(x)*1e6, np.max(x)*1e6]\nax[1].imshow(intensity.transpose(), extent=extent, origin='lower', cmap='gray_r',vmax=1)\nax[1].set_xlabel('z [µm]')\nax[1].set_ylabel('x [µm]')\nax[1].set_xlim(-5, 5)\nax[1].set_ylim(-5, 5)\n\nextent = [np.min(z)*1e6, np.max(z)*1e6, np.min(x)*1e6, np.max(x)*1e6]\nax[0].imshow(intensity.transpose(), extent=extent, origin='lower', cmap='gray_r',vmax=1)\nax[0].set_xlabel('z [µm]')\nax[0].set_ylabel('x [µm]')\nax[0].set_xlim(-15, 15)\nax[0].set_ylim(-15, 15)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nThe pattern changes with increasing angle of the arc, which is consistent with our knowledge of the numerical aperature defining the resolution of and optical system. The changes are especially visible along the vertical axis.\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef spherical_wave(k, omega, r, r0, t):\n    k_norm = np.linalg.norm(k)\n    d = np.linalg.norm(r - r0[:, np.newaxis, np.newaxis], axis=0)\n    return np.exp(1j * (k_norm * d - omega * t)) / d\n\n# Parameters\nwavelength = 532e-9  # Wavelength in meters (green light)\nk0 = 2 * np.pi / wavelength  # Wave number\nc = 299792458  # Speed of light in m/s\nomega0 = k0 * c  # Angular frequency\nt = 0  # Time\n\nx = np.linspace(-15e-6, 15e-6, 900)  # x-axis from -5 µm to 5 µm\nz = np.linspace(-15e-6, 15e-6, 900)  # z-axis from -5 µm to 5 µm\nX, Z = np.meshgrid(x, z)\nr = np.array([X, np.zeros_like(X), Z])  # Observation points in 3D space (y=0)\n\nnum_sources = 100  # Number of point sources along the arc\narc_angle = np.deg2rad(150)  # Total arc angle in radians (60 degrees)\ntheta_sources = np.linspace(-arc_angle / 2, arc_angle / 2, num_sources)  # Source angles\nradius = 10e-6  # Radius of the arc (10 µm)\n\ntotal_field = np.zeros_like(X, dtype=complex)\n\nfor theta in theta_sources:\n    # Calculate source position (x0, z0) on the arc\n    x0 = radius * np.cos(theta)\n    z0 = radius * np.sin(theta)\n    r0 = np.array([x0, 0, z0])  # Source position in 3D space\n    field = spherical_wave(k0, omega0, r, r0, t)\n    total_field += field\n\nintensity = np.abs(total_field)**2\n\nintensity/=intensity[450,450]\nfig,ax=plt.subplots(1,2,figsize=get_size(18, 10))\n\nextent = [np.min(z)*1e6, np.max(z)*1e6, np.min(x)*1e6, np.max(x)*1e6]\nax[1].imshow(intensity.transpose(), extent=extent, origin='lower', cmap='gray_r',vmax=1)\nax[1].set_xlabel('z [µm]')\nax[1].set_ylabel('x [µm]')\nax[1].set_xlim(-5, 5)\nax[1].set_ylim(-5, 5)\n\nextent = [np.min(z)*1e6, np.max(z)*1e6, np.min(x)*1e6, np.max(x)*1e6]\nax[0].imshow(intensity.transpose(), extent=extent, origin='lower', cmap='gray_r',vmax=1)\nax[0].set_xlabel('z [µm]')\nax[0].set_ylabel('x [µm]')\nax[0].set_xlim(-15, 15)\nax[0].set_ylim(-15, 15)\nplt.tight_layout()\nplt.show()",
    "crumbs": [
      "Geometrical Optics",
      "Lecture 11",
      "Diffraction"
    ]
  },
  {
    "objectID": "wave-optics/Fourier.html",
    "href": "wave-optics/Fourier.html",
    "title": "Experimental Physics 3 Course on Optics and Quantum Mechanics",
    "section": "",
    "text": "Fourier Transform and Diffraction\n\n\n\n\n\nIn the context of wave optics, the diffraction pattern observed in the far field (Fraunhofer diffraction) can be understood as the Fourier transform of the aperture function. For a single slit, the aperture function is a rectangular function.\n\nAperture Function of a Slit\nConsider a single slit of width \\(b\\) centered at \\(x = 0\\). The aperture function \\(A(x)\\) can be described as:\n\\[\nA(x) = \\begin{cases}\n1 & \\text{if } -\\frac{b}{2} \\leq x \\leq \\frac{b}{2} \\\\\n0 & \\text{otherwise}\n\\end{cases}\n\\]\nThis is a rectangular function, often denoted as \\(\\text{rect}\\left(\\frac{x}{b}\\right)\\).\n\n\nFourier Transform of the Aperture Function\nThe Fourier transform of the aperture function \\(A(x)\\) gives us the amplitude distribution in the far field. The Fourier transform \\(\\mathcal{F}\\{A(x)\\}\\) is defined as:\n\\[\n\\mathcal{F}\\{A(x)\\} = \\int_{-\\infty}^{\\infty} A(x) e^{-i 2 \\pi f x} \\, dx\n\\]\nFor the rectangular function \\(A(x) = \\text{rect}\\left(\\frac{x}{b}\\right)\\), the Fourier transform is:\n\\[\n\\mathcal{F}\\left\\{\\text{rect}\\left(\\frac{x}{b}\\right)\\right\\} = \\int_{-\\frac{b}{2}}^{\\frac{b}{2}} e^{-i 2 \\pi f x} \\, dx\n\\]\n\n\nEvaluating the Integral\nLet’s evaluate the integral:\n\\[\n\\mathcal{F}\\left\\{\\text{rect}\\left(\\frac{x}{b}\\right)\\right\\} = \\int_{-\\frac{b}{2}}^{\\frac{b}{2}} e^{-i 2 \\pi f x} \\, dx\n\\]\nThis integral can be solved as follows:\n\\[\n\\mathcal{F}\\left\\{\\text{rect}\\left(\\frac{x}{b}\\right)\\right\\} = \\left[ \\frac{e^{-i 2 \\pi f x}}{-i 2 \\pi f} \\right]_{-\\frac{b}{2}}^{\\frac{b}{2}}\n\\]\nSubstituting the limits:\n\\[\n\\mathcal{F}\\left\\{\\text{rect}\\left(\\frac{x}{b}\\right)\\right\\} = \\frac{1}{-i 2 \\pi f} \\left( e^{-i 2 \\pi f \\frac{b}{2}} - e^{i 2 \\pi f \\frac{b}{2}} \\right)\n\\]\nUsing Euler’s formula \\(e^{i \\theta} - e^{-i \\theta} = 2i \\sin(\\theta)\\):\n\\[\n\\mathcal{F}\\left\\{\\text{rect}\\left(\\frac{x}{b}\\right)\\right\\} = \\frac{1}{-i 2 \\pi f} \\cdot (-2i \\sin(\\pi f b))\n\\]\nSimplifying:\n\\[\n\\mathcal{F}\\left\\{\\text{rect}\\left(\\frac{x}{b}\\right)\\right\\} = \\frac{2 \\sin(\\pi f b)}{2 \\pi f} = \\frac{\\sin(\\pi f b)}{\\pi f}\n\\]\n\n\nSinc Function\nThe result can be expressed in terms of the sinc function. The sinc function is defined as:\n\\[\n\\text{sinc}(x) = \\frac{\\sin(\\pi x)}{\\pi x}\n\\]\nTherefore, the Fourier transform of the rectangular aperture function is:\n\\[\n\\mathcal{F}\\left\\{\\text{rect}\\left(\\frac{x}{b}\\right)\\right\\} = b \\cdot \\text{sinc}(b f)\n\\]"
  },
  {
    "objectID": "wave-optics/Diffraction Integral Dummy.html",
    "href": "wave-optics/Diffraction Integral Dummy.html",
    "title": "Diffraction Integral",
    "section": "",
    "text": "In the last section about Fresnel zones and the zone plate, we considered how different paths contribute to the intensity at a point on the optical axis. We would like to generalize this idea to an integral formulation that allows us to calculate any kind of diffraction pattern.\nAssume we have a light source \\(S\\) as shown in the image above, which emits a spherical wave (though it does not necessarily have to be a spherical wave). The spatial amplitude of this wave at the point \\(P(x,y)\\) at a tiny aperture element \\(d\\sigma\\) is given by:\n\\[\nU_s(x,y) = U_0(x,y)e^{i\\phi(x,y)}\n\\]\nwhere\n\\[\nU_0 = \\frac{A}{R} = \\frac{A}{\\sqrt{g^2 + x^2 + y^2}}\n\\]\nand\n\\[\n\\phi(x,y) = -kR\n\\]\nThis represents the amplitude of the Huygens wave, which emanates from the point \\(P(x,y)\\) and propagates towards the screen at \\(P(x',y')\\). This Huygens wave contributes a fraction of an amplitude \\(dU_p\\) to the total amplitude at point \\(P(x',y')\\), which is given by:\n\\[\ndU_p = C \\frac{U_s d\\sigma}{r} e^{-ikr}\n\\]\nwith \\(C = \\frac{i \\cos(\\theta)}{\\lambda}\\), known as the obliquity factor, found through a more detailed calculation.\nThe total amplitude at the point \\(P(x',y')\\) is then given by the integral over all contributions:\n\\[\nU_p = \\iint C U_s \\frac{e^{-ikr}}{r} dx dy\n\\]\nwhere \\(dx dy = d\\sigma\\). The integral runs over all positions in the aperture plane \\((x,y)\\) where there is an opening. This integral is called the Fresnel-Kirchhoff diffraction integral and allows us to calculate complex scalar diffraction patterns.\nThis formulation generalizes the concept of Fresnel zones and provides a powerful tool for analyzing and predicting diffraction patterns for various aperture shapes and configurations."
  },
  {
    "objectID": "wave-optics/Diffraction Integral Dummy.html#fresnel-approximation",
    "href": "wave-optics/Diffraction Integral Dummy.html#fresnel-approximation",
    "title": "Diffraction Integral",
    "section": "Fresnel Approximation",
    "text": "Fresnel Approximation\nThe diffraction integral does not always need to be calculated in full; we can use approximations to obtain diffraction patterns in different regimes. One such approximation is the Fresnel approximation, which yields the diffraction pattern in the near field.\nThe distance \\(r\\) from the point \\(P(x,y)\\) to the point \\(P(x',y')\\) can be written as:\n\\[\nr = \\sqrt{z_0^2 + (x - x')^2 + (y - y')^2}\n\\]\nUsing a binomial expansion for small angles, we can approximate this as:\n\\[\nr \\approx z_0 \\left(1 + \\frac{(x - x')^2}{2z_0^2} + \\frac{(y - y')^2}{2z_0^2} + \\ldots \\right)\n\\]\nIn this approximation, we assume that \\(\\cos(\\theta) = z_0 / r \\approx 1\\) and \\(C = i / \\lambda\\), considering small diffraction angles. Using this approximation, we find the amplitude of the wave at a point \\(P(x',y')\\):\n\\[\nU(x', y', z_0) = i \\frac{e^{-ikz_0}}{\\lambda z_0} \\iint U_s(x, y) \\exp \\left[ -\\frac{ik}{2z_0} \\left( (x - x')^2 + (y - y')^2 \\right) \\right] dx dy\n\\]\nAs the integration is over \\(x\\) and \\(y\\), we can factor out all screen coordinate elements, yielding:\n\\[\nU(x', y', z_0) = i \\frac{e^{-ikz_0}}{\\lambda z_0} e^{-\\frac{ik}{2z_0}(x'^2 + y'^2)} \\iint U_s(x, y) e^{-\\frac{ik}{2z_0}(x^2 + y^2)} e^{\\frac{ik}{2z_0}(xx' + yy')} dx dy\n\\]\nThis is the Fresnel approximation. It simplifies the calculation of the diffraction pattern in the near field by making reasonable assumptions about the geometry and angles involved."
  },
  {
    "objectID": "wave-optics/Diffraction Integral Dummy.html#fraunhofer-approximation",
    "href": "wave-optics/Diffraction Integral Dummy.html#fraunhofer-approximation",
    "title": "Diffraction Integral",
    "section": "Fraunhofer Approximation",
    "text": "Fraunhofer Approximation\nIf we further assume that the aperture is small as compared to the distance at which we observe the diffraction pattern, we can further simplify the Fresnel approximation to yield the Fraunhofer approximation giving the diffraction patter in the far field. The condition is\n\\[\nz_0\\gg\\frac{1}{\\lambda}(x^2+y^2)\n\\]\nIn this case we can neglect the term\n\\[\ne^{ -\\frac{ik}{2z_0}(x^2+y^2)} \\approx 1\n\\]\nwhich results in\n\\[\nU(x^{\\prime},y^{\\prime},z_0)=i\\frac{e^{-ikz_0}}{\\lambda z_0} e^{-\\frac{ik}{2z_0}(x^{\\prime 2}+y^{\\prime 2})}\n\\iint U_{s}(x,y)\ne^{\\frac{ik}{2z_0}(xx^{\\prime}+yy^{\\prime})} dx dy\n\\]\n\n\n\nDiffraction pattern of a slit in the near field (Fresnel diffraction, left) and the far field (Fraunhofer diffraction, right).\n\n\nWhile these formulas provide the mathematical tools, we may obtain a more intuitive idea about the different approximation in the following way. Consider the image below, where we would like to know about the diffraction intensity of a slit of width \\(b\\) at the optical axis at a distance \\(D\\).\n\n\n\nIllustration of the importance of additional geometrical path length difference for the discrimination of Fresnel (near-field) and Fraunhofer (far-field) diffraction.\n\n\nThe waves from the center of the slit and the edge have to travel towards that point a different pathlength, whcih we may calculate to\n\\[\\begin{eqnarray}\n\\Delta s &=&  \\sqrt{\\frac{b^2}{4}+D^2}-D\\\\\n&=& D\\sqrt{\\frac{b^2}{4D^2}+1}-D\n\\end{eqnarray}\\]\nWe may develop the square root into a Taylor series and obtain\n\\[\\begin{eqnarray}\n\\Delta s &=& \\frac{b^2}{8D}-\\frac{b^4}{128 D^3}+O(4)\\\\\n&\\approx & \\frac{b^2}{8D}\n\\end{eqnarray}\\]\nThe second order correction term \\(\\frac{b^2}{8D}\\) decreases quadratic with the distance \\(D\\) of the point, which means that at large distances, we can safely assume \\(\\Delta s=0\\) on the axis, i.e. all waves arriving at that point have to travel the same distance. This corresponds to the far-field approximation. To be more specific we require\n\\[\n\\frac{b^2}{8D^2}&lt;\\frac{\\lambda}{8}\n\\]\nor\n\\[\n\\frac{b^2}{\\lambda D}&lt;1\n\\]\nto be fullfilled to be in the far field.\n\\[\nF=\\frac{b^2}{\\lambda D}\n\\begin{cases}\n\\ll 1 ,&\\textrm{Fraunhofer}\\\\\n\\approx 1,& \\textrm{Fresnel}\\\\\n\\gg 1, & \\textrm{Full vector}\n\\end{cases}\n\\]\nThis number \\(F\\) is called the Frensel number and gives us an idea by how far the dimensions of the opening contribute to the diffraction pattern rather than the direction of the wave propagation only."
  },
  {
    "objectID": "wave-optics/Diffraction Integral Dummy.html#babinets-principle",
    "href": "wave-optics/Diffraction Integral Dummy.html#babinets-principle",
    "title": "Diffraction Integral",
    "section": "Babinet’s Principle",
    "text": "Babinet’s Principle\nThe above considerations of diffraction have some intruiging consequence. Consider the two apertures in the image below.\n\n\n\nTwo complementary apertures, which have the same diffraction pattern in the far field.\n\n\nThe left aperture will create in the far field an amplitude distribution \\(U_h\\), while the inverse aperture on the right will cause an amplitude \\(U_d\\). If we combine both amplitudes in the far field, we obtain a total amplitude distribution\n\\[\nU=U_h+U_d\n\\]\nIn the case when we have two complementary apertures, that total amplitude has to be zeor, when hole and dot are placed at the same position. We therefore obtain\n\\[\nU_h=-U_d\n\\]\nand therefore\n\\[\nI_h=I_d\n\\]\nThis is the Principle of Babinet which states:\n\n\n\n\n\n\nBabinet’s Principle\n\n\n\nBabinet’s principle states that the far-field diffraction intensity distribution of complementary apertures is identical. This means that an opaque object and its complementary aperture (where the object is replaced by a transparent region and vice versa) produce the same diffraction pattern in the far field.\n\n\nThe images below show an experimental demonstration of Babinet’s principle on a slit and a wire.\n\n\n\nBabinet’s principle demonstrated experimentally on a slit (left) and a wire (right)."
  },
  {
    "objectID": "wave-optics/LIGO.html",
    "href": "wave-optics/LIGO.html",
    "title": "LIGO",
    "section": "",
    "text": "The Laser Interferometer Gravitational-Wave Observatory (LIGO) is designed to detect gravitational waves—ripples in spacetime caused by massive accelerating objects, such as merging black holes or neutron stars. LIGO uses a Michelson interferometer configuration with two perpendicular arms, each several kilometers long. A laser beam is split into two beams that travel down these arms, reflect off mirrors at the ends, and then recombine at the beam splitter. Under normal conditions, the lengths of the arms are such that the beams interfere destructively, resulting in no light reaching the detector.\nWhen a gravitational wave passes through the interferometer, it causes a tiny but measurable change in the lengths of the arms. This change alters the interference pattern of the recombined beams, allowing the detection of the gravitational wave. The sensitivity of LIGO is such that it can detect changes in arm length smaller than a thousandth of the diameter of a proton.\nThe phase shift \\(\\Delta \\phi\\) caused by a gravitational wave can be expressed as:\n\\[\n\\Delta \\phi = \\frac{4 \\pi \\Delta L}{\\lambda}\n\\]\nwhere \\(\\Delta L\\) is the change in the length of the interferometer arms due to the gravitational wave, and \\(\\lambda\\) is the wavelength of the laser light used in the interferometer.\n\n\nTo understand the phase shift in LIGO, consider the effect of a gravitational wave passing through the interferometer. The wave causes a differential change in the lengths of the two arms, denoted as \\(\\Delta L\\). This change in length affects the travel time of the laser beams in each arm.\nThe time difference \\(\\Delta T\\) between the beams traveling in the two arms can be expressed as:\n\\[\n\\Delta T = \\frac{\\Delta L}{c}\n\\]\nThe phase shift \\(\\Delta \\phi\\) is then related to this time difference by the equation:\n\\[\n\\Delta \\phi = \\frac{2 \\pi \\Delta T}{T} = \\frac{4 \\pi \\Delta L}{\\lambda}\n\\]\nThis phase shift alters the interference pattern observed at the detector, allowing LIGO to measure the presence and properties of gravitational waves. The extraordinary precision of LIGO’s measurements enables it to detect incredibly small disturbances in spacetime, providing valuable insights into some of the most energetic events in the universe."
  },
  {
    "objectID": "wave-optics/LIGO.html#ligo-interferometer-overview",
    "href": "wave-optics/LIGO.html#ligo-interferometer-overview",
    "title": "LIGO",
    "section": "",
    "text": "The Laser Interferometer Gravitational-Wave Observatory (LIGO) is designed to detect gravitational waves—ripples in spacetime caused by massive accelerating objects, such as merging black holes or neutron stars. LIGO uses a Michelson interferometer configuration with two perpendicular arms, each several kilometers long. A laser beam is split into two beams that travel down these arms, reflect off mirrors at the ends, and then recombine at the beam splitter. Under normal conditions, the lengths of the arms are such that the beams interfere destructively, resulting in no light reaching the detector.\nWhen a gravitational wave passes through the interferometer, it causes a tiny but measurable change in the lengths of the arms. This change alters the interference pattern of the recombined beams, allowing the detection of the gravitational wave. The sensitivity of LIGO is such that it can detect changes in arm length smaller than a thousandth of the diameter of a proton.\nThe phase shift \\(\\Delta \\phi\\) caused by a gravitational wave can be expressed as:\n\\[\n\\Delta \\phi = \\frac{4 \\pi \\Delta L}{\\lambda}\n\\]\nwhere \\(\\Delta L\\) is the change in the length of the interferometer arms due to the gravitational wave, and \\(\\lambda\\) is the wavelength of the laser light used in the interferometer.\n\n\nTo understand the phase shift in LIGO, consider the effect of a gravitational wave passing through the interferometer. The wave causes a differential change in the lengths of the two arms, denoted as \\(\\Delta L\\). This change in length affects the travel time of the laser beams in each arm.\nThe time difference \\(\\Delta T\\) between the beams traveling in the two arms can be expressed as:\n\\[\n\\Delta T = \\frac{\\Delta L}{c}\n\\]\nThe phase shift \\(\\Delta \\phi\\) is then related to this time difference by the equation:\n\\[\n\\Delta \\phi = \\frac{2 \\pi \\Delta T}{T} = \\frac{4 \\pi \\Delta L}{\\lambda}\n\\]\nThis phase shift alters the interference pattern observed at the detector, allowing LIGO to measure the presence and properties of gravitational waves. The extraordinary precision of LIGO’s measurements enables it to detect incredibly small disturbances in spacetime, providing valuable insights into some of the most energetic events in the universe."
  },
  {
    "objectID": "wave-optics/Diffraction.html",
    "href": "wave-optics/Diffraction.html",
    "title": "Diffraction",
    "section": "",
    "text": "Formulated by Christiaan Huygens in 1678, Huygens’ principle states that every point on a wavefront acts as a source of secondary spherical wavelets that spread out in the forward direction. The new position of the wavefront at any later time is found by constructing a surface tangent to these secondary wavelets. This principle provides a powerful method for analyzing wave propagation and explains various wave phenomena such as reflection, refraction, and diffraction.\n\n\n\nIllustration of Huygens’ principle for a plane wave incident with a wave vector \\(\\vec{k}\\). Each point on the wavefront acts as a source of secondary wavelets, and the new wavefront is the envelope of these wavelets.\n\n\nHuygens’ principle can be demonstrated numerically and visually. By placing a large number of spherical wave sources closely along a line and allowing their waves to interfere, we can reconstruct a plane wavefront propagating in the forward direction, illustrating how a plane wave advances according to Huygens’ concept.\n\n\n\nNumerical demonstration of Huygens’ principle used to recreate a plane wave from a set of spherical waves. The graph on the left shows the amplitude of a single spherical wave of wavelength \\(\\lambda=532\\) nm. By arranging 500 spherical wave sources densely along the x-axis at \\(z=0\\), all in phase (representing the phase of the incident plane wave at \\(z=0\\)), we can recreate the plane wavefronts for \\(z&gt;0\\) (middle) and the constant intensity distribution (right).\n\n\nMathematically, this phenomenon can be described using our earlier treatment of multi-wave interference. Consider \\(M\\) spherical wave sources arranged along the x-axis at \\(z=0\\), each separated by a small distance \\(d\\) from its neighbor. At a point far away from the sources (in the far-field approximation), the path difference between waves from adjacent sources leads to a phase difference given by:\n\\[\n\\Delta \\phi = \\frac{2\\pi d \\sin \\theta }{\\lambda}\n\\]\nwhere \\(\\theta\\) is the angle relative to the z-axis (the forward direction), and \\(\\lambda\\) is the wavelength of the waves. The superposition of these waves results in an intensity pattern described by:\n\\[\nI(\\theta) = I_0 \\frac{\\sin^2\\left ( M \\frac{\\pi d \\sin \\theta }{\\lambda} \\right )}{\\sin^2\\left ( \\frac{\\pi d \\sin \\theta }{\\lambda} \\right )}\n\\]\nThis expression arises from the interference of \\(M\\) waves with a constant phase difference \\(\\Delta \\phi\\) between neighboring waves. The numerator represents the constructive and destructive interference due to the finite number of sources, and the denominator accounts for the spacing between them.\nThis mathematical framework serves as the foundation for understanding diffraction phenomena, particularly in two important cases:\n\nSingle-Slit Diffraction: When Huygens’ wavelets are confined to a finite width (the slit width), the interference between these wavelets produces a characteristic diffraction pattern with a central maximum and diminishing side lobes.\nDiffraction Gratings: When multiple slits are arranged periodically, the interference of the transmitted waves leads to sharp diffraction maxima at specific angles, making diffraction gratings powerful tools for spectroscopic analysis.\n\nWhile we commonly use the term “diffraction” to describe these phenomena, they are fundamentally due to the interference of waves, as explained by Huygens’ principle. By considering every point on a wavefront as a source of secondary wavelets, we can understand and predict the complex patterns that arise when waves encounter obstacles or apertures.",
    "crumbs": [
      "Geometrical Optics",
      "Lecture 10",
      "Diffraction"
    ]
  },
  {
    "objectID": "wave-optics/Diffraction.html#huygens-principle",
    "href": "wave-optics/Diffraction.html#huygens-principle",
    "title": "Diffraction",
    "section": "",
    "text": "Formulated by Christiaan Huygens in 1678, Huygens’ principle states that every point on a wavefront acts as a source of secondary spherical wavelets that spread out in the forward direction. The new position of the wavefront at any later time is found by constructing a surface tangent to these secondary wavelets. This principle provides a powerful method for analyzing wave propagation and explains various wave phenomena such as reflection, refraction, and diffraction.\n\n\n\nIllustration of Huygens’ principle for a plane wave incident with a wave vector \\(\\vec{k}\\). Each point on the wavefront acts as a source of secondary wavelets, and the new wavefront is the envelope of these wavelets.\n\n\nHuygens’ principle can be demonstrated numerically and visually. By placing a large number of spherical wave sources closely along a line and allowing their waves to interfere, we can reconstruct a plane wavefront propagating in the forward direction, illustrating how a plane wave advances according to Huygens’ concept.\n\n\n\nNumerical demonstration of Huygens’ principle used to recreate a plane wave from a set of spherical waves. The graph on the left shows the amplitude of a single spherical wave of wavelength \\(\\lambda=532\\) nm. By arranging 500 spherical wave sources densely along the x-axis at \\(z=0\\), all in phase (representing the phase of the incident plane wave at \\(z=0\\)), we can recreate the plane wavefronts for \\(z&gt;0\\) (middle) and the constant intensity distribution (right).\n\n\nMathematically, this phenomenon can be described using our earlier treatment of multi-wave interference. Consider \\(M\\) spherical wave sources arranged along the x-axis at \\(z=0\\), each separated by a small distance \\(d\\) from its neighbor. At a point far away from the sources (in the far-field approximation), the path difference between waves from adjacent sources leads to a phase difference given by:\n\\[\n\\Delta \\phi = \\frac{2\\pi d \\sin \\theta }{\\lambda}\n\\]\nwhere \\(\\theta\\) is the angle relative to the z-axis (the forward direction), and \\(\\lambda\\) is the wavelength of the waves. The superposition of these waves results in an intensity pattern described by:\n\\[\nI(\\theta) = I_0 \\frac{\\sin^2\\left ( M \\frac{\\pi d \\sin \\theta }{\\lambda} \\right )}{\\sin^2\\left ( \\frac{\\pi d \\sin \\theta }{\\lambda} \\right )}\n\\]\nThis expression arises from the interference of \\(M\\) waves with a constant phase difference \\(\\Delta \\phi\\) between neighboring waves. The numerator represents the constructive and destructive interference due to the finite number of sources, and the denominator accounts for the spacing between them.\nThis mathematical framework serves as the foundation for understanding diffraction phenomena, particularly in two important cases:\n\nSingle-Slit Diffraction: When Huygens’ wavelets are confined to a finite width (the slit width), the interference between these wavelets produces a characteristic diffraction pattern with a central maximum and diminishing side lobes.\nDiffraction Gratings: When multiple slits are arranged periodically, the interference of the transmitted waves leads to sharp diffraction maxima at specific angles, making diffraction gratings powerful tools for spectroscopic analysis.\n\nWhile we commonly use the term “diffraction” to describe these phenomena, they are fundamentally due to the interference of waves, as explained by Huygens’ principle. By considering every point on a wavefront as a source of secondary wavelets, we can understand and predict the complex patterns that arise when waves encounter obstacles or apertures.",
    "crumbs": [
      "Geometrical Optics",
      "Lecture 10",
      "Diffraction"
    ]
  },
  {
    "objectID": "wave-optics/Diffraction.html#single-slit-diffraction",
    "href": "wave-optics/Diffraction.html#single-slit-diffraction",
    "title": "Diffraction",
    "section": "Single Slit Diffraction",
    "text": "Single Slit Diffraction\nWe now apply our interference formula to study the diffraction of an incident plane wave (wavevector \\(\\vec{k}\\)) on a single slit of width \\(b\\). We can model this by placing a series of Huygens sources along the slit opening. While the sketch below shows just 3 sources for clarity, we’ll generalize this to \\(M\\) sources.\n\n\n\n\n\nWe divide the slit into segments of width \\(\\Delta b\\) such that we have \\(M=b/\\Delta b\\) Huygens sources, each with amplitude \\(A_0=\\sqrt{I_0}\\). Applying our previous multi-wave interference formula with spacing \\(d=\\Delta b\\), we obtain:\n\\[\nI=I_0 \\frac{\\sin^2\\left (M\\pi\\frac{\\Delta b}{\\lambda}\\sin(\\theta)\\right)}{\\sin^2\\left (\\pi\\frac{\\Delta b}{\\lambda}\\sin(\\theta)\\right)}\n\\]\nSince \\(M\\Delta b = b\\), we can rewrite this as:\n\\[\nI=I_0 \\frac{\\sin^2\\left (\\pi\\frac{b}{\\lambda}\\sin(\\theta)\\right)}{\\sin^2\\left (\\pi\\frac{b}{M\\lambda}\\sin(\\theta)\\right)}\n\\]\nFor convenience, let’s substitute \\(x=\\pi \\frac{b}{\\lambda}\\sin(\\theta)\\), giving:\n\\[\nI=I_0\\frac{\\sin^2(x)}{\\sin^2(x/M)}\n\\]\nIn reality, we have a continuous distribution of sources across the slit width, corresponding to \\(M\\to\\infty\\). In this limit, for the denominator, \\(x/M\\) becomes very small, and we can use the small-angle approximation:\n\\[\n\\sin^2\\left (\\frac{x}{M}\\right) \\approx \\left(\\frac{x}{M}\\right)^2\n\\]\nTherefore, our final expression becomes:\n\\[\nI(\\theta)=I_s\\frac{\\sin^2\\left (\\pi \\frac{b}{\\lambda}\\sin(\\theta)\\right)}{\\left(\\pi \\frac{b}{\\lambda}\\sin(\\theta)\\right)^2}\n\\]\nwhere \\(I_s=M^2I_0\\) represents the total intensity from all sources. This expression is often written using the sinc function (sinus cardinalis):\n\\[\nI(\\theta)=I_s\\,\\text{sinc}^2\\left(\\pi \\frac{b}{\\lambda}\\sin(\\theta)\\right)\n\\]\nThis formula describes the characteristic diffraction pattern of a single slit, with a central maximum and symmetric side lobes of decreasing intensity.\n\n\n\n\n\n\nSingle Slit Diffraction\n\n\n\n\n\nThe intensity distribution generated by the diffraction of monochromatic light on a single slit and observed in the far field is given by\n\\[\nI(\\theta)=I_s\\frac{\\sin^2\\left (\\pi \\frac{b}{\\lambda}\\sin(\\theta)\\right)}{\\left( \\pi \\frac{b}{\\lambda}\\sin(\\theta)\\right)^2}\n\\]\nwhere \\(\\lambda\\) is the wavelength of the light and \\(b\\) the width of the slit. The angle of observation is given by \\(\\theta\\). Note that the diffraction pattern on any aperture is resulting from the fact that you remove Huygens sources that would be normally needed to form a plane wavefront for example.\nFourier Transform and Diffraction\nThe intensity distribution generated by the diffraction of monochromatic light on a single slit and observed in the far field is given by\n\\[\nI(\\theta)=I_s\\frac{\\sin^2\\left (\\pi \\frac{b}{\\lambda}\\sin(\\theta)\\right)}{\\left( \\pi \\frac{b}{\\lambda}\\sin(\\theta)\\right)^2}\n\\]\nwhere \\(\\lambda\\) is the wavelength of the light and \\(b\\) the width of the slit. The angle of observation is given by \\(\\theta\\). Note that the diffraction pattern on any aperture is resulting from the fact that you remove Huygens sources that would be normally needed to form a plane wavefront for example.\nThis diffraction pattern can be understood as the Fourier transform of the aperture function. In the case of a single slit, the aperture function is a rectangular function, and its Fourier transform is a sinc function. This relationship between the aperture and its diffraction pattern is a fundamental concept in wave optics and is widely used in various applications, including imaging and signal processing.\n\n\n\n\n\n\nTotal wave amplitude behind a slit (b=2µm) for an incident wave of 532 nm wavelength. The plot in the middle shows the intensity in the space behind the slit. The graph on the right displays the diffraction pattern at a screen at 100 µm distance from the slit.\n\n\nLet’s have a look at some of the properties of the intensity distribution.\n\n\nCode\n#\ndef single_slit(d,theta,wl):\n    d=np.pi*d/wl*np.sin(theta)\n    return((np.sin(d)/d)**2)\n\nwl=532e-9\nb=5e-6\ntheta=np.linspace(-np.pi/6,np.pi/6,1000)\n\nplt.figure(figsize=get_size(18,7))\nplt.subplot(1,2,1)\nplt.plot(np.sin(theta),single_slit(b,theta,532e-9),'green',lw=2,label=\"532 nm\")\nplt.plot(np.sin(theta),single_slit(b,theta,700e-9),'red',lw=2,label=\"700 nm\")\nplt.annotate('first minimum 700 nm',xy=(0.14, 0),xytext=(0.14, 0.25),arrowprops=dict(facecolor='black', width=0.5,headwidth=6))\nplt.xlabel(r'$\\sin(\\theta)$')\nplt.ylabel('$I/I_s$')\nplt.legend()\nplt.subplot(1,2,2)\nplt.plot(np.sin(theta),single_slit(b/2,theta,532e-9),'green',lw=2,label=\"532 nm\")\nplt.plot(np.sin(theta),single_slit(b/2,theta,700e-9),'red',lw=2,label=\"700 nm\")\nplt.xlabel(r'$\\sin(\\theta)$')\nplt.ylabel('$I/I_s$')\nplt.legend()\nplt.show()\n\n\n\n\n\nCaption\n\n\n\n\nThe single-slit diffraction pattern shows characteristic features that we can observe in both theoretical calculations and experimental measurements. The intensity distribution is described by an oscillating function with decreasing amplitude. The oscillations arise from the \\(\\sin^2\\) term in the numerator, while the decay comes from the square term in the denominator.\n\n\n\nDiffraction patterns as a function of the sine of the diffraction angle. The minima of the diffraction pattern in this plot are at integer multiples of \\(\\lambda/b\\).\n\n\nThe graphs above illustrate two key relationships in single-slit diffraction:\n\nThe effect of wavelength: When comparing patterns for different wavelengths (with fixed slit width \\(b=5\\,\\mathrm{\\mu m}\\)), longer wavelengths produce broader diffraction patterns\nThe effect of slit width: For the same wavelength, reducing the slit width to \\(b=2.5\\,\\mathrm{\\mu m}\\) results in a broader diffraction pattern\n\nThese observations can be quantified by analyzing the positions of intensity minima. The intensity goes to zero when the argument of the sine function in the numerator equals multiples of π:\n\\[\n\\pi \\frac{b}{\\lambda}\\sin(\\theta) = m\\pi\n\\]\nwhere \\(m\\) is an integer. This simplifies to:\n\\[\n\\sin(\\theta)=m\\frac{\\lambda}{b}\n\\]\nThis relationship reveals a fundamental principle in diffraction: the angular spread of the pattern is proportional to the ratio of wavelength to the size of the diffracting object (\\(\\lambda/b\\)). While the exact mathematical form may vary for different geometries, this basic scaling remains valid.\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 1— Diffraction patterns on a single slit as observed in the lecture. The left image shows the diffraction pattern for red light, while the right image combines two different wavelengths (red, blue), where one clearly recognizes the wider diffraction peaks for the longer red wavelength.\n\n\n\nThe experimental observations above clearly demonstrate these principles, particularly showing how red light (longer wavelength) produces a broader diffraction pattern than blue light (shorter wavelength).",
    "crumbs": [
      "Geometrical Optics",
      "Lecture 10",
      "Diffraction"
    ]
  },
  {
    "objectID": "wave-optics/Diffraction.html#circular-aperture",
    "href": "wave-optics/Diffraction.html#circular-aperture",
    "title": "Diffraction",
    "section": "Circular Aperture",
    "text": "Circular Aperture\nFor a circular aperture, the diffraction pattern follows a more complex mathematical form involving Bessel functions. The intensity distribution is given by:\n\\[\nI(\\theta)=I_0\\left( \\frac{2J_1(x)}{x} \\right )^2\n\\]\nwhere \\(J_1\\) is the Bessel function of the first kind, and\n\\[\nx=\\frac{2\\pi R}{\\lambda}\\sin(\\theta)\n\\]\nHere, \\(R\\) is the radius of the aperture. While similar to the sine function, the Bessel function has zeros at different positions: \\(x_1=1.22\\pi\\), \\(x_2=2.23\\pi\\), and so on.\n\n\n\nDiffraction pattern of a circular aperture of radius \\(5\\) µm. Note that the intensity scale is saturated. The diffraction rings would otherwise not be visible. The minima of the diffraction pattern in this plot are at integer multiples of \\(0.61\\lambda/R\\).\n\n\nThe first minimum of the diffraction pattern occurs when:\n\\[\nx_1=1.22\\pi=\\frac{2\\pi R}{\\lambda}\\sin(\\theta_1)\n\\]\nSolving for \\(\\sin(\\theta_1)\\):\n\\[\n\\sin(\\theta_1)=0.61\\frac{\\lambda}{R}\n\\]\nThis follows the same general principle we’ve seen before: the angular spread is proportional to wavelength divided by aperture size. The central bright region up to this first minimum is known as the Airy disc, and in microscopy, this defines a resolution element or resel.",
    "crumbs": [
      "Geometrical Optics",
      "Lecture 10",
      "Diffraction"
    ]
  },
  {
    "objectID": "wave-optics/Diffraction.html#application-diffraction-grating",
    "href": "wave-optics/Diffraction.html#application-diffraction-grating",
    "title": "Diffraction",
    "section": "Application: Diffraction Grating",
    "text": "Application: Diffraction Grating\nWe now combine the concepts of single-slit diffraction and multiple-wave interference to understand the behavior of diffraction gratings. Diffraction gratings are important in spectroscopy and the compression of short laser pulses.\nConsider a diffraction grating with \\(N\\) slits, each of width \\(b\\), and separated by a distance \\(d\\). Each slit acts as a source of diffraction, producing an intensity pattern that oscillates with decreasing amplitude. The width of this diffraction pattern is determined by \\(\\lambda/b\\), and the pattern is given by:\n\\[\nI(\\theta) = I_s \\frac{\\sin^2\\left(\\pi \\frac{b}{\\lambda} \\sin(\\theta)\\right)}{\\left(\\pi \\frac{b}{\\lambda} \\sin(\\theta)\\right)^2}\n\\]\nNow, we have multiple slits, each separated by a distance \\(d\\). The interference of waves from these slits is described by:\n\\[\nI = I_0 \\frac{\\sin^2(N \\phi / 2)}{\\sin^2(\\phi / 2)}\n\\]\nwhere the phase difference \\(\\phi\\) between waves from neighboring slits is given by:\n\\[\n\\phi = k \\Delta s = \\frac{2\\pi}{\\lambda} d \\sin(\\theta)\n\\]\nCombining these expressions, the intensity distribution for a diffraction grating is:\n\\[\nI(\\theta) = I_0 \\frac{\\sin^2\\left(\\pi \\frac{b}{\\lambda} \\sin(\\theta)\\right)}{\\left(\\pi \\frac{b}{\\lambda} \\sin(\\theta)\\right)^2} \\frac{\\sin^2\\left(N \\pi \\frac{d}{\\lambda} \\sin(\\theta)\\right)}{\\sin^2\\left(\\pi \\frac{d}{\\lambda} \\sin(\\theta)\\right)}\n\\]\nThis formula describes the intensity pattern produced by a diffraction grating, which is the product of the single-slit diffraction pattern and the multiple-slit interference pattern.\n\n\n\n\n\n\nDiffraction Grating\n\n\n\nThe intensity distribution generated by a diffraction grating from monochromatic light and observed in the far field is given by\n\\[\nI(\\theta) = I_0 \\frac{\\sin^2\\left(\\pi \\frac{b}{\\lambda} \\sin(\\theta)\\right)}{\\left(\\pi \\frac{b}{\\lambda} \\sin(\\theta)\\right)^2} \\frac{\\sin^2\\left(N \\pi \\frac{d}{\\lambda} \\sin(\\theta)\\right)}{\\sin^2\\left(\\pi \\frac{d}{\\lambda} \\sin(\\theta)\\right)}\n\\]\nwhere \\(\\lambda\\) is the wavelength of the light, \\(b\\) is the width of the slit, \\(d\\) is the distance between the slits, and \\(N\\) is the number of slits illuminated. The angle of observation is given by \\(\\theta\\).\n\n\n\nProperties of the Diffraction Pattern\nLet’s examine the properties of this intensity distribution. The graph below shows the intensity distribution for a diffraction grating with \\(N=8\\) slits, a slit distance of \\(d=4\\) µm, a slit width of \\(b=2\\) µm, and a wavelength of 532 nm. We observe the following general properties:\n\nThe intensity pattern consists of main maxima, called diffraction orders, characterized by integer numbers. The central peak is the 0th order peak, the first main peak to the right is the 1st diffraction order, and so on.\nThe main peaks are separated by \\(N-2\\) secondary peaks and \\(N-1\\) minima.\nThe intensity distribution is characterized by an envelope, which is the diffraction pattern of a single slit (dashed line). In the example below, the 2nd order peak is suppressed. The envelope becomes wider if the slits become narrower.\n\n\n\nPosition of the Main Peaks\nThe position of the main peaks is determined by the condition that the denominator of the multiple-slit interference term is zero. This occurs when the argument is an integer multiple of \\(\\pi\\), i.e., \\(\\pi \\frac{d}{\\lambda} \\sin(\\theta) = m\\pi\\), or:\n\\[\n\\sin(\\theta) = m \\frac{\\lambda}{d}\n\\]\nwhere \\(m\\) is an integer. The first-order diffraction maximum is found at \\(\\sin(\\theta) = \\frac{\\lambda}{d}\\), independent of the number of slits \\(N\\). This means that the position of the main peaks increases linearly with the wavelength \\(\\lambda\\) and decreases with increasing slit distance \\(d\\).\n\n\nCode\n# Parameters\nN = 8  # Number of slits\nb = 2e-6  # Slit width in meters\nd = 4e-6  # Separation between slits in meters\nwavelength = 532e-9  # Wavelength of light in meters\n\n# Diffraction angle range\ntheta = np.linspace(-np.pi/2, np.pi/2, 1000)\nsin_theta = np.sin(theta)\n\n# Calculate the intensity\nbeta = (np.pi * b / wavelength) * sin_theta\ngamma = (np.pi * d / wavelength) * sin_theta\n\nsingle_slit = (np.sin(beta) / beta)**2\nmulti_slit = (np.sin(N * gamma) / np.sin(gamma))**2\n\n# Handle division by zero for beta and gamma\nsingle_slit[np.isnan(single_slit)] = 1\nmulti_slit[np.isnan(multi_slit)] = N**2\n\nintensity = single_slit * multi_slit\n\n# Plot the intensity\nplt.figure(figsize=get_size(12, 8))\nplt.plot(sin_theta, intensity/np.max(intensity),label='Intensity')\nplt.plot(sin_theta, single_slit, 'r--',label='Single Slit')\nplt.xlabel(r'$\\sin(\\theta)$')\nplt.ylabel(r'$I/I_{max}$')\nplt.xlim(-0.5,0.5)\nplt.show()\n\n\n\n\n\nDiffraction pattern of a grating where 8 slits with a width of 2 µm and a distance of 4 micrometers are illuminated by a wavelength of 532 nm.\n\n\n\n\n\n\nInfluence of the Slit Width\nThe two plots below show the influence of the slit width while keeping the slit distance the same. We have \\(N=8\\) slits with \\(d=4\\) µm, while the slit width is \\(b=2\\) µm on the left side and \\(b=1\\) µm on the right side. The result is an increased width of the envelope. The first minimum of the slit diffraction pattern occurs at \\(\\sin(\\theta) = \\frac{\\lambda}{b}\\).\n\n\nCode\n# Parameters\nN = 8  # Number of slits\nd = 4e-6  # Separation between slits in meters\nwavelength = 532e-9  # Wavelength of light in meters\n\n# Diffraction angle range\ntheta = np.linspace(-np.pi / 2, np.pi / 2, 1000)\nsin_theta = np.sin(theta)\n\ndef calculate_intensity(N, b, d, wavelength, sin_theta):\n    beta = (np.pi * b / wavelength) * sin_theta\n    gamma = (np.pi * d / wavelength) * sin_theta\n\n    # Single slit intensity pattern using sinc function\n    single_slit = (np.sinc(beta / np.pi))**2\n\n    # Multi-slit interference pattern\n    multi_slit = np.ones_like(gamma)\n    gamma_nonzero = gamma != 0\n    multi_slit[gamma_nonzero] = (np.sin(N * gamma[gamma_nonzero]) / np.sin(gamma[gamma_nonzero]))**2\n    multi_slit[~gamma_nonzero] = N**2\n\n    intensity = single_slit * multi_slit\n\n    return single_slit, intensity\n\n# Plotting\nfig, ax = plt.subplots(1, 2, figsize=get_size(18, 8))\n\n# First plot with b = 2e-6\nb = 2e-6\nsingle_slit, intensity = calculate_intensity(N, b, d, wavelength, sin_theta)\nax[0].plot(sin_theta, intensity / np.max(intensity), label='Intensity')\nax[0].plot(sin_theta, single_slit, 'r--', label='Single Slit')\nax[0].set_xlabel(r'$\\sin(\\theta)$')\nax[0].set_ylabel(r'$I/I_{max}$')\nax[0].set_xlim(-0.5, 0.5)\nax[0].legend()\n\n# Second plot with b = 1e-6\nb = 1e-6\nsingle_slit, intensity = calculate_intensity(N, b, d, wavelength, sin_theta)\nax[1].plot(sin_theta, intensity / np.max(intensity), label='Intensity')\nax[1].plot(sin_theta, single_slit, 'r--', label='Single Slit')\nax[1].set_xlabel(r'$\\sin(\\theta)$')\nax[1].set_ylabel(r'$I/I_{max}$')\nax[1].set_xlim(-0.5, 0.5)\nax[1].legend()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\nDiffraction pattern of a grating with \\(N=8\\) slits (\\(d=4\\) µm, \\(b=1\\) µm) with \\(\\lambda=532\\) nm.\n\n\n\n\n\n\nInfluence of the Slit Number\nWhen increasing the number of slits, the main diffraction peaks become sharper. The location of the main peaks for a given wavelength remains unchanged, but there are now \\(N-2\\) secondary maxima in between. This decreased width of the main peaks is important for the spectral resolution of the grating.\n\n\nCode\nN = 100  # Number of slits\nb = 1e-6  # Slit width in meters\nd = 4e-6  # Separation between slits in meters\nwavelength = 532e-9  # Wavelength of light in meters\n\n# Diffraction angle range\ntheta = np.linspace(-np.pi/2, np.pi/2, 10000)\nsin_theta = np.sin(theta)\n\n# Calculate the intensity\nbeta = (np.pi * b / wavelength) * sin_theta\ngamma = (np.pi * d / wavelength) * sin_theta\n\nsingle_slit = (np.sin(beta) / beta)**2\nmulti_slit = (np.sin(N * gamma) / np.sin(gamma))**2\n\n# Handle division by zero for beta and gamma\nsingle_slit[np.isnan(single_slit)] = 1\nmulti_slit[np.isnan(multi_slit)] = N**2\n\nintensity = single_slit * multi_slit\n\n# Plot the intensity\nplt.figure(figsize=get_size(12, 8))\nplt.plot(sin_theta, intensity/np.max(intensity),label='Intensity')\nplt.plot(sin_theta, single_slit, 'r--',label='Single Slit')\nplt.xlabel(r'$\\sin(\\theta)$')\nplt.ylabel(r'$I/I_{max}$')\nplt.xlim(-0.5,0.5)\nplt.show()\n\n\n\n\n\nDiffraction pattern of a grating with \\(N=100\\) slits (\\(d=4\\) µm, \\(b=1\\) µm) with \\(\\lambda=532\\) nm.\n\n\n\n\n\n\nSpectral Resolution\nTo quantify the spectral resolution, we use a criterion similar to the optical resolution of a microscope: two peaks are separable if the second peak is located at the minimum of the first diffraction pattern. Here, the diffraction patterns refer to different wavelengths \\(\\lambda_1\\) and \\(\\lambda_2\\).\n\n\nCode\nN = 100  # Number of slits\nb = 1e-6  # Slit width in meters\nd = 4e-6  # Separation between slits in meters\n\n# Diffraction angle range\ntheta = np.linspace(0.01, 1, 10000)\nsin_theta = np.sin(theta)\n\ndef intensity(sin_theta, wavelength, b, d, N):\n    # Calculate beta and gamma\n    beta = (np.pi * b / wavelength) * sin_theta\n    gamma = (np.pi * d / wavelength) * sin_theta\n\n    # Compute single-slit intensity\n    single_slit = np.where(beta == 0, 1.0, (np.sin(beta) / beta))**2\n\n    # Compute multi-slit interference\n    multi_slit = np.where(gamma == 0, N**2, (np.sin(N * gamma) / np.sin(gamma))**2)\n\n    # Combine intensities\n    intensity = single_slit * multi_slit\n    return intensity\n\ni1 = intensity(sin_theta, 532e-9, b, d, N)\ni2 = intensity(sin_theta, 537e-9, b, d, N)\n\n# Plot the intensity\nfig, ax = plt.subplots(1, 2, figsize=get_size(16, 8))\nax[0].plot(sin_theta, i1 / np.max(i1), label='532 nm')\nax[0].plot(sin_theta, i2 / np.max(i2), label='537 nm')\nax[0].set_xlabel(r'$\\sin(\\theta)$')\nax[0].set_ylabel(r'$I/I_{max}$')\nax[0].set_xlim(0.12, 0.15)\nax[0].legend()\n\nax[1].plot(sin_theta, i1 / np.max(i1), label='532 nm')\nax[1].plot(sin_theta, i2 / np.max(i2), label='537 nm')\nax[1].set_xlabel(r'$\\sin(\\theta)$')\nax[1].set_ylabel(r'$I/I_{max}$')\nax[1].set_xlim(0.255, 0.28)\nax[1].legend()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\nRayleigh resolution limit of a grating with \\(N=100\\) slits (\\(d=4\\) µm, \\(b=1\\) µm) with \\(\\lambda_1=532\\) nm and \\(\\lambda_2=537\\) nm in the first order diffraction peak (left) and the second order peak (right).\n\n\n\n\nConsider the \\(m\\)th order diffraction peak for the wavelength \\(\\lambda_1\\). This occurs at:\n\\[\n\\sin(\\theta) = m \\frac{\\lambda_1}{d}\n\\]\nThe next secondary minimum to larger angles of the diffraction pattern is located where the numerator of the multiple-wave interference term:\n\\[\n\\sin^2\\left(N \\pi \\frac{d}{\\lambda} \\sin(\\theta)\\right)\n\\]\nbecomes zero, or the argument:\n\\[\nN \\pi \\frac{d}{\\lambda} \\sin(\\theta) = l \\pi\n\\]\nbecomes a multiple \\(l\\) of \\(\\pi\\). For the first-order main peak, we have \\(N-2\\) intermediate peaks as well as the 0th and now the first-order peak. Therefore, \\(m = l/N\\), and the next minimum after the 1st order peak is at:\n\\[\n\\sin(\\theta_1) = \\frac{l+1}{N} \\frac{\\lambda_1}{d}\n\\]\nThis angle must correspond to the position of the main peak of the first-order diffraction of the wavelength \\(\\lambda_2\\), so:\n\\[\n\\sin(\\theta_1) = m \\frac{\\lambda_2}{d}\n\\]\nCombining both equations for the two wavelengths yields:\n\\[\n\\left(m + \\frac{1}{N}\\right) \\frac{\\lambda_1}{d} = m \\frac{\\lambda_2}{d}\n\\]\nand after some rearrangements (setting \\(\\lambda_1 = \\lambda\\)):\n\\[\nR = \\frac{\\lambda}{\\Delta \\lambda} = mN\n\\]\nThis is the resolving power \\(R\\) of a grating. The ability to resolve two wavelengths increases with the diffraction order \\(m\\) and the number of slits used for the diffraction. However, the intensity of higher diffraction orders rapidly decreases due to the grating envelope. Therefore, the main parameter to change is the number of illuminated slits.\nOur finding is illustrated in the figure above, where we achieve a resolution of about 5 nm when using \\(N=100\\) slits at a distance of \\(d=4\\) µm.\n\n\n\n\n\n\n\n\nDiffraction pattern observed for a grating in the lecture with red light (left) and white light (right).\n\n\n\n\n\n\n\nDiffraction pattern observed for a grating in the lecture with red light (left) and white light (right).\n\n\n\n\n\n\nFigure 2— Diffraction pattern observed for a grating in the lecture with red light (left) and white light (right).\n\n\n\n\n\n\n\n\n\nDiffraction Grating Playground\n\n\n\n\n\n\n  Wavelength (nm):\n  \n  532 nm\n  \n  Slit Width (µm):\n  \n  2 µm\n  \n  Number of Slits:\n  \n  8\n\n\n\n\n\n\nApp to play with the parameters of a grating with a slit distance of 4 µm and a slit width of 2 µm.",
    "crumbs": [
      "Geometrical Optics",
      "Lecture 10",
      "Diffraction"
    ]
  },
  {
    "objectID": "foundations-of-quantum-physics/index.html",
    "href": "foundations-of-quantum-physics/index.html",
    "title": "EXP3 Quarto",
    "section": "",
    "text": "This is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites."
  },
  {
    "objectID": "course-info/assignments.html",
    "href": "course-info/assignments.html",
    "title": "Seminars & Assignments",
    "section": "",
    "text": "Assignments are an essential part of the course. They help you to understand the material better and to prepare for the final exam. Our experience shows that students who regularly work on the assignments have a better understanding of the material and are more successful in the final exam.\nAll of the assignments for the lecture will be handled online. An assignment will be handed out every week starting October 17, 2024 on the Moodle page of the course (see below).\nWe will use future seminars to discuss without any announcement problems that are similar to some questions we will use in the exam.\nAll assignments will be corrected, and the solutions to the individual problems will be discussed in the seminar one week later. There will be no online versions of the solutions available. Science is about discussing and understanding, so use the seminar to ask questions and to understand the solutions.",
    "crumbs": [
      "Course Info",
      "Assignments"
    ]
  },
  {
    "objectID": "course-info/assignments.html#moodle-page",
    "href": "course-info/assignments.html#moodle-page",
    "title": "Seminars & Assignments",
    "section": "Moodle Page",
    "text": "Moodle Page\nYou can find the current assignments on the Moodle page of the course. The Moodle page is available at Moodle.",
    "crumbs": [
      "Course Info",
      "Assignments"
    ]
  },
  {
    "objectID": "course-info/exam.html",
    "href": "course-info/exam.html",
    "title": "Exam",
    "section": "",
    "text": "The exam will take place on February 24, 2025, 09:00–12:00 in the Large Lecture Hall. We also intent to create a mock exam to help you prepare for the exam.\n\n\n\n\n\n\nExam Format\n\n\n\nThis course will end with a written exam of 180 minutes duration.\n\n\n\n\n\n\n\n\nExam Eligibility\n\n\n\nTo take part in the exam, you need to qualify by earning 50% of the possible points from the exercises handed out weekly.",
    "crumbs": [
      "Course Info",
      "Exam"
    ]
  },
  {
    "objectID": "course-info/schedule.html",
    "href": "course-info/schedule.html",
    "title": "Course Schedule",
    "section": "",
    "text": "Lectures\nThe course will be held in two weekly lectures, starting 14.10.2024. The lectures will be held in the Large Lecture Hall (GHS) at the Linnéstr. 5. The course will be held in English.\n\n\n\n\n\n\nLecture Times\n\n\n\n\nMonday 11:15 am – 12:45 pm GHS\nThursday 11:15 am – 12:45 pm GHS\n\n\n\nThe course and the material are available online on this website. You may come back to study whenever it is suitable for you. Please note that the lectures are a place to give feedback on your understanding he topics. No feedback means all is good.\n\n\nSeminars\nSeminars are an essential part of the course. They help you to understand the material better and to prepare for the final exam. Our experience shows that students who regularly work on the assignments have a better understanding of the material and are more successful in the final exam.\n\n\n\n\n\n\nSeminar Start\n\n\n\nThe seminars will start on October 22 The solutions to the exercise sheets have to be handed in on Thursdays before the lecture.\n\n\n\n\n\n\n\n\nSeminar Times\n\n\n\n\nTuesday 11:15 am – 12:45 pm, SR 224\nTuesday 15:15 am – 16:45 pm, ThHS\n\n\n\nThe seminar will be held by Diptabrata Paul and Markus Anton.",
    "crumbs": [
      "Course Info",
      "Schedule"
    ]
  },
  {
    "objectID": "geometrical-optics/ContentsL6.html",
    "href": "geometrical-optics/ContentsL6.html",
    "title": "Contents",
    "section": "",
    "text": "The contents of lecture 6 will only be presented in the lectures and not part of the online publications.",
    "crumbs": [
      "Geometrical Optics",
      "Lecture 6",
      "Contents"
    ]
  },
  {
    "objectID": "geometrical-optics/Telescope.html",
    "href": "geometrical-optics/Telescope.html",
    "title": "Telescopes",
    "section": "",
    "text": "Other than the microscope, the telescope is made to observe distant objects, which would appear under a very small observation angle. This can be achieved with different optical designs. The most common telescopes are refracting telescopes, which use lenses to magnify the angle under which the object is observed. The second type of telescopes are reflecting telescopes, which use mirrors to magnify the angle under which the object is observed.\n\nRefracting Telescopes\nThe telescope is therefore made to magnify the angle under which the object is observed. In the same way as a microscope, the telescope consists of two lenses with the focal distances \\(f_1,f_2\\).\n\n\n\nKepler telescope with two biconvex lenses, creating a reversed image of distance objects.\n\n\nAs indicated in the sketch above, the first lens generates an image at the focal length of the first lens. This intermediate image is the magnified by an eye-piece as well acting as a magnifying glass. We may therefore apply the same kind of techniques as earlier for the calculation of the angular magnification. The angle of observation for the object of size \\(D\\) is given by\n\\[\n2\\epsilon_0=\\frac{D}{f_1}\n\\]\nwhile the angle of observation through the telescope is given as\n\\[\n2\\epsilon=\\frac{D}{f_2}\n\\]\nCorrespondingly, the angular magnification is given by\n\\[\nV=\\frac{\\epsilon}{\\epsilon_0}=\\frac{D}{f_2}\\frac{f_1}{D}=\\frac{f_1}{f_2}\n\\]\nThe magnification is therefore given by the ration of the focal length of the entrance lens and the eye-piece. The above telescope is also termed astronomical telescope or Kepler telescope, since it has been used for astromical observations. It creates an image which is reversed.\nA telescope with an upright image may be created with the help of a concave lens. This type of telescope is called Galilei telescope and obeyes the same magnification formula as above. Due to the fact that a concave lens has a negative focal length, the total magnification will be negative as well being indicative for an upright image.\n\n\n\nGalilei telescope for imaging objects into upright images with the help of a concave and a convex lens.\n\n\n\n\nReflecting Telescopes\nModern powerful telescopes also use mirrors instead of refracting optical elements, as reflecting elements with nearly 100 percent reflectivity can be built with a much smaller mass than large glass elements. Such telescopes come in different setups. The one below is a Cassegrain telescope, where a secondary convex miror is used for imaging the intermediate image to the eye.\n\n\n\n\n\n\n\n\n\n\n\n\nReflective optics is commonly used in modern high quality telescopes for the advantage of weight. The image and sketch shows the optics of a so-called Cassegrain telescope.\n\n\n\n\n\n\n\nAdaptive Optics\nWhen observing objects from the ground, the atmosphere can distort the image. This is due to the fact that the atmosphere is not homogeneous and the refractive index of the air is changing with time. This leads to a distortion of the image, which can be corrected with the help of adaptive optics. The principle of adaptive optics is to measure the distortion of the image with the help of a laser beam and to correct the image with the help of a deformable mirror. The deformable mirror is a mirror with a number of actuators, which can change the shape of the mirror in order to correct the distortion of the image. The principle of adaptive optics is shown in the figure below.\n\n\n\nPrinciple of adaptive optics. The image of a star is distorted by the atmosphere. The distortion is measured with the help of a laser beam and corrected with the help of a deformable mirror.\n\n\n\n\nSpace-Based Telescopes\nPlacing telescopes in space eliminates atmospheric interference completely. The Hubble Space Telescope revolutionized astronomy with its crystal-clear views of the universe.\n\n\n\nLight path in the Hubble space telescope.\n\n\nIts successor, the James Webb Space Telescope (launched in 2021), operates in the infrared spectrum and can peer even further into space and time. Being above the atmosphere not only provides clearer images but also allows these telescopes to observe wavelengths that are normally blocked by Earth’s atmosphere, particularly in the infrared and ultraviolet regions.",
    "crumbs": [
      "Geometrical Optics",
      "Lecture 5",
      "Optical Instruments- Telescope"
    ]
  },
  {
    "objectID": "geometrical-optics/NA Derivation.html",
    "href": "geometrical-optics/NA Derivation.html",
    "title": "Experimental Physics 3 Course on Optics and Quantum Mechanics",
    "section": "",
    "text": "We start with Snell’s law at the core-cladding interface:\n\\[n_1 \\sin \\theta_1 = n_2 \\sin \\theta_2\\]\nwhere \\(n_1\\) is the core refractive index and \\(n_2\\) is the cladding refractive index.\nFor total internal reflection, the critical angle \\(\\theta_c\\) occurs when \\(\\theta_2 = 90°\\):\n\\[n_1 \\sin \\theta_c = n_2 \\sin 90° = n_2\\]\nThus, we can express the critical angle as:\n\\[\\sin \\theta_c = \\frac{n_2}{n_1}\\]\nIn the fiber, the maximum angle for total internal reflection is \\((90° - \\theta_c)\\):\n\\[\\cos \\theta_c = \\sin(90° - \\theta_c)\\]\nUsing the trigonometric identity \\(\\cos^2 \\theta + \\sin^2 \\theta = 1\\):\n\\[\\cos^2 \\theta_c = 1 - \\sin^2 \\theta_c = 1 - \\left(\\frac{n_2}{n_1}\\right)^2\\]\nAt the air-core interface, we apply Snell’s law again:\n\\[\\sin \\theta_a = n_1 \\sin(90° - \\theta_c) = n_1 \\cos \\theta_c\\]\nSubstituting the result from step 5:\n\\[\\sin \\theta_a = n_1 \\sqrt{1 - \\left(\\frac{n_2}{n_1}\\right)^2} = \\sqrt{n_1^2 - n_2^2}\\]\nThis final result is the Numerical Aperture (NA):\n\\[NA = \\sin \\theta_a = \\sqrt{n_1^2 - n_2^2}\\]\nThis formula relates the maximum acceptance angle \\(\\theta_a\\) to the refractive indices of the core (\\(n_1\\)) and cladding (\\(n_2\\)). It’s a crucial parameter in fiber optics, determining the light-gathering ability and the range of angles over which the fiber can accept or emit light."
  },
  {
    "objectID": "geometrical-optics/NA Derivation.html#derivation-of-numerical-aperture-for-optical-fibers",
    "href": "geometrical-optics/NA Derivation.html#derivation-of-numerical-aperture-for-optical-fibers",
    "title": "Experimental Physics 3 Course on Optics and Quantum Mechanics",
    "section": "",
    "text": "We start with Snell’s law at the core-cladding interface:\n\\[n_1 \\sin \\theta_1 = n_2 \\sin \\theta_2\\]\nwhere \\(n_1\\) is the core refractive index and \\(n_2\\) is the cladding refractive index.\nFor total internal reflection, the critical angle \\(\\theta_c\\) occurs when \\(\\theta_2 = 90°\\):\n\\[n_1 \\sin \\theta_c = n_2 \\sin 90° = n_2\\]\nThus, we can express the critical angle as:\n\\[\\sin \\theta_c = \\frac{n_2}{n_1}\\]\nIn the fiber, the maximum angle for total internal reflection is \\((90° - \\theta_c)\\):\n\\[\\cos \\theta_c = \\sin(90° - \\theta_c)\\]\nUsing the trigonometric identity \\(\\cos^2 \\theta + \\sin^2 \\theta = 1\\):\n\\[\\cos^2 \\theta_c = 1 - \\sin^2 \\theta_c = 1 - \\left(\\frac{n_2}{n_1}\\right)^2\\]\nAt the air-core interface, we apply Snell’s law again:\n\\[\\sin \\theta_a = n_1 \\sin(90° - \\theta_c) = n_1 \\cos \\theta_c\\]\nSubstituting the result from step 5:\n\\[\\sin \\theta_a = n_1 \\sqrt{1 - \\left(\\frac{n_2}{n_1}\\right)^2} = \\sqrt{n_1^2 - n_2^2}\\]\nThis final result is the Numerical Aperture (NA):\n\\[NA = \\sin \\theta_a = \\sqrt{n_1^2 - n_2^2}\\]\nThis formula relates the maximum acceptance angle \\(\\theta_a\\) to the refractive indices of the core (\\(n_1\\)) and cladding (\\(n_2\\)). It’s a crucial parameter in fiber optics, determining the light-gathering ability and the range of angles over which the fiber can accept or emit light."
  },
  {
    "objectID": "geometrical-optics/Magnifying Glass.html",
    "href": "geometrical-optics/Magnifying Glass.html",
    "title": "Optical Instruments",
    "section": "",
    "text": "Optical instruments now combine a number of optical elements or even consist only out of a single one as in the case of the magnifying glass or the eye.",
    "crumbs": [
      "Geometrical Optics",
      "Lecture 5",
      "Optical Instruments- Magnifying Glass"
    ]
  },
  {
    "objectID": "geometrical-optics/Magnifying Glass.html#magnifying-glass",
    "href": "geometrical-optics/Magnifying Glass.html#magnifying-glass",
    "title": "Optical Instruments",
    "section": "Magnifying Glass",
    "text": "Magnifying Glass\nA magnifying glass has several applications. First of all, it allows to see objects with details that would otherwise be too small to be observed with the eye even of the eye lens can accommodate to the distances. Such magnifying glasses are also used in microscopes as the so-called eye-piece as we will later see in the section on microscopes.\nConsider the sketch below. The sketch shows an object of a size \\(A\\) which is at a distance of \\(s_0\\) from the eye. The object makes an angle \\(\\epsilon_0\\) with the optical axis. If we insert now a lens into the space between object and eye and the lens is positioned in a way that it is exactly at a distance \\(f\\) (the focal distance of the lens) from the object then we are able to observe the object under a different angle \\(\\epsilon\\).\n\n\n\nMagnifying glass at the focal distance.\n\n\nThe magnification of this magnifying glass can the be calculated from the angles \\(\\epsilon\\approx A/f\\) and \\(\\epsilon_0\\approx A/s_0\\):\n\\[\nV=\\frac{\\tan(\\epsilon)}{\\tan(\\epsilon_0)}\\approx \\frac{\\epsilon}{\\epsilon_0}=\\frac{A}{f}\\frac{s_0}{A}=\\frac{s_0}{f}.\n\\]\nThe angular magnification is, thus, just given by the ratio of the clear visual range to the focal distance of the lens. If the focal distance \\(f\\) becomes much smaller than \\(s_0\\), large magnifications are possible.\nA second very useful effect is that when the object is placed inside the focal distance from the lens, the eye images a virtual image at infinite distance to the retina (see sketch). This means the eye muscle can stay relaxed when observing the object, while it would otherwise probably have to accommodate to the distance.\nYet, placing the object at exactly the focal distance is rather tedious when holding the magnifying glass by hand. If the object is now placed inside the focal distance of the magnifying glass, we may also calculate a magnification in this case knowing the virtual image size \\(B\\) created in this case (see sketch below)\n\n\n\nMagnifying glass for an object inside the focal range of the lens.\n\n\nIf \\(a\\) is the distance of the object from the principle plane of the magnifying glass and \\(b\\) and \\(B\\) are the distance and the size of the virtual image, respectively, we obtain\n\\[\nV=\\frac{\\tan(\\epsilon)}{\\tan(\\epsilon_0)}\\approx \\frac{\\epsilon}{\\epsilon_0}=\\frac{B}{b}\\frac{s_0}{A}=\\frac{s_0}{a}.\n\\]\nUsing the imaging equation\n\\[\n\\frac{1}{f}=\\frac{1}{a}+\\frac{1}{b}\n\\]\nwe may finally arrive at\n\\[\nV=\\frac{s_0(b-f)}{b\\,f}\n\\]\nin this case. If we place the virtual image directly at the clear visual range, i.e., \\(b=-s_0\\), we find\n\\[\nV=\\frac{s_0}{f}+1.\n\\]",
    "crumbs": [
      "Geometrical Optics",
      "Lecture 5",
      "Optical Instruments- Magnifying Glass"
    ]
  },
  {
    "objectID": "geometrical-optics/Rainbow.html",
    "href": "geometrical-optics/Rainbow.html",
    "title": "Rainbow",
    "section": "",
    "text": "As the last topic of the optical elements we would like to have a look at a phenomenon, which has nothing to do with optical elements but is fun and just fits to the topic of dispersion. We will explore the rainbow and in addition a DIY version, the glassbow."
  },
  {
    "objectID": "geometrical-optics/Rainbow.html#single-drop-analysis",
    "href": "geometrical-optics/Rainbow.html#single-drop-analysis",
    "title": "Rainbow",
    "section": "Single Drop Analysis",
    "text": "Single Drop Analysis\nTo understand the rainbow we will have first a look at the reflection of rays from a single droplet.\n\n\n\nReflection of rays in a single drop\n\n\nIn the sketch above a light ray of white light is entering the droplet under an angle \\(\\alpha\\) to the surface normal on the top. The ray is refracted and enters the droplet under an angle \\(\\beta\\) to the surface normal. The angle can be calculated from Snell’s law\n\\[n_{\\rm air}\\sin(\\alpha)=n_{\\rm water}\\sin(\\beta).\\]\nInside the droplet, the ray is now hitting the water/air surface at the backside from which it gets reflected. There, the incident angle is also \\(\\beta\\) and the ray is reflected under an angle \\(\\beta\\) as well. At that point, most of the light will, however, exit the drop on the backside, so that only a small fraction is reflected and traveling further to hit a second time the water/air surface at the angle \\(\\beta\\). The light refracted out at that point leaves the droplet under an angle \\(\\alpha\\) with the surface normal due to the reversiblity of the light path. We are, however, interested in the angle \\(\\phi\\) that the ray makes with the incident direction.\nThis angle \\(\\phi\\) can be calculated from the above sketch to be\n\\[\\phi=4\\beta-2\\alpha.\\]\nSince\n\\[\\beta=\\sin^{-1}\\left (\\frac{n_{\\rm air}}{n_{\\rm water}}\\sin(\\alpha) \\right)\\]\nsuch that finally\n\\[\\phi=4\\sin^{-1}\\left (\\frac{n_{\\rm air}}{n_{\\rm water}}\\sin(\\alpha) \\right)-2\\alpha\\]\nSo let us have a look at this dependence of the deflection angle as a function of the incidence angle.\n\n\nCode\nalpha=np.linspace(0,np.pi/2,10000)\nh2o=pd.read_csv(\"data/H2O.csv\",delimiter=\",\")\nn=np.interp(0.500,h2o.wl,h2o.n)\n\ndef rainbow(alpha,n):\n    return(4*np.arcsin(np.sin(alpha)/n)-2*alpha)\n\nplt.figure(figsize=(4,3))\nplt.plot(alpha*180/np.pi,rainbow(alpha,n)*180/np.pi)\nplt.xlabel(r\"incident angle $\\alpha$ [°]\")\nplt.ylabel(r\"deflection angle $\\phi$ [°]\")\nplt.show()\n\n\n\n\n\nDeflection angle of a light ray in a water droplet as a function of the incidence angle. The refractive index of water is taken from the data file H2O.csv.\n\n\n\n\nThe dependence seems to show a maximum deflection angle at an incidence angle of around \\(\\alpha=60^{\\circ}\\). This is an important finding, as the whole appearance of the rainbow depends on that.\n\n\nMaximum deflection angle  41.78815648670841\n\n\n\nColor Formation and Dispersion\nThe color of the rainbow is the result of the fact that the maximum deflection angle depends on the color of the light due to the dispersion. Since we have a refraction, reflection and another refraction, the largest maximum deflection angle is observed for red light, while the smallest one appears for blue light. The diagrams below show this result, which is in general true for materials with normal dispersion.\n\n\nCode\nplt.figure(figsize=(8,4))\nplt.subplot(1,2,1)\nfor wl in np.linspace(0.400,0.700,100):\n    c=wavelength_to_rgb(wl*1000, gamma=0.8)\n    n=np.interp(wl,h2o.wl,h2o.n)\n    plt.plot(alpha*180/np.pi,rainbow(alpha,n)*180/np.pi,c=c,alpha=1,lw=1)\nplt.xlabel(r\"incident angle $\\alpha$ [°]\")\nplt.ylabel(r\"deflection angle $\\phi$ [°]\")\n\nplt.subplot(1,2,2)\nfor wl in np.linspace(0.400,0.700,100):\n    c=wavelength_to_rgb(wl*1000, gamma=0.8)\n    n=np.interp(wl,h2o.wl,h2o.n)\n    plt.plot(alpha*180/np.pi,rainbow(alpha,n)*180/np.pi,c=c,alpha=1,lw=1)\nplt.xlabel(r\"incident angle $\\alpha$ [°]\")\nplt.ylabel(r\"deflection angle $\\phi$ [°]\")\nplt.xlim(45,70)\nplt.ylim(40,43)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\nCaption\n\n\n\n\nThis order of the colors is actually true for all incident angles, which raises the question, why the rainbow is actually colored. The blue color of a certain incidence angle would actually overlap with the green color of a different incidence angle and the red color of an even different incidence angle. If you select a specific outgoing angle under which you observe the rainbow, let us say \\(41^{\\circ}\\), then you find under this observation angle all color and, therefore, should observe always white light.\nThis is actually true if you look at the inside of a rainbow. You clearly recognize that inside the rainbow it is much brighter than outside. Yet when you reach the maximum angle of each color, you have a region, where even for larger angles for the incidence angles, the deflection angle does not change. Thus, if you assume you send in rays at constantly spaced incidence angles, you will have more rays with a deflection angle close to the maximum. The diagram below just counts the number of deflection angles in the different for each color and you clearly see that around the maximum deflection angles for each color you have a strong peak.\n\n\nCode\nplt.figure(figsize=(6,4))\nfor wl in np.linspace(0.400,0.700,4):\n    c=wavelength_to_rgb(wl*1000, gamma=0.8)\n    n=np.interp(wl,h2o.wl,h2o.n)\n    plt.hist(rainbow(alpha,n)*180/np.pi,bins=400,color=c,alpha=0.6,lw=1);\nplt.xlabel(r\"deflection angle $\\alpha$ [°]\")\nplt.ylabel(r\"intensity [a.u.]\")\n\nplt.xlim(30,45)\nplt.ylim(0,150)\nplt.show()\n\n\n\n\n\nHistogram of the deflection angle of light rays in a water droplet for different colors. The refractive index of water is taken from the data file H2O.csv.\n\n\n\n\nThus, around each droplet on the sky, there is a cone of deflected light reflected back from the sun. On the outside of that cone is red light under an angle of almost \\(42^{\\circ}\\) while on the inside edge we find blue light and finally white light (see left image below). We just have to connect that to the observer now. This is shown in the right sketch. The rainbow, therefore, results from the fact that we look at different height at different edges of the cone.\n\n\n\n\n\n\n\n\n\n\n\n(a) Deflection cones\n\n\n\n\n\n\n\n\n\n\n\n(b) Resulting rainbow\n\n\n\n\n\n\n\nFigure 1: Deflection cones of different colors on a single drop in a rainbow (left) and the resulting rainbow as observed from these cones (right).\n\n\n\n\n\nPrimary and Secondary Rainbows\nThe photos below show a remarkable example of both primary and secondary rainbows. Between these two bows, a careful observer will notice a darker region known as Alexander’s dark band, first described by Alexander of Aphrodisias in 200 AD. This dark band occurs because no light is scattered back to the observer at angles between approximately \\(42^{\\circ}\\) (maximum angle of primary rainbow) and \\(50^{\\circ}\\) (minimum angle of secondary rainbow).\n\n\n\nDouble rainbow over Grand Canyon. (Frank Cichos)\n\n\nThe primary rainbow results from one internal reflection within each water droplet, while the secondary rainbow involves two internal reflections. This double reflection explains both the reversed color order and the reduced brightness of the secondary rainbow, as each reflection decreases the light intensity.\n\n\n\nZoom into the Rainbow fotograph showing Alexanders dark band."
  },
  {
    "objectID": "geometrical-optics/Rainbow.html#glassbow",
    "href": "geometrical-optics/Rainbow.html#glassbow",
    "title": "Rainbow",
    "section": "Glassbow",
    "text": "Glassbow\nA beatiful demonstration of rainbow physics can be created at home using glass beads of about \\(200\\, \\mu m\\) diameter (available from our lab). When these beads are placed on a black background and illuminated with a flash lamp, they create what we call a “glassbow” - a rainbow-like pattern produced by glass instead of water droplets.\nThe main difference between a glassbow and a natural rainbow lies in the observation angle, due to the different refractive index of glass (\\(n \\approx 1.5\\)) compared to water (\\(n \\approx 1.33\\)). Using the same deflection angle equation:\n\\[\n\\phi=4\\sin^{-1}\\left (\\frac{n_{\\rm air}}{n_{\\rm glass}}\\sin(\\alpha) \\right)-2\\alpha\n\\]\nwe can calculate why the glassbow appears at a different angle than its atmospheric counterpart.\n\n\n\nA glassbow created by light reflection and refraction in microscopic glass beads on a black surface. (c) Picture by Axel Märcker"
  },
  {
    "objectID": "geometrical-optics/introduction.html",
    "href": "geometrical-optics/introduction.html",
    "title": "Geometrical Optics",
    "section": "",
    "text": "In this section, we will explore the fundamental principles that govern how light behaves when it encounters different media and surfaces.",
    "crumbs": [
      "Geometrical Optics",
      "Introduction"
    ]
  },
  {
    "objectID": "geometrical-optics/introduction.html#learning-objectives",
    "href": "geometrical-optics/introduction.html#learning-objectives",
    "title": "Geometrical Optics",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nBy the end of this section, you should be able to:\n\nUnderstand and apply the laws of reflection and refraction.\nAnalyze image formation by mirrors, lenses, and prisms.\nDescribe the working principles of various optical instruments.\nExplain phenomena such as dispersion and imaging errors.",
    "crumbs": [
      "Geometrical Optics",
      "Introduction"
    ]
  },
  {
    "objectID": "geometrical-optics/introduction.html#topics-covered",
    "href": "geometrical-optics/introduction.html#topics-covered",
    "title": "Geometrical Optics",
    "section": "Topics Covered",
    "text": "Topics Covered\n\nReflection Explore how light reflects off surfaces following the law of reflection.\nRefraction and Total Internal Reflection Understand how light bends when passing through different media and the conditions for total internal reflection.\nMirrors,Prisms and Lenses  Learn about various optical elements and how they form images.\nOptical Instruments Study devices like telescopes and microscopes that utilize mirrors and lenses.\nDispersion Discover how different wavelengths of light refract differently, leading to phenomena like rainbows.\nImaging Errors Examine common aberrations in optical systems and methods to correct them.",
    "crumbs": [
      "Geometrical Optics",
      "Introduction"
    ]
  },
  {
    "objectID": "geometrical-optics/introduction.html#introduction",
    "href": "geometrical-optics/introduction.html#introduction",
    "title": "Geometrical Optics",
    "section": "Introduction",
    "text": "Introduction\nGeometrical optics is an approximate description of light propagation in the limit of infinitely small wavelength, where all wave phenomena like diffraction can be neglected.\n\n\n\nLight rays passing through a lens system generated with Tantalum\n\n\nLight interacts with materials in predictable ways, allowing us to design optical systems for imaging, magnification, and more.",
    "crumbs": [
      "Geometrical Optics",
      "Introduction"
    ]
  },
  {
    "objectID": "geometrical-optics/introduction.html#assumptions-of-geometrical-optics",
    "href": "geometrical-optics/introduction.html#assumptions-of-geometrical-optics",
    "title": "Geometrical Optics",
    "section": "Assumptions of Geometrical Optics",
    "text": "Assumptions of Geometrical Optics\nGeometrical optics provides an approximate description of light behavior and is based on several key assumptions. These assumptions simplify the complex nature of light while still allowing for accurate predictions in many practical scenarios.\n\n\n\n\n\n\nCore Assumptions\n\n\n\n\nLight Sources and Detection:\n\nLight rays emerge from a light source\nLight rays are detected by a detector\n\nLight-Matter Interaction:\n\nInteraction is characterized by a refractive index \\(n\\)\nThe speed of light in a medium is given by \\(c=c_0/n\\), where \\(c_0\\) is the speed of light in vacuum\nThe speed in vacuum is 299.792.458 m/s and is connected to the definition of the meter\n\nLight Propagation:\n\nLight propagates in straight line paths (rays) in a homogeneous medium\nLight bends to a curved path in inhomogeneous media with varying refractive index \\(n(\\textbf{r})\\)\n\nBehavior at Interfaces:\n\nRays may be reflected and refracted at interfaces between media\n\n\nThese assumptions form the foundation for understanding and predicting light behavior in the context of geometrical optics.",
    "crumbs": [
      "Geometrical Optics",
      "Introduction"
    ]
  },
  {
    "objectID": "geometrical-optics/Lens Systems and Optical Instruments.html",
    "href": "geometrical-optics/Lens Systems and Optical Instruments.html",
    "title": "Lens Systems and Optical Instruments",
    "section": "",
    "text": "Lens Systems\nMost of the optical instruments consist of multiple lenses that are used to image objects or to magnify them. They are combined at distances, which are either larger or smaller than the sum of their focal distances. The image below shows for example an artifical image of a lens system contained in a single microscope objctive lens, where you see multiple elements e.g. doublets and triplets of lenses. These elements as joined objects may considerably improve the performance of the optics, e.g. correct for imaging errors.\n\n\n\n\n\n\n\n\nFig.: System of of lenses inside a microscope objective lens.\n\n\n\nWe will consider first a pair of two bi-convex lenses that are at a distance \\(D&gt;f_1+f_2\\)m where \\(f_1\\) and \\(f_2\\) are their focal distances.\n\n\n\n\n\n\n\n\n\n\n\nFig.: System of two bi-convex lenses at a distance larger than the sum of their focal distances.\n\n\n\nHere the first lens creates an image at a position\n\\[b_1=\\frac{a_1 f_1}{(a_1-f_1)}\\]\nAccordingly the object distance for lens 2 is then \\(a_2=D-b_1\\).\nThe second lens then images this intermediate object into\n\\[b_2=\\frac{a_2 f_2}{a_2-f_2}=\\frac{(D-b_1) f_2}{D-b_1-f_2}\\]\nfrom which we can finally calculate the image location and also size with the help of \\(b_1\\).\nInstead of doing a lengthy transformation I would like to draw your attention to a simple method which arises from the linearization of Snells law. This is called matrix optics. Matrix optics relates the outgoing angle \\(\\theta_2\\) and height \\(y_2\\) of an optical element to its incident angle \\(\\theta_1\\) and \\(y_1\\) via a matrix operation. Let’s have a look at an example of a bi-convex lens with a focal length \\(f\\). An incident ray is then expressed by a vector\n\\[\\begin{bmatrix}\ny_1\\\\\n\\theta_1\n\\end{bmatrix}\\]\nwhich is converted by the lens into an outgoing ray vector\n\\[\\begin{bmatrix}\ny_2\\\\\n\\theta_2\n\\end{bmatrix}\\]\nIf you have two 2D vectors which you want to transform by a linear operation into each other, then the transformation can be described by a 2x2 matrix, which is given for a lens with\n\\[\\begin{bmatrix}\nA & B\\\\\nC & D\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n1 & 0\\\\\n-\\frac{1}{f} & 1\n\\end{bmatrix}\n\\]\nSimilarly we can also define a free space propagation matrix for a propagation by a distance \\(D\\), which is\n\\[\\begin{bmatrix}\nA & B\\\\\nC & D\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n1 & D\\\\\n0 & 1\n\\end{bmatrix}\n\\]\nThe propagation of light through two lenses, which are seprarated by a distance \\(D\\) is then the product of two matrices for the lenses and one for the free space. The transformation then in addition requires to multiply from the right side the incdent vector and we obtain on the left side the outgoing ray vector.\n\\[\\begin{bmatrix}\ny_2\\\\\n\\theta_2\\\\\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n1 & 0\\\\\n-\\frac{1}{f_2} & 1 \\\\\n\\end{bmatrix}\n\\begin{bmatrix}\n1 & D\\\\\n0 & 1\n\\end{bmatrix}\n\\begin{bmatrix}\n1 & 0\\\\\n-\\frac{1}{f_1} & 1\n\\end{bmatrix}\n\\begin{bmatrix}\ny_1\\\\\n\\theta_1\n\\end{bmatrix}\\]\nIf you multiply the 2x2 matrices with each other, you will obtain a new 2x2 matrix with a matrix element \\(C\\), which should correspond to the effective focal length of that system. This is the case since the element \\(C=-\\frac{1}{f}\\)\nThe result of that calculation is\n\\[\\frac{1}{f}=\\frac{1}{f_1}+\\frac{1}{f_2}-\\frac{D}{f_1 f_2}\\]\nwhich gives the effective focal length of two bi-convex lenses at a distance \\(D\\).\nFollowing this equation the inverse of the total focal length of the combined lenses is just the sum of its inverse focal distances minus a term, which depends on the distance of the two lenses. If this distance is small as compared to the focal length, i.e. the lenses are close to each other, the total inverse focal is just given by the first two terms. The inverse focal distances characterize the refractive power of a lens. The larger the invserse value, the smaller is the focal distance. This refractive power is commonly measured in the unit diopter. One diopter corresponds to 1 dpt=1 \\(m^{-1}\\).\nThe image above shows also, that in the case of the combined lenses and a real inverted intermediate image, the final image will be upright again. Thus, if the first lens has a magnification \\(M_1=-b_1/a_1\\) and the second lens a magnification \\(M_2=-b_2/a_2\\) the total magnification is the product, which is\n\\[M=\\frac{b_1}{a_1}\\frac{b_2}{a_2}\\]\nfrom which we may finally obtain with \\(M=\\frac{f}{f-a}\\)\n\\[M=\\frac{1}{1-\\frac{a_1}{f_1}-\\frac{a_1+D}{f_2}+\\frac{a_1D}{f_1 f_2}}\\]\nFor more than two lenses, there is a versatile framework called Matrix Optics, which treats each optical element as a 2x2 matrix. This becomes possible as we derived earlier equations which were linear in \\(y\\) and \\(\\theta\\). A whole system of different lenses, plates and other optical elements can thus be treated as a matrix multiplication, which is quite useful."
  },
  {
    "objectID": "geometrical-optics/Microscope.html",
    "href": "geometrical-optics/Microscope.html",
    "title": "Optical Instruments",
    "section": "",
    "text": "Historical Context of Microscope Development\n\n\n\n\n\nOptical Microscopy has a rich history of development, and is a very important tool in the fields of biology, materials science, and nanotechnology. Here are some key milestones in the history of microscopy:\nAncient Times - 13th Century: Simple magnifying glasses - The concept of magnification was known to ancient civilizations. - In the 13th century, Italian craftsmen created the first wearable glasses.\n1590: Compound Microscope - Hans and Zacharias Janssen, Dutch spectacle makers, created the first compound microscope.\n1665: Robert Hooke’s “Micrographia” - Hooke published detailed observations made with his improved compound microscope. - He coined the term “cell” after observing cork tissue.\n1670s: Antonie van Leeuwenhoek’s Single-Lens Microscopes - Developed high-quality single-lens microscopes with up to 270x magnification. - First to observe and describe bacteria, yeast, and other microorganisms.\n\n\n\nImage of Leeuwenhoek’s microscope\n\n\n18th-19th Centuries: Achromatic Lenses - Joseph Jackson Lister developed achromatic lenses, reducing chromatic aberration.\n1830s: Ernst Abbe’s Theoretical Work - Formulated the Abbe Sine Condition, crucial for modern lens design.\nLate 19th Century: Oil Immersion Lenses - Allowed for higher resolution in light microscopy.\n1931: Electron Microscope - Ernst Ruska and Max Knoll developed the first electron microscope.\n1950s-1960s: Phase Contrast and Fluorescence Microscopy - Frits Zernike invented phase contrast microscopy. - Development of fluorescence microscopy techniques.\n1981: Scanning Tunneling Microscope - Gerd Binnig and Heinrich Rohrer invented the STM, allowing imaging at the atomic level.\n1980s-Present: Digital and Computational Microscopy - Integration of CCD cameras and digital imaging. - Development of confocal microscopy, super-resolution techniques, and computational methods like ptychography.\n\n\n\nIn this section we will analyze the optical properties of microscopes from the perspective of geometrical optics which explains image formation. Yet, the key to the performance of a microscope is the understanding provided by wave optics. We will discuss this in a later section. The simplest form of a microscope consists of an objective lens with a focal distance \\(f_1\\) and a magnifying glass called eye-piece with a focal length \\(f_2\\). In this system of two lenses (which are itself systems of lenses in modern microscopes, see below),\n\n\n\nFig.: Cut through a microscope objective lens (left) and an eye-piece.\n\n\nthe object is placed at a distance \\(f_1&lt; a_1&lt;2f_1\\) from the objective lens creating a real and reversed image at a distance \\(b_1\\) behind the lens. This reversed image is observed by the eye through the eye-piece. The image of the objective lens is thereby adjusted to appear at the focal distance of the eye-piece.\n\n\n\nFig.: Sketch of a simple microscope. The strange object on the right is an eye.\n\n\nFor this simple microscope system we may calculate first the intermediate image position \\(b_1\\):\n\\[\n\\frac{1}{f_1}=\\frac{1}{a_1}+\\frac{1}{b_1}\n\\]\nresulting in\n\\[\nb_1=\\frac{a_1 f_1}{a_1-f_1}.\n\\]\nIf we assume a \\(\\delta\\) to be the distance of the object from the focal point of the objective lens, we even find for \\(\\delta \\rightarrow 0\\)\n\\[\nb_1=\\frac{a_1 f_1}{\\delta}.\n\\]\nThe intermediate image of size \\(B_1\\) is now imaged by a magnifying glass of focal distance \\(f_2\\). According to what we calculated earlier, we have now the observation angle\n\\[\n\\tan(\\epsilon)=\\frac{B_1}{f_2}=\\frac{Ab_1}{a_1 f_2}.\n\\]\nIf we observe the object of a size \\(A\\) and the clear visual distance \\(s_0\\), it would cover an angle of\n\\[\n\\tan(\\epsilon_0)=\\frac{A}{s_0}\n\\]\nand we may obtain the total angular magnification\n\\[\nV=\\frac{A b_1 s_0}{A a_1 f_2}=\\frac{b_1 s_0}{a_1 f_2}.\n\\]\nIf we set the distance between the two lenses to \\(D=b_1+f_2\\) and \\(a_1\\approx f_1\\) then we obtain\n\\[\nV=\\frac{(D-f_2)s_0}{f_1 f_2}\n\\]\nwhich says that the magnification is the result of the two focal length \\(f_1,f_2\\).\n\n\nWhile the description above accurately represents the simplest microscope design, contemporary microscopes employ more intricate light paths and generally utilize what is known as infinity corrected optics. This system incorporates an objective lens that projects images of objects in the focal plane to infinity. Such an objective lens is invariably paired with a secondary lens, called the tube lens. Together, these lenses are engineered to provide a magnification level that is specified on the objective lens housing.\n\n\n\nFig.: Infinity optics vs. normal microscopy optics.\n\n\nInfinity optics allows you to have a free length with a parallel optical path where you can insert optical elements. There is no fixed tube length as in the case sketched above, where the distance of the intermediate image has to be considered. Therefore, it has tremendous technical advantages. Common optical microscopes are further today coupled to CCD cameras to record images digitally. Yet, an eye-piece may still be available in many cases. The sketch below shows the light path for a simple fluorescence microscope recording fluorescence images with a camera.\n\n\n\nFig.: Simple fluorescence microscope.\n\n\n\n\n\nThe possibility to digitally record images creates endless possibilities to computationally enhance and combine images. Nowadays the field of optics is one of the fastest developing fields in physics with numerous new techniques appearing every week. In this field of imaging methods of machine learning also play an increasingly important role. While I’m not ablields in physics with numerous new techniques appearing every week. In this field of imaging methods of machine learning also play an increasingly important role. While I am not able to refer to all possible optical microscopy techniques he to refer to all possible optical microscopy techniques here, I will exemplarily show some data from the Waller group at Berkley using computational methods to enhance the resolution by keeping at the same time a large field of view for imaging. This technique is called ptychography and can be understood if you consider Fourier Optics (a field of optics describing ligh propagation in terms Fourier transforms).\n\n\n\nFig.: Ptychographic imaging with LED arrays.\n\n\nThere is a massive amount of other techniques with increadible images being generated. Have a look around.\n\n\n\n\n\n\nAdvanced Microscopy Techniques\n\n\n\n\n\nWhile traditional light microscopy has been invaluable, it’s limited by the diffraction of light, restricting resolution to about 200 nm as will be discussed in a later part of this course. Modern techniques have pushed beyond this limit, revolutionizing our ability to visualize microscopic structures.\n\n\n\nSuper resolution Imaging Methods Overview (Schermelleh, L. et al. Super-resolution microscopy demystified. Nat. Cell Biol. 21, 72–84 (2019))\n\n\n\n\nConfocal microscopy uses point illumination and a pinhole in an optically conjugate plane in front of the detector to eliminate out-of-focus signal.\n\n\n\nConfocal Microscope.\n\n\n\nKey Features:\n\nImproved optical resolution and contrast\nAbility to collect serial optical sections from thick specimens\nWidely used in biological sciences\n\nOvercoming Limitations:\n\nEliminates background information away from the focal plane\nAllows for 3D reconstruction of samples\n\n\n\n\n\nSuper-resolution techniques bypass the diffraction limit, achieving resolutions down to tens of nanometers.\n\nStimulated Emission Depletion (STED) Microscopy\n\nUses two laser beams: one to excite fluorescent molecules, another to suppress fluorescence around the excitation spot\nOvercoming Limitations: Achieves resolution as fine as 20-50 nm by precisely controlling which fluorophores are allowed to fluoresce\n\nPhotoactivated Localization Microscopy (PALM)\n\nRelies on selective activation and sampling of sparse subsets of photoactivatable fluorescent molecules\nOvercoming Limitations: Locates individual molecules with nanometer precision by isolating their signals over time\n\nStochastic Optical Reconstruction Microscopy (STORM)\n\nSimilar to PALM, but uses photoswitchable fluorophores\nOvercoming Limitations: Achieves resolutions of ~20 nm by precisely locating the centers of single fluorescent molecules\n\nStructured Illumination Microscopy (SIM)\n\nUses patterned illumination to create moiré fringes, which are computationally processed to reconstruct super-resolution images\nOvercoming Limitations: Doubles the resolution of traditional light microscopy to ~100 nm\n\nSuperresolution Photothermal Infrared Imaging\n\nSuperresolution photothermal infrared imaging is a novel technique that brings the advantages of superresolution microscopy to the infrared regime.\nOvercoming Limitations: Achieves resolutions of ~300 nm for infrared imaging at wavelength of 10 µm by using photothermal lensing effects.",
    "crumbs": [
      "Geometrical Optics",
      "Lecture 5",
      "Optical Instruments- Microscope"
    ]
  },
  {
    "objectID": "geometrical-optics/Microscope.html#microscope",
    "href": "geometrical-optics/Microscope.html#microscope",
    "title": "Optical Instruments",
    "section": "",
    "text": "Historical Context of Microscope Development\n\n\n\n\n\nOptical Microscopy has a rich history of development, and is a very important tool in the fields of biology, materials science, and nanotechnology. Here are some key milestones in the history of microscopy:\nAncient Times - 13th Century: Simple magnifying glasses - The concept of magnification was known to ancient civilizations. - In the 13th century, Italian craftsmen created the first wearable glasses.\n1590: Compound Microscope - Hans and Zacharias Janssen, Dutch spectacle makers, created the first compound microscope.\n1665: Robert Hooke’s “Micrographia” - Hooke published detailed observations made with his improved compound microscope. - He coined the term “cell” after observing cork tissue.\n1670s: Antonie van Leeuwenhoek’s Single-Lens Microscopes - Developed high-quality single-lens microscopes with up to 270x magnification. - First to observe and describe bacteria, yeast, and other microorganisms.\n\n\n\nImage of Leeuwenhoek’s microscope\n\n\n18th-19th Centuries: Achromatic Lenses - Joseph Jackson Lister developed achromatic lenses, reducing chromatic aberration.\n1830s: Ernst Abbe’s Theoretical Work - Formulated the Abbe Sine Condition, crucial for modern lens design.\nLate 19th Century: Oil Immersion Lenses - Allowed for higher resolution in light microscopy.\n1931: Electron Microscope - Ernst Ruska and Max Knoll developed the first electron microscope.\n1950s-1960s: Phase Contrast and Fluorescence Microscopy - Frits Zernike invented phase contrast microscopy. - Development of fluorescence microscopy techniques.\n1981: Scanning Tunneling Microscope - Gerd Binnig and Heinrich Rohrer invented the STM, allowing imaging at the atomic level.\n1980s-Present: Digital and Computational Microscopy - Integration of CCD cameras and digital imaging. - Development of confocal microscopy, super-resolution techniques, and computational methods like ptychography.\n\n\n\nIn this section we will analyze the optical properties of microscopes from the perspective of geometrical optics which explains image formation. Yet, the key to the performance of a microscope is the understanding provided by wave optics. We will discuss this in a later section. The simplest form of a microscope consists of an objective lens with a focal distance \\(f_1\\) and a magnifying glass called eye-piece with a focal length \\(f_2\\). In this system of two lenses (which are itself systems of lenses in modern microscopes, see below),\n\n\n\nFig.: Cut through a microscope objective lens (left) and an eye-piece.\n\n\nthe object is placed at a distance \\(f_1&lt; a_1&lt;2f_1\\) from the objective lens creating a real and reversed image at a distance \\(b_1\\) behind the lens. This reversed image is observed by the eye through the eye-piece. The image of the objective lens is thereby adjusted to appear at the focal distance of the eye-piece.\n\n\n\nFig.: Sketch of a simple microscope. The strange object on the right is an eye.\n\n\nFor this simple microscope system we may calculate first the intermediate image position \\(b_1\\):\n\\[\n\\frac{1}{f_1}=\\frac{1}{a_1}+\\frac{1}{b_1}\n\\]\nresulting in\n\\[\nb_1=\\frac{a_1 f_1}{a_1-f_1}.\n\\]\nIf we assume a \\(\\delta\\) to be the distance of the object from the focal point of the objective lens, we even find for \\(\\delta \\rightarrow 0\\)\n\\[\nb_1=\\frac{a_1 f_1}{\\delta}.\n\\]\nThe intermediate image of size \\(B_1\\) is now imaged by a magnifying glass of focal distance \\(f_2\\). According to what we calculated earlier, we have now the observation angle\n\\[\n\\tan(\\epsilon)=\\frac{B_1}{f_2}=\\frac{Ab_1}{a_1 f_2}.\n\\]\nIf we observe the object of a size \\(A\\) and the clear visual distance \\(s_0\\), it would cover an angle of\n\\[\n\\tan(\\epsilon_0)=\\frac{A}{s_0}\n\\]\nand we may obtain the total angular magnification\n\\[\nV=\\frac{A b_1 s_0}{A a_1 f_2}=\\frac{b_1 s_0}{a_1 f_2}.\n\\]\nIf we set the distance between the two lenses to \\(D=b_1+f_2\\) and \\(a_1\\approx f_1\\) then we obtain\n\\[\nV=\\frac{(D-f_2)s_0}{f_1 f_2}\n\\]\nwhich says that the magnification is the result of the two focal length \\(f_1,f_2\\).\n\n\nWhile the description above accurately represents the simplest microscope design, contemporary microscopes employ more intricate light paths and generally utilize what is known as infinity corrected optics. This system incorporates an objective lens that projects images of objects in the focal plane to infinity. Such an objective lens is invariably paired with a secondary lens, called the tube lens. Together, these lenses are engineered to provide a magnification level that is specified on the objective lens housing.\n\n\n\nFig.: Infinity optics vs. normal microscopy optics.\n\n\nInfinity optics allows you to have a free length with a parallel optical path where you can insert optical elements. There is no fixed tube length as in the case sketched above, where the distance of the intermediate image has to be considered. Therefore, it has tremendous technical advantages. Common optical microscopes are further today coupled to CCD cameras to record images digitally. Yet, an eye-piece may still be available in many cases. The sketch below shows the light path for a simple fluorescence microscope recording fluorescence images with a camera.\n\n\n\nFig.: Simple fluorescence microscope.\n\n\n\n\n\nThe possibility to digitally record images creates endless possibilities to computationally enhance and combine images. Nowadays the field of optics is one of the fastest developing fields in physics with numerous new techniques appearing every week. In this field of imaging methods of machine learning also play an increasingly important role. While I’m not ablields in physics with numerous new techniques appearing every week. In this field of imaging methods of machine learning also play an increasingly important role. While I am not able to refer to all possible optical microscopy techniques he to refer to all possible optical microscopy techniques here, I will exemplarily show some data from the Waller group at Berkley using computational methods to enhance the resolution by keeping at the same time a large field of view for imaging. This technique is called ptychography and can be understood if you consider Fourier Optics (a field of optics describing ligh propagation in terms Fourier transforms).\n\n\n\nFig.: Ptychographic imaging with LED arrays.\n\n\nThere is a massive amount of other techniques with increadible images being generated. Have a look around.\n\n\n\n\n\n\nAdvanced Microscopy Techniques\n\n\n\n\n\nWhile traditional light microscopy has been invaluable, it’s limited by the diffraction of light, restricting resolution to about 200 nm as will be discussed in a later part of this course. Modern techniques have pushed beyond this limit, revolutionizing our ability to visualize microscopic structures.\n\n\n\nSuper resolution Imaging Methods Overview (Schermelleh, L. et al. Super-resolution microscopy demystified. Nat. Cell Biol. 21, 72–84 (2019))\n\n\n\n\nConfocal microscopy uses point illumination and a pinhole in an optically conjugate plane in front of the detector to eliminate out-of-focus signal.\n\n\n\nConfocal Microscope.\n\n\n\nKey Features:\n\nImproved optical resolution and contrast\nAbility to collect serial optical sections from thick specimens\nWidely used in biological sciences\n\nOvercoming Limitations:\n\nEliminates background information away from the focal plane\nAllows for 3D reconstruction of samples\n\n\n\n\n\nSuper-resolution techniques bypass the diffraction limit, achieving resolutions down to tens of nanometers.\n\nStimulated Emission Depletion (STED) Microscopy\n\nUses two laser beams: one to excite fluorescent molecules, another to suppress fluorescence around the excitation spot\nOvercoming Limitations: Achieves resolution as fine as 20-50 nm by precisely controlling which fluorophores are allowed to fluoresce\n\nPhotoactivated Localization Microscopy (PALM)\n\nRelies on selective activation and sampling of sparse subsets of photoactivatable fluorescent molecules\nOvercoming Limitations: Locates individual molecules with nanometer precision by isolating their signals over time\n\nStochastic Optical Reconstruction Microscopy (STORM)\n\nSimilar to PALM, but uses photoswitchable fluorophores\nOvercoming Limitations: Achieves resolutions of ~20 nm by precisely locating the centers of single fluorescent molecules\n\nStructured Illumination Microscopy (SIM)\n\nUses patterned illumination to create moiré fringes, which are computationally processed to reconstruct super-resolution images\nOvercoming Limitations: Doubles the resolution of traditional light microscopy to ~100 nm\n\nSuperresolution Photothermal Infrared Imaging\n\nSuperresolution photothermal infrared imaging is a novel technique that brings the advantages of superresolution microscopy to the infrared regime.\nOvercoming Limitations: Achieves resolutions of ~300 nm for infrared imaging at wavelength of 10 µm by using photothermal lensing effects.",
    "crumbs": [
      "Geometrical Optics",
      "Lecture 5",
      "Optical Instruments- Microscope"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "test.html",
    "href": "test.html",
    "title": "Proof that a Mirror Must Have a Parabolic Shape",
    "section": "",
    "text": "We would like to show in the following, that a parabolic mirror is a shape which reflects all light rays parallel to the principal axis to a single point, the focus. This is a fundamental property of parabolic mirrors and is used in many optical systems, such as telescopes, satellite dishes, and car headlights.\nFor this purpose, we would like to use Fermat’s principle. We examine a light ray originating from a point \\(x,y_0\\) and travelling parallel to the principal axis. The light ray is reflected at a point \\((x,y)\\) on the mirror and travels to the focus at \\((0,p)\\). The light path is therefore consisting out of two linear segments \\(A\\) and \\(B\\) for which we have to calculate the time of travel. The total duration of the light’s journey is then: \\[\nt = t_A + t_B\n\\]\nwhere:\n\n\\(t_A\\) is the time taken to travel from \\(x,y_0\\) to the mirror.\n\\(t_B\\) is the time taken to travel from \\((x,y)\\) to \\((0,p)\\).\n\n\nTime for Path A\nThe distance covered in path A is equal to \\(y_0 - y\\), where \\(y\\) represents the y-coordinate of the point where the ray meets the mirror. Consequently, the time taken for the light to traverse path A can be expressed as:\n\\[\nt_A = \\frac{y_0 - y}{c}\n\\]\nIn this equation, \\(c\\) represents the speed of light in the medium.\n\n\nTime for Path B\nAfter reflection, the light ray travels from the point \\((x, y)\\) on the mirror’s surface to the focal point located at \\((0, p)\\). The length of this segment of the path can be calculated using the distance formula:\n\\[\n\\sqrt{x^2 + (y - p)^2}\n\\]\nConsequently, the time required for the light to traverse path B is expressed as:\n\\[\nt_B = \\frac{\\sqrt{x^2 + (y - p)^2}}{c}\n\\]\n\n\nTotal Time\nThe total time for the light ray’s journey is the sum of times for paths A and B:\n\\[\nt = \\frac{y_0 - y}{v} + \\frac{\\sqrt{x^2 + (y - p)^2}}{c}\n\\]\nAccording to Fermat’s principle, all light rays should take the same time. We can express this by setting the total time equal to a constant \\(t_c\\):\n\\[\n\\frac{y_0 - y}{v} + \\frac{\\sqrt{x^2 + (y - p)^2}}{v} = t_c\n\\]\nFor a ray traveling along the y-axis, reflecting at \\((0, 0)\\), the total distance is \\(y_0 + p\\). The time for this ray is:\n\\[\n\\frac{y_0 + p}{c}\n\\]\nThis gives us \\(t_c = \\frac{y_0 + p}{c}\\). Substituting into our general equation:\n\\[\n\\frac{y_0 - y}{v} + \\frac{\\sqrt{x^2 + (y - p)^2}}{c} = \\frac{y_0 + p}{c}\n\\]\nMultiplying by \\(c\\) and rearranging:\n\\[\ny_0 - y + \\sqrt{x^2 + (y - p)^2} = y_0 + p\n\\]\n\\[\n\\sqrt{x^2 + (y - p)^2} = y + p\n\\]\nSquaring both sides and simplifying:\n\\[\nx^2 + (y - p)^2 = (y + p)^2\n\\]\n\\[\nx^2 + y^2 - 2py + p^2 = y^2 + 2py + p^2\n\\]\n\\[\nx^2 = 4py\n\\]\nor\n\\[\ny=\\frac{1}{4p}x^2\n\\]\nThis final equation describes a parabola with its focus at \\((0, p)\\).\nMatrix Representation For a thin lens of focal length f, the matrix is:\n\\[M_{thin} = \\begin{bmatrix} 1 & 0 \\\\ -1/f & 1 \\end{bmatrix}\\]\nEquivalent Thin Lens: We want our thick lens matrix to be equivalent to a thin lens sandwiched between two translations:\n\\[\\begin{bmatrix} 1 & -H' \\\\ 0 & 1 \\end{bmatrix}\n   \\begin{bmatrix} 1 & 0 \\\\ -1/f & 1 \\end{bmatrix}\n   \\begin{bmatrix} 1 & H \\\\ 0 & 1 \\end{bmatrix}\n   = \\begin{bmatrix} A & B \\\\ C & D \\end{bmatrix}\\]"
  },
  {
    "objectID": "electromagnetic-waves/index.html",
    "href": "electromagnetic-waves/index.html",
    "title": "EXP3 Quarto",
    "section": "",
    "text": "This is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites."
  }
]